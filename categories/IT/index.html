<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: IT - SBR Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SBR Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SBR Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="SBR Blog"><meta property="og:url" content="https://songbaoru.github.io/"><meta property="og:site_name" content="SBR Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://songbaoru.github.io/img/og_image.png"><meta property="article:author" content="SBR"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://songbaoru.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://songbaoru.github.io"},"headline":"SBR Blog","image":["https://songbaoru.github.io/img/og_image.png"],"author":{"@type":"Person","name":"SBR"},"publisher":{"@type":"Organization","name":"SBR Blog","logo":{"@type":"ImageObject","url":"https://songbaoru.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="SBR Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">IT</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-24T08:13:44.000Z" title="2023/5/24 16:13:44">2023-05-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-05-30T07:40:23.273Z" title="2023/5/30 15:40:23">2023-05-30</time></span><span class="level-item"><a class="link-muted" href="/categories/IT/">IT</a></span><span class="level-item">an hour read (About 8715 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/24/RocketMQ/">RocketMQ</a></p><div class="content"><h1 id="RocketMQ简介"><a href="#RocketMQ简介" class="headerlink" title="RocketMQ简介"></a>RocketMQ简介</h1><p>RocketMQ是一款由Alibaba研发的分布式的消息中间件。支持事务消息、顺序消息、延时消息、定时消息、批量消息。</p>
<p>Apache RocketMQ 中消息的生命周期主要分为消息生产、消息存储、消息消费这三部分。生产者生产消息并发送至 Apache RocketMQ 服务端（Broker），消息被存储在Broker的主题（Topic）中，消费者通过订阅主题消费消息。</p>
<h1 id="消息中间件的应用场景"><a href="#消息中间件的应用场景" class="headerlink" title="消息中间件的应用场景"></a>消息中间件的应用场景</h1><p>消息中间件常用于分布式系统中的应用解耦、流量削峰填谷、异步处理等场景。比如，再秒杀业务中，在秒杀业务中下单后可以发送延迟消息，若5分钟未支付，就取消订单、回滚库存。</p>
<p>消息队列的应用场景：</p>
<ol>
<li>应用解耦：系统的耦合度越高，容错性就越低。在等待系统恢复正常的时间里，要处理的数据可以被缓存到消息队列中。</li>
<li>流量削峰填谷：消息到加入消息队列而不是直接发给消费者，消费者按照自己的消费速度从消息队列获取消息进行处理。</li>
<li>异步处理：不需要同步处理完成后才能响应，由消息队列缓存消息后续通知消息接收方进行异步处理，提高了响应效率。</li>
</ol>
<h1 id="模型概念"><a href="#模型概念" class="headerlink" title="模型概念"></a>模型概念</h1><h2 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h2><ul>
<li><p>Broker</p>
<p>Broker是Apache RocketMQ的服务端，生产者生产的消息会发送到 Broker，并存储在Broker的主题（Topic）中。</p>
</li>
<li><p>NameServer</p>
<p>NameServer是Broker注册中心，支持Broker的注册和发现、Topic路由、Broker心跳检测。</p>
<p>NameServer通常采用集群的方式部署，各实例间互相不进行通信，Broker会向每一台NameServer注册，所以每一个NameServer都保存一份完整的路由信息，当某个NameServer下线了，Broker依然可以向其它的NameServer注册。</p>
</li>
</ul>
<h2 id="消息生产"><a href="#消息生产" class="headerlink" title="消息生产"></a><strong>消息生产</strong></h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/domainModel/04producer">生产者（Producer）</a>：</p>
<p>Apache RocketMQ 中用于产生消息的运行实体，一般集成于业务调用链路的上游。生产者是轻量级匿名无身份的。</p>
</li>
</ul>
<h2 id="消息存储"><a href="#消息存储" class="headerlink" title="消息存储"></a><strong>消息存储</strong></h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/domainModel/02topic">主题（Topic）</a>：</p>
<p>Apache RocketMQ 消息传输和存储的分组容器，主题内部由多个队列组成，消息的存储和水平扩展实际是通过主题内的队列实现的。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/domainModel/03messagequeue">队列（MessageQueue）</a>：</p>
<p>Apache RocketMQ 消息传输和存储的实际单元容器，类比于其他消息队列中的分区。 Apache RocketMQ 通过流式特性的无限队列结构来存储消息，消息在队列内具备顺序性存储特征。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/domainModel/04message">消息（Message）</a>：</p>
<p>Apache RocketMQ 的最小传输单元。消息具备不可变性，在初始化发送和完成存储后即不可变。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/docs/introduction/02concepts#messagetype">队列类型（MessageType）</a>：</p>
<p>由用于类型管理和安全验证的消息传输特性定义的类别。Apache RocketMQ支持NORMAL、FIFO、TRANSACTION和DELAY消息类型。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/docs/introduction/02concepts#messageview">消息视图（MessageView）</a>：</p>
<p>从开发的角度来看，MessageView 是消息的只读接口。消息视图允许读取消息中的多个属性和负载信息，但不能对消息本身进行任何更改。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/docs/introduction/02concepts#messagetag">消息标签（MessageTag）</a>：</p>
<p>MessageTag是一个细粒度的消息分类属性，允许在主题级别以下对消息进行细分。消费者通过订阅特定标签来实现消息过滤。</p>
</li>
</ul>
<h2 id="消息消费"><a href="#消息消费" class="headerlink" title="消息消费"></a><strong>消息消费</strong></h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/domainModel/07consumergroup">消费者分组（ConsumerGroup）</a>：</p>
<p>Apache RocketMQ 发布订阅模型中定义的独立的消费身份分组，用于统一管理底层运行的多个消费者（Consumer）。同一个消费组的多个消费者必须保持消费逻辑和配置一致，共同分担该消费组订阅的消息，实现消费能力的水平扩展。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/domainModel/08consumer">消费者（Consumer）</a>：</p>
<p>Apache RocketMQ 消费消息的运行实体，一般集成在业务调用链路的下游。消费者必须被指定到某一个消费组中。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/domainModel/09subscription">订阅关系（Subscription）</a>：</p>
<p>Apache RocketMQ 发布订阅模型中消息过滤、重试、消费进度的规则配置。订阅关系以消费组粒度进行管理，消费组通过定义订阅关系控制指定消费组下的消费者如何实现消息过滤、消费重试及消费进度恢复等。</p>
<p>Apache RocketMQ 的订阅关系除过滤表达式之外都是持久化的，即服务端重启或请求断开，订阅关系依然保留。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/introduction/02concepts#%E6%B6%88%E8%B4%B9%E7%BB%93%E6%9E%9Cconsumeresult">消费结果（ConsumeResult）</a></p>
<p>Apache RocketMQ 中PushConsumer消费监听器处理消息完成后返回的处理结果，用来标识本次消息是否正确处理。消费结果包含消费成功和消费失败。</p>
</li>
</ul>
<h2 id="消息类型"><a href="#消息类型" class="headerlink" title="消息类型"></a>消息类型</h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/01normalmessage">普通消息</a></p>
<p>普通消息为 Apache RocketMQ 中最基础的消息，区别于有特性的顺序消息、定时&#x2F;延时消息和事务消息。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/introduction/02concepts#%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF">事务消息</a></p>
<p>事务消息是Apache RocketMQ 提供的一种高级消息类型，支持在分布式场景下保障消息生产和本地事务的最终一致性。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/introduction/02concepts#%E5%AE%9A%E6%97%B6%E5%BB%B6%E6%97%B6%E6%B6%88%E6%81%AF">定时&#x2F;延时消息</a></p>
<p>定时&#x2F;延时消息是Apache RocketMQ 提供的一种高级消息类型，消息被发送至服务端后，在指定时间后才能被消费者消费。通过设置一定的定时时间可以实现分布式场景的延时调度触发效果。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/introduction/02concepts#%E9%A1%BA%E5%BA%8F%E6%B6%88%E6%81%AF">顺序消息</a></p>
<p>顺序消息是Apache RocketMQ 提供的一种高级消息类型，支持消费者按照发送消息的先后顺序获取消息，从而实现业务场景中的顺序处理。</p>
</li>
</ul>
<h2 id="消息处理"><a href="#消息处理" class="headerlink" title="消息处理"></a>消息处理</h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/introduction/02concepts#%E6%B6%88%E6%81%AF%E8%BF%87%E6%BB%A4">消息过滤</a></p>
<p>消费者可以通过订阅指定消息标签（Tag）对消息进行过滤，确保最终只接收被过滤后的消息合集。过滤规则的计算和匹配在Apache RocketMQ 的服务端完成。更多信息，请参见<a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/07messagefilter">消息过滤</a>。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/introduction/02concepts#%E9%87%8D%E7%BD%AE%E6%B6%88%E8%B4%B9%E4%BD%8D%E7%82%B9">重置消费位点</a></p>
<p>以时间轴为坐标，在消息持久化存储的时间范围内，重新设置消费者分组对已订阅主题的消费进度，设置完成后消费者将接收设定时间点之后，由生产者发送到Apache RocketMQ 服务端的消息。更多信息，请参见<a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/09consumerprogress">重置消费位点</a>。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/introduction/02concepts#%E6%B6%88%E6%81%AF%E8%BD%A8%E8%BF%B9">消息轨迹</a></p>
<p>在一条消息从生产者发出到消费者接收并处理过程中，由各个相关节点的时间、地点等数据汇聚而成的完整链路信息。通过消息轨迹，您能清晰定位消息从生产者发出，经由Apache RocketMQ 服务端，投递给消费者的完整链路，方便定位排查问题。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/introduction/02concepts#%E6%B6%88%E6%81%AF%E5%A0%86%E7%A7%AF">消息堆积</a></p>
<p>生产者已经将消息发送到Apache RocketMQ 的服务端，但由于消费者的消费能力有限，未能在短时间内将所有消息正确消费掉，此时在服务端保存着未被消费的消息，该状态即消息堆积。</p>
</li>
</ul>
<h1 id="消息类型原理"><a href="#消息类型原理" class="headerlink" title="消息类型原理"></a>消息类型原理</h1><h2 id="普通消息"><a href="#普通消息" class="headerlink" title="普通消息"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/01normalmessage">普通消息</a></h2><p><strong>应用场景</strong></p>
<p>普通消息一般应用于微服务解耦、事件驱动、数据集成等场景，这些场景大多数要求数据传输通道具有可靠传输的能力，且对消息的处理时机、处理顺序没有特别要求。</p>
<p>普通消息仅支持使用MessageType为Normal主题，即普通消息只能发送至类型为普通消息的主题中，发送的消息的类型必须和主题的类型一致。</p>
<p><strong>普通消息生命周期</strong></p>
<ul>
<li>初始化：消息被生产者构建并完成初始化，待发送到服务端的状态。</li>
<li>待消费：消息被发送到服务端，对消费者可见，等待消费者消费的状态。</li>
<li>消费中：消息被消费者获取，并按照消费者本地的业务逻辑进行处理的过程。 此时服务端会等待消费者完成消费并提交消费结果，如果一定时间后没有收到消费者的响应，Apache RocketMQ会对消息进行重试处理。具体信息，请参见<a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/10consumerretrypolicy">消费重试</a>。</li>
<li>消费提交：消费者完成消费处理，并向服务端提交消费结果，服务端标记当前消息已经被处理（包括消费成功和失败）。 Apache RocketMQ默认支持保留所有消息，此时消息数据并不会立即被删除，只是逻辑标记已消费。消息在保存时间到期或存储空间不足被删除前，消费者仍然可以回溯消息重新消费。</li>
<li>消息删除：Apache RocketMQ按照消息保存机制滚动清理最早的消息数据，将消息从物理文件中删除。更多信息，请参见<a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/11messagestorepolicy">消息存储和清理机制</a>。</li>
</ul>
<h2 id="顺序消息"><a href="#顺序消息" class="headerlink" title="顺序消息"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/03fifomessage">顺序消息</a></h2><p>顺序消息是 Apache RocketMQ 提供的一种高级消息类型，支持消费者按照发送消息的先后顺序获取消息，从而实现业务场景中的顺序处理。 相比其他类型消息，顺序消息在发送、存储和投递的处理过程中，更多强调多条消息间的先后顺序关系。</p>
<p>Apache RocketMQ 顺序消息的顺序关系通过消息组（MessageGroup）判定和识别，发送顺序消息时需要为每条消息设置归属的消息组，相同消息组的多条消息之间遵循先进先出的顺序关系，不同消息组、无消息组的消息之间不涉及顺序性。</p>
<p>基于消息组的顺序判定逻辑，支持按照业务逻辑做细粒度拆分，可以在满足业务局部顺序的前提下提高系统的并行度和吞吐能力。</p>
<p>顺序消息仅支持使用MessageType为FIFO的主题，即顺序消息只能发送至类型为顺序消息的主题中，发送的消息的类型必须和主题的类型一致。</p>
<p><strong>应用场景</strong></p>
<p>在有序事件处理、撮合交易、数据实时增量同步等场景下，异构系统间需要维持强一致的状态同步，上游的事件变更需要按照顺序传递到下游进行处理。在这类场景下使用 Apache RocketMQ 的顺序消息可以有效保证数据传输的顺序性。</p>
<ul>
<li><p><strong>典型场景一：撮合交易</strong></p>
<p>以证券、股票交易撮合场景为例，对于出价相同的交易单，坚持按照先出价先交易的原则，下游处理订单的系统需要严格按照出价顺序来处理订单。</p>
</li>
<li><p><strong>典型场景二：数据实时增量同步</strong></p>
<p>以数据库变更增量同步场景为例，上游源端数据库按需执行增删改操作，将二进制操作日志作为消息，通过 Apache RocketMQ 传输到下游搜索系统，下游系统按顺序还原消息数据，实现状态数据按序刷新。如果是普通消息则可能会导致状态混乱，和预期操作结果不符，基于顺序消息可以实现下游状态和上游操作结果一致。</p>
</li>
</ul>
<p><strong>如何保证消息的顺序性</strong></p>
<p>Apache RocketMQ 的消息的顺序性分为两部分，生产顺序性和消费顺序性。</p>
<ul>
<li><p><strong>生产顺序性</strong> ：</p>
<p>Apache RocketMQ 通过生产者和服务端的协议保障单个生产者串行地发送消息，并按序存储和持久化。</p>
<p>如需保证消息生产的顺序性，则必须满足以下条件：</p>
<ul>
<li>单一生产者：消息生产的顺序性仅支持单一生产者，不同生产者分布在不同的系统，即使设置相同的消息组，不同生产者之间产生的消息也无法判定其先后顺序。</li>
<li>串行发送：Apache RocketMQ 生产者客户端支持多线程安全访问，但如果生产者使用多线程并行发送，则不同线程间产生的消息将无法判定其先后顺序。</li>
</ul>
<p>满足以上条件的生产者，将顺序消息发送至 Apache RocketMQ 后，会保证设置了同一消息组的消息，按照发送顺序存储在同一队列中。服务端顺序存储逻辑如下：</p>
<ul>
<li>相同消息组的消息按照先后顺序被存储在同一个队列。</li>
<li>不同消息组的消息可以混合在同一个队列中，且不保证连续。</li>
</ul>
<p><img src="https://rocketmq.apache.org/zh/assets/images/fifomessagegroup-aad0a1b7e64089075db956c0eca0cbf4.png" alt="顺序存储逻辑"></p>
</li>
</ul>
<p>如上图所示，消息组1和消息组4的消息混合存储在队列1中， Apache RocketMQ 保证消息组1中的消息G1-M1、G1-M2、G1-M3是按发送顺序存储，且消息组4的消息G4-M1、G4-M2也是按顺序存储，但消息组1和消息组4中的消息不涉及顺序关系。</p>
<ul>
<li><p><strong>消费顺序性</strong> ：</p>
<p>Apache RocketMQ 通过消费者和服务端的协议保障消息消费严格按照存储的先后顺序来处理。</p>
<p>如需保证消息消费的顺序性，则必须满足以下条件：</p>
<ul>
<li><p>投递顺序</p>
<p>Apache RocketMQ 通过客户端SDK和服务端通信协议保障消息按照服务端存储顺序投递，但业务方消费消息时需要严格按照接收—处理—应答的语义处理消息，避免因异步处理导致消息乱序。</p>
<p>备注：消费者类型为PushConsumer时， Apache RocketMQ 保证消息按照存储顺序一条一条投递给消费者，若消费者类型为SimpleConsumer，则消费者有可能一次拉取多条消息。此时，消息消费的顺序性需要由业务方自行保证。消费者类型的具体信息，请参见<a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/06consumertype">消费者分类</a>。</p>
</li>
<li><p>有限重试</p>
<p>Apache RocketMQ 顺序消息投递仅在重试次数限定范围内，即一条消息如果一直重试失败，超过最大重试次数后将不再重试，跳过这条消息消费，不会一直阻塞后续消息处理。</p>
<p>对于需要严格保证消费顺序的场景，请务设置合理的重试次数，避免参数不合理导致消息乱序。</p>
</li>
</ul>
</li>
</ul>
<p><strong>生产顺序性和消费顺序性组合</strong></p>
<p>如果消息需要严格按照先进先出（FIFO）的原则处理，即先发送的先消费、后发送的后消费，则必须要同时满足生产顺序性和消费顺序性。</p>
<p>一般业务场景下，同一个生产者可能对接多个下游消费者，不一定所有的消费者业务都需要顺序消费，您可以将生产顺序性和消费顺序性进行差异化组合，应用于不同的业务场景。例如发送顺序消息，但使用非顺序的并发消费方式来提高吞吐能力。</p>
<p><strong>顺序消息生命周期</strong></p>
<p><a href="##%E6%99%AE%E9%80%9A%E6%B6%88%E6%81%AF">同普通消息的生命周期</a></p>
<h2 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/04transactionmessage">事务消息</a></h2><p>Apache RocketMQ 提供的事务消息支持在分布式场景下保障消息的最终一致性。</p>
<p><strong>其它事务消息的处理方案</strong></p>
<ul>
<li><p><strong>传统XA事务方案：性能不足</strong></p>
<p>为了保证分支的执行结果一致性，典型方案是基于XA协议的分布式事务系统来实现。将多个调用分支封装成包含独立事务分支的大事务。基于XA分布式事务的方案可以满足业务处理结果的正确性，但最大的缺点是多分支环境下资源锁定范围大，并发度低，随着下游分支的增加，系统性能会越来越差。</p>
</li>
</ul>
<p><strong>事务消息处理流程</strong></p>
<p>事务消息交互流程如下图所示。<img src="https://rocketmq.apache.org/zh/assets/images/transflow-0b07236d124ddb814aeaf5f6b5f3f72c.png" alt="事务消息"></p>
<ol>
<li>生产者将消息发送至Apache RocketMQ服务端。</li>
<li>Apache RocketMQ服务端将消息持久化成功之后，向生产者返回Ack确认消息已经发送成功，此时消息被标记为”暂不能投递”，这种状态下的消息即为<strong>半事务消息</strong>。</li>
<li>生产者开始执行本地事务逻辑。</li>
<li>生产者根据本地事务执行结果向服务端提交二次确认结果（Commit或是Rollback），服务端收到确认结果后处理逻辑如下：<ul>
<li>二次确认结果为Commit：服务端将半事务消息标记为可投递，并投递给消费者。</li>
<li>二次确认结果为Rollback：服务端将回滚事务，不会将半事务消息投递给消费者。</li>
</ul>
</li>
<li>在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。 <strong>说明</strong>：服务端回查的间隔时间和最大回查次数，请参见<a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/introduction/03limits">参数限制</a>。</li>
<li>生产者收到消息回查后，需要检查对应消息的本地事务执行的最终结果。</li>
<li>生产者根据检查到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行处理。</li>
</ol>
<p><strong>事务消息生命周期</strong></p>
<ul>
<li>初始化：半事务消息被生产者构建并完成初始化，待发送到服务端的状态。</li>
<li>事务待提交：半事务消息被发送到服务端，和普通消息不同，并不会直接被服务端持久化，而是会被单独存储到事务存储系统中，等待第二阶段本地事务返回执行结果后再提交。此时消息对下游消费者不可见。</li>
<li>消息回滚：第二阶段如果事务执行结果明确为回滚，服务端会将半事务消息回滚，该事务消息流程终止。</li>
<li>提交待消费：第二阶段如果事务执行结果明确为提交，服务端会将半事务消息重新存储到普通存储系统中，此时消息对下游消费者可见，等待被消费者获取并消费。</li>
<li>消费中：<a href="##%E6%99%AE%E9%80%9A%E6%B6%88%E6%81%AF">同普通消息的生命周期</a></li>
<li>消费提交：<a href="##%E6%99%AE%E9%80%9A%E6%B6%88%E6%81%AF">同普通消息的生命周期</a></li>
<li>消息删除：<a href="##%E6%99%AE%E9%80%9A%E6%B6%88%E6%81%AF">同普通消息的生命周期</a></li>
</ul>
<h2 id="定时-x2F-延时消息"><a href="#定时-x2F-延时消息" class="headerlink" title="定时&#x2F;延时消息"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/02delaymessage">定时&#x2F;延时消息</a></h2><p>在分布式定时调度触发、任务超时处理等场景，需要实现精准、可靠的定时事件触发。使用 Apache RocketMQ 的定时消息可以简化定时调度任务的开发逻辑，实现高性能、可扩展、高可靠的定时触发能力。</p>
<ul>
<li>定时消息：例如，当前系统时间为2022-06-09 17:30:00，您希望消息在下午19:20:00定时投递，则定时时间为2022-06-09 19:20:00，转换成时间戳格式为1654773600000。</li>
<li>延时消息：例如，当前系统时间为2022-06-09 17:30:00，您希望延时1个小时后投递消息，则您需要根据当前时间和延时时长换算成定时时刻，即消息投递时间为2022-06-09 18:30:00，转换为时间戳格式为1654770600000。</li>
</ul>
<p>定时消息仅支持在 MessageType为Delay 的主题内使用，即定时消息只能发送至类型为定时消息的主题中，发送的消息的类型必须和主题的类型一致。</p>
<p><strong>应用场景</strong></p>
<ul>
<li><p><strong>典型场景一：分布式定时调度</strong></p>
<p>在分布式定时调度场景下，需要实现各类精度的定时任务，例如每天5点执行文件清理，每隔2分钟触发一次消息推送等需求。传统基于数据库的定时调度方案在分布式场景下，性能不高，实现复杂。基于 Apache RocketMQ 的定时消息可以封装出多种类型的定时触发器。</p>
</li>
<li><p><strong>典型场景二：任务超时处理</strong></p>
<p>以电商交易场景为例，订单下单后暂未支付，此时不可以直接关闭订单，而是需要等待一段时间后才能关闭订单。使用 Apache RocketMQ 定时消息可以实现超时任务的检查触发。</p>
</li>
</ul>
<p><strong>定时消息生命周期</strong></p>
<ul>
<li>初始化：<a href="##%E6%99%AE%E9%80%9A%E6%B6%88%E6%81%AF">同普通消息的生命周期</a></li>
<li>定时中：消息被发送到服务端，和普通消息不同的是，服务端不会直接构建消息索引，而是会将定时消息单独存储在定时存储系统中，等待定时时刻到达。</li>
<li>待消费：定时时刻到达后，服务端将消息重新写入普通存储引擎，对下游消费者可见，等待消费者消费的状态。</li>
<li>消费中：<a href="##%E6%99%AE%E9%80%9A%E6%B6%88%E6%81%AF">同普通消息的生命周期</a></li>
<li>消费提交：<a href="##%E6%99%AE%E9%80%9A%E6%B6%88%E6%81%AF">同普通消息的生命周期</a></li>
<li>消息删除：<a href="##%E6%99%AE%E9%80%9A%E6%B6%88%E6%81%AF">同普通消息的生命周期</a></li>
</ul>
<h1 id="消息处理原理"><a href="#消息处理原理" class="headerlink" title="消息处理原理"></a>消息处理原理</h1><h2 id="消息发送重试机制"><a href="#消息发送重试机制" class="headerlink" title="消息发送重试机制"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/05sendretrypolicy">消息发送重试机制</a></h2><p>Apache RocketMQ 客户端连接服务端发起消息发送请求时，可能会因为网络故障、服务异常等原因导致调用失败。为保证消息的可靠性， Apache RocketMQ 在客户端SDK中内置请求重试逻辑，尝试通过重试发送达到最终调用成功的效果。</p>
<p>同步发送和异步发送模式均支持消息发送重试。</p>
<p> <strong>重试触发条件</strong></p>
<p>触发消息发送重试机制的条件如下：</p>
<ul>
<li>客户端消息发送请求调用失败或请求超时</li>
<li>网络异常造成连接失败或请求超时。</li>
<li>服务端节点处于重启或下线等状态造成连接失败。</li>
<li>服务端运行慢造成请求超时。</li>
<li>服务端返回失败错误码<ul>
<li>系统逻辑错误：因运行逻辑不正确造成的错误。</li>
<li>系统流控错误：因容量超限造成的流控错误。</li>
</ul>
</li>
</ul>
<p>对于事务消息，只会进行<a target="_blank" rel="noopener" href="https://github.com/grpc/proposal/blob/master/A6-client-retries.md#transparent-retries">透明重试（transparent retries）</a>，网络超时或异常等场景不会进行重试。</p>
<h3 id="重试流程"><a href="#重试流程" class="headerlink" title="重试流程"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/05sendretrypolicy#%E9%87%8D%E8%AF%95%E6%B5%81%E7%A8%8B">重试流程</a></h3><p>生产者在初始化时设置消息发送最大重试次数，当出现上述触发条件的场景时，生产者客户端会按照设置的重试次数一直重试发送消息，直到消息发送成功或达到最大重试次数重试结束，并在最后一次重试失败后返回调用错误响应。</p>
<ul>
<li>同步发送：调用线程会一直阻塞，直到某次重试成功或最终重试失败，抛出错误码和异常。</li>
<li>异步发送：调用线程不会阻塞，但调用结果会通过异常事件或者成功事件返回。</li>
</ul>
<h3 id="功能约束"><a href="#功能约束" class="headerlink" title="功能约束"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/05sendretrypolicy#%E5%8A%9F%E8%83%BD%E7%BA%A6%E6%9D%9F">功能约束</a></h3><ul>
<li>链路耗时阻塞评估：从上述重试机制可以看出，在重试流程中生产者仅能控制最大重试次数。若由于系统异常触发了SDK内置的重试逻辑，则服务端需要等待最终重试结果，可能会导致消息发送请求链路被阻塞。对于某些实时调用类场景，您需要合理评估每次调用请求的超时时间以及最大重试次数，避免影响全链路的耗时。</li>
<li>最终异常兜底： Apache RocketMQ 客户端内置的发送请求重试机制并不能保证消息发送一定成功。当最终重试仍然失败时，业务方调用需要捕获异常，并做好冗余保护处理，避免消息发送结果不一致。</li>
<li>消息重复问题：因远程调用的不确定性，当Apache RocketMQ客户端因请求超时触发消息发送重试流程，此时客户端无法感知服务端的处理结果，客户端进行的消息发送重试可能会产生消息重复问题，业务逻辑需要自行处理消息重复问题。</li>
</ul>
<h2 id="消息流控机制"><a href="#消息流控机制" class="headerlink" title="消息流控机制"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/05sendretrypolicy">消息流控机制</a></h2><p>消息流控指的是系统容量或水位过高， Apache RocketMQ 服务端会通过快速失败返回流控错误来避免底层资源承受过高压力。</p>
<h3 id="触发条件"><a href="#触发条件" class="headerlink" title="触发条件"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/05sendretrypolicy#%E8%A7%A6%E5%8F%91%E6%9D%A1%E4%BB%B6">触发条件</a></h3><p>Apache RocketMQ 的消息流控触发条件如下：</p>
<ul>
<li>存储压力大：参考<a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/09consumerprogress">消费进度管理</a>的原理机制，消费者分组的初始消费位点为当前队列的最大消费位点。若某些场景例如业务上新等需要回溯到指定时刻前开始消费，此时队列的存储压力会瞬间飙升，触发消息流控。</li>
<li>服务端请求任务排队溢出：若消费者消费能力不足，导致队列中有大量堆积消息，当堆积消息超过一定数量后会触发消息流控，减少下游消费系统压力。</li>
</ul>
<h3 id="流控行为"><a href="#流控行为" class="headerlink" title="流控行为"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/05sendretrypolicy#%E6%B5%81%E6%8E%A7%E8%A1%8C%E4%B8%BA">流控行为</a></h3><p>当系统触发消息发送流控时，客户端会收到系统限流错误和异常，错误码信息如下：</p>
<ul>
<li>reply-code：530</li>
<li>reply-text：TOO_MANY_REQUESTS</li>
</ul>
<p>客户端收到系统流控错误码后，会根据指数退避策略进行消息发送重试。</p>
<h3 id="处理建议"><a href="#处理建议" class="headerlink" title="处理建议"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/05sendretrypolicy#%E5%A4%84%E7%90%86%E5%BB%BA%E8%AE%AE">处理建议</a></h3><ul>
<li>如何避免触发消息流控：触发限流的根本原因是系统容量或水位过高，您可以利用可观测性功能监控系统水位容量等，保证底层资源充足，避免触发流控机制。</li>
<li>突发消息流控处理：如果因为突发原因触发消息流控，且客户端内置的重试流程执行失败，则建议业务方将请求调用临时替换到其他系统进行应急处理。</li>
</ul>
<h2 id="消息过滤"><a href="#消息过滤" class="headerlink" title="消息过滤"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/07messagefilter">消息过滤</a></h2><p>消费者订阅了某个主题后，Apache RocketMQ 会将该主题中的所有消息投递给消费者。若消费者只需要关注部分消息，可通过设置过滤条件在 Apache RocketMQ 服务端进行过滤，只获取到需要关注的消息子集，避免接收到大量无效的消息。</p>
<p>消息过滤主要解决的单个业务域即同一个主题内不同消息子集的过滤问题，一般是基于同一业务下更具体的分类进行过滤匹配。如果是需要对不同业务域的消息进行拆分，建议使用不同主题处理不同业务域的消息。</p>
<h3 id="功能概述"><a href="#功能概述" class="headerlink" title="功能概述"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/07messagefilter#%E5%8A%9F%E8%83%BD%E6%A6%82%E8%BF%B0">功能概述</a></h3><p><strong>消息过滤定义</strong></p>
<p>过滤的含义指的是将符合条件的消息投递给消费者，而不是将匹配到的消息过滤掉。</p>
<p>Apache RocketMQ 的消息过滤功能通过生产者和消费者对消息的属性、标签进行定义，并在 Apache RocketMQ 服务端根据过滤条件进行筛选匹配，将符合条件的消息投递给消费者进行消费。</p>
<p><strong>消息过滤原理</strong></p>
<p>消息过滤主要通过以下几个关键流程实现：</p>
<ul>
<li>生产者：生产者在初始化消息时预先为消息设置一些属性和标签，用于后续消费时指定过滤目标。</li>
<li>消费者：消费者在初始化及后续消费流程中通过调用订阅关系注册接口，向服务端上报需要订阅指定主题的哪些消息，即过滤条件。</li>
<li>服务端：消费者获取消息时会触发服务端的动态过滤计算，Apache RocketMQ 服务端根据消费者上报的过滤条件的表达式进行匹配，并将符合条件的消息投递给消费者。</li>
</ul>
<h3 id="消息过滤分类"><a href="#消息过滤分类" class="headerlink" title="消息过滤分类"></a><strong>消息过滤分类</strong></h3><p>Apache RocketMQ 支持Tag标签过滤和SQL属性过滤。</p>
<ul>
<li><p>Tag标签过滤方式是生产者在发送消息时，设置消息的Tag标签，消费者需指定已有的Tag标签来进行匹配订阅。</p>
</li>
<li><p>SQL属性过滤方式是是生产者定义消息属性，消费者设置SQL过滤条件。生产者发送消息时可以自定义消息属性，每个属性都是一个自定义的键值对（Key-Value）。生产者在发送消息时可设置多个属性，消费者订阅时可设置SQL语法的过滤表达式过滤多个属性。</p>
</li>
</ul>
<h2 id="消费重试"><a href="#消费重试" class="headerlink" title="消费重试"></a><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/docs/featureBehavior/10consumerretrypolicy">消费重试</a></h2><p>消费重试指的是，消费者在消费某条消息失败后，Apache RocketMQ 服务端会根据重试策略重新消费该消息，超过一次定数后若还未消费成功，则该消息将不再继续重试，直接被发送到死信队列中。</p>
<p>Apache RocketMQ 的消费重试主要解决的是业务处理逻辑失败导致的消费完整性问题，是一种为业务兜底的策略，不应该被用做业务流程控制。</p>
<h3 id="PushConsumer消费重试策略"><a href="#PushConsumer消费重试策略" class="headerlink" title="PushConsumer消费重试策略"></a>PushConsumer消费重试策略</h3><p><strong>重试状态机</strong></p>
<p>PushConsumer消费消息时，消息的几个主要状态如下：</p>
<ul>
<li>Ready：已就绪状态。消息在Apache RocketMQ服务端已就绪，可以被消费者消费。</li>
<li>Inflight：处理中状态。消息被消费者客户端获取，处于消费中还未返回消费结果的状态。</li>
<li>WaitingRetry：待重试状态，PushConsumer独有的状态。当消费者消息处理失败或消费超时，会触发消费重试逻辑判断。如果当前重试次数未达到最大次数，则该消息变为待重试状态，经过重试间隔后，消息将重新变为已就绪状态可被重新消费。多次重试之间，可通过重试间隔进行延长，防止无效高频的失败。</li>
<li>Commit：提交状态。消费成功的状态，消费者返回成功响应即可结束消息的状态机。</li>
<li>DLQ：死信状态。消费逻辑的最终兜底机制，若消息一直处理失败并不断进行重试，直到超过最大重试次数还未成功，此时消息不会再重试，会被投递至死信队列。您可以通过消费死信队列的消息进行业务恢复。</li>
</ul>
<p>消息重试过程中，每次重试消息状态都会经过已就绪&gt;处理中&gt;待重试的变化，两次消费间的间隔时间实际由消费耗时及重试间隔控制，消费耗时的最大上限受服务端系统参数控制，一般不应该超过上限时间。</p>
<h3 id="SimpleConsumer消费重试策略"><a href="#SimpleConsumer消费重试策略" class="headerlink" title="SimpleConsumer消费重试策略"></a>SimpleConsumer消费重试策略</h3><p><strong>重试状态机</strong></p>
<p>SimpleConsumer消费消息时，消息的几个主要状态如下：</p>
<h2 id="消费者负载均衡"><a href="#消费者负载均衡" class="headerlink" title="消费者负载均衡"></a>消费者负载均衡</h2><h2 id="消费进度管理"><a href="#消费进度管理" class="headerlink" title="消费进度管理"></a>消费进度管理</h2><h1 id="集群服务"><a href="#集群服务" class="headerlink" title="集群服务"></a>集群服务</h1><p>NameServer集群</p>
<p>Broker集群</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/">https://rocketmq.apache.org/</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/apache/rocketmq">https://github.com/apache/rocketmq</a></li>
<li><a target="_blank" rel="noopener" href="https://rocketmq.apache.org/zh/">https://rocketmq.apache.org/zh/</a></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-24T08:08:42.000Z" title="2023/5/24 16:08:42">2023-05-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-05-30T07:46:19.546Z" title="2023/5/30 15:46:19">2023-05-30</time></span><span class="level-item"><a class="link-muted" href="/categories/IT/">IT</a></span><span class="level-item">2 hours read (About 15309 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/24/Spring-Cloud/">Spring Cloud</a></p><div class="content"><h1 id="服务架构"><a href="#服务架构" class="headerlink" title="服务架构"></a>服务架构</h1><p>微服务架构是一种一个单一应用程序开发为一组小型服务的代码结构，每个服务运行在自己的进程中，服务间采用轻量级通信机制（如HTTP）进行通信。这些服务可以独立部署，不同服务可以使用不同语言开发，使用不同的数据存储技术。</p>
<h2 id="微服务与Spring-Cloud"><a href="#微服务与Spring-Cloud" class="headerlink" title="微服务与Spring Cloud"></a>微服务与Spring Cloud</h2><p>为了降低构建和维护分布式系统的难度，加快微服务的落地，Spring Cloud提供了快速构建分布式微服务系统的一些常用功能，如配置管理、服务发现、断路器、路由、服务代理、控制总线等工具。使用这些工具可以快速构建分布式微服务架构的系统。</p>
<h2 id="Spring-Cloud与Dubbo"><a href="#Spring-Cloud与Dubbo" class="headerlink" title="Spring Cloud与Dubbo"></a>Spring Cloud与Dubbo</h2><h3 id="Dubbo"><a href="#Dubbo" class="headerlink" title="Dubbo"></a>Dubbo</h3><p>Apache Dubbo 是一款 RPC 服务开发框架，用于解决微服务架构下的服务治理与通信问题。利用 Dubbo 提供的丰富服务治理特性，可以实现诸如服务发现、负载均衡、流量调度等服务治理诉求。</p>
<p><a target="_blank" rel="noopener" href="https://cn.dubbo.apache.org/zh-cn/overview/what/overview/">官网对Dubbo的含义的介绍</a>：</p>
<ul>
<li>Dubbo的产生原因：微服务的分布式特性，使得应用间的依赖、网络交互、数据传输变得更频繁，因此不同的应用需要定义、暴露或调用 RPC 服务，那么这些 RPC 服务如何定义、如何与应用开发框架结合、服务调用行为如何控制？</li>
<li>Dubbo的含义：<strong>Dubbo 在微服务应用开发框架之上抽象了一套 RPC 服务定义、暴露、调用与治理的编程范式</strong>。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://cn.dubbo.apache.org/zh-cn/overview/mannual/java-sdk/reference-manual/registry/">Dubbo支持的注册中心</a>的官网介绍。</p>
<h3 id="Spring-Cloud与Dubbo的区别"><a href="#Spring-Cloud与Dubbo的区别" class="headerlink" title="Spring Cloud与Dubbo的区别"></a>Spring Cloud与Dubbo的区别</h3><p>Dubbo主要用来实现服务治理，而Spring Cloud的各个组件实现了微服务架构下的所需的各种功能，服务治理只是其中的一个方面。</p>
<p>Dubbo的在Spring Cloud Netfix技术架构中的替代方案可以是，通过Consul或Eureka Server等实现服务注册中心（对应Dubbo中的注册中心），通过Ribbon实现软负载均衡。 </p>
<h2 id="Spring-Cloud-Netfix和Spring-Cloud-Alibaba"><a href="#Spring-Cloud-Netfix和Spring-Cloud-Alibaba" class="headerlink" title="Spring Cloud Netfix和Spring Cloud Alibaba"></a>Spring Cloud Netfix和Spring Cloud Alibaba</h2><p>Spring Cloud Netfix和Spring Cloud Alibaba是Spring Cloud的两套技术架构。</p>
<h3 id="Spring-Cloud-Netfix"><a href="#Spring-Cloud-Netfix" class="headerlink" title="Spring Cloud Netfix"></a>Spring Cloud Netfix</h3><p><a target="_blank" rel="noopener" href="https://www.springcloud.cc/spring-cloud-netflix.html">Spring Cloud Netfix在官方文档</a>中介绍：该项目通过自动配置和绑定到Spring环境和其他Spring编程模型的习惯方式来为Spring Boot应用程序提供Netflix OSS集成。通过几个简单的注释，您可以快速启用和配置应用程序中的常见模式，并通过经过测试的Netflix组件构建大型分布式系统。提供的组件包括服务发现（Eureka），断路器（Hystrix），智能路由（Zuul）和客户端负载平衡（Ribbon）。可以从<a target="_blank" rel="noopener" href="https://github.com/Netflix">Netfix的GitHub</a>中找到这些组件。</p>
<h3 id="Spring-Cloud-Alibaba"><a href="#Spring-Cloud-Alibaba" class="headerlink" title="Spring Cloud Alibaba"></a>Spring Cloud Alibaba</h3><p>Spring Cloud Alibaba的相关文档：<a target="_blank" rel="noopener" href="https://spring-cloud-alibaba-group.github.io/github-pages/hoxton/zh-cn/index.html">Spring Cloud Alibaba参考文档</a>、<a target="_blank" rel="noopener" href="https://github.com/alibaba/spring-cloud-alibaba/blob/2022.x/README-zh.md">Spring Cloud Alibaba中文版README.md</a>。其提供的组件有：Sentinel(分布式流控：流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性)、Nacos（注册中心）、RocketMQ（分布式消息组件）、Seata（分布式事务组件）等。</p>
<h1 id="服务注册中心和配置中心"><a href="#服务注册中心和配置中心" class="headerlink" title="服务注册中心和配置中心"></a>服务注册中心和配置中心</h1><p>服务注册中心提供了服务注册和服务发现功能</p>
<ol>
<li>服务注册：所有服务的提供方启动时向注册中心发送自己的信息，包括地址、端口、提供的服务等。</li>
<li>服务发现：当服务调用方需要调用服务时，只需要向注册中心查询谁提供了自己需要的服务。</li>
</ol>
<h2 id="Zookeeper（注册中心和配置中心）"><a href="#Zookeeper（注册中心和配置中心）" class="headerlink" title="Zookeeper（注册中心和配置中心）"></a>Zookeeper（注册中心和配置中心）</h2><h3 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h3><p>Zookeeper可以解决分布式应用中的服务的注册和发现、统一命名服务、状态同步服务、集群管理、分布式应用配置管理等问题。可以替代Eureka、Spring Cloud Config。不能替代路由网关（Zuul）、负载均衡（Ribbon）、断路器（Hystricx）等。</p>
<h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><ol>
<li>启动Zookeeper的服务，可以使用Docker等方法启动Zookeeper。</li>
<li>在Zookeeper服务提供方：<ol>
<li>添加依赖spring-cloud0zookeeper-discovery和org.apache.curator。注：Zookeeper通过Curator（Curator 是一个 Apache ZooKeeper 客户端框架）实现了服务注册和发现功能，实现了和Eureka相同的功能。</li>
<li>在配置文件中添加对Zookeeper的配置，指定Zookeeper服务暴露的的连接ip和端口。</li>
<li>在启动类添加@EnableDiscoveryClient注解。</li>
</ol>
</li>
<li>在服务消费方：<ol>
<li>添加依赖</li>
<li>添加配置信息</li>
</ol>
</li>
</ol>
<h2 id="Nacos（注册中心和配置中心）"><a href="#Nacos（注册中心和配置中心）" class="headerlink" title="Nacos（注册中心和配置中心）"></a>Nacos（注册中心和配置中心）</h2><h3 id="功能和特性"><a href="#功能和特性" class="headerlink" title="功能和特性"></a>功能和特性</h3><p><a target="_blank" rel="noopener" href="https://nacos.io/zh-cn/docs/what-is-nacos.html">Nacos</a> &#x2F;nɑ:kəʊs&#x2F; 是 Dynamic Naming and Configuration Service的首字母简称，一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。</p>
<p>Nacos官网给出的关键特性包括:</p>
<ul>
<li><p><strong>服务发现和服务健康监测</strong></p>
<p>Nacos 支持基于 DNS 和基于 RPC 的服务发现。服务提供者使用 <a target="_blank" rel="noopener" href="https://nacos.io/zh-cn/docs/sdk.html">原生SDK</a>、<a target="_blank" rel="noopener" href="https://nacos.io/zh-cn/docs/open-api.html">OpenAPI</a>、或一个<a target="_blank" rel="noopener" href="https://nacos.io/zh-cn/docs/other-language.html">独立的Agent TODO</a>注册 Service 后，服务消费者可以使用<a target="_blank" rel="noopener" href="https://nacos.io/zh-cn/docs/xx">DNS TODO</a> 或<a target="_blank" rel="noopener" href="https://nacos.io/zh-cn/docs/open-api.html">HTTP&amp;API</a>查找和发现服务。</p>
<p>Nacos 提供对服务的实时的健康检查，阻止向不健康的主机或服务实例发送请求。Nacos 支持传输层 (PING 或 TCP)和应用层 (如 HTTP、MySQL、用户自定义）的健康检查。 对于复杂的云环境和网络拓扑环境中（如 VPC、边缘网络等）服务的健康检查，Nacos 提供了 agent 上报模式和服务端主动检测2种健康检查模式。Nacos 还提供了统一的健康检查仪表盘，帮助您根据健康状态管理服务的可用性及流量。</p>
</li>
<li><p><strong>动态配置服务</strong></p>
<p>动态配置服务可以让您以中心化、外部化和动态化的方式管理所有环境的应用配置和服务配置。</p>
<p>动态配置消除了配置变更时重新部署应用和服务的需要，让配置管理变得更加高效和敏捷。</p>
<p>配置中心化管理让实现无状态服务变得更简单，让服务按需弹性扩展变得更容易。</p>
<p>Nacos 提供了一个简洁易用的UI (<a target="_blank" rel="noopener" href="http://console.nacos.io/nacos/index.html">控制台样例 Demo</a>) 帮助您管理所有的服务和应用的配置。Nacos 还提供包括配置版本跟踪、金丝雀发布、一键回滚配置以及客户端配置更新状态跟踪在内的一系列开箱即用的配置管理特性，帮助您更安全地在生产环境中管理配置变更和降低配置变更带来的风险。</p>
</li>
<li><p><strong>动态 DNS 服务</strong></p>
<p>动态 DNS 服务支持权重路由，让您更容易地实现中间层负载均衡、更灵活的路由策略、流量控制以及数据中心内网的简单DNS解析服务。动态DNS服务还能让您更容易地实现以 DNS 协议为基础的服务发现，以帮助您消除耦合到厂商私有服务发现 API 上的风险。</p>
<p>Nacos 提供了一些简单的 <a target="_blank" rel="noopener" href="https://nacos.io/zh-cn/docs/xx">DNS APIs TODO</a> 帮助您管理服务的关联域名和可用的 IP:PORT 列表.</p>
</li>
<li><p><strong>服务及其元数据管理</strong></p>
<p>Nacos 能让您从微服务平台建设的视角管理数据中心的所有服务及元数据，包括管理服务的描述、生命周期、服务的静态依赖分析、服务的健康状态、服务的流量管理、路由及安全策略、服务的 SLA 以及最首要的 metrics 统计数据。</p>
</li>
</ul>
<h3 id="使用方法-1"><a href="#使用方法-1" class="headerlink" title="使用方法"></a>使用方法</h3><ol>
<li>在创建的SpringBoot项目中添加依赖nacos-discovery-spring-boot- starter</li>
<li>创建Controller类，通过@NacosInjected注入Nacos的NamingService，并提供discovery方法用于根据服务名称获取注册到Nacos上的服务地址</li>
<li>添加对Nacos服务地址的配置</li>
</ol>
<h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><p>在分布式架构中，任何中间件或者应用都不允许单点存在，所以开源组件一般都会支持高可用的集群。Nacos的集群架构类似于Zookeeper，包含一个Leader节点和多个Follower节点，和Zookeeper不同的是，它的数据一致性算法使用的是Raft。</p>
<p>Nacos支持Derby和MySQL两种持久化机制，默认使用的是Derby数据库，Derby的吞吐量没有MySQL大，生产环境中可以使用MySQL替换，如果使用M有SQL，需要运行nacos-mysql-sql脚本创建数据库和表。</p>
<h3 id="Dubbo使用Nacos作为注册中心"><a href="#Dubbo使用Nacos作为注册中心" class="headerlink" title="Dubbo使用Nacos作为注册中心"></a>Dubbo使用Nacos作为注册中心</h3><blockquote>
<p>官方文档：<a target="_blank" rel="noopener" href="https://cn.dubbo.apache.org/zh-cn/overview/quickstart/java/spring-boot/">Dubbo x Spring Boot 开发</a></p>
</blockquote>
<ol>
<li><p>在一个Maven项目（spring-boot-dubbo-sample）中添加三个模块，分别用来声明接口、实现接口和使用接口的实现类。</p>
</li>
<li><p>在声明接口的模块（nacos-sample-interface）中声明接口，打包安装模块。</p>
</li>
<li><p>在实现接口的模块（nacos-sample-provider）中添加三个依赖nacos-discovery-spring-boot-starter（Nacos的Starter组件）、dubbo-spring-boot-starter（Dubbo的Starter组件）以及nacos-sample-api（声明接口的模块名）；</p>
<p>创建接口的实现类，并在实现类中添加<code>@DubboService</code> 注解（<code>@Service</code> 注解从 3.0 版本开始就已经废弃，改用 <code>@DubboService</code>，以区别于 Spring 的 <code>@Service</code> 注解）；配置Dubbo 的应用名（dubbo.application.name）、Dubbo 协议信息（dubbo.protocol）、Dubbo 使用的注册中心地址（dubbo.register.adderss）等信息。配置示例：</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">dubbo:</span><br>  <span class="hljs-attr">application:</span><br>    <span class="hljs-attr">name:</span> <span class="hljs-string">nacos-sample-provider</span><br>  <span class="hljs-attr">protocol:</span><br>    <span class="hljs-attr">name:</span> <span class="hljs-string">dubbo</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">-1</span><br>  <span class="hljs-attr">registry:</span><br>    <span class="hljs-attr">address:</span> <span class="hljs-string">nacos://127.0.0.1:8848</span><br>    <span class="hljs-comment">#如果使用Zookeeper作为注册中心，只需要修改此address如下</span><br>    <span class="hljs-comment">#address: zookeeper:127.0.0.1:2181</span><br></code></pre></td></tr></table></figure>

<p>在启动类中添加注解@EnableDubbo。</p>
</li>
<li><p>在使用接口的实现类的模块（nacos-sample-consumer）使用@DubboReference注解（<code>@Reference</code> 注解从 3.0 版本开始就已经废弃，改用 <code>@DubboReference</code>，以区别于 Spring 的 <code>@Reference</code> 注解）即可获取nacos-sample-provider中的实现类对象；在配置文件中配置Dubbo 的应用名、Dubbo 协议信息、Dubbo 使用的注册中心地址；在启动类中添加注解@EnableDubbo。</p>
</li>
</ol>
<h3 id="Nacos源码（待完善）"><a href="#Nacos源码（待完善）" class="headerlink" title="Nacos源码（待完善）"></a>Nacos源码（待完善）</h3><p>根据注册中心的主要功能确定Nacos源码关键的部分有：服务注册、服务地址的获取、服务变化的感知。</p>
<ol>
<li>服务注册</li>
<li>服务地址的获取</li>
<li>服务变化的感知</li>
</ol>
<h3 id="Nacos作为配置中心"><a href="#Nacos作为配置中心" class="headerlink" title="Nacos作为配置中心"></a>Nacos作为配置中心</h3><p><a target="_blank" rel="noopener" href="https://github.com/alibaba/spring-cloud-alibaba/wiki/Nacos-config">使用方法</a>：</p>
<ol>
<li>引入依赖spring-cloud-starter-alibaba-nacos-config。</li>
<li>添加配置，使用 bootstrap.properties 配置文件来配置Nacos Server 地址、文件扩展名。</li>
</ol>
<p>特性：</p>
<ol>
<li><p>spring-cloud-starter-alibaba-nacos-config 支持配置的动态更新</p>
<p>可以通过配置 <code>spring.cloud.nacos.config.refresh.enabled=false</code> 来关闭动态刷新</p>
</li>
<li><p>可支持profile粒度的配置</p>
<p>spring-cloud-starter-alibaba-nacos-config 在加载配置的时候，不仅仅加载了以 dataId 为 <code>$&#123;spring.application.name&#125;.$&#123;file-extension:properties&#125;</code> 为前缀的基础配置，还加载了dataId为 <code>$&#123;spring.application.name&#125;-$&#123;profile&#125;.$&#123;file-extension:properties&#125;</code> 的基础配置。在日常开发中如果遇到多套环境下的不同配置，可以通过Spring 提供的 <code>$&#123;spring.profiles.active&#125;</code> 这个配置项来配置。</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">spring.profiles.active</span>=<span class="hljs-string">develop</span><br></code></pre></td></tr></table></figure>
</li>
<li><p>支持自定义 namespace 的配置</p>
<p>首先看一下 Nacos 的 Namespace 的概念， <a target="_blank" rel="noopener" href="https://nacos.io/zh-cn/docs/concepts.html">Nacos 概念</a></p>
<blockquote>
<p>用于进行租户粒度的配置隔离。不同的命名空间下，可以存在相同的 Group 或 Data ID 的配置。Namespace 的常用场景之一是不同环境的配置的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。</p>
</blockquote>
<p>在没有明确指定 <code>$&#123;spring.cloud.nacos.config.namespace&#125;</code> 配置的情况下， 默认使用的是 Nacos 上 Public 这个namespace。如果需要使用自定义的命名空间，可以通过以下配置来实现：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">spring.cloud.nacos.config.namespace</span>=<span class="hljs-string">b3404bc0-d7dc-4855-b519-570ed34b62d7</span><br></code></pre></td></tr></table></figure>

<p>该配置必须放在 bootstrap.properties 文件中。此外 <code>spring.cloud.nacos.config.namespace</code> 的值是 namespace 对应的 id，id 值可以在 Nacos 的控制台获取。并且在添加配置时注意不要选择其他的 namespace，否则将会导致读取不到正确的配置。</p>
</li>
<li><p>支持自定义 Group 的配置</p>
<p>在没有明确指定 <code>$&#123;spring.cloud.nacos.config.group&#125;</code> 配置的情况下， 默认使用的是 DEFAULT_GROUP 。如果需要自定义自己的 Group，可以通过以下配置来实现：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">spring.cloud.nacos.config.group</span>=<span class="hljs-string">DEVELOP_GROUP</span><br></code></pre></td></tr></table></figure>

<p>该配置必须放在 bootstrap.properties 文件中。并且在添加配置时 Group 的值一定要和 <code>spring.cloud.nacos.config.group</code> 的配置值一致。</p>
</li>
<li><p>支持自定义扩展的 Data Id 配置</p>
<p>Spring Cloud Alibaba Nacos Config 从 0.2.1 版本后，可支持自定义 Data Id 的配置。关于这部分详细的设计可参考 <a target="_blank" rel="noopener" href="https://github.com/spring-cloud-incubator/spring-cloud-alibaba/issues/141">这里</a>。 一个完整的配置案例如下所示：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">spring.application.name</span>=<span class="hljs-string">opensource-service-provider</span><br><span class="hljs-attr">spring.cloud.nacos.config.server-addr</span>=<span class="hljs-string">127.0.0.1:8848</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># config external configuration</span><br><span class="hljs-comment"># 1、Data Id 在默认的组 DEFAULT_GROUP,不支持配置的动态刷新</span><br><span class="hljs-attr">spring.cloud.nacos.config.extension-configs[0].data-id</span>=<span class="hljs-string">ext-config-common01.properties</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># 2、Data Id 不在默认的组，不支持动态刷新</span><br><span class="hljs-attr">spring.cloud.nacos.config.extension-configs[1].data-id</span>=<span class="hljs-string">ext-config-common02.properties</span><br><span class="hljs-attr">spring.cloud.nacos.config.extension-configs[1].group</span>=<span class="hljs-string">GLOBALE_GROUP</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># 3、Data Id 既不在默认的组，也支持动态刷新</span><br><span class="hljs-attr">spring.cloud.nacos.config.extension-configs[2].data-id</span>=<span class="hljs-string">ext-config-common03.properties</span><br><span class="hljs-attr">spring.cloud.nacos.config.extension-configs[2].group</span>=<span class="hljs-string">REFRESH_GROUP</span><br><span class="hljs-attr">spring.cloud.nacos.config.extension-configs[2].refresh</span>=<span class="hljs-string">true</span><br></code></pre></td></tr></table></figure>

<p>可以看到:</p>
<ul>
<li>通过 <code>spring.cloud.nacos.config.extension-configs[n].data-id</code> 的配置方式来支持多个 Data Id 的配置。</li>
<li>通过 <code>spring.cloud.nacos.config.extension-configs[n].group</code> 的配置方式自定义 Data Id 所在的组，不明确配置的话，默认是 DEFAULT_GROUP。</li>
<li>通过 <code>spring.cloud.nacos.config.extension-configs[n].refresh</code> 的配置方式来控制该 Data Id 在配置变更时，是否支持应用中可动态刷新， 感知到最新的配置值。默认是不支持的。</li>
</ul>
<p>多个 Data Id 同时配置时，他的优先级关系是 <code>spring.cloud.nacos.config.extension-configs[n].data-id</code> 其中 n 的值越大，优先级越高。</p>
<p><code>spring.cloud.nacos.config.extension-configs[n].data-id</code> 的值必须带文件扩展名，文件扩展名既可支持 properties，又可以支持 yaml&#x2F;yml。 此时 <code>spring.cloud.nacos.config.file-extension</code> 的配置对自定义扩展配置的 Data Id 文件扩展名没有影响。</p>
<p>通过自定义扩展的 Data Id 配置，既可以解决多个应用间配置共享的问题，又可以支持一个应用有多个配置文件。</p>
<p>为了更加清晰的在多个应用间配置共享的 Data Id ，你可以通过以下的方式来配置：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-comment"># 配置支持共享的 Data Id</span><br><span class="hljs-attr">spring.cloud.nacos.config.shared-configs[0].data-id</span>=<span class="hljs-string">common.yaml</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># 配置 Data Id 所在分组，缺省默认 DEFAULT_GROUP</span><br><span class="hljs-attr">spring.cloud.nacos.config.shared-configs[0].group</span>=<span class="hljs-string">GROUP_APP1</span><br><span class="hljs-comment"></span><br><span class="hljs-comment"># 配置Data Id 在配置变更时，是否动态刷新，缺省默认 false</span><br><span class="hljs-attr">spring.cloud.nacos.config.shared-configs[0].refresh</span>=<span class="hljs-string">true</span><br></code></pre></td></tr></table></figure>

<p>可以看到：</p>
<ul>
<li>通过 <code>spring.cloud.nacos.config.shared-configs[n].data-id</code> 来支持多个共享 Data Id 的配置。</li>
<li>通过 <code>spring.cloud.nacos.config.shared-configs[n].group</code> 来配置自定义 Data Id 所在的组，不明确配置的话，默认是 DEFAULT_GROUP。</li>
<li>通过 <code>spring.cloud.nacos.config.shared-configs[n].refresh</code> 来控制该Data Id在配置变更时，是否支持应用中动态刷新，默认false。</li>
</ul>
</li>
<li><p>配置的优先级</p>
<p>Spring Cloud Alibaba Nacos Config 目前提供了三种配置能力从 Nacos 拉取相关的配置。</p>
<ul>
<li>A: 通过 <code>spring.cloud.nacos.config.shared-configs[n].data-id</code> 支持多个共享 Data Id 的配置</li>
<li>B: 通过 <code>spring.cloud.nacos.config.extension-configs[n].data-id</code> 的方式支持多个扩展 Data Id 的配置</li>
<li>C: 通过内部相关规则(应用名、应用名+ Profile )自动生成相关的 Data Id 配置</li>
</ul>
<p>当三种方式共同使用时，他们的一个优先级关系是:A &lt; B &lt; C</p>
</li>
<li><p>完全关闭配置</p>
<p>通过设置 spring.cloud.nacos.config.enabled &#x3D; false 来完全关闭 Spring Cloud Nacos Config</p>
</li>
</ol>
<h2 id="Consul（注册中心和配置中心）"><a href="#Consul（注册中心和配置中心）" class="headerlink" title="Consul（注册中心和配置中心）"></a>Consul（注册中心和配置中心）</h2><h3 id="功能-1"><a href="#功能-1" class="headerlink" title="功能"></a>功能</h3><p>Consul是HashiCrop公司推出的开源工具，提供了服务注册和发现、分布式一致性协议实现、健康检查、Key&#x2F;Value存储、多数据中心方案等。</p>
<h3 id="使用方法-2"><a href="#使用方法-2" class="headerlink" title="使用方法"></a>使用方法</h3><ol>
<li>启动Consul服务，可以使用Docker等方法启动Consul。</li>
<li>其它步骤参加Zookeeper的使用方法，不同的是依赖是spring-cloud-consul-discovery</li>
</ol>
<h2 id="Eureka（注册中心）"><a href="#Eureka（注册中心）" class="headerlink" title="Eureka（注册中心）"></a>Eureka（注册中心）</h2><h3 id="功能和组成"><a href="#功能和组成" class="headerlink" title="功能和组成"></a>功能和组成</h3><p>Eureka提供了完整的服务注册和服务发现功能，以及负载均衡、故障转移的功能。</p>
<p>主要包含两个部分：Eureka Client、Eureka Server：</p>
<ul>
<li><p>Eureka Server: 服务注册中心，用于管理各种微服务实例的注册与发现。Eureka Server提供了一种能力，让各个微服务之间彼此连接并互相感知。每当有新的微服务被启动时，它会向Eureka Server节点发送一个REST请求，并且在该服务器上进行注册。同时，对于已经注册的微服务，Eureka Server会接收并存储它们发送的心跳信息，以便为客户端提供最新可用的服务列表。</p>
</li>
<li><p>Eureka Client: （微）服务实例，用于与Eureka Server注册中心进行交互。Eureka Client会向Eureka Server注册自己，并定期发送心跳消息来更新它的状态。同时，它还可以查询Eureka Server上已注册的其他微服务实例的信息，并通过负载均衡算法从可用的微服务列表中选择合适的服务来处理请求。服务提供方和服务消费方都是Eureka Client。</p>
</li>
</ul>
<p>Eureka Server和Eureka Client之间的协作使得微服务可以快速地、灵活地进行部署和扩展，并且可以轻松地进行服务监控和故障排除。</p>
<h3 id="使用方法-3"><a href="#使用方法-3" class="headerlink" title="使用方法"></a>使用方法</h3><ol>
<li>在Eureka Server中，添加pom依赖（spring-cloud-strater-eureka-server），在启动类上添加@EnableEurekaServer注解表示该服务是一个EurekaServer。</li>
<li>在Eureka Client中，添加pom依赖（spring-cloud-strater-eureka），在application.yml中添加配置（配置注册中心的地址defaultZone和自身的名字name），在启动类上添加@EnableEurekaClient注解表示该服务是一个EurekaClient。</li>
</ol>
<h3 id="健康检查"><a href="#健康检查" class="headerlink" title="健康检查"></a>健康检查</h3><p>Eureka通过客户端（Eureka Client）的心跳包来检测客户端状态，但是这种方式只能检测客户端是否在线，不能保证客户端可以对外提供服务，这是因为客户端可能依赖了其它的资源，如数据库、缓存等，如果其依赖的服务无法正常使用，那么即使客户端在线，也不能对外提供服务，这时就需要客户端自己向Eureka Server提供自身的状态。</p>
<p>开启Eureka的健康检查，客户端就能将自身状态就可以传送给Eureka Server了。在application.yml中添加配置即可开启Eureka的健康检查。</p>
<p>Eureka Client有如下状态：UP、DOWN、STARTING、OUT_OF_SERVICE、UNKNOWN</p>
<h3 id="自我保护模式"><a href="#自我保护模式" class="headerlink" title="自我保护模式"></a>自我保护模式</h3><p>自我保护模式是一种应对网络异常的安全保护机制，它的理念是宁可同时保留所有实例（健康的实例和不健康的实例），也不盲目注销任何健康的实例。</p>
<h3 id="就近原则"><a href="#就近原则" class="headerlink" title="就近原则"></a>就近原则</h3><p>Eureka有Region和Zone的概念，Region可以理解为区、Zone可以理解为机房。Eureka Serve启动时需要指定自己所在的Zone。Eureka Client启动时也需要指定Zone，Eureka Client会优先请求自己的Zone下的Eureka Serve列表中的Eureka Serve；如果没有指定，会默认使用defaultZone作为自己的Zone。</p>
<h2 id="Config（配置中心）"><a href="#Config（配置中心）" class="headerlink" title="Config（配置中心）"></a>Config（配置中心）</h2><h3 id="功能、特点和组成"><a href="#功能、特点和组成" class="headerlink" title="功能、特点和组成"></a>功能、特点和组成</h3><p>在研发流程中有测试环境、UAT（User Acceptance Testing，用户验收测试）环境、生产环境等，每个微服务对应多个不同环境的配置文件，修改配置文件十分繁琐。这就需要引入配置中心组件。</p>
<p>Spring Cloud Config提供了分布式配置管理功能。特点如下：</p>
<ol>
<li>服务器存储后端的默认实现使用git。</li>
<li>支持丰富的文件格式，包括yml、json、properities等，还可以自定义文件格式。</li>
<li>配合Spring Cloud Bus可实现配置推送。</li>
<li>Spring Boot项目中不需要改动代码，加入一个启动配置文件指明使用Config Server中哪个配置文件即可。</li>
</ol>
<p>主要包含两个部分：Config Client、Config Server。</p>
<h3 id="使用方法-4"><a href="#使用方法-4" class="headerlink" title="使用方法"></a>使用方法</h3><ol>
<li>Config的配置必须放在bootstrap.properities中，才能被正确加载，因为放在bootstrap.properities中才能确保config相关的配置先于application.properities加载（bootstrap.properities的加载先于application.properities）。</li>
<li>在Config Server中，添加pom依赖，在启动类上添加@EnableConfigServer注解表示允许该服务以HTTP形式对外提供配置管理服务。</li>
<li>在Config Client中，添加pom依赖，在启动类上添加@EnableAutoConfiguration注解表示自动向Config Server获取项目的配置。</li>
</ol>
<h3 id="热生效"><a href="#热生效" class="headerlink" title="热生效"></a>热生效</h3><p>热生效是指，让修改后的配置动态生效。</p>
<p>用法是在Config Client的启动类上添加@RefreshScope注解。此外，还需要搭配Spring Cloud Bus，通知Config Client进行本地配置更新。</p>
<h3 id="高可用-1"><a href="#高可用-1" class="headerlink" title="高可用"></a>高可用</h3><p>通过将所有Config Server实例以服务提供方的形式注册到Eureka上，Config Client以服务消费方的形式区Eureka获取Config Server的实例。由Eureka提供故障转移、服务注册和发现等功能。</p>
<p>使用方法：</p>
<ol>
<li><p>在Config Server（作为Eureka Client）添加pom依赖，在配置文件application.yml中添加对Eureka注册中心的配置，在启动类上添加注解（具体方法见Eureka的使用方法之Eureka Client的配置方法）。</p>
</li>
<li><p>在Config Client（也是作为Eureka Client）添加pom依赖，在启动类上添加注解（具体方法见Eureka的使用方法之Eureka Client的配置方法）。</p>
<p>不同的是添加配置的位置是bootstrap.yml，在bootstrap.yml中添加对Eureka注册中心的配置，并在原Config Client配置的基础上删除spring.cloud.config.uri的静态的指定，改为将spring.cloud.config.discovery.enabled设为true， 并通过spring.cloud.config.discovery.serviceId指定在注册中心配置的serviceId。</p>
</li>
</ol>
<h1 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h1><h2 id="Ribbon"><a href="#Ribbon" class="headerlink" title="Ribbon"></a>Ribbon</h2><h3 id="功能-2"><a href="#功能-2" class="headerlink" title="功能"></a>功能</h3><p>Ribbon最主要的功能是提供了客户端的负载均衡算法，还提供了一系列完整的服务调用配置项，如连接超时、失败重试、访问权重、调用优先级等。</p>
<h3 id="使用方法-5"><a href="#使用方法-5" class="headerlink" title="使用方法"></a>使用方法</h3><ol>
<li><p>在Eureka的客户端代码的基础上进行改造</p>
<p>将DiscoveryClient改为LoadBalancerClient，并调用其choose方法，会使原先得到的ServiceInstance集合变为得到单个ServiceInstance实例。</p>
</li>
<li><p>使用@LoadBalanced注解</p>
<p>在启动类上（通常，有时也用在配置类上、组件类上等）使用@RibbonClient注解设置需要调用的服务名，在RestTemplate的bean对象上使用@LoadBalanced注解。</p>
<p>如果想要自定义参数和策略，就需要使用自定义配置：</p>
<ol>
<li>使用@RibbonClient注解时，可以设置configuration的值来自定义配置类。</li>
<li>也可以使用配置文件，在配置文件中指定使用的配置类</li>
</ol>
</li>
</ol>
<h1 id="熔断器（断路器）"><a href="#熔断器（断路器）" class="headerlink" title="熔断器（断路器）"></a>熔断器（断路器）</h1><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h3 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h3><ol>
<li>漏桶算法：漏捅按固定流量流出</li>
<li>令牌桶算法：生成令牌的速度是恒定的，而拿令牌的数量是没有限制的</li>
<li>固定时间窗口法：在一个时间间隔内进行限制，存在临界点缺陷，在时间临界点前后的极短时间内容易遭受攻击</li>
<li>滑动时间窗口算法：可以有效规避固定时间窗口算法中时间临界点的问题</li>
</ol>
<h3 id="隔离方法"><a href="#隔离方法" class="headerlink" title="隔离方法"></a>隔离方法</h3><ol>
<li>线程池隔离：给服务调用设置固定数量的线程，如果被调用服务的正在被使用的线程数达到了限制的数量，就不会再调用，使用存在代价，代价包括线程的上下文切换。</li>
<li>信号量隔离：信号量隔离是使用Semaphore实现的，通过设置的最大信号量控制对资源调用的数量，拿不到信号时直接拒绝。</li>
<li>通过响应时间隔离：当依赖的资源出现响应时间过长的情况，就拒绝对该资源的请求。</li>
<li>QPS（每秒请求次数）隔离：当调用服务的QPS达到阈值时，就拒绝。</li>
</ol>
<h3 id="熔断概念"><a href="#熔断概念" class="headerlink" title="熔断概念"></a>熔断概念</h3><p>当下游服务不可用时，上游服务为了保证自身服务的可用性，不再继续调用目标服务，而是直接返回。</p>
<h3 id="降级概念"><a href="#降级概念" class="headerlink" title="降级概念"></a>降级概念</h3><p>降级是系统将某些不重要的业务或接口的功能停止，以应对高负载的场景。</p>
<h2 id="Hystrix"><a href="#Hystrix" class="headerlink" title="Hystrix"></a>Hystrix</h2><p>微服务架构中一般存在较多的服务单元，这样就出现某个单元因为网络原因等问题出现延迟，如果此时请求方的请求不断增多，时间一长就会形成调用方的任务积压，阻塞请求占用大量的系统的线程、IO等资源，导致调用方的服务瘫痪。进一步的会影响调用方的上游，从而产生“雪崩效应”。</p>
<blockquote>
<p>雪崩效应（Avalanche Effect）是指在分布式系统中，由于某个服务的故障或不可用，从而导致整个系统的连锁反应，最终导致整个系统无法正常工作的现象。</p>
<p>具体来说，当一个服务出现故障时，其它依赖该服务的服务都会请求该服务，并等待响应。如果这些请求全部被堵塞住或响应时间过长，则会消耗掉资源，进而阻塞或延迟其它请求，造成一系列连锁反应。这可能会导致更多的请求堆积，使整个系统变得异常缓慢或直接崩溃。</p>
<p>为了避免雪崩效应，需要考虑以下几种解决方案：</p>
<ol>
<li>限流：限制对服务的访问量和频率，避免过多的请求排队等待。</li>
<li>降级：在一定条件下降低服务的质量和功能，如缩短超时时间、返回默认值等，以保证系统的稳定性。</li>
<li>熔断：在服务发生故障时快速断开与该服务的连接，并通过降级方式替代该服务响应请求，以避免因故障而导致其它服务出现雪崩效应。</li>
</ol>
<p>综上所述，为了保证分布式系统的健壮性和可用性，在设计和实现中需要充分考虑服务之间的依赖和关系，并采取一些必要的措施来避免或应对雪崩问题。</p>
</blockquote>
<p>为解决这一问题，可以使用熔断器（Circuit Breaker）。</p>
<p>熔断器的原理是：当某个服务单元发生故障，通过熔断器的故障监控，向调用方返回一个错误请求，而不是长时间的等待响应，避免故障在分布式系统中蔓延。</p>
<h3 id="熔断原理"><a href="#熔断原理" class="headerlink" title="熔断原理"></a>熔断原理</h3><p>Hystrix提供了熔断模式和隔离模式来缓解雪崩效应。这两种方案都属于阻塞发生之后的应对策略，而非预防性策略（如限流）。</p>
<ol>
<li><p>熔断模式（服务熔断）</p>
<p>如果某个服务响应调用太慢，则熔断对该服务的调用，即后续请求不再调用该服务，直接返回并快速释放资源。</p>
<p>熔断恢复：被熔断的请求不是永久被切断，而是暂停一段时间（默认是5秒）之后允许部分请求通过，若请求都是健康的（ResponseTime&lt;250ms），则取消熔断。</p>
</li>
<li><p>隔离模式（服务降级）</p>
<p>为每个依赖调用分配一个线程池，如果线程池已满，调用将立即被拒绝，加速失败时间。</p>
</li>
</ol>
<p>服务调用的各种结果（成功、异常、超时、拒绝）都会上报给熔断器，加入bucket计算发生的总数。</p>
<h3 id="使用方法-6"><a href="#使用方法-6" class="headerlink" title="使用方法"></a>使用方法</h3><ol>
<li><p>引入Hystrix的maven依赖，spring-cloud-starter-hystrix</p>
</li>
<li><p>在启动类中添加@EnableCircutBreaker注解或@EnableHystrix注解</p>
</li>
<li><p>在controller方法上添加@HystrixCommand，表示开启对该方法的熔断检测功能。</p>
</li>
<li><p>配置方法：</p>
<ol>
<li>直接对@HystrixCommand注解的commandProperities设置@HystirxProperities注解的参数进行配置。</li>
<li>使用配置文件进行配置，Hystrix的大部分配置都以hystrix.command开头</li>
</ol>
<p>可以配置的参数包括：</p>
<ul>
<li>隔离策略的超时时间</li>
<li>最大请求数</li>
<li>进行短路的失败请求的次数阈值</li>
<li>短路后多长时间之后进行重试</li>
<li>出错百分比阈值</li>
<li>……</li>
</ul>
</li>
</ol>
<h3 id="监测工具"><a href="#监测工具" class="headerlink" title="监测工具"></a>监测工具</h3><p>熔断的监测工具有两个：</p>
<ol>
<li>Hystrix Dashboard：针对Hystrix进行实时监控的工具，通过Hystrix Dashboard可以直观的看到各个Hystrix命令的请求响应时间、请求成功率等数据。</li>
<li>Turbine：只使用Hystrix Dashboard只能看到单个应用内的服务信息，而Turbine能够汇总系统内多个服务的数据并显示到Hystrix Dashboard上。</li>
</ol>
<p>Hystrix Dashboard和Turbine监测工具使用方法：</p>
<ol>
<li>在需要被监测的项目中，引入依赖spring-boot-starter-actuator</li>
<li>在仪表盘应用中，引入依赖spring-cloud-starter-hystrix-dashboard，主类中添加@EnableHystrixDashboard注解开启仪表板</li>
<li>在上面创建的仪表盘应用中，继续添加Turbine的依赖spring-cloud-starter-turbine，在配置文件application.yml中添加配置信息，除了要配置Turbine，还需要指定Eureka的地址，使Turbine能够到注册中心查找需要监测的服务实例。</li>
<li>在被监测的服务项目中，也需要进行配置，保证配置中的eureka.instance.metadata-map.cluster和Turbine中的clusterConfig的配置名称一致。</li>
<li>请求Turbine的聚合监测面板地址就能看到聚合后的图形化监测信息。</li>
</ol>
<h2 id="Sentinel"><a href="#Sentinel" class="headerlink" title="Sentinel"></a>Sentinel</h2><h3 id="功能-3"><a href="#功能-3" class="headerlink" title="功能"></a>功能</h3><p> <a target="_blank" rel="noopener" href="https://github.com/alibaba/Sentinel">Sentinel</a> 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。</p>
<p>Sentinel在服务隔离的实现方式和Hystrix完全不一样，Hystrix使用的是通过线程池隔离，而Sentinel采用了两种不同的手段，信号量隔离、响应时间隔离、QPS隔离。</p>
<p>Sentinel的系统负载保护意思是，Sentinel从系统的维度提供了保护，确保系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围内处理最多的请求。</p>
<h3 id="使用方法-7"><a href="#使用方法-7" class="headerlink" title="使用方法"></a><a target="_blank" rel="noopener" href="https://github.com/alibaba/spring-cloud-alibaba/wiki/Sentinel">使用方法</a></h3><ol>
<li>引入依赖spring-cloud-starter-alibaba-sentinel</li>
<li>添加配置，如Sentinal DashBoard的地址、端口</li>
<li>在Service类要使用Sentinel的方法上使用@SentinelResource注解</li>
</ol>
<h3 id="Sentinel持久化"><a href="#Sentinel持久化" class="headerlink" title="Sentinel持久化"></a><a target="_blank" rel="noopener" href="https://github.com/all4you/sentinel-tutorial/blob/master/sentinel-practice/sentinel-persistence-rules/sentinel-persistence-rules.md">Sentinel持久化</a></h3><p>无论是通过硬编码的方式来更新规则，还是通过接入 Sentinel Dashboard 后，在页面上操作来更新规则，都无法避免一个问题，那就是服务重新后，规则就丢失了，因为默认情况下规则是保存在内存中的。</p>
<p>目前 Sentinel 中默认实现了5种规则持久化的方式，分别是：file、redis、nacos、zk和apollo。</p>
<p>使用方法：</p>
<ol>
<li>引入sentinel持久化依赖</li>
<li>增加配置</li>
<li>实现init()函数</li>
</ol>
<h3 id="Sentinal-DashBoard配置项"><a href="#Sentinal-DashBoard配置项" class="headerlink" title="Sentinal DashBoard配置项"></a>Sentinal DashBoard配置项</h3><h4 id="流控模式"><a href="#流控模式" class="headerlink" title="流控模式"></a>流控模式</h4><ol>
<li>直接：api达到限流条件时，直接限流</li>
<li>关联：当关联的资源达到阈值时，就限流自己</li>
<li>链路：只记录指定链路上的流量（指资源从入口资源进来的流量，如果达到阈值，就进行限流）</li>
</ol>
<h4 id="流控效果"><a href="#流控效果" class="headerlink" title="流控效果"></a>流控效果</h4><ol>
<li>快速失败：直接失败并抛出异常</li>
<li><a target="_blank" rel="noopener" href="https://sentinelguard.io/zh-cn/blog/sentinel-golang-0-6-0-release.html">Warm UP</a>：当系统长期处于低水位的情况下，流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。比如刚启动的服务，数据库连接池可能还未初始化，缓存也处于空的状态，这时候激增的流量非常容易导致服务崩溃。这时我们就可以利用 Sentinel 的 Warm-Up 流控模式，控制通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，而不是在一瞬间全部放行。这样可以给冷系统一个预热的时间，避免冷系统被压垮。</li>
<li>排队等待（<a target="_blank" rel="noopener" href="https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6-%E5%8C%80%E9%80%9F%E6%8E%92%E9%98%9F%E6%A8%A1%E5%BC%8F">匀速排队模式</a>）：这种方式适合用于请求以突刺状来到，这个时候我们不希望一下子把所有的请求都通过，这样可能会把系统压垮；同时我们也期待系统以稳定的速度，逐步处理这些请求，以起到“削峰填谷”的效果，而不是拒绝所有请求。</li>
</ol>
<h4 id="熔断降级"><a href="#熔断降级" class="headerlink" title="熔断降级"></a>熔断降级</h4><p><a target="_blank" rel="noopener" href="https://sentinelguard.io/zh-cn/docs/circuit-breaking.html">Sentinel 提供以下几种熔断策略</a>：</p>
<ul>
<li>慢调用比例 (<code>SLOW_REQUEST_RATIO</code>)：选择以慢调用比例作为阈值，需要设置允许的慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长（<code>statIntervalMs</code>）内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。</li>
<li>异常比例 (<code>ERROR_RATIO</code>)：当单位统计时长（<code>statIntervalMs</code>）内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。异常比率的阈值范围是 <code>[0.0, 1.0]</code>，代表 0% - 100%。</li>
<li>异常数 (<code>ERROR_COUNT</code>)：当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。</li>
</ul>
<h4 id="热点参数限流"><a href="#热点参数限流" class="headerlink" title="热点参数限流"></a>热点参数限流</h4><p><a target="_blank" rel="noopener" href="https://sentinelguard.io/zh-cn/docs/parameter-flow-control.html">热点参数限流</a>会根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流。</p>
<p>Sentinel 利用 LRU 策略统计最近最常访问的热点参数，结合令牌桶算法来进行参数级别的流控。</p>
<p>要使用热点参数限流功能，需要引入sentinel-parameter-flow-control，并使用<code>@SentinelResource</code> 注解（与Hysyrix的@HysyrixCommand类似）定义资源</p>
<h1 id="声明式RESTful客户端"><a href="#声明式RESTful客户端" class="headerlink" title="声明式RESTful客户端"></a>声明式RESTful客户端</h1><h2 id="Feign"><a href="#Feign" class="headerlink" title="Feign"></a>Feign</h2><p>使用Ribbon的缺点是需要对请求拼接参数，而<a target="_blank" rel="noopener" href="https://cloud.spring.io/spring-cloud-openfeign/reference/html/#spring-cloud-feign">Feign</a>解决了这个问题。使用Feign，可以通过定义接口并添加注解的方式来描述服务间的交互，而无需手动编写HTTP请求代码。</p>
<h3 id="使用方法-8"><a href="#使用方法-8" class="headerlink" title="使用方法"></a><a target="_blank" rel="noopener" href="https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-feign.html">使用方法</a></h3><ol>
<li><p>添加依赖：spring-cloud-starter-feign</p>
</li>
<li><p>在启动类上添加注解：@EnableFeignClients，该注解的defaultConfiguration属性可以指定所有Feign接口的配置类。</p>
</li>
<li><p>定义Feign接口：使用@FeignClient(name&#x3D;”xxx”)注解定义Feign接口。</p>
<p>该注解除了name属性还有，可以指定用户自定义的配置类的configuration属性，可以在使用了Hystrix的服务中指定熔断的FallBack类的fallback属性。</p>
</li>
</ol>
<h1 id="路由网关"><a href="#路由网关" class="headerlink" title="路由网关"></a>路由网关</h1><p>API 网关是一个搭建在客户端和微服务之间的服务，我们可以在 API 网关中处理一些非业务功能的逻辑，例如权限验证、监控、缓存、请求路由等。</p>
<p>API 网关就像整个微服务系统的门面一样，是系统对外的唯一入口。有了它，客户端会先将请求发送到 API 网关，然后由 API 网关根据请求的标识信息将请求转发到微服务实例。</p>
<h2 id="Zuul"><a href="#Zuul" class="headerlink" title="Zuul"></a>Zuul</h2><h3 id="功能-4"><a href="#功能-4" class="headerlink" title="功能"></a>功能</h3><p>Zuul的具体作用就是服务转发，Zuul可以作为为资源的统一访问入口。</p>
<p>此外Zuul还提供了过滤器的功能，可以用来进行接口权限校验、限流、统计等。</p>
<h3 id="使用方法-9"><a href="#使用方法-9" class="headerlink" title="使用方法"></a>使用方法</h3><p>Zuul用做服务转发的使用方法：</p>
<ol>
<li><p>添加pom依赖，spring-cloud-starter-zuul</p>
</li>
<li><p>在启动类上添加@EnableZuulProxy注解</p>
</li>
<li><p>在application.yml文件中添加配置，zuul.routes的配置格式如下：</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-comment">#第一种</span><br>[<span class="hljs-string">serviceId</span>]<span class="hljs-string">:</span>					<span class="hljs-comment">#对应Eureka中的serviceId，规则名与serviceId相同</span><br>	<span class="hljs-attr">path:</span> <span class="hljs-string">/providerURL/**</span>		<span class="hljs-comment">#转发哪些path（URL的path部分，见下文的补充）</span><br><span class="hljs-comment">#第二种</span><br><span class="hljs-attr">customName1:</span>					<span class="hljs-comment">#自定义的转发规则名称</span><br>	<span class="hljs-attr">path:</span> <span class="hljs-string">/fromURL1/**</span>			<span class="hljs-comment">#转发哪些path</span><br>	<span class="hljs-attr">url:</span> <span class="hljs-string">http://localhost:8081</span>	<span class="hljs-comment">#转发到哪个scheme://domain:port</span><br><span class="hljs-attr">customName2:</span>					<br>	<span class="hljs-attr">path:</span> <span class="hljs-string">/fromURL2/**</span>			<br>	<span class="hljs-attr">url:</span> <span class="hljs-string">http://localhost:8082</span>	<br></code></pre></td></tr></table></figure>

<p>示例：</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">zuul:</span><br>  <span class="hljs-attr">host:</span><br>    <span class="hljs-attr">socket-timeout-millis:</span> <span class="hljs-number">60000</span><br>    <span class="hljs-attr">connect-timeout-millis:</span> <span class="hljs-number">60000</span><br>  <span class="hljs-attr">routes:</span><br>    <span class="hljs-attr">frameFronted:</span><br>      <span class="hljs-attr">path:</span> <span class="hljs-string">/fronted/frame/**</span><br>      <span class="hljs-attr">url:</span> <span class="hljs-string">http://localhost:8111</span><br>    <span class="hljs-attr">loginFronted:</span><br>      <span class="hljs-attr">path:</span> <span class="hljs-string">/fronted/login/**</span><br>      <span class="hljs-attr">url:</span> <span class="hljs-string">http://localhost:8222</span><br></code></pre></td></tr></table></figure></li>
</ol>
<p>其它配置参数：</p>
<ol>
<li>忽略匹配：ingoredPatterns参数可以配置忽略URL</li>
<li>敏感Header过滤：在请求的转发中默认会转发HTTP的Header信息，然而可能有些敏感信息不能被转发给下游系统，如Cookie。可以通过sensitiveHeaders参数进行配置，各项之间使用逗号分隔。</li>
</ol>
<p>匹配顺序：如果想按配置的顺序进行路由规则控制，则需要使用YMAL，如果使用的是properities文件，则会丢失顺序。</p>
<p>补充：</p>
<p>URL结构：</p>
<img src="./Spring-Cloud/image-20230525183105335.png" alt="image-20230525183105335" style="zoom:80%;" />

<h2 id="Gateway"><a href="#Gateway" class="headerlink" title="Gateway"></a>Gateway</h2><h3 id="功能和特点"><a href="#功能和特点" class="headerlink" title="功能和特点"></a>功能和特点</h3><p>Spring Cloud Gateway 是 Spring Cloud 团队基于 Spring 5.0、Spring Boot 2.0 和 Project Reactor 等技术开发的高性能 API 网关组件。</p>
<p>Spring Cloud Gateway 旨在提供一种简单而有效的途径来发送 API，并为它们提供横切关注点，例如：安全性，监控&#x2F;指标和弹性。 </p>
<blockquote>
<p>Spring Cloud Gateway 是基于 WebFlux 框架实现的，而 WebFlux 框架底层则使用了高性能的 Reactor 模式通信框架 Netty。</p>
</blockquote>
<p>Spring Cloud Gateway 具有以下特性：</p>
<ul>
<li>基于 Spring Framework 5、Project Reactor 和 Spring Boot 2.0 构建。</li>
<li>能够在任意请求属性上匹配路由。</li>
<li>predicates（断言） 和 filters（过滤器）是特定于路由的。</li>
<li>集成了 Hystrix 熔断器。</li>
<li>集成了 Spring Cloud DiscoveryClient（服务发现客户端）。</li>
<li>易于编写断言和过滤器。</li>
<li>能够限制请求频率。</li>
<li>能够重写请求路径。</li>
</ul>
<p>可以通过配置使Gateway兼容HTTPS请求，</p>
<p>核心概念（<a target="_blank" rel="noopener" href="https://cloud.spring.io/spring-cloud-gateway/reference/html/#glossary">Glossary</a>）</p>
<p>Spring Cloud GateWay 最主要的功能就是路由转发，而在定义转发规则时主要涉及了以下三个核心概念，如下表。</p>
<table>
<thead>
<tr>
<th>核心概念</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>Route（路由）</td>
<td>网关最基本的模块。它由一个 ID、一个目标 URI、一组断言（Predicate）和一组过滤器（Filter）组成。</td>
</tr>
<tr>
<td>Predicate（断言）</td>
<td>路由转发的判断条件，我们可以通过 Predicate 对 HTTP 请求进行匹配，例如请求方式、请求路径、请求头、参数等，如果请求与断言匹配成功，则将请求转发到相应的服务。</td>
</tr>
<tr>
<td>Filter（过滤器）</td>
<td>过滤器，我们可以使用它对请求进行拦截和修改，还可以使用它对上文的响应进行再处理。</td>
</tr>
</tbody></table>
<blockquote>
<p>注意：其中 Route 和 Predicate 必须同时声明（路由断言）。</p>
</blockquote>
<h3 id="断言的类型"><a href="#断言的类型" class="headerlink" title="断言的类型"></a>断言的类型</h3><ol>
<li>After</li>
<li>Before</li>
<li>Between</li>
<li>Cookie</li>
<li>Headers</li>
<li>Host</li>
<li>Method</li>
<li>Path</li>
<li>Query</li>
<li>RemoteAddr</li>
</ol>
<p>多个路由断言可以通过与或非等逻辑连接。</p>
<h3 id="过滤器的类型"><a href="#过滤器的类型" class="headerlink" title="过滤器的类型"></a>过滤器的类型</h3><ol>
<li>AddRequestHeader</li>
<li>AddRequestParameter</li>
<li>AddResponseHeader</li>
<li>Hystrix</li>
<li>PrefixPath</li>
<li>RedictTo</li>
<li>RemoteNonProxyHeaders</li>
<li>RemoveRequestHeader</li>
<li>RemoveResponseHeader</li>
<li>RewritePath</li>
<li>SaveSession</li>
<li>SetPath</li>
<li>SetResponseHeader</li>
<li>SetStatus</li>
<li>StripPrefix</li>
<li>Retry</li>
</ol>
<h3 id="工作流程如下图"><a href="#工作流程如下图" class="headerlink" title="工作流程如下图"></a>工作流程如下图</h3><img src="./Spring-Cloud/image-20230525221748527.png" alt="image-20230525221748527" style="zoom: 80%;" />                                                                                                                                                                                                                                                                                                                       

<h1 id="调用链跟踪"><a href="#调用链跟踪" class="headerlink" title="调用链跟踪"></a>调用链跟踪</h1><h2 id="Sleuth"><a href="#Sleuth" class="headerlink" title="Sleuth"></a>Sleuth</h2><blockquote>
<p>Sleuth</p>
<p> &#x2F; sluːθ</p>
<p>侦查；侦察；警犬</p>
</blockquote>
<h3 id="功能-5"><a href="#功能-5" class="headerlink" title="功能"></a>功能</h3><p>要实现准确快速地定位到线上故障，比较成熟的方案是使用调用链跟踪。调用链跟踪监测系统可以实现如下的功能：</p>
<ol>
<li>快速定位故障</li>
<li>各个调用环节的性能分析</li>
<li>数据分析</li>
</ol>
<p>Spring Cloud Sleuth是Spring Cloud生态中实现调用链跟踪的子项目，Spring Cloud Sleuth可以结合Zipkin，将消息发送到Zipkin，利用Zipkin存储信息，利用Zipkin UI展示数据，也可以只是简单的把数据存储在日记中。</p>
<h3 id="术语（Terminology）"><a href="#术语（Terminology）" class="headerlink" title="术语（Terminology）"></a>术语（<a target="_blank" rel="noopener" href="https://docs.spring.io/spring-cloud-sleuth/docs/3.1.8/reference/htmlsingle/spring-cloud-sleuth.html#getting-started-terminology">Terminology</a>）</h3><p>Spring Cloud Sleuth borrows <a target="_blank" rel="noopener" href="https://research.google.com/pubs/pub36356.html">Dapper’s</a> terminology.</p>
<p><strong>Span</strong>: The basic unit of work. For example, sending an RPC is a new span, as is sending a response to an RPC. Spans also have other data, such as descriptions, timestamped events, key-value annotations (tags), the ID of the span that caused them, and process IDs (normally IP addresses).</p>
<p>Spans can be started and stopped, and they keep track of their timing information. Once you create a span, you must stop it at some point in the future.</p>
<p><strong>Trace:</strong> A set of spans forming a tree-like structure. For example, if you run a distributed big-data store, a trace might be formed by a <code>PUT</code> request.</p>
<p><strong>Annotation&#x2F;Event:</strong> Used to record the existence of an event in time.</p>
<p>Conceptually in a typical RPC scenario we mark these events to highlight what kind of an action took place (it doesn’t mean that physically such an event will be set on a span).</p>
<ul>
<li><strong>cs</strong>: Client Sent. The client has made a request. This annotation indicates the start of the span.</li>
<li><strong>sr</strong>: Server Received: The server side got the request and started processing it. Subtracting the <code>cs</code> timestamp from this timestamp reveals the network latency.</li>
<li><strong>ss</strong>: Server Sent. Annotated upon completion of request processing (when the response got sent back to the client). Subtracting the <code>sr</code> timestamp from this timestamp reveals the time needed by the server side to process the request.</li>
<li><strong>cr</strong>: Client Received. Signifies the end of the span. The client has successfully received the response from the server side. Subtracting the <code>cs</code> timestamp from this timestamp reveals the whole time needed by the client to receive the response from the server.</li>
</ul>
<h2 id="Zipkin"><a href="#Zipkin" class="headerlink" title="Zipkin"></a>Zipkin</h2><h3 id="功能-6"><a href="#功能-6" class="headerlink" title="功能"></a>功能</h3><p>Zipkin是分布式实时数据追踪系统，由Twitter公司开发。主要功能是聚集来自各系统的实时监控数据。</p>
<p>主要由四部分组成：</p>
<ol>
<li>收集器：收集追踪数据。</li>
<li>数据存储：数据存储默认使用内存存储，也可以替换成MySQL、Cassandra等。</li>
<li>查询：向其它服务服务提供数据查询功能</li>
<li>Web页面</li>
</ol>
<h3 id="使用方法-10"><a href="#使用方法-10" class="headerlink" title="使用方法"></a>使用方法</h3><ol>
<li>创建Zipkin Server、<ol>
<li>添加pom依赖zipkin-autoconfigure-ui和zipkin-server；</li>
<li>在启动类中添加@EnableZipkinServer，表示启动Zipkin服务端。</li>
</ol>
</li>
<li>在服务中添加依赖和配置：<ol>
<li>添加对Sleuth的依赖spring-cloud-starter-sleuth（生成带有spanId和traceId的日志）和spring-cloud-sleuth-zipkin（将日志以HTTP协议传输到Zipkin Server）</li>
<li>配置zipkin的base-url（Zipkin Server的地址）、sleuth的samper.percentage（创建并传输日志的传输比例）</li>
</ol>
</li>
</ol>
<h3 id="整合Stream"><a href="#整合Stream" class="headerlink" title="整合Stream"></a>整合Stream</h3><p>由于将日志传输到Zipkin Server的方式是HTTP请求，请求量太大时会给系统带来很大压力，如果改为使用Stream消息机制传输监控日志就可以减轻压力。</p>
<p>Zipkin与Spring Cloud Stream整合的方法是：</p>
<ol>
<li>在Zipkin Server端<ol>
<li>添加对Stream消息中间件的依赖（以RabbitMQ为例）：spring-cloud-sleuth-zipkin-stream；spring-cloud-sleuth-stream；spring-cloud-stream-binder-rabbit。</li>
<li>在配置文件中添加对Stream的配置信息和RabbitMQ的连接信息。</li>
<li>将Zipkin Server的启动类注解@EnableZipkinServer改为@EnableZipkinStreamServer。</li>
</ol>
</li>
<li>在服务端<ol>
<li>将spring-cloud-sleuth-zipkin依赖注掉，在此基础上添加spring-cloud-sleuth-stream和spring-cloud-stream-binder-rabbit依赖。</li>
<li>和在Zipkin Server端一样，配置文件中添加对Stream的配置信息和RabbitMQ的连接信息。</li>
</ol>
</li>
</ol>
<h3 id="整合MySQL"><a href="#整合MySQL" class="headerlink" title="整合MySQL"></a>整合MySQL</h3><p>Zipkin默认将数据存储在内存中，如果要持久化这些数据可以整合MySQL.</p>
<p>Zipkin与MySQL整合的方法是：</p>
<ol>
<li>添加对JDBC和MySQL驱动的依赖，spring-boot-starter-jdbc和mysql-connector-java</li>
<li>在配置文件中配置MySQL的连接信息，设置initialize参数为true（在启动时创建表结构  ）</li>
</ol>
<h1 id="消息驱动"><a href="#消息驱动" class="headerlink" title="消息驱动"></a>消息驱动</h1><h2 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h2><h3 id="功能和概念"><a href="#功能和概念" class="headerlink" title="功能和概念"></a>功能和概念</h3><p>在企业级应用中处理非同步场景、消息通知、应用间解耦等场景经常会使用消息中间件，常见的消息中间件有如，ActiveMQ、RabbitMQ、MetaMQ、Kafka、Redis等。</p>
<p><a target="_blank" rel="noopener" href="https://spring.io/projects/spring-cloud-stream">Spring Cloud Stream</a>是一个构建事件驱动或消息驱动微服务的框架，提供了一个灵活的编程模型，该模型建立在已经建立和熟悉的 Spring 习惯用法和最佳实践之上，包括对持久发布&#x2F;订阅语义、消费者组和有状态分区的支持。</p>
<p>利用Stream可以对消息中间件实现进一步的封装，使代码更具有通用性，降低项目对消息中间件的耦合。更重要的是这一就可以方便地实现消息中间件的混用，比如生产者使用Kafka，消费者使用RabbitMQ。</p>
<p>Stream目前支持的中间件：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/spring-cloud/spring-cloud-stream-binder-rabbit">RabbitMQ</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/spring-cloud/spring-cloud-stream-binder-kafka">Apache Kafka</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/spring-cloud/spring-cloud-stream-binder-kafka/tree/master/spring-cloud-stream-binder-kafka-streams">Kafka Streams</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/spring-cloud/spring-cloud-stream-binder-aws-kinesis">Amazon Kinesis</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/spring-cloud/spring-cloud-gcp/tree/master/spring-cloud-gcp-pubsub-stream-binder">Google PubSub <em>(partner maintained)</em></a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/SolaceProducts/spring-cloud-stream-binder-solace">Solace PubSub+ <em>(partner maintained)</em></a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Azure/azure-sdk-for-java/tree/main/sdk/spring/spring-cloud-azure-stream-binder-eventhubs">Azure Event Hubs <em>(partner maintained)</em></a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Azure/azure-sdk-for-java/tree/main/sdk/spring/spring-cloud-azure-stream-binder-servicebus">Azure Service Bus <em>(partner maintained)</em></a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/idealo/spring-cloud-stream-binder-sqs">AWS SQS <em>(partner maintained)</em></a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/idealo/spring-cloud-stream-binder-sns">AWS SNS <em>(partner maintained)</em></a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/alibaba/spring-cloud-alibaba/wiki/RocketMQ-en">Apache RocketMQ <em>(partner maintained)</em></a></li>
</ul>
<p>概念：</p>
<ul>
<li><em>Bindings</em>（绑定）：是一组接口，以声明方式标识输入和输出通道。在<code>@EnableBinding</code>注解中，你可以指定要绑定的通道集合。</li>
<li><em>Binder</em>（绑定器）：是消息中间件的实现，例如Kafka或RabbitMQ。绑定器负责将应用程序与特定的消息中间件进行连接和通信。</li>
<li><em>Channel</em>（通道）：代表消息中间件与应用程序之间的通信管道。通道可以是输入通道（用于接收消息）或输出通道（用于发送消息）。</li>
<li><em>StreamListeners</em>（流监听器）：是在Bean中定义的用于处理消息的方法。这些方法会自动在通道上接收到消息后被调用。在调用之前，消息转换器（MessageConverter）会执行消息的序列化和反序列化操作，将消息转换为中间件特定的事件和领域对象类型&#x2F;POJO之间进行转换。</li>
<li><em>Message Schemas</em>（消息模式）：用于消息的序列化和反序列化的模式。消息模式可以静态地从位置读取或动态加载，支持领域对象类型的演进。消息模式可以确保消息在不同系统之间的一致性和互操作性。</li>
</ul>
<h3 id="使用方法（以RabbitMQ为例）"><a href="#使用方法（以RabbitMQ为例）" class="headerlink" title="使用方法（以RabbitMQ为例）"></a>使用方法（以RabbitMQ为例）</h3><ol>
<li>启动RabbitMQ服务，比如可以使用Docker启动RabbitMQ</li>
<li>建两个Maven项目，分别作为消息的生产者和消费者</li>
<li>均添加依赖spring-cloud-starter-stream（对Streram的依赖）和spring-cloud-starter-stream-rabbit（对RabbitMQ的依赖）。</li>
<li>在消费者增加配置，配置消费的消息信息和RabbitMQ服务的信息</li>
<li>在消费者启动类上添加@EnableBinding(BindingsInterface.class)，该注解表示为该Spring Boot项目增加Stream通道监听功能。BindingsInterface可以是sink、source、processor或三者的组合：<ol>
<li>sink：只带有输入通道的应用</li>
<li>source：只带有输出通道应用</li>
<li>processor：带有输入通道和输出通道的应用</li>
</ol>
</li>
<li>创建BindingsInterface接口</li>
</ol>
<h1 id="消息总线"><a href="#消息总线" class="headerlink" title="消息总线"></a>消息总线</h1><h2 id="Bus"><a href="#Bus" class="headerlink" title="Bus"></a>Bus</h2><h3 id="功能-7"><a href="#功能-7" class="headerlink" title="功能"></a>功能</h3><p>Bus的一个常用功能是进行配置中心客户端的刷新。当Git Repository改变时，Bus会通过POST请求Config Server的&#x2F;bus&#x2F;refresh，Config Server会从Repository获取最新的信息并传递给Client。通过&#x2F;bus&#x2F;refresh的destination参数可以指定刷新某一台Client实例。</p>
<p>Bus的配置刷新通知功能是基于Spring的事件机制实现的，这些事件是可追踪的。</p>
<h1 id="短生命微服务"><a href="#短生命微服务" class="headerlink" title="短生命微服务"></a>短生命微服务</h1><h2 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h2><h3 id="功能-8"><a href="#功能-8" class="headerlink" title="功能"></a>功能</h3><p><a target="_blank" rel="noopener" href="https://spring.io/projects/spring-cloud-task">官方对Spring Cloud Task的介绍</a>十分简单明了：Spring Cloud Task allows a user to develop and run short lived microservices using Spring Cloud and run them locally, in the cloud, even on Spring Cloud Data Flow. Just add <code>@EnableTask</code> and run your app as a Spring Boot app (single application context).</p>
<p>Task用于支持短生命周期的微服务，该类微服务常见于定时任务、批处理等场景。</p>
<h3 id="使用方法-11"><a href="#使用方法-11" class="headerlink" title="使用方法"></a>使用方法</h3><ol>
<li>添加依赖spring-cloud-task-core</li>
<li>在启动类添加@EnableTask注解</li>
</ol>
<p>Task默认将Task生命周期记录在内存中，可以和数据库集成将其存储到数据库中。 </p>
<p>Task可以通过Stream启动，实现方法是在Task项目中创建一个Sink来监听包含TaskLaunchRequest的消息实现的。</p>
<h1 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a><a target="_blank" rel="noopener" href="https://juejin.cn/post/6844903647197806605">分布式事务</a></h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h3><p>说到数据库事务就不得不说，数据库事务中的四大特性，ACID:</p>
<ul>
<li><p>A（Atomicity，原子性）：事务作为一个整体被执行，要么全部成功，要么全部失败。</p>
</li>
<li><p>C（Consistency，一致性）：事务执行之前和执行之后数据（如数据库中的数据）都必须处于一致性状态。</p>
<p>如果事务成功地完成，那么系统中所有变化将正确地应用，系统处于有效状态。如果在事务中出现错误，那么系统中的所有变化将自动地回滚，系统返回到原始状态。</p>
</li>
<li><p>I（Isolation，隔离性）：一个事务的中间状态对其他事务是不可见的。</p>
</li>
<li><p>D（Durability，持久性）：事务成功完成后，即使在系统出现故障时，对数据的更改仍然存在并且不会撤消。</p>
</li>
</ul>
<h3 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h3><p>BASE理论是Basically Available(基本可用)，Soft State（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。</p>
<p>其核心思想是：</p>
<blockquote>
<p>既是无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。</p>
</blockquote>
<h3 id="分布式事务解决方案"><a href="#分布式事务解决方案" class="headerlink" title="分布式事务解决方案"></a>分布式事务解决方案</h3><h4 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h4><p>2PC（两阶段提交协议）将事务分成两个阶段：</p>
<ul>
<li><p>准备阶段（Prepare Phase）:事务管理器给每个参与者发送Prepare消息，每个数据库参与者在本地执行事务，并写本地的Undo&#x2F;Redo日志，此时事务没有提交。</p>
<p>Undo log是记录修改前的数据，用于数据库回滚，Redo log记录修改后的数据，用于提交事务后写入数据的文件。</p>
</li>
<li><p>提交阶段（Commit Phase）:如果事务管理器收到了参与者的执行失败或者超时消息时，直接给每个参与者发送回滚（Rollback）消息；否则发送提交（Commit）消息。参与者根据事务管理器指令进行提交或者回滚操作，并释放事务处理过程中使用的资源。</p>
</li>
</ul>
<h4 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a>TCC</h4><p>TCC将事务分成三个阶段：</p>
<ol>
<li>Try阶段（Try）：对业务系统进行检测及预留资源。</li>
<li>确认阶段（Confirm）：对业务做确认提交。</li>
<li>撤销阶段（Cancel）：撤销事务。</li>
</ol>
<p>TCC采用的是补偿机制，核心思想是针对每个操作，都要编写一个与其对应的确认和补偿（撤销）操作逻辑。</p>
<h2 id="Seata"><a href="#Seata" class="headerlink" title="Seata"></a><a target="_blank" rel="noopener" href="https://seata.io/zh-cn/docs/overview/what-is-seata.html">Seata</a></h2><p>Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。</p>
<h3 id="Seata术语"><a href="#Seata术语" class="headerlink" title="Seata术语"></a>Seata术语</h3><ul>
<li>TC (Transaction Coordinator) - 事务协调者 - Seata Server</li>
</ul>
<p>维护全局和分支事务的状态，驱动全局事务提交或回滚。</p>
<ul>
<li>TM (Transaction Manager) - 事务管理器</li>
</ul>
<p>定义全局事务的范围：开始全局事务、提交或回滚全局事务。</p>
<ul>
<li>RM (Resource Manager) - 资源管理器</li>
</ul>
<p>管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。</p>
<h3 id="事务模式"><a href="#事务模式" class="headerlink" title="事务模式"></a>事务模式</h3><p>Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式。</p>
<h4 id="AT-模式"><a href="#AT-模式" class="headerlink" title="AT 模式"></a><a target="_blank" rel="noopener" href="https://seata.io/zh-cn/blog/seata-at-lock.html#:~:text=Seata%20AT%20%E6%A8%A1%E5%BC%8F%E6%98%AF%E4%B8%80,%E6%97%A5%E5%BF%97%EF%BC%8C%E6%A3%80%E6%9F%A5%E5%85%A8%E5%B1%80%E9%94%81%E7%AD%89%E3%80%82">AT 模式</a></h4><p>Seata AT 模式是一种非侵入式的分布式事务解决方案，Seata 在内部做了对数据库操作的代理层，我们使用 Seata AT 模式时，实际上用的是 Seata 自带的数据源代理 DataSourceProxy，Seata 在这层代理中加入了很多逻辑，比如插入回滚 undo_log 日志，检查全局锁等。</p>
<p>AT 模式是2PC的演变：</p>
<ol>
<li><p>一阶段</p>
<p>在一阶段中，Seata会拦截“业务SQL”，首先解析SQL语义，找到要更新的业务数据，在数据更新前，保存下”undo log”，然后执行“业务SQL”更新数据，更新之后保存数据“redo log”，最后生成锁，这些操作都是在本地数据库事务内完成，这样保证了一阶段的原子性。</p>
</li>
<li><p>二阶段</p>
<p>相对一阶段，二阶段比较简单，负责整体的回滚和提交，如果之前的一阶段中有本地事务没有通过吗，那么就执行全局回滚，否则执行全局提交，回滚用到的就是一阶段记录的“undo log”，通过回滚记录生成反向更新SQL并执行，已完成分支事务的回滚，当然事务完成后释放所有资源和删除所有日志。</p>
</li>
</ol>
<p>性能：高</p>
<p>模式:：AP，存在数据不一致的中间状态</p>
<p>难易程度：简单，靠SEATA自己解析反向SQL并回滚</p>
<p>使用要求：</p>
<ul>
<li>所有服务与数据库必须要自己拥有管理权，因为要创建UNDO_LOG表</li>
</ul>
<p>应用场景：</p>
<ul>
<li>高并发互联网应用，允许数据出现短时不一致，可通过对账程序或补录来保证最终一致性。</li>
</ul>
<h4 id="TCC模式"><a href="#TCC模式" class="headerlink" title="TCC模式"></a>TCC模式</h4><p>TCC是Try-尝试、Confirm-确认、Cancel-取消Try尝试阶段，对资源进行锁定。Confirm 确认阶段，对资源进行确认，完成操作Cancel 取消阶段，对资源进行还原，取消操作</p>
<p>实现原理</p>
<ul>
<li>在代码与数据表中扩展字段，实现对数据资源的锁定。</li>
</ul>
<p>性能：好</p>
<p>模式：AP，存在数据不一致的中间状态</p>
<p>难易程度：复杂，SEATATC只负责全局事务的提交与回滚指令，具体的回滚处理全靠程序员自己实现</p>
<p>使用要求：</p>
<ul>
<li><p>所有服务与数据库必须要自己拥有管理权</p>
</li>
<li><p>支持异构数据库，可以使用不同选型实现</p>
</li>
</ul>
<p>应用场景：</p>
<ul>
<li>高并发互联网应用，允许数据出现短时不一致，于对账程序或补录来保证最终一致性。</li>
</ul>
<h4 id="SAGA模式"><a href="#SAGA模式" class="headerlink" title="SAGA模式"></a>SAGA模式</h4><p>Saga模式是SEATA提供的长事务解决方案，在Saga模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败，则补偿前面已经成功的参与者，一阶段的正向服务和二阶段的补偿服务都由业务开发实现。</p>
<p>性能：不一定，取决于三方服务</p>
<p>模式：AP，存在数据不一致的中间状态</p>
<p>难易程度：复杂，提交与回滚流程全靠程序员编排</p>
<p>使用要求：</p>
<ul>
<li><p>在当前架构引入状态机机制，类似于工作流</p>
</li>
<li><p>无法保证隔离性</p>
</li>
</ul>
<p>应用场景：</p>
<ul>
<li>需要与第三方交互时才会考虑，例如:调用支付宝支付接口→出库失败-&gt;调用支付宝退款接口</li>
</ul>
<h4 id="XA模式"><a href="#XA模式" class="headerlink" title="XA模式"></a>XA模式</h4><p>基于数据库的XA协议来实现2PC又称为XA方案。</p>
<p>性能：低</p>
<p>模式：CP，强一致性</p>
<p>难易程度：简单，基于数据库自带特性实现，无需改表</p>
<p>使用要求：</p>
<ul>
<li>使用支持XA方案的关系型数据库（(主流都支持)</li>
</ul>
<p>应用场景：</p>
<ul>
<li>金融行业，并发量不大，但数据很重要的项目</li>
</ul>
<h3 id="使用方法-12"><a href="#使用方法-12" class="headerlink" title="使用方法"></a>使用方法</h3><p>以AT模式为例：</p>
<ol>
<li>创建undo_log日志</li>
<li>对Seata两个主要的配置文件file.config和registry.config</li>
<li>添加pom依赖seata-spring-boot-starter</li>
<li>在需要开启分布式事务的业务方法上添加注解@GlobalTransactional</li>
</ol>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><p>胡劲寒. 极简Spring Cloud实战. 北京: 机械工业出版社, 2019.</p>
</li>
<li><p>开课吧,李伟杰,刘雪松,刘自强,王超. Spring Cloud Alibaba微服务开发从入门到实战.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/alibaba/spring-cloud-alibaba/wiki/Sentinel">https://github.com/alibaba/spring-cloud-alibaba/wiki/Sentinel</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://spring-cloud-alibaba-group.github.io/github-pages/hoxton/en-us/index.html">https://spring-cloud-alibaba-group.github.io/github-pages/hoxton/en-us/index.html</a></p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-06T03:03:01.000Z" title="2023/5/6 11:03:01">2023-05-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-05-30T07:46:29.228Z" title="2023/5/30 15:46:29">2023-05-30</time></span><span class="level-item"><a class="link-muted" href="/categories/IT/">IT</a></span><span class="level-item">2 hours read (About 13642 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/06/Redis/">Redis</a></p><div class="content"><h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><h2 id="基础数据结构"><a href="#基础数据结构" class="headerlink" title="基础数据结构"></a>基础数据结构</h2><h3 id="5种基础数据结构"><a href="#5种基础数据结构" class="headerlink" title="5种基础数据结构"></a>5种基础数据结构</h3><h4 id="string（字符串）"><a href="#string（字符串）" class="headerlink" title="string（字符串）"></a>string（字符串）</h4><p>Redis的string是动态字符串，可以被修改，内部实现结构类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配，如果字符串长度小于1MB，扩容方式是加倍现有的空间，如果字符串长度超过1MB，扩容方式是只多扩1MB的空间。</p>
<p>Redis所有数据结构都以唯一的key字符串作为名称</p>
<p>一个常见的用途是缓存用户信息，将用户信息序列化成字符串，存入Redis缓存，取出用户信息的时候会经过一次反序列化的过程</p>
<p>mset、mget命令可以实现对多个字符串进行批量读写</p>
<p>ex后缀可以在set的时候指定过期时间</p>
<p>nx后缀可以在set的时候设置条件，如果key不存在才set</p>
<h4 id="list（列表）"><a href="#list（列表）" class="headerlink" title="list（列表）"></a>list（列表）</h4><p>Redis的列表相当于Java的LinkedList，是双向链表，不是数组。</p>
<p>当 List 中的元素数量较少且元素都比较短时，Redis 通常会采用 ziplist 来存储。ziplist 是一个特殊的双向链表（本质上是一个字节数组），特殊之处在于：没有维护双向指针，prev、next，而是存储了上一个 entry 的长度和当前 entry 的长度，通过长度推算下一个元素。多个ziplist之间使用指针串联起来，这种结构叫做quicklist（快速链表）。</p>
<p>底层使用的是ziplist，即压缩列表</p>
<p>list常用来做异步队列使用，将需要延后处理的任务序列化成字符串放入列表</p>
<p>支持的命令有：rpush、rpop、lpush、lpop、lindex、lrange、ltrim</p>
<h4 id="hash（字典）"><a href="#hash（字典）" class="headerlink" title="hash（字典）"></a>hash（字典）</h4><p>相当于Java中的HashMap，跟HashMap一样，底层也是数组+链表的实现方式，不同的是Redis的hash的值只能是字符串，且rehash的方式也不一样，rehash 是指在哈希表发生扩容时进行的重新哈希操作。扩容过程包括创建新的哈希表、将旧哈希表的元素 rehash 到新哈希表中，redis采用了渐进式哈希扩容的策略，通过分多次操作逐步完成整个扩容过程，避免服务阻塞的问题。</p>
<p>具体来说，Redis 的哈希表扩容过程如下：</p>
<ol>
<li><p>创建新哈希表：系统会根据当前数据库的元素数量和设置的负载因子计算出扩容所需的最小桶数，然后创建一个新的哈希表，将其指针保存在旧哈希表的 rehashidx 属性中。</p>
</li>
<li><p>逐步 rehash 元素：从旧哈希表中取出一个桶（或一个链表），并将其中的元素 rehash 到新哈希表中，如果新哈希表中的相应桶为空，则直接插入元素；如果不为空，则使用链表结构将其作为链表头插入。这个过程需要遍历旧哈希表中所有的非空桶，每次操作都只处理一个桶中的元素，避免一次性处理过多数据。</p>
</li>
<li><p>完成 rehash：当旧哈希表中的所有元素都被 rehash 到新哈希表后，会释放旧哈希表占用的内存。</p>
</li>
</ol>
<p>支持的命令有：hset、hget、hlen、hgetall等</p>
<h4 id="set（集合）"><a href="#set（集合）" class="headerlink" title="set（集合）"></a>set（集合）</h4><p>Redis的集合set相当于Java的HashSet，是无序的，内部实现相当于一个特殊的字典，字典中所有的value都是NULL。</p>
<p>支持的命令有：sadd、scard、sismember等，scard用于获取计数值。</p>
<h4 id="zset（有序集合）"><a href="#zset（有序集合）" class="headerlink" title="zset（有序集合）"></a>zset（有序集合）</h4><p>类似于Java中的SortedSet和HashMap的结合体，同样是key-value结构，不同的是zset的value不是一个值，而是member和score两个值（可理解为member-score键值对），member是不重复的，按照score进行排序。底层实现使用的是跳表。</p>
<p>zset可以用来存储粉丝列表，value是粉丝的用户id，score是关注时间，按照关注时间排序，类似的，还可以用来存储学生的成绩。</p>
<p>zset支持的操作：</p>
<ul>
<li>zadd：向有序集合添加一个或多个成员，并指定对应的分数。</li>
<li>zrank：获取成员在有序集合中的排名（从小到大）。</li>
<li>zrevrank：获取成员在有序集合中的倒序排名（从大到小）。</li>
<li>zrange：按照排名范围获取有序集合中的成员。</li>
<li>zrevrange：按照倒序排名范围获取有序集合中的成员。</li>
<li>zscore：获取成员的分数。</li>
<li>zincrby：增加成员的分数。</li>
<li>zrem：从有序集合中移除一个或多个成员。</li>
<li>zcard：获取有序集合元素的总和</li>
</ul>
<h3 id="容器型数据结构的两条规则"><a href="#容器型数据结构的两条规则" class="headerlink" title="容器型数据结构的两条规则"></a>容器型数据结构的两条规则</h3><p>list、set、hash、zset这四种数据结构都是容器型数据结构，容器型数据结构遵从两条规则：</p>
<ol>
<li>create if not exists：如果添加元素时容器不存在，就创建。</li>
<li>drop if no elements：如果容器里没有元素，那么立即删除容器释放内存。</li>
</ol>
<h3 id="过期时间"><a href="#过期时间" class="headerlink" title="过期时间"></a>过期时间</h3><p>Redis中所有对象都可以设置过期时间。例如，可以对一个hash对象设置过期时间，但是不能对齐某一个key-value设置过期时间。</p>
<p>需要注意的是，如果一个对象已经设置了过期时间，然后调用set修改了这个对象，那么之前设置是过期时间就会失效。</p>
<h2 id="其它数据结构"><a href="#其它数据结构" class="headerlink" title="其它数据结构"></a>其它数据结构</h2><h3 id="位图"><a href="#位图" class="headerlink" title="位图"></a>位图</h3><p>对于一些需要存储大量bool型数据的情况（比如一年内的签到数据），如果使用普通的key-value，存储空间消耗极大。为解决这个问题，Redis提供了位图数据结构（不是全新的数据结构，底层其实是string字符串）。位图的最小单位是比特（0或1）。</p>
<p>支持的命令有：getbit、setbit、bitcount、bitpos、bitfield等</p>
<p>其中bitcount和bitpos命令是位图的统计命令，bitcount用来统计指定范围内1的个数、bitops用来查找指定范围内出现的第一个0或1的位置。</p>
<p>bitfield命令可以实现一次性对指定位片段进行多位操作，bitfield有三个子命令，get、set、incrby。如果使用incrby命令时出现了溢出，Redis默认的处理方式是折返（wrap），即不对溢出进行特殊处理，溢出之后是什么值就取什么值。Redisbitfield命令的选择溢出策略的子命令是overflow，用户可以选择溢出行为，包括折返、失败（fail，报错并不予执行）、饱和截断（sat，超过了范围就停留在最大或最小值）。</p>
<p>常用的使用方式有：零存（对位值逐个设置）整取、零存零取、整存（使用字符串一次性填充所有位）零取。</p>
<h3 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h3><p>要统计网站上每个网页每天的UV数据总数，数据不需要太精确。由于统计UV需要去重，所以简单的方案是使用set，但是如果页面访问量很大，就存在浪费存储空间的问题。更好的解决方案是使用HyperLogLog，HyperLogLog 使用的内存消耗最多是12 KB，无论估算的基数有多大，它始终只占用 12 KB 的内存空间。</p>
<p>HyperLogLog提供了不精确的去重计数方案，标准误差是0.81%，这样的精确度可以满足UV统计需求。</p>
<p>HyperLogLog之所以内存消耗如此之小，是因为HyperLogLog的存储算法具备这一特点：</p>
<ol>
<li>当计数比较小时，它的存储空间采用稀疏矩阵存储。</li>
<li>计数值增大到稀疏矩阵占用空间超过阈值后，才会一次性转变为稠密矩阵，占用12KB。</li>
</ol>
<p>HyperLogLog提供的命令有：pfadd、pfcount、pfmerge</p>
<p>pfadd用来添加数据，pfcount用来获取计数值，pfmerge用来合并HyperLogLog</p>
<p>补充：</p>
<p>UV（Unique Visitor）数据指的是网站或应用程序的独立访问者数量。UV数据用于衡量网站或应用程序的受众规模和用户活跃度。UV数据通常基于用户的唯一标识符（如用户ID、Cookie、设备ID等）进行统计，以便区分不同的访问者。它可以帮助网站或应用程序的管理者了解其用户群体的规模、用户活跃度、用户留存率等重要指标，从而做出相应的优化和决策。</p>
<p>PV（Page View）数据指的是网站或应用程序的页面访问次数。PV数据记录了每个页面被访问的次数，无论是同一个用户多次访问同一个页面，还是不同用户访问同一个页面，每一次访问都计算为一次PV。PV数据可以帮助评估网站或应用程序的流量、页面热度以及用户行为。</p>
<h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p>虽然HyperLogLog数据结构能够对数据进行去重计数，但是不能用来判断数据是否已存在。布隆过滤器（Bloom Filter）就是专门用来解决这种问题的，用来判断对象是否存在，相比set能够节省90%的空间，唯一不足是不精确，有一定的误判概率。</p>
<p>布隆过滤器判断结果的真实性的规则是：</p>
<ol>
<li>如果布隆过滤器输出某个值存在，这个值可能不存在</li>
<li>如果布隆过滤器输出某个值不存在，这个值一定不存在</li>
</ol>
<p>布隆过滤器提供两条命令：bf.add（一次添加一个元素）、bf.madd（一次添加多个元素）、bf.exists</p>
<p>Redis的布隆过滤器是从Redis4.0开始以插件的形式添加到Redis中的，要使用Redis的布隆过滤器，需要安装对应插件。在使用时，布隆过滤器的initial_size（预计放入的元素数量）参数越大，error_rate（误判率）越小。</p>
<p><strong>布隆过滤器的原理：</strong></p>
<p>布隆过滤器底层的数据结构是一个大型的位数组，添加key时，使用几个不同的无偏hash函数，对添加到布隆过滤器的key进行hash，分别算出索引值，然后将索引值位置的值置为1。判断key是否存在时，对添加到布隆过滤器的key进行hash，分别算出索引值，然后看位数组中这几个位的值是否都是1，如果都是1，说明极有可能存在，如果不都是1，说明一定不存在。</p>
<p>所谓无偏就是能够把元素的hash值算得比较均匀，让key被hash映射到位数组中的位值比较随机。</p>
<p><strong>布隆过滤器的空间占用估计：</strong></p>
<p>计算布隆过滤器的空间占用估计需要两个参数，预计元素的数量（设为N）和错误率（设为F），可以得到两个输出，位数组的长度（设为L）和hash函数的最佳数量（设为K）：</p>
<p>K &#x3D; 0.7 * (L &#x2F; N)</p>
<p>F &#x3D; 0.6185 ^ (L &#x2F; N)</p>
<p>K和（L&#x2F;N）成正比，F和（L&#x2F;N）成反比。</p>
<p>在线计算布隆过滤器计算器：<a target="_blank" rel="noopener" href="https://krisives.github.io/bloom-calculator">https://krisives.github.io/bloom-calculator</a></p>
<img src="./Redis/image-20230522110209728.png" alt="image-20230522110209728" style="zoom:67%;" />

<p><strong>当实际元素数量超过设置的预计元素的数量：</strong></p>
<p>当实际元素数量超过设置的预计元素的数量，错误率会有陡峭的增大，设实际元素数量和设置的预计元素的数量比值为T，使用的hash函数的数量是K，错误率（设为F）的计算公式是：</p>
<p>F &#x3D; (1 - 0.5^T) ^ K;</p>
<p><strong>布隆过滤器的其它应用：</strong></p>
<ul>
<li>在爬虫系统中对URL进行去重。</li>
<li>在NoSQL数据库中通过内存中的布隆过滤器过滤掉不存在的row的请求。</li>
<li>邮箱系统的垃圾邮件过滤。</li>
</ul>
<h3 id="GeoHash"><a href="#GeoHash" class="headerlink" title="GeoHash"></a>GeoHash</h3><p>Redis在3.2版本后增加了处理地理位置信息的模块Geo（底层使用的是zset），可以用于实现“附近的单车”、“附近的餐馆”这样的需要对地理位置距离进行排序的功能，在Redis中，是基于GeoHash算法实现的。</p>
<p>GeoHash算法将二维的经纬度数据映射到一维的整数（使用二刀法等刀法实现），要寻找附近的XXX时只需要找一维下的附近的点。计算后的地图元素的坐标都会变为整数，通过这个整数可以还原出元素的坐标，整数越长，还原出来的坐标值的损失程度就越小。GeoHash算法会对这个整数做一次Base32编码。</p>
<p>Base32 是一种数据编码机制，使用 32 个可打印字符（字母 A-Z 和数字 2-7）对任意字节数据进行编码的方案。Base32 将任意字符串按照字节进行切分，并将每个字节对应的二进制值（不足 8 比特高位补 0）串联起来，按照 5 比特一组进行切分，并将每组二进制值转换成十进制来对应 32 个可打印字符中的一个。由于数据的二进制传输是按照 8 比特一组进行（即一个字节），因此 Base32 按 5 比特切分的二进制数据必须是 40 比特的倍数（5 和 8 的最小公倍数）。不足 40 比特的倍数则通过填充符号“&#x3D;”来补齐。</p>
<p>支持的命令有：geoadd、geodist、geopos、georadiusbymember、georadius</p>
<ul>
<li>geodist：获取两个元素之间的距离</li>
<li>geopos：获取集合中任意元素的经纬度坐标</li>
<li>georadiusbymember：查询元素附近的其它元素</li>
<li>georadius：查找经纬度坐标附近的其它元素</li>
</ul>
<h3 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h3><p>Redis Stream是Redis 5.0版本中新增的数据结构，是一个支持多播的可持久化的消息队列。</p>
<p>Stream的消息有定长的功能，在 xadd 的指令中提供了一定长长度参数 maxlen，就可以实现清除旧有超长的消息。</p>
<h4 id="消费组"><a href="#消费组" class="headerlink" title="消费组"></a>消费组</h4><p>每个Stream都可以挂载多个消费组（Consumer Group），每个消费组会有一个游标（last_delivered_id），用于表示当前消费组以及消费到哪条消息。</p>
<p>消费组之间是独立的</p>
<p>一个消费组可以挂载多个消费者，任意一个消费者读取了消息都会使游标向前移动。</p>
<h5 id="创建消费组"><a href="#创建消费组" class="headerlink" title="创建消费组"></a>创建消费组</h5><p>消费组不会自动创建，创建消费组的命令是xgroup create，创建消费组需要提供起始消息 ID 参数用来初始化 last_delivered_id 变量。</p>
<h5 id="独立消费"><a href="#独立消费" class="headerlink" title="独立消费"></a>独立消费</h5><p>可以不定义消费组，将 Stream 当成普通的消息队列（list）来使用。</p>
<h4 id="消息"><a href="#消息" class="headerlink" title="消息"></a>消息</h4><h5 id="消息ID"><a href="#消息ID" class="headerlink" title="消息ID"></a>消息ID</h5><p>消息 ID 的形式是 TimestampInMillis-sequence，例如 1527846880572-5，它表示当前的消息再毫秒时间戳 1527846880572 时产生，并且是该毫秒内产生的第 5 条消息。消息 ID 可以由服务器自动生成，也可以由客户端自己指定，但是形式必须是 “整数-整数”，而且后面加入的消息的 ID 必须要大于前面的消息 ID。</p>
<h5 id="消息内容"><a href="#消息内容" class="headerlink" title="消息内容"></a>消息内容</h5><p>消息内容的形式的键值对。</p>
<h5 id="消息操作"><a href="#消息操作" class="headerlink" title="消息操作"></a>消息操作</h5><p>1）xadd：向 Stream 追加消息。</p>
<p>2）xdel：向 Stream 中删除消息，这里的删除仅仅是设置标志位，不影响消息总长度。</p>
<p>3）xrange：获取 Stream 中的消息列表，会自动过滤已经删除的消息。</p>
<p>4）xlen：获取 Stream 消息长度。</p>
<p>5）del：删除整个 Stream 消息列表的所有消息。</p>
<h4 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h4><h5 id="消费消息"><a href="#消费消息" class="headerlink" title="消费消息"></a>消费消息</h5><p>消费者使用<code>XREAD</code>或<code>XREADGROUP GROUP</code>命令从Redis Stream中读取消息。</p>
<p>使用 XREAD 以阻塞或非阻塞方式获取消息列表 ，语法格式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] id [id ...]<br></code></pre></td></tr></table></figure>

<ul>
<li><strong>count</strong> ：数量</li>
<li><strong>milliseconds</strong> ：可选，阻塞毫秒数，没有设置就是非阻塞模式</li>
<li><strong>key</strong> ：队列名</li>
<li><strong>id</strong> ：消息 ID</li>
</ul>
<p>示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plaintext"># 从 Stream 头部读取两条消息<br>XREAD COUNT 2 STREAMS mystream writers 0-0 0-0<br></code></pre></td></tr></table></figure>

<p>使用 XREADGROUP GROUP 读取消费组中的消息，语法格式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS key [key ...] ID [ID ...]<br></code></pre></td></tr></table></figure>

<ul>
<li><strong>group</strong> ：消费组名</li>
<li><strong>consumer</strong> ：消费者名。</li>
<li><strong>count</strong> ： 读取数量。</li>
<li><strong>milliseconds</strong> ： 阻塞毫秒数。</li>
<li><strong>key</strong> ： 队列名。</li>
<li><strong>ID</strong> ： 消息 ID。</li>
</ul>
<p>示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">XREADGROUP GROUP consumer-group-name consumer-name COUNT 1 STREAMS mystream &gt;<br></code></pre></td></tr></table></figure>

<p>消息 ID可以指定读取的起始位置，如<code>0</code>表示从最早的消息开始读取，或者使用特殊符号<code>&gt;</code>表示从当前最新的消息开始读取。</p>
<p>处理完消息后，消费者需要使用<code>XACK</code>命令确认消息的处理完成。</p>
<h5 id="pending-ids"><a href="#pending-ids" class="headerlink" title="pending_ids"></a>pending_ids</h5><p>每个消费者中维持一个状态变量pending_ids，简称为PEL(Pending Entries List)，记录了当前已经被客户端读取的但尚未被ACK的消息。</p>
<h2 id="Redis操作命令"><a href="#Redis操作命令" class="headerlink" title="Redis操作命令"></a>Redis操作命令</h2><h3 id="scan"><a href="#scan" class="headerlink" title="scan"></a>scan</h3><p>scan是一个Redis命令，用于从海量的key中找出满足特定前缀的key列表。相比Redis之前提供的keys命令（也可以完成这一功能）scan具备以下特点：</p>
<ul>
<li>虽然复杂度也是O(n)，但它是通过游标分步进行的，不会阻塞线程</li>
<li>提供了limit参数，可以控制服务器单次遍历的最大条数</li>
<li>返回的结果可能有重复（key存储在hash中，hash缩容时会重复遍历正在遍历的槽），需要客户端去重</li>
</ul>
<p>scan指令返回的游标就是第一维数组的位置索引（槽，slot），limit参数就表示需要遍历的槽位数</p>
<p>scan的遍历顺序是高进位加法，高进位加法从左边加，进位往右边移动。</p>
<p>对于rehash中的字典，scan会同时访问新旧两个数据结构</p>
<p>除了有可以遍历key的scan指令外，还有针对其它容器集合的遍历操作：</p>
<ul>
<li>sscan：遍历set集合</li>
<li>zscan：遍历zset集合</li>
<li>hscan：遍历hash字典中的元素</li>
</ul>
<p>scan还可以用来查找大key，方法是对于每个扫描出来的key，使用type指令获得key的类型，然后使用相应数据结构的size或len方法来得到value的大小，对于每一种类型，将大小排名的前若干名作为扫描结果输出。要编写上面过程的脚本比较繁琐，不过Redis官方已经在redis-cli指令中提供了这样的扫描功能。</p>
<p>示例如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">redis-cli -h 127.0.0.1 -0 6379 --bigkeys<br></code></pre></td></tr></table></figure>

<p>还可以指定睡眠时间：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">redis-cli -h 127.0.0.1 -0 6379 --bigkeys -i 0.1<br></code></pre></td></tr></table></figure>

<p>上面这条指令可以实现每个100条scan指令就会休眠0.1s</p>
<p>补充：</p>
<p>大key：指的是key对应的value值大，在实际业务中要尽量避免大key的产生，原因是大key会带来如下坏处：</p>
<ul>
<li>请求阻塞：redis为单线程，读、写或删除大key需要较长的处理时间，会阻塞后续的请求处理。</li>
<li>网络阻塞：大key会明显需要更长的传输时间，在整个传输时间内，占用大量的带宽，导致网络阻塞。</li>
<li>占用内存：大 key 在 Redis 内部通常会占用较多的内存空间，导致 Redis 的整体内存使用率变高，可能会引起内存溢出等问题。</li>
</ul>
<h2 id="Redis的应用"><a href="#Redis的应用" class="headerlink" title="Redis的应用"></a>Redis的应用</h2><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p>Redis可以用作分布式锁。</p>
<p>需要注意的点有：获取锁和设置超时时间需要是组合在一起的原子操作。</p>
<p>可重入性的一个实现方案是使用线程的ThreadLocal变量存储当前持有锁的计数</p>
<p>请求阻塞等待的一个实现方案是使用延时队列</p>
<h3 id="延时队列（zset做异步消息队列）"><a href="#延时队列（zset做异步消息队列）" class="headerlink" title="延时队列（zset做异步消息队列）"></a>延时队列（zset做异步消息队列）</h3><p>对于消费者数量较少等简单的使用情景，可以使用Redis创建消息队列，简化操作，但是需要注意的是，Redis不是专业的消息中间件，没有非常多的高级特性，没有ack保证，如果对消息的可靠性要求较高，那就不适合使用Redis。</p>
<p>Redis用来做异步消息队列的数据结构通常是list。当队列为空，消费者还是会不断地通过pop操作尝试获取数据，进行空轮询，浪费系统资源，解决方法是，让消费者线程进入sleep状态，一段时间比如1秒后再苏醒继续执行。</p>
<p>但是这会造成系统延迟，更好的解决方案是使用blpop或brpop，前缀b代表的是blocking（阻塞读），阻塞读保证在队列为空的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为0。</p>
<p>当发生锁竞争时，要实现处理请求的阻塞等待，可以使用zset作为队列（Jedis提供的RedisDelayingQueue的底层就是基于Redis的zset数据结构），将冲突的请求放入队列延后处理。</p>
<h3 id="简单限流"><a href="#简单限流" class="headerlink" title="简单限流"></a>简单限流</h3><p>一个简单的限流策略的例子是，在指定时间内限制某个请求只允许发生N次。使用Redis可以实现这一功能。</p>
<p>实现示例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RedisLimiter</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Jedis jedis;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">RedisLimiter</span><span class="hljs-params">(Jedis jedis)</span> &#123;<br>        <span class="hljs-built_in">this</span>.jedis = jedis;<br>    &#125;<br>    <br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isActionAllowed</span><span class="hljs-params">(String userId, String action, <span class="hljs-type">int</span> period, <span class="hljs-type">int</span> maxCount)</span> &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">key</span> <span class="hljs-operator">=</span> String.format(<span class="hljs-string">&quot;hist:%s:%s&quot;</span>, userId, action);<br>        <span class="hljs-type">long</span> <span class="hljs-variable">nowTimeMillis</span> <span class="hljs-operator">=</span> System.currentTimeMillis();<br>        <span class="hljs-type">Pipeline</span> <span class="hljs-variable">pipeline</span> <span class="hljs-operator">=</span> jedis.pipelined();<br>        pipeline.zadd(key, nowTimeMillis, String.valueOf(nowTimeMillis)); <span class="hljs-comment">// 向key中添加member-score，方法的参数是zadd(String key, double score, String member)</span><br>        pipeline.zremrangeByScore(key, <span class="hljs-number">0</span>, nowTimeMillis - period * <span class="hljs-number">1000L</span>); <span class="hljs-comment">//删除key里面过期的member-score，只保留最近period * 1000L毫秒内的member-score</span><br>        Response&lt;Long&gt; count = pipeline.zcard(key);<br>        pipeline.expire(key, period); <span class="hljs-comment">//设置过期时间</span><br>        pipeline.close();<br>        pipeline.sync();<br>        <span class="hljs-type">Long</span> <span class="hljs-variable">value</span> <span class="hljs-operator">=</span> count.get();<br>        <span class="hljs-comment">//System.out.println(&quot;value = &quot; + value); //如果没有删除缓存，就可能看到value不是从1开始的</span><br>        <span class="hljs-keyword">return</span> count.get() &lt;= maxCount;<br>    &#125;<br>    <br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">deleteCache</span><span class="hljs-params">(String userId, String action)</span> &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">key</span> <span class="hljs-operator">=</span> String.format(<span class="hljs-string">&quot;hist:%s:%s&quot;</span>, userId, action);<br>        jedis.del(key);<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> InterruptedException &#123;<br>        <span class="hljs-type">Jedis</span> <span class="hljs-variable">jedis</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Jedis</span>();<br>        <span class="hljs-type">RedisLimiter</span> <span class="hljs-variable">redisLimiter</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RedisLimiter</span>(jedis);<br>        <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">USER_ID</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;user&quot;</span>;<br>        <span class="hljs-keyword">final</span> <span class="hljs-type">String</span> <span class="hljs-variable">ACTION</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;getRequest&quot;</span>;<br>        redisLimiter.deleteCache(USER_ID, ACTION); <span class="hljs-comment">//删除Redis缓存</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">20</span>; i++) &#123;<br>            Thread.sleep(<span class="hljs-number">1</span>); <span class="hljs-comment">//sleep一毫秒，确保isActionAllowed函数中的nowTimeMillis值每次都不同</span><br>            System.out.println(redisLimiter.isActionAllowed(USER_ID, ACTION, <span class="hljs-number">60</span>, <span class="hljs-number">5</span>));<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>输出结果如下，只有当缓存中存储的次数不超过maxCount允许的数量（例子中是5），才可以返回true：</p>
<img src="./Redis/image-20230522172919614.png" alt="image-20230522172919614" style="zoom: 80%;" />

<h3 id="漏斗限流（Redis-Cell模块的cl-throttle命令）"><a href="#漏斗限流（Redis-Cell模块的cl-throttle命令）" class="headerlink" title="漏斗限流（Redis-Cell模块的cl.throttle命令）"></a>漏斗限流（Redis-Cell模块的cl.throttle命令）</h3><p>漏斗（Funnel）限流是最常用的限流算法之一。漏斗的剩余空间代表着行为当前可以进行的数量，漏斗的流水速率代表系统允许该行为的最大频率。要实现这一算法需要存储几个参数，比如漏斗容量、流水速率、漏斗剩余空间，可以考虑使用Redis的hash数据结构实现，但是存在一个问题，就是无法保证漏斗容量计算时涉及到的取值、运算、写值的三个过程的原子性。</p>
<p>Redis-Cell模块提供了漏斗算法的实现，解决了这一问题，该模块的命令只有一个，cl.throttle，该命令的使用格式如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">cl.throttle [key] [capacity] [velocity] [apply 1 operation](optional)<br></code></pre></td></tr></table></figure>

<ol>
<li>key：键</li>
<li>capacity：漏斗容量</li>
<li>velocity：流水速率</li>
<li>apply 1 operation：添加一个数，是可选的。</li>
</ol>
<p>示例：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">cl.throttle 1001 15 30 60 1<br></code></pre></td></tr></table></figure>

<p>输出如下：</p>
<p>1)(Integer) 0        # 0表示允许，1表示拒绝</p>
<p>2)(Integer) 15      # 漏斗容量是15</p>
<p>3)(Integer) 14      # 漏斗剩余空间是14</p>
<p>4)(Integer) -1       # 如果被拒绝了，多长时间后重试</p>
<p>5)(Integer) 2         # 多长时间后漏斗完全空出来</p>
<h1 id="数据传输与网络"><a href="#数据传输与网络" class="headerlink" title="数据传输与网络"></a>数据传输与网络</h1><h2 id="Redis的特点"><a href="#Redis的特点" class="headerlink" title="Redis的特点"></a>Redis的特点</h2><ul>
<li>是单线程程序。除Redis外，Node.js和Nginx也都是单线程。</li>
<li>数据存储在内存中</li>
<li>I&#x2F;O多路复用，是Redis能够处理大量客户端连接的原因</li>
<li>速度快</li>
</ul>
<p>Redis 速度快的原因主要包括以下几点：</p>
<ol>
<li>内存存储：Redis 将数据存放在内存中，而不是硬盘上。因为内存访问速度比硬盘快得多，所以 Redis 能够达到非常快的读写速度，这也是 Redis 被称为高性能数据库的重要原因之一。</li>
<li>单线程模型：Redis 使用单线程模型，即使用一个线程来处理所有的客户端请求，这使得 Redis 可以避免锁竞争、多线程切换等问题，从而提高了效率。</li>
<li>高效的网络 IO 模型：Redis 使用 I&#x2F;O 多路复用技术来实现高效的网络 IO 模型，这种模型可以同时管理多个客户端连接，并且每个连接都只被唤醒一次，从而减少了系统调用次数，提高了效率。</li>
<li>高效的数据结构：Redis 支持多种数据结构，如字符串、哈希表、列表、集合、有序集合等，这些数据结构经过优化和精简，能够快速地进行插入、删除、查询等操作，从而提高了性能。比如rehash就是优化的一个例子。</li>
<li>高效的持久化和异步处理机制：Redis 提供了 RDB 和 AOF 两种持久化方案，通过定期或追加记录将内存中的数据同步到硬盘。同时 Redis 还具有异步处理机制，可以延迟一部分 I&#x2F;O 操作，让 CPU 可以在更多的时间内执行其他操作，从而提高了系统的整体效率。</li>
</ol>
<h2 id="I-x2F-O线程模型"><a href="#I-x2F-O线程模型" class="headerlink" title="I&#x2F;O线程模型"></a>I&#x2F;O线程模型</h2><h3 id="同步与异步"><a href="#同步与异步" class="headerlink" title="同步与异步"></a>同步与异步</h3><p>同步指的是在发出一个功能调用时，在没有得到结果之前，该调用就不返回。也就是必须一件一件事做，等前一件做完了才能做下一件事。</p>
<p>异步的概念和同步相对，当一个异步过程调用发出后，调用者不需要立刻得到结果。调用被执行完成后，会通知调用者。</p>
<h3 id="5种主要的IO模型"><a href="#5种主要的IO模型" class="headerlink" title="5种主要的IO模型"></a>5种主要的IO模型</h3><ol>
<li><p>阻塞IO模型</p>
<p>当我们调用套接字的读写放方法，默认是阻塞的，read操作是在没有读取到字节时线程阻塞，write操作是在写缓冲区已满时阻塞。</p>
<p>典型应用：BIO（Blocking I&#x2F;O）</p>
</li>
<li><p>非阻塞IO模型</p>
<p>非阻塞IO在套接字对象上设置了non_blocking，读写方法不会阻塞，会反复地发起读&#x2F;写请求，对于read操作，当内核准备好数据之后就进行读，对于写操作，当写缓冲区的有空闲空间就进行写。</p>
<p>典型应用：Java NIO（Non-blocking I&#x2F;O，New I&#x2F;O）</p>
</li>
<li><p>多路复用IO模型</p>
<p>一种简单的多路复用API是select，多个的进程的IO注册到一个复用器（select）上，然后用一个进程调用该select，select会监听所有注册进来的IO。</p>
<p>如果select没有监听的IO在内核缓冲区都没有可读数据，select调用进程会被阻塞；而当任一IO在内核缓冲区中有可数据时，select调用就会返回；</p>
<p>典型应用：epoll（linux系统的性能最好的多路复用API）。</p>
</li>
<li><p>异步IO模型</p>
<p>当进程发起一个IO操作，进程返回（不阻塞），但也不能返回果结；内核把整个IO处理完后，会通知进程结果。如果IO操作成功则进程直接获取到数据。</p>
<p>典型应用：Java AIO（Asynchronous I&#x2F;O）</p>
</li>
<li><p>信号驱动IO模型</p>
<p>当进程发起一个IO操作，会向内核注册一个信号处理函数，然后进程返回不阻塞；当内核数据就绪时会发送一个信号给进程，进程便在信号处理函数中调用IO读取数据。</p>
</li>
</ol>
<h2 id="Redis序列化协议（RESP）"><a href="#Redis序列化协议（RESP）" class="headerlink" title="Redis序列化协议（RESP）"></a>Redis序列化协议（RESP）</h2><p>RESP是Redis序列化协议（Redis Serialization Protocal）的简写，是一种直观的文本协议。</p>
<p>RESP将传输的数据分为5种最小单元类型，单元结束时统一加上回车换行符号\r\n。<a target="_blank" rel="noopener" href="https://redis.io/docs/reference/protocol-spec/">规则如下</a>：</p>
<p>In RESP, the first byte determines the data type:</p>
<ul>
<li>For <strong>Simple Strings</strong>, the first byte of the reply is “+”</li>
<li>For <strong>Errors</strong>, the first byte of the reply is “-“</li>
<li>For <strong>Integers</strong>, the first byte of the reply is “:”</li>
<li>For <strong>Bulk Strings</strong>, the first byte of the reply is “$”. A “$” byte followed by the number of bytes composing the string (a prefixed length), terminated by CRLF.</li>
<li>For <strong>Arrays</strong>, the first byte of the reply is “<code>*</code>“</li>
</ul>
<p>NULL用多行字符串表示，不过长度要写成-1：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">$-1\r\n<br></code></pre></td></tr></table></figure>

<p>客户端向服务端发送的指令只有一种格式，多行字符串数组。比如指令<code>set author codehole</code>会被序列化为下面的字符串：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">*3\r\n$3\r\nset\r\n$6\r\nauthor\r\n$8\r\ncodehole\r\n<br></code></pre></td></tr></table></figure>

<p>服务端向客户端返回的数据结构有的比较复杂，不过也是以上五种基本类型的组合。例如scan命令的返回给客户端的结果，scan命令返回的是一个嵌套数组，数组的第一个值表示游标的值，如果这个值为零，说明已经遍历完毕。scan返回结果示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">*2\r\n$1\r\n0\r\n*3\r\n$4\r\ninfo\r\n$5\r\nbooks\r\n$6author\r\n<br></code></pre></td></tr></table></figure>

<p>里面嵌套了一个数组</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">*3\r\n$4\r\ninfo\r\n$5\r\nbooks\r\n$6author\r\n<br></code></pre></td></tr></table></figure>

<p>虽然RESP协议里面有大量冗余的回车换行符，但是依然是非常受欢迎的一个文本协议。</p>
<h2 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h2><p>Redis的管道（Pipeline）不是由Redis服务器提供的技术，而是由客户端提供的。</p>
<p>Redis管道通过将多个命令打包在一起，然后一次性发送给Redis服务器，在一次通信中获得多个命令的执行结果。这样就可以减少通信次数，提高性能。</p>
<p>使用Redis自带的压力测试工具redis-benchmark,，可以测试出设置不同的单个管道内并行的请求数量所带来的QPS（Queries Per Second，每秒查询率）的改变。</p>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>Redis事务的操作指令有multi、exec、discard、watch。分别表示事务的开始、提交、丢弃、监视变量。</p>
<p>所有指令在exec之前不会执行，而是缓存在服务器的事务队列中。执行完毕后一次性返回所有指令的运行结果。</p>
<p>Redis的事务不具备原子性，仅仅实现了事务的“串行化”，当前执行的事务不被其它的事务打断。</p>
<p>Redis的事务通常会结合pipeline一起使用，可以将多次IO操作合并为一次。在Python的Redis客户端，Redis执行事务时要强制使用pipeline。</p>
<p><strong>watch</strong></p>
<p>在 Redis 中，watch命令用来监视某个键，在服务器收到exec命令将要执行缓存的事务队列时，Redis会检查自变量被watch之后是否被改过。如果该键watch之后和exec之前被修改过，exec就会返回 NULL告诉客户端事务执行失败，这个时候客户端一般会选择重试。</p>
<p>需要注意的是，Redis禁止在multi和exec之间执行watch命令，必须在multi之前watch变量。</p>
<p>示例（Java语言中使用watch命令）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">WatchUsage</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> String <span class="hljs-title function_">keyFor</span><span class="hljs-params">(String userId)</span> &#123;<br>        <span class="hljs-keyword">return</span> String.format(<span class="hljs-string">&quot;account_%s&quot;</span>, userId);<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">doubleAccount</span><span class="hljs-params">(Jedis jedis, String userId)</span> &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">key</span> <span class="hljs-operator">=</span> keyFor(userId);<br>        <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;<br>            jedis.watch(key);<br>            <span class="hljs-type">int</span> <span class="hljs-variable">value</span> <span class="hljs-operator">=</span> Integer.parseInt(jedis.get(key));<br>            value &lt;&lt;= <span class="hljs-number">1</span>; <span class="hljs-comment">//乘以2</span><br>            <span class="hljs-type">Transaction</span> <span class="hljs-variable">transaction</span> <span class="hljs-operator">=</span> jedis.multi();<br>            transaction.set(key, String.valueOf(value));<br>            List&lt;Object&gt; result = transaction.exec();<br>            <span class="hljs-keyword">if</span> (result != <span class="hljs-literal">null</span>) &#123;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> Integer.parseInt(jedis.get(key));<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        <span class="hljs-type">Jedis</span> <span class="hljs-variable">jedis</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Jedis</span>();<br>        <span class="hljs-type">String</span> <span class="hljs-variable">userId</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;1001&quot;</span>;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">key</span> <span class="hljs-operator">=</span> keyFor(userId);<br>        jedis.setnx(key, String.valueOf(<span class="hljs-number">5</span>));<br>        System.out.println(doubleAccount(jedis, userId));<br>        jedis.close();<br>        <span class="hljs-comment">/*</span><br><span class="hljs-comment">        输出结果：</span><br><span class="hljs-comment">        	10</span><br><span class="hljs-comment">        */</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>



<h2 id="消息多播（PubSub）"><a href="#消息多播（PubSub）" class="headerlink" title="消息多播（PubSub）"></a>消息多播（PubSub）</h2><p>消息多播允许生产者只生产一次消息，由中间件负责将消息复制到多个消息队列，每个消费队列由对应的消费组进行消费。这是分布式系统常用的一种解耦方式，用于将多个消费组的逻辑进行拆分。</p>
<p>Redis中支持消息多播的模块是PubSub（PublisherSubscriber，发布者-订阅者模式）</p>
<p>Redis提供的模式订阅命令是<code>subscribe</code>，Redis还提供了<code>psubscribe</code>命令（pattern subscribe），可以实现通过模式匹配订阅主题。</p>
<p>命令：</p>
<ol>
<li>subscribe：订阅主题</li>
<li>psubscribe：通过模式匹配订阅主题</li>
<li>unsubscribe：取消订阅主题</li>
<li>unpsubscribe：通过模式匹配取消订阅主题</li>
</ol>
<p>PubSub的缺点：</p>
<ol>
<li>当生产者发送消息时，如果消费者下线没有收到消息，那么该消息对于该消费者来说就是彻底丢失了</li>
</ol>
<p>正式因为PubSub有这个缺点，在消息队列的领域几乎找不到合适的应用场景。Redis5.0新增了Stream数据结构，给Redis带来了持久化的消息队列，从此PubSub退出作为消息队列的技术方案选项。</p>
<h1 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h1><h3 id="RDB日志（内存快照）"><a href="#RDB日志（内存快照）" class="headerlink" title="RDB日志（内存快照）"></a>RDB日志（内存快照）</h3><p>RDB（Redis DataBase）日志（内存快照）是内存数据的二进制序列化，是全量备份。</p>
<p>内存快照要求Redis必须进行文件IO操作，而Redis是单线程程序，如果一边处理业务请求，一边进行文件IO操作，会降低处理业务请求的性能，还有个问题是，这种操作下，内存数据一边被持久化一边被修改，快照就不是对一个时间点的记录，而是成了多个时间点交错的记录，无法使用。</p>
<p>Redis使用操作系统多进程COW（Copy On Write）机制来实现快照持久化。</p>
<p>Copy-On-Write（COW）是一种操作系统中常用的技术，其基本思想是：当多个进程需要访问同一块内存地址时，操作系统会将这块内存标识为只读，并且在任何进程试图写入该内存前，都会复制一份副本供该进程使用。这样就能够保证每个进程都拥有自己的独立内存空间，而不会互相干扰。</p>
<h3 id="AOF日志"><a href="#AOF日志" class="headerlink" title="AOF日志"></a>AOF日志</h3><p>AOF（Append Only File）日志是内存数据修改的指令记录文本，是增量备份。</p>
<p>Redis收到客户端的修改命令后，进行参数校验、逻辑处理，如果没问题，就将该指令文本存储到AOF日志中，即先执行指令再将存储日志。</p>
<p>AOF日志在长期的运行过程中会变得十分庞大，数据库重启时需要加载AOF日志进行指令重放，这个过程就会很漫长，所以需要定期进行AOF重写，给AOF日志进行瘦身。</p>
<p>Redis提供了bgrewriteaof命令用于对AOF日志进行瘦身，其原理是开辟一个子进程对内存进行遍历，转换成一系列Redis的操作命令，序列化到一个新的AOF日志文件中，序列化完成后再将操作期间发生的增量AOF日志追加到这个新的AOF日志文件中，追加完毕后就可以替代旧的AOF日志文件了。</p>
<p>当程序对AOF日志文件进行写操作时，实际上是将内容写到了以内核为文件描述符分配的一个内存缓存中，然后内核会异步地将脏数据刷回到磁盘。这就意味着，如果突然宕机，AOF日志还没有完全刷新到磁盘中，就会出现日志丢失。Linux的glibc提供的fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷新到磁盘，只要Redis进行实时调用fsync函数就可以保证AOF日志不丢失。但是fsync是一个磁盘IO操作，很慢，如果Redis执行一条指令就要fsync一次，那么会严重降低Redis的性能。所以在生产环境的服务器中，Redis通常是每隔1s左右执行一次fsync操作，这个1s的周期是可以配置的，是在安全性和性能间做的折中。</p>
<p>因为RDB和AOF都会加重系统的负担，所以通常Redis的主节点不会进行持久化操作，持久化操作主要在从节点进行，这是因为从节点没有来自客户端请求的压力，系统资源充足。</p>
<h3 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h3><p>使用RDB恢复内存状态会丢失备份后修改的数据，而使用AOF日志的全量文件重放又相对RDB慢很多，Redis为解决这个问题，从Redis4.0开始，引入了一个新的持久化选项，混合持久化。</p>
<p>混合持久化的持久化方式是指生成RDB全量日志和该RDB的AOF增量日志，在Redis重启的时候，先加载RDB日志，再加载AOF日志。</p>
<h1 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h1><h2 id="内存回收机制"><a href="#内存回收机制" class="headerlink" title="内存回收机制"></a>内存回收机制</h2><p>被删除的key分散在很多页面中，这个页面可能还有其它正在使用的key，操作系统是以页为单位进行内存回收的，这个页上只要还有一个key在使用，那这个页就不能回收。</p>
<p>Redis虽然无法保证立即回收已经删除key的内存，但是它会重新使用哪些尚未回收的空闲内存。</p>
<h2 id="内存分配机制"><a href="#内存分配机制" class="headerlink" title="内存分配机制"></a>内存分配机制</h2><p>Redis在内存分配方面，直接使用了第三方的内存分配库，目前Redis使用jemalloc（facebook）库来管理内存，也可以切换到tcmalloc（google），因为jemalloc比tcmalloc性能稍好，所以Redis默认使用jemalloc。</p>
<p>通过<code>info memory</code>可以查看Redis使用的是哪个第三方的内存分配库。</p>
<h2 id="数据过期机制"><a href="#数据过期机制" class="headerlink" title="数据过期机制"></a>数据过期机制</h2><h3 id="定时删除"><a href="#定时删除" class="headerlink" title="定时删除"></a>定时删除</h3><p>EXPIRE命令可以为指定的键设置过期时间，时间到达后，这些建会被自动删除。</p>
<p>serverCron函数会定时触expire.c下的activeExpireCycle函数，该函数会清除数据库中的过期数据，该函数可以设置最长执行时间和每次删除操作删除的最大的key数量。以避免删除操作延时过长。</p>
<h3 id="惰性删除"><a href="#惰性删除" class="headerlink" title="惰性删除"></a>惰性删除</h3><p>惰性删除是当用户查询键时，检测键是否过期，如果键已经过期，则删除该键。该操作由expireIfNeeded函数完成。</p>
<h2 id="数据淘汰策略"><a href="#数据淘汰策略" class="headerlink" title="数据淘汰策略"></a>数据淘汰策略</h2><h3 id="Redis支持的数据淘汰策略"><a href="#Redis支持的数据淘汰策略" class="headerlink" title="Redis支持的数据淘汰策略"></a>Redis支持的数据淘汰策略</h3><p><a target="_blank" rel="noopener" href="https://redis.io/docs/reference/eviction/">Redis官方给出的数据淘汰策略（Eviction policies）文档</a>。下面是从官网复制的Redis支持的数据淘汰策略及其解释。</p>
<p>The exact behavior Redis follows when the <code>maxmemory</code> limit is reached is configured using the <code>maxmemory-policy</code> configuration directive.</p>
<p>The following policies are available:</p>
<ul>
<li><strong>noeviction</strong>: New values aren’t saved when memory limit is reached. When a database uses replication, this applies to the primary database</li>
<li><strong>allkeys-lru</strong>: Keeps most recently used keys; removes least recently used (LRU) keys</li>
<li><strong>allkeys-lfu</strong>: Keeps frequently used keys; removes least frequently used (LFU) keys</li>
<li><strong>volatile-lru</strong>: Removes least recently used keys with the <code>expire</code> field set to <code>true</code>.</li>
<li><strong>volatile-lfu</strong>: Removes least frequently used keys with the <code>expire</code> field set to <code>true</code>.</li>
<li><strong>allkeys-random</strong>: Randomly removes keys to make space for the new data added.</li>
<li><strong>volatile-random</strong>: Randomly removes keys with <code>expire</code> field set to <code>true</code>.</li>
<li><strong>volatile-ttl</strong>: Removes keys with <code>expire</code> field set to <code>true</code> and the shortest remaining time-to-live (TTL) value.</li>
</ul>
<h3 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h3><p>LRU（Least Recently Used）：如果一个数据在最近一段时间内没有被访问，那么可以认为它未来被访问的概率很小。当空间满时，最久没有访问的数据会最先被淘汰。</p>
<p>LRU记录的是时间戳。</p>
<p>Redis的LRU算法是一种近似LRU算法，没有维护key的被访问时间顺序，而是采用随机采样出N个（比如5个，可以设置），然后淘汰掉最旧的key，为能够识别出key的访问时间，Redis给每个key增加了一个额外的字段，最后一次被访问的时间戳。</p>
<h3 id="LFU"><a href="#LFU" class="headerlink" title="LFU"></a>LFU</h3><p>LFU（Least Frequently Used）：如果一个数据在最近一段时间内很少被访问，那么认为将来它被访问的可能性很小。当空间满时，最小频率访问的数据最先被淘汰。</p>
<p>LFU记录的是使用次数。</p>
<p>Redis会根据键的空闲事件对LFU计数进行衰减。</p>
<h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><h2 id="主从同步"><a href="#主从同步" class="headerlink" title="主从同步"></a>主从同步</h2><p>Redis的主从数据是异步复制的，所以分布式Redis系统不满足CAP理论中的一致性（C，Consistency）。</p>
<p>即使在主从网络断开的情况下，主从节点依旧可以向外提供服务，所以Redis满足可用性（A，Availability）。</p>
<p>Redis支持主从同步和从从同步（用以减轻主节点同步的负担）</p>
<h3 id="快照（RDB）同步"><a href="#快照（RDB）同步" class="headerlink" title="快照（RDB）同步"></a>快照（RDB）同步</h3><p>快照同步是在主节点上进行一次bgsave，将当前内存的数据快照存储到磁盘，再将快照文件传输到从节点，从节点接收完毕后，执行全量加载，加载完毕后通知主节点进行增量同步。</p>
<p>进行快照同步时，文件IO操作十分耗时，且会影响fsync的执行，所以从Redis2.8.18开始支持无盘复制，主服务器通过套接字直接将快照内容发送给从节点，从节点将接收到的内容存储到硬盘文件。</p>
<h3 id="增量（AOF）同步"><a href="#增量（AOF）同步" class="headerlink" title="增量（AOF）同步"></a>增量（AOF）同步</h3><p>Redis增量同步同步的是指令流，主节点会将那些对自己的状态产生修改性影响的指令记录在本地的内存buffer中，然后异步地将buffer中的指令同步到从节点。</p>
<p>Redis的buffer是一个定长的环形数组，如果数组内容满了，就会从头开始覆盖前面的内容，如果因为网络状况不好等原因没有及时的同步，那么没有同步的指令可能会被后续的指令覆盖，此时就需要使用快照同步。如果进行快照同步的过程中，buffer又发生了覆盖，就会引发又一次的快照同步，所以如果buffer大小设置不当，可能引起快照同步的死循环。</p>
<h3 id="增加节点"><a href="#增加节点" class="headerlink" title="增加节点"></a>增加节点</h3><p>当节点添加到集群，会先进行一次快照同步，完成后再继续进行增量同步。</p>
<h3 id="同步复制"><a href="#同步复制" class="headerlink" title="同步复制"></a>同步复制</h3><p>Redis3.0之后增加了wait指令，可以将主从复制由异步改为同步，可以设置需要同步的从节点的数量和最长等待时间（-1表示无限等待）。</p>
<h2 id="Sentinel"><a href="#Sentinel" class="headerlink" title="Sentinel"></a>Sentinel</h2><p>Redis提供的Sentinel（哨兵）可以实现集群主节点发生故障后自动进行主从切换。具体作用如下：</p>
<ul>
<li><p>Sentinel能够持续监控主从节点的在线状况。</p>
</li>
<li><p>客户端连接集群时，会首先连接Sentinel，通过Sentinel查询主节点的地址，当主节点发生故障时，Sentinel会将最新的主节点地址告诉客户端。</p>
</li>
<li><p>Sentinel无法保证主从同步因为异步而在主节点下线后产生消息丢失，但是会采取措施限制主从延迟，方式是设置参数<code>min-slaves-to-write</code>和<code>min-slaves-max-tag</code>，第一个参数表示主节点至少有多少个从节点正在进行正常复制，如果不够，就停止写服务。正常复制是含义是由第二个参数控制的，它的单位是秒，表示如果在多少秒内没有收到从节点的反馈，就意味着从节点的同步不正常。</p>
</li>
<li><p>主从切换后，为使客户端“知道”地址变更了，Sentinel会关闭所有的客户端连接，在重连时使客户端使用新的地址。</p>
</li>
</ul>
<h2 id="Redis集群方案"><a href="#Redis集群方案" class="headerlink" title="Redis集群方案"></a>Redis集群方案</h2><h3 id="Codis"><a href="#Codis" class="headerlink" title="Codis"></a>Codis</h3><p>Codis是Redis的集群代理中间件，当客户端向Codis发送指令时，Codis负责将指令转发到后面的Redis实例执行，并将返回结构转回给客户端。Code上挂接的所有Redis实例构成一个Redis集群，当集群空间不足时，可以通过动态增加Redis实例来实现扩容。</p>
<p>因为单个Codis代理能支撑的QPS有限，可以启动多个Codis代理增加QPS，还可以起到容灾的功能。</p>
<p><strong>Codis的槽位定位算法：</strong></p>
<p>Codis将key转发到对应Redis实例的定位机制是通过划分槽位实现的。Codis默认将所有的key划分为1024个槽位（slot），对客户端传入的key进行crc32运算计算hash值，然后用这个hash值对1024取余，这个余数就是key所属的槽位。</p>
<p>每个槽位都会映射到多个Redis实例。Codis会维护槽位和Redis实例的对应关系。当使用到多个Codis实例，就需要对不同Codis实例的槽位信息进行同步，需要使用一个分布式配置存储库如zookeeper，Codis会监听到槽位信息的变化并同步槽位信息。</p>
<p><strong>Codis处理Redis扩容：</strong></p>
<p>当Redis扩容（增加Redis实例）时，会对槽位关系进行调整，并进行自动均衡。</p>
<p><strong>使用Codis的缺点：</strong></p>
<p>由于key分散在不同的Redis实例中，所以不再支持事务。</p>
<p>客户端需要多走一个网络节点（Codis节点）才能到达Redis，性能上比直接访问Redis性能有所下降。</p>
<p><strong>Codis的优点：</strong></p>
<p>Codis在设计上比Redis Cluster简单，将分布式配置问题交给了第三方（zookeeper或etcd）负责，省去了编写和维护分布式一致性的工作。而Redis Cluster自己实现了这一点，混合使用了Raft和Gossip协议，有大量需要调优的配置参数，集群出现故障时不容易排查。</p>
<h3 id="Codis和Redis-Cluster的不同"><a href="#Codis和Redis-Cluster的不同" class="headerlink" title="Codis和Redis Cluster的不同"></a>Codis和Redis Cluster的不同</h3><ol>
<li>Codis的默认槽位数是1024，而Redis Cluster的默认槽位数是16382</li>
<li>Codis是中心化的（需要使用如zookeeper维护配置信息），Redis Cluster是去中心化的（通过Raft和Gossip协议自行维护配置信息）</li>
<li>客户端访问Codis维护的Redis集群每次都需要经过Codis节点，而客户端访问Redis Cluster维护的Redis集群可以直接根据获取到的配置信息定位到Redis实例</li>
<li>Codis默认使用crc32算法计算key的hash值，Redis Cluster默认使用的是crc16</li>
</ol>
<h3 id="Redis-Cluster"><a href="#Redis-Cluster" class="headerlink" title="Redis Cluster"></a>Redis Cluster</h3><p>与Codis不同，Redis Cluster是去中心化的，该集群由三个Redis节点组成，每个节点负责整个集群的一部分数据，它们之间使用一种特殊的二进制协议交互集群信息。</p>
<p>Redis Cluster将所有key划分为16382个槽位，每个节点负责存储其中一部分槽位映射信息。客户端连接集群时会得到一份集群的槽位配置信息，客户端可以直接根据该信息定位到目标节点（Redis实例）。</p>
<p><strong>Redis Cluster的槽位定位算法：</strong></p>
<p>Redis Cluster默认对key使用crs16算法进行hash，得到一个整数值，然后对16382取余得到具体的槽位</p>
<p>Redis Cluster还允许用户强制把指定key挂在特定的槽位上，实现方法是在key字符串上添加tag标记。</p>
<p><strong>Redis Cluster的槽位纠错机制：</strong></p>
<p>当客户端向一个错误节点发出了指令，该节点会发现指令的key所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳跃指令（MOVED指令）携带目标操作的节点地址，告诉客户端去连接这个节点以获取数据。</p>
<p><strong>Redis Cluster的数据迁移策略：</strong></p>
<p>Redis Cluster的数据迁移的单位是槽，提供的迁移工具是redis-trib，redis-trib首先会在源节点和目标节点设置好中间过渡状态，然后再一次性获取源节点槽位的所有key列表，再逐个key进行迁移。每个key迁移到过程是以源节点作为目标节点的客户端，源节点对当前key执行dump指令得到序列化内容，然后向目标节点发送restore指令携带序列化的内容作为参数，目标节点再反序列化就可以把内容恢复到目标节点的内存中。然后返回给源节点OK信息，源节点收到后把当前节点的key删除。</p>
<p>当源节点正在进行对key的数据迁移，源节点的主线程就会处于阻塞状态，直到key被成功删除。在迁移过程中如果每个key都很小，migrate迁移指令会执行的很快，而如果key比较大，就会导致阻塞源节点的正常服务。</p>
<p>因为migrate命令是同步阻塞的，因此不会存在一个key正在被迁移又同时被读写的情况，但由于一个slot下可能有部分key被迁移完成，部分key正在等待迁移的情况，因此如果读写的key所属的slot正在被迁移，redis-cluster做如下处理：</p>
<ol>
<li>客户端根据本地slots缓存发送命令到源节点，如果存在键对象则直接指向并返回结果给客户端。</li>
<li>如果key对象不存在，但key所在的slot属于本节点，则可能存在于目标节点，这时源节点会回复ASK重定向异常<code>-ASK targetNodeAddr</code></li>
<li>客户端从ASK重定向异常提取出目标节点的地址信息（targetNodeAddr），发送asking命令到目标节点。目标节点如果key存在则执行，不存在则返回不存在信息。</li>
</ol>
<p><strong>Redis Cluster处理网络抖动：</strong></p>
<p>网络抖动是突然间部分连接不可访问，然后很快又恢复正常的一种现象。</p>
<p>为解决网络抖动的问题，Redis Cluster提供了配置参数cluster-node-timeout，表示当前某个节点持续timeout的时间失联时，才认定该节点出现故障。如果没有这一配置选项，网络抖动会导致频繁的主从切换。</p>
<h4 id="Raft协议"><a href="#Raft协议" class="headerlink" title="Raft协议"></a>Raft协议</h4><h4 id="Gossip协议"><a href="#Gossip协议" class="headerlink" title="Gossip协议"></a>Gossip协议</h4><p>可能下线（PFail）和确定下线（Fail）：因为Redis Cluster是去中心化的，一个节点认为某个节点失联了并不代表所有节点都认为它失联了，所以集群需要进行一次协商，只有当大多数节点都认为某节点失联了，集群才做出节点已经下线的判断。</p>
<p>Redis Cluster采用Gossip协议来广播自己的状态以及改变对整个集群节点的在线状态。</p>
<h1 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h1><h2 id="info指令"><a href="#info指令" class="headerlink" title="info指令"></a>info指令</h2><ul>
<li>info stats：查看Redis 每秒执行多少次指令。</li>
<li>info clients：查看Redis 连接了多少客户端。</li>
<li>rejected_connections：查看因为超出大量连接限制而被拒接的客户端连接次数。如果这个数字很大意味着服务器的最大连接数设置的过低，需要调整 maxclients 参数。其默认值为 1w。</li>
<li>info memory：查看Redis 内存占用多大</li>
<li>info replication：查看复制积压缓冲区大小</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-05-05T13:02:38.000Z" title="2023/5/5 21:02:38">2023-05-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-05-30T07:46:25.050Z" title="2023/5/30 15:46:25">2023-05-30</time></span><span class="level-item"><a class="link-muted" href="/categories/IT/">IT</a></span><span class="level-item">35 minutes read (About 5301 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2023/05/05/Spring/">Spring</a></p><div class="content"><h1 id="Spring特性"><a href="#Spring特性" class="headerlink" title="Spring特性"></a>Spring特性</h1><p>Spring基于J2EE技术实现了一套轻量的Java Web Service系统应用框架，有很多优秀的特性，包括，依赖注入（DI）、控制反转（IoC）、面向切面（AOP）、轻量、灵活</p>
<ol>
<li>控制反转<ol>
<li>指的是对象依赖的对象，将会在容器的初始化完成后会主动传递给对象，而不需要对象自己创建或查询其依赖的对象，实现了系统对象之间依赖的解耦</li>
<li>Spring通过依赖注入实现控制反转，依赖注入是一种设计模式，通过该模式，对象不再创建或管理它们所需要的其他对象或服务，而是由容器（例如Spring容器）负责创建和管理这些对象或服务，并注入到需要它们的对象中。</li>
</ol>
</li>
<li>面向切面<ol>
<li>面向切面是一种编程范式，用于将系统的横切关注点（如安全性、事务、日志记录等）与业务逻辑分离</li>
<li>面向切面通过将横切关注点划分为独立的模块，并在运行时动态地将这些模块植入到程序中，从而实现了对业务逻辑的无侵入式增强</li>
<li>Spring AOP通过使用动态代理技术来实现对目标对象的增强</li>
</ol>
</li>
<li>轻量<ol>
<li>spring-web-5.2.0.RELEASE.jar和spring-core-5.2.0.RELEASE.jar均仅有1.4M左右</li>
<li>只需要少量的操作系统资源</li>
</ol>
</li>
<li>灵活<ol>
<li>是模块化的，可以按需引入模块（以jar包依赖的方式引入）</li>
</ol>
</li>
</ol>
<h1 id="Spring的核心JAR包"><a href="#Spring的核心JAR包" class="headerlink" title="Spring的核心JAR包"></a>Spring的核心JAR包</h1><p>Spring是模块化实现的，每个模块对应不同的JAR包</p>
<p>Spring框架的所有JAR包：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>简介</th>
</tr>
</thead>
<tbody><tr>
<td>spring-aop</td>
<td>提供了Spring框架的面向切面编程（AOP）功能，用于在运行时动态地增强应用程序的功能。</td>
</tr>
<tr>
<td>spring-aspects</td>
<td>提供了Spring框架的切面库，包括对AspectJ切面的支持和一些通用切面的实现。</td>
</tr>
<tr>
<td>spring-beans</td>
<td>提供了Spring框架的BeanFactory和FactoryBean等工厂类，用于管理和配置应用程序中的对象。</td>
</tr>
<tr>
<td>spring-context</td>
<td>提供了Spring框架的应用上下文（ApplicationContext），用于管理应用程序中的Bean对象，以及Spring框架的事件驱动编程模型。</td>
</tr>
<tr>
<td>spring-context-indexer</td>
<td>提供了一个工具，用于在编译时为Spring应用程序生成索引文件，以提高应用程序启动的速度。</td>
</tr>
<tr>
<td>spring-context-support</td>
<td>提供了一些扩展类，用于在Spring应用程序中支持特定的应用场景，例如JPA、Velocity等。</td>
</tr>
<tr>
<td>spring-core</td>
<td>Spring框架的核心模块，提供了Spring框架的基本功能，如依赖注入、控制反转、Bean工厂等。</td>
</tr>
<tr>
<td>spring-expression</td>
<td>提供了Spring框架的表达式语言（SpEL），用于在应用程序中动态地访问和操作对象。</td>
</tr>
<tr>
<td>spring-instrument</td>
<td>提供了Spring框架的Instrumentation API支持，用于在运行时通过Java Agent来提供增强功能。</td>
</tr>
<tr>
<td>spring-instrument-tomcat</td>
<td>提供了Spring框架在Tomcat服务器中使用Instrumentation API的支持。</td>
</tr>
<tr>
<td>spring-jcl</td>
<td>提供了Spring框架的通用日志抽象库，可以在不同的日志实现之间进行切换。</td>
</tr>
<tr>
<td>spring-jdbc</td>
<td>提供了Spring框架的JDBC支持，包括对JdbcTemplate和NamedParameterJdbcTemplate等的封装。</td>
</tr>
<tr>
<td>spring-jms</td>
<td>提供了Spring框架的Java Message Service（JMS）支持，用于在应用程序中发送和接收消息。</td>
</tr>
<tr>
<td>spring-messaging</td>
<td>提供了Spring框架的消息处理功能，包括对WebSocket、STOMP、AMQP等协议的支持。</td>
</tr>
<tr>
<td>spring-orm</td>
<td>提供了Spring框架的对象关系映射（ORM）支持，包括对Hibernate、MyBatis等ORM框架的集成。</td>
</tr>
<tr>
<td>spring-oxm</td>
<td>提供了Spring框架的对象XML映射（OXM）支持，用于在Java对象和XML文档之间进行转换。</td>
</tr>
<tr>
<td>spring-test</td>
<td>提供了Spring框架的测试支持，包括对JUnit、TestNG等测试框架的集成，以及对Spring应用程序的集成测试支持。</td>
</tr>
<tr>
<td>spring-tx</td>
<td>提供了Spring框</td>
</tr>
</tbody></table>
<h1 id="Spring注解"><a href="#Spring注解" class="headerlink" title="Spring注解"></a>Spring注解</h1><p>Spring的注解将Bean的定义和依赖关系从XML配置中解放出来，应用程序只要使用注解依赖注入即可</p>
<p>Bean具体的定义和依赖关系由Spring的自动装配完成</p>
<h2 id="依赖注入相关注解"><a href="#依赖注入相关注解" class="headerlink" title="依赖注入相关注解"></a>依赖注入相关注解</h2><table>
<thead>
<tr>
<th>注解</th>
<th>翻译名称</th>
<th>简介</th>
</tr>
</thead>
<tbody><tr>
<td>@Autowired</td>
<td>自动注入</td>
<td>根据类型进行自动注入，如果有多个符合条件的Bean，可以通过指定名称或限定符来进行注入。</td>
</tr>
<tr>
<td>@Qualifier</td>
<td>限定符</td>
<td>与@Autowired一起使用，指定Bean的名称或限定符，以便进行注入。</td>
</tr>
<tr>
<td>@Resource</td>
<td>资源注入</td>
<td>根据名称进行自动注入，可以与指定类型或名称的方式进行限定。</td>
</tr>
<tr>
<td>@Value</td>
<td>属性注入</td>
<td>用于注入常量或表达式计算的结果值。</td>
</tr>
<tr>
<td>@Inject</td>
<td>JSR-330注解</td>
<td>与@Autowired类似，但具有更加灵活的限定符支持。</td>
</tr>
</tbody></table>
<h2 id="Bean定义相关注解"><a href="#Bean定义相关注解" class="headerlink" title="Bean定义相关注解"></a>Bean定义相关注解</h2><table>
<thead>
<tr>
<th>注解</th>
<th>翻译名称</th>
<th>简介</th>
</tr>
</thead>
<tbody><tr>
<td>@Component</td>
<td>通用组件</td>
<td>用于将类定义为Spring组件，并且可以与其他注解一起使用，如@Controller、@Service、@Repository等。</td>
</tr>
<tr>
<td>@Configuration</td>
<td>配置类</td>
<td>用于定义Spring应用程序的配置类，并且可以通过@Bean方法定义Bean对象。</td>
</tr>
<tr>
<td>@Bean</td>
<td>Bean定义</td>
<td>用于在配置类中定义Bean对象，并将其添加到Spring容器中。</td>
</tr>
<tr>
<td>@Profile</td>
<td>环境选择</td>
<td>用于基于不同的应用程序环境选择Bean定义，可以与@Conditional一起使用。</td>
</tr>
<tr>
<td>@Scope</td>
<td>Bean作用域</td>
<td>用于定义Bean对象的作用域，包括Singleton、Prototype、Request、Session等。</td>
</tr>
</tbody></table>
<h2 id="AOP相关注解"><a href="#AOP相关注解" class="headerlink" title="AOP相关注解"></a>AOP相关注解</h2><table>
<thead>
<tr>
<th>注解</th>
<th>翻译名称</th>
<th>简介</th>
</tr>
</thead>
<tbody><tr>
<td>@Aspect</td>
<td>切面定义</td>
<td>用于将类定义为切面，可以在其中定义切点和通知。</td>
</tr>
<tr>
<td>@Pointcut</td>
<td>切点定义</td>
<td>用于定义切点，指定连接点的匹配规则。</td>
</tr>
<tr>
<td>@Before</td>
<td>前置通知</td>
<td>在方法执行之前执行通知。</td>
</tr>
<tr>
<td>@After</td>
<td>后置通知</td>
<td>在方法执行之后执行通知。</td>
</tr>
<tr>
<td>@AfterReturning</td>
<td>返回通知</td>
<td>在方法执行之后返回结果后执行通知。</td>
</tr>
<tr>
<td>@AfterThrowing</td>
<td>异常通知</td>
<td>在方法执行时抛出异常后执行通知。</td>
</tr>
<tr>
<td>@Around</td>
<td>环绕通知</td>
<td>在方法执行之前和之后都可以执行通知。</td>
</tr>
</tbody></table>
<h2 id="Web相关注解"><a href="#Web相关注解" class="headerlink" title="Web相关注解"></a>Web相关注解</h2><table>
<thead>
<tr>
<th>注解</th>
<th>翻译名称</th>
<th>简介</th>
</tr>
</thead>
<tbody><tr>
<td>@Controller</td>
<td>控制器</td>
<td>用于将类定义为Spring MVC的控制器，处理HTTP请求并返回响应结果。</td>
</tr>
<tr>
<td>@RestController</td>
<td>REST控制器</td>
<td>与@Controller类似，但默认情况下返回JSON或XML格式的响应结果。</td>
</tr>
<tr>
<td>@RequestMapping</td>
<td>请求映射</td>
<td>用于将HTTP请求映射到处理方法上，并指定请求的URL、请求方法、请求参数等。</td>
</tr>
<tr>
<td>@GetMapping</td>
<td>GET请求映射</td>
<td>用于将HTTP GET请求映射到处理方法上，简化了@RequestMapping的用法。</td>
</tr>
<tr>
<td>@PostMapping</td>
<td>POST请求映射</td>
<td>用于将HTTP POST请求映射到处理方法上，简化了@RequestMapping的用法。</td>
</tr>
<tr>
<td>@PutMapping</td>
<td>PUT请求映射</td>
<td>用于将HTTP PUT请求映射到处理方法上，简化了@RequestMapping的用法。</td>
</tr>
<tr>
<td>@DeleteMapping</td>
<td>DELETE请求映射</td>
<td>用于将HTTP DELETE请求映射到处理方法上，简化了@RequestMapping的用法。</td>
</tr>
<tr>
<td>@PatchMapping</td>
<td>PATCH请求映射</td>
<td>用于将HTTP PATCH请求映射到处理方法上，简化了@RequestMapping的用法。</td>
</tr>
<tr>
<td>@PathVariable</td>
<td>路径变量</td>
<td>用于将URI中的变量绑定到处理方法的参数上。</td>
</tr>
<tr>
<td>@RequestParam</td>
<td>请求参数</td>
<td>用于将HTTP请求中的参数绑定到处理方法的参数上。</td>
</tr>
<tr>
<td>@RequestBody</td>
<td>请求体</td>
<td>用于将HTTP请求体中的数据绑定到处理方法的参数上。</td>
</tr>
<tr>
<td>@RequestHeader</td>
<td>请求头</td>
<td>用于将HTTP请求头中的数据绑定到处理方法的参数上。</td>
</tr>
<tr>
<td>@CookieValue</td>
<td>Cookie值</td>
<td>用于将HTTP Cookie中的值绑定到处理方法的参数上。</td>
</tr>
<tr>
<td>@ResponseBody</td>
<td>响应体</td>
<td>用于将处理方法的返回值作为HTTP响应体返回给客户端。</td>
</tr>
<tr>
<td>@ResponseStatus</td>
<td>响应状态码</td>
<td>用于指定处理方法的返回状态码。</td>
</tr>
<tr>
<td>@SessionAttributes</td>
<td>会话属性</td>
<td>用于在会话中存储处理方法的模型属性。</td>
</tr>
<tr>
<td>@ModelAttribute</td>
<td>模型属性</td>
<td>用于将请求参数绑定到模型属性上。</td>
</tr>
<tr>
<td>@InitBinder</td>
<td>初始化绑定器</td>
<td>用于初始化WebDataBinder，用于数据绑定和格式化等操作。</td>
</tr>
<tr>
<td>@ExceptionHandler</td>
<td>异常处理</td>
<td>用于处理控制器中抛出的异常。</td>
</tr>
<tr>
<td>@CrossOrigin</td>
<td>跨域资源共享</td>
<td>用于处理跨域请求，允许指定允许跨域请求的来源、方法和头信息等。</td>
</tr>
</tbody></table>
<h1 id="Spring-IoC原理"><a href="#Spring-IoC原理" class="headerlink" title="Spring IoC原理"></a>Spring IoC原理</h1><h2 id="IoC简介"><a href="#IoC简介" class="headerlink" title="IoC简介"></a>IoC简介</h2><p>Spring IoC通过Java反射功能实例化并建立Bean之间的依赖关系</p>
<p>Spring IoC在完成这些底层工作的基础上，还提供了Bean实例缓存管理、Bean生命周期管理、Bean实例代理、事件发布和资源装载等高级服务</p>
<h2 id="Bean的装配流程"><a href="#Bean的装配流程" class="headerlink" title="Bean的装配流程"></a>Bean的装配流程</h2><p>Spring通过读取XML或注解获取Bean的配置信息，并在Bean容器中生成Bean配置注册表，然后根据配置注册表实例化Bean，将Bean实例载入Bean缓存池，业务程序就可以从Bean缓存池中获取Bean</p>
<h2 id="Bean的作用域"><a href="#Bean的作用域" class="headerlink" title="Bean的作用域"></a>Bean的作用域</h2><p>Bean有五种作用域：</p>
<ul>
<li>Singleton：单例作用域，表示在 Spring IoC 容器中只存在一个 Bean 对象实例，所有对该 Bean 的请求都将返回该唯一实例。</li>
<li>Prototype：原型作用域，每次对该 Bean 的请求都将创建一个新的 Bean 实例。每次使用时都会创建新的对象。</li>
<li>Request：请求作用域，每个 HTTP 请求都将创建一个新的 Bean 实例，该 Bean 仅在当前 HTTP 请求中有效。</li>
<li>Session：会话作用域，每个 HTTP 会话都将创建一个新的 Bean 实例，该 Bean 仅在当前 HTTP 会话中有效。</li>
<li>GlobalSession：全局会话作用域，仅适用于使用基于 Portlet 的 web 应用。它是在一个全局的 Portlet 会话中共享的 Bean 实例。</li>
</ul>
<p>除了这五种标准作用域外，Spring 还支持自定义作用域。在 Spring 中，我们可以通过实现 Scope 接口并重写对应方法来实现自定义作用域。这样可以让我们更加灵活地管理 Bean 的生命周期，以满足应用程序的特定需求。</p>
<h2 id="Bean的生命周期"><a href="#Bean的生命周期" class="headerlink" title="Bean的生命周期"></a>Bean的生命周期</h2><p>Spring Bean 的生命周期是 Spring IoC 容器管理的重要部分，它由一系列的回调函数来控制。在 Spring 容器创建 Bean 实例对象时，会经历以下阶段：</p>
<ol>
<li><p>Bean 实例化：Spring IoC 容器通过反射机制实例化一个 Bean 对象，通常是使用默认的构造函数来创建 Bean 实例。</p>
</li>
<li><p>属性注入：Spring IoC 容器通过 setter 方法或者直接访问 Bean 属性来注入 Bean 的属性。</p>
</li>
<li><p>BeanPostProcessor 前置处理器：在 Bean 实例化之后，Spring IoC 容器会自动检测是否有实现了 BeanPostProcessor 接口的类，并调用它们的 postProcessBeforeInitialization() 方法来对 Bean 进行前置处理。</p>
</li>
<li><p>初始化：Spring IoC 容器调用 Bean 实现 InitializingBean 接口或者配置的 init-method 方法，执行 Bean 的初始化操作。</p>
</li>
<li><p>BeanPostProcessor 后置处理器：在 Bean 初始化之后，Spring IoC 容器会自动检测是否有实现了 BeanPostProcessor 接口的类，并调用它们的 postProcessAfterInitialization() 方法来对 Bean 进行后置处理。</p>
</li>
<li><p>使用：Bean 实例化完成并初始化后，就可以在应用程序中使用它了。</p>
</li>
<li><p>销毁：当 Spring IoC 容器关闭时，它会调用 Bean 实现 DisposableBean 接口或者配置的 destroy-method 方法，执行 Bean 的销毁操作。</p>
</li>
</ol>
<p>此外，Spring Bean 的生命周期可以被定制化，我们可以自定义 BeanPostProcessor 实现类或者配置 init-method 和 destroy-method 方法，来在 Bean 的生命周期中加入自己的逻辑处理。</p>
<p>BeanPostProcessor 前置处理器是 Spring IoC 容器中的一个扩展点，用于在 Bean 的初始化前进行额外的处理，可以对 Bean 对象进行修改或增强。BeanPostProcessor 接口定义了两个方法：</p>
<ol>
<li><p>postProcessBeforeInitialization(Object bean, String beanName)：在 Bean 初始化之前调用该方法，可以对 Bean 对象进行一些修改或增强操作。</p>
</li>
<li><p>postProcessAfterInitialization(Object bean, String beanName)：在 Bean 初始化之后调用该方法，可以对 Bean 对象进行一些修改或增强操作。</p>
</li>
</ol>
<p>在 Spring IoC 容器中，当一个 Bean 实例化完成后，会检查是否有实现了 BeanPostProcessor 接口的类，如果有，则会依次调用它们的 postProcessBeforeInitialization() 方法，然后进行 Bean 的初始化操作，最后再依次调用实现了 BeanPostProcessor 接口的类的 postProcessAfterInitialization() 方法。通过实现 BeanPostProcessor 接口，我们可以在 Bean 实例化前后进行一些自定义的操作，例如：</p>
<ol>
<li><p>为 Bean 注入日志处理、事务处理等公共的功能。</p>
</li>
<li><p>在 Bean 初始化前后进行性能监控、安全检查等操作。</p>
</li>
<li><p>对 Bean 进行代理，实现 AOP 的功能。</p>
</li>
</ol>
<p>需要注意的是，在实现 BeanPostProcessor 接口时，必须小心处理，以免破坏 Bean 的正常生命周期。同时，也应该尽量保持 BeanPostProcessor 的轻量级，避免对系统性能产生过大的影响。</p>
<p>总之，BeanPostProcessor 前置处理器是 Spring IoC 容器中的一个重要扩展点，通过实现该接口，可以在 Bean 实例化前后进行一些自定义的操作，从而增强 Bean 的功能和灵活性。</p>
<h1 id="Spring-AOP原理"><a href="#Spring-AOP原理" class="headerlink" title="Spring AOP原理"></a>Spring AOP原理</h1><h2 id="AOP简介"><a href="#AOP简介" class="headerlink" title="AOP简介"></a>AOP简介</h2><p>Spring AOP通过面向切面技术，将与业务无关或被业务模块共用的代码封装起来，以提高代码的复用度，降低模块间的耦合度</p>
<h2 id="AOP-的核心概念"><a href="#AOP-的核心概念" class="headerlink" title="AOP 的核心概念"></a>AOP 的核心概念</h2><table>
<thead>
<tr>
<th>概念</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>切面（Aspect）</td>
<td>对一个或多个横切关注点的封装，它包含了切点、通知和切点表达式等元素。切面定义了何时、何地以及如何将横切关注点织入到目标对象中。</td>
</tr>
<tr>
<td>切点（Pointcut）</td>
<td>目标对象中的一组方法或者类，它们将被织入到横切关注点中。切点通常由切点表达式和其他过滤条件组成。</td>
</tr>
<tr>
<td>通知（Advice）</td>
<td>在织入横切关注点时要执行的逻辑代码，它包括了前置通知、后置通知、环绕通知、异常通知和最终通知等不同类型。</td>
</tr>
<tr>
<td>切点表达式（Pointcut Expression）</td>
<td>一种指定切点的语法规则，它可以根据方法名、返回值类型、方法参数等多种条件进行切点匹配。</td>
</tr>
<tr>
<td>连接点（Join Point）</td>
<td>程序执行过程中的某个特定位置，例如方法调用、方法执行、异常抛出等。连接点是织入横切关注点的具体执行位置。</td>
</tr>
<tr>
<td>织入（Weaving）</td>
<td>将横切关注点应用到目标对象的过程，它可以通过代理模式实现。在 Spring AOP 中，织入分为编译期织入、类装载期织入和运行期织入三种方式。</td>
</tr>
</tbody></table>
<p>上述概念是 Spring AOP 技术中的核心要素，了解这些概念对于掌握和使用 Spring AOP 技术非常重要。切面、切点、通知和切点表达式是定义 AOP 配置的基础，连接点则表示切点匹配到的具体执行位置，织入则是实现 AOP 功能的核心机制。</p>
<h2 id="AOP横切关注点"><a href="#AOP横切关注点" class="headerlink" title="AOP横切关注点"></a>AOP横切关注点</h2><p>Srping将应用分为核心关注点和横切关注点两部分</p>
<ul>
<li><p>核心关注点（Core Concerns）是指应用程序的基本业务逻辑，例如数据访问、业务逻辑处理等。核心关注点是应用程序的主要功能，通常是由应用程序开发人员直接实现的。</p>
</li>
<li><p>横切关注点（Cross-Cutting Concerns）是指应用程序中与核心业务逻辑无关的横切问题，例如日志记录、事务管理、安全控制等。</p>
</li>
</ul>
<p>在 Spring AOP 中，横切关注点可以通过定义切面（Aspect）来实现。通常情况下，切面是一个 Java 类，其中包含了一些切点（Pointcut）、通知（Advice）和切点表达式（Pointcut Expression）等元素。</p>
<ul>
<li>切点（Pointcut）：用于定义一个或多个目标对象中哪些方法需要被织入横切关注点。</li>
<li>通知（Advice）：定义了横切关注点在目标对象中何时被执行以及执行的逻辑。</li>
<li>切点表达式（Pointcut Expression）：用于指定切点的匹配规则。</li>
</ul>
<p>Spring AOP 的实现是基于代理模式的，它通过创建代理对象来织入切面逻辑。Spring AOP 支持两种代理方式：JDK 动态代理和 CGLIB 代理。对于实现了接口的类，Spring AOP 将使用 JDK 动态代理来创建代理对象；对于没有实现接口的类，Spring AOP 将使用 CGLIB 代理来创建代理对象。</p>
<h2 id="AOP的5种通知类型"><a href="#AOP的5种通知类型" class="headerlink" title="AOP的5种通知类型"></a>AOP的5种通知类型</h2><p>Spring AOP 提供了以下五种类型的通知：</p>
<ul>
<li>前置通知（Before Advice）：在目标方法执行前执行。</li>
<li>后置通知（After Returning Advice）：在目标方法返回后执行。</li>
<li>环绕通知（Around Advice）：在目标方法执行前后都执行。</li>
<li>异常通知（After Throwing Advice）：在目标方法抛出异常时执行。</li>
<li>最终通知（After Advice）：无论目标方法是否正常执行完成，最终通知都会被执行。</li>
</ul>
<h2 id="AOP的应用"><a href="#AOP的应用" class="headerlink" title="AOP的应用"></a>AOP的应用</h2><table>
<thead>
<tr>
<th>应用场景</th>
<th>切面类型</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>日志记录</td>
<td>前置通知（Before）</td>
<td>在用户登录时记录登录时间和 IP 地址</td>
</tr>
<tr>
<td>性能监控</td>
<td>环绕通知（Around）</td>
<td>在对数据库进行查询时统计查询时间和资源占用情况</td>
</tr>
<tr>
<td>安全控制</td>
<td>前置通知（Before）</td>
<td>在访问受保护的资源时检查用户的身份和权限信息</td>
</tr>
<tr>
<td>事务管理</td>
<td>环绕通知（Around）</td>
<td>在对数据库进行更新操作时开启和提交事务</td>
</tr>
<tr>
<td>异常处理</td>
<td>异常通知（AfterThrowing）</td>
<td>在文件上传时捕获文件格式不正确等异常信息，并进行相应的处理</td>
</tr>
</tbody></table>
<h1 id="Spring-MVC原理"><a href="#Spring-MVC原理" class="headerlink" title="Spring MVC原理"></a>Spring MVC原理</h1><h2 id="MVC简介"><a href="#MVC简介" class="headerlink" title="MVC简介"></a>MVC简介</h2><p>Spring的MVC即模型-视图-控制器，该框架围绕DispatcherServlet设计而成，DispatcherServlet会把请求分发给各个处理器</p>
<p>SpringMVC 的工作流程主要包括以下几个步骤：</p>
<ol>
<li><p>客户端发送请求：客户端向服务器发送请求，请求可以是一个 URL 地址、一个表单提交或者一个 AJAX 请求。</p>
</li>
<li><p>DispatcherServlet 接收请求：DispatcherServlet 是 SpringMVC 框架的核心控制器，它负责接收客户端发送的请求，并将请求转发给对应的处理器。</p>
</li>
<li><p>HandlerMapping 查找处理器：HandlerMapping 负责根据请求 URL 查找对应的处理器，处理器可以是一个 Controller 或者一个 Restful Web Service。</p>
</li>
<li><p>HandlerAdapter 调用处理器：HandlerAdapter 负责调用处理器，将请求传递给处理器进行处理，并获取处理器的处理结果。</p>
</li>
<li><p>处理器处理请求：处理器根据请求的类型和参数，进行相应的业务处理，并返回一个 ModelAndView 对象。</p>
</li>
<li><p>视图解析器解析视图：视图解析器根据 ModelAndView 中的视图名，将其解析成对应的视图对象，视图可以是一个 JSP 页面、一个 Thymeleaf 模板或者一个 HTML 片段等。</p>
</li>
<li><p>渲染视图：视图对象根据数据模型和视图模板，生成 HTML 内容，并将其返回给客户端。</p>
</li>
<li><p>返回响应：DispatcherServlet 将视图渲染的结果返回给客户端，客户端可以是一个浏览器、一个移动应用或者一个 API 调用。</p>
</li>
</ol>
<p>总之，SpringMVC 的工作流程涉及到多个组件之间的协作，其中 DispatcherServlet 负责接收请求和控制流程，HandlerMapping 负责查找处理器，HandlerAdapter 负责调用处理器，视图解析器负责解析视图，视图对象负责渲染视图，最终将响应返回给客户端。</p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">11</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Category</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">10</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/IT/"><span class="level-start"><span class="level-item">IT</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-24T08:13:44.000Z">2023-05-24</time></p><p class="title"><a href="/2023/05/24/RocketMQ/">RocketMQ</a></p><p class="categories"><a href="/categories/IT/">IT</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-24T08:08:42.000Z">2023-05-24</time></p><p class="title"><a href="/2023/05/24/Spring-Cloud/">Spring Cloud</a></p><p class="categories"><a href="/categories/IT/">IT</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-07T13:39:13.000Z">2023-05-07</time></p><p class="title"><a href="/2023/05/07/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/">Java并发编程</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-07T13:37:05.000Z">2023-05-07</time></p><p class="title"><a href="/2023/05/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-06T03:04:46.000Z">2023-05-06</time></p><p class="title"><a href="/2023/05/06/MyBatis/">MyBatis</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/JVM/"><span class="tag">JVM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kafka/"><span class="tag">Kafka</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MyBatis/"><span class="tag">MyBatis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MySQL/"><span class="tag">MySQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Redis/"><span class="tag">Redis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RocketMQ/"><span class="tag">RocketMQ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring/"><span class="tag">Spring</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring-Cloud/"><span class="tag">Spring Cloud</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/java/"><span class="tag">java</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B9%B6%E5%8F%91/"><span class="tag">并发</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="SBR Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 SBR</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>